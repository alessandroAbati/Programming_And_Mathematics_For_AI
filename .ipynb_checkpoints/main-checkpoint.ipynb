{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Mathematics for AI - coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The task is about classification on the MNIST dataset. \n",
    "You can use other APIâ€™s/libraries for loading the dataset, but not for the neural network \n",
    "implementation. The point of this task is to develop a multi-layer neural network for \n",
    "classification using numpy. The task requires following sub-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Implement sigmoid and ReLU layers\n",
    "For this sub-task, you should implement forward and backward pass for \n",
    "sigmoid and ReLU. You should consider presenting these activation\n",
    "functions in the report with any pros cons if they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLu(x):\n",
    "    '''\n",
    "    Implementation of reLu function.\n",
    "    '''\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Implementation of Sigmoid function.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Implementation of Softmax function\n",
    "    '''\n",
    "    normalization = np.sum(np.exp(x))\n",
    "    return [np.exp(el)/normalization for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ReLU activation function')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, reLu(x))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.title(\"ReLU activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x221517e6790>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2215182dc50>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, softmax(x))\n",
    "# How do I test my implementation of the softmax function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.input = x # store the input to use it in the backward pass\n",
    "        return np.maximum(0, x)  # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        self.input[self.input <= 0] = 0 # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return self.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('gradient_values'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        \n",
    "        sigmoid_derivative = self.output * (1 - self.output) # calculate the derivative of Sigmoid: f(x) * (1 - f(x)) where f(x) is the Sigmoid function\n",
    "        return sigmoid_derivative  # multiply the gradient of the loss function by the derivative of Sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - Implement softmax layer\n",
    "Implement softmax with both forward and backward pass. Present the \n",
    "softmax in the report along with any numerical issues when calculating the \n",
    "softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'x', with the\n",
    "                         same shape as 'x'.\n",
    "        '''        \n",
    "        #e_x = np.exp(x - np.max(x, axis=-1, keepdims=True)) # shift input 'x' for numerical stability (prevention of overflow/underflow).\n",
    "        e_x = np.exp(x)\n",
    "        #self.output = e_x / np.sum(e_x, axis=-1, keepdims=True) # apply the softmax function: f(xi) = exp(xi) / sum(exp(x)) for x=[x1,...,xK]\n",
    "        self.output = e_x / np.sum(e_x)\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        softmax_jacobian = self.output * (np.eye(self.output.shape[0]) - self.output.T)\n",
    "        #print(softmax_jacobian)\n",
    "        print(softmax_jacobian.shape)\n",
    "        return softmax_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    weights = 0\n",
    "    new_weights = 0\n",
    "    bias = 0\n",
    "    activation = 0\n",
    "    layer_input = 0\n",
    "    \n",
    "    def __init__(self, input_units, output_units, activation):\n",
    "        self.weights = np.random.rand(output_units, input_units)\n",
    "        self.new_weights = np.random.rand(output_units, input_units)\n",
    "        self.layer_input = 0\n",
    "\n",
    "        self.bias = 1\n",
    "        if activation == 'relu':\n",
    "            print(\"ReLU\")\n",
    "            self.activation = ReLu()\n",
    "        elif activation == 'sigmoid':\n",
    "            print(\"Sigmoid\")\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'softmax':\n",
    "            print(\"Softmax\")\n",
    "            self.activation = Softmax()\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        #print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "        #print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(self.weights, x) + self.bias\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "        \n",
    "    '''\n",
    "    Idea is to have backward pass for activation functions just return the derivative of the activation,\n",
    "    and backward_pass for layer perform any other calculation (dot product of activation function with loss for example)\n",
    "    '''   \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "        #print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        derivative_final = x * activation_derivative\n",
    "        #print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "        #print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "        #print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        self.new_weights = (self.weights - learning_rate*np.dot(derivative_final, self.layer_input.T))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        derivative_pass = np.dot(self.weights.T, derivative_final)\n",
    "        #print (\"%Shape of output derivative_pass{}\".format(derivative_pass.shape))\n",
    "        return derivative_pass\n",
    "       \n",
    "    def gradient(self):\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        #print(\"Updating weights!!\")\n",
    "        print(\"Old_weights\")\n",
    "        print(self.weights)\n",
    "        print(\"New_weights\")\n",
    "        print(self.new_weights)\n",
    "        self.weights = self.new_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass of layer\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, input_units, output_units, activation):\n",
    "        super().__init__(input_units, output_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        #print (\"Shape of weights {}\".format(self.weights.shape))         \n",
    "        #print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = x\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "    \n",
    "    # No weights in input layer\n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        print(\"Last backwards pass layer\")\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"No weights in input layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, input_units, output_units, activation):\n",
    "        super().__init__(input_units, output_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        #print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "        #print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(self.weights, x) + self.bias\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "    \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "        #print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        derivative_final = x * activation_derivative\n",
    "        #print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "        #print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "        #print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        self.new_weights = (self.weights - learning_rate*np.dot(derivative_final, self.layer_input.T))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        derivative_pass = np.dot(self.weights.T, derivative_final)\n",
    "        #print (\"%Shape of output derivative_pass{}\".format(derivative_pass.shape))\n",
    "        return derivative_pass\n",
    "    \n",
    "    def mse_loss(self, output, target):\n",
    "        loss = 1/len(output)*np.sum((output-target)**2)\n",
    "        return loss\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        #print(\"Updating weights!!\")\n",
    "        print(\"Old_weights\")\n",
    "        print(self.weights)\n",
    "        print(\"New_weights\")\n",
    "        print(self.new_weights)\n",
    "        self.weights = self.new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY\n",
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "prediction = softmax.forward_pass(x)\n",
    "loss = np.sum((prediction - y) ** 2)\n",
    "loss_derivative = (prediction -y)\n",
    "prediction, loss, np.sum(prediction)\n",
    "loss_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_derivative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_softmax = softmax.backward_pass(loss_derivative.T, learning_rate)\n",
    "gradient_softmax.shape, gradient_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - Implement dropout \n",
    "Present dropout in the report. Implement inverted dropout. Forward and \n",
    "backward pass should be implemented.\n",
    "Note: Since the test performance is critical, it is also preferable to leaving \n",
    "the forward pass unchanged at test time. Therefore, in most \n",
    "implementations inverted dropout is employed to overcome the \n",
    "undesirable property of the original dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of \n",
    "hidden layers, units, activation functions can be changed. In addition, you \n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used \n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots \n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "    A class representing the Fully Parametrizable Neural Network.\n",
    "    '''\n",
    "    layer_list = []\n",
    "    X = 0\n",
    "    Y = 0\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 8\n",
    "    epochs = 100\n",
    "    \n",
    "    \n",
    "    def __init__(self, X, Y, learning_rate, dropout_rate = 0.5, batch_size = 4, epochs = 10):\n",
    "        self.layer_list = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def addLayer(self, input_units, output_units, activation, mode = \"input\"):\n",
    "        if mode == \"input\":\n",
    "            print(\"Added input\")\n",
    "            layer = InputLayer(input_units, output_units, activation)\n",
    "        elif mode == \"output\":\n",
    "            print(\"Added output\")\n",
    "            layer = OutputLayer(input_units, output_units, activation)\n",
    "        else:\n",
    "            print(\"Added hidden\")\n",
    "            layer = Layer(input_units, output_units, activation)\n",
    "        self.layer_list.append(layer)\n",
    "        \n",
    "    def loss(self, output, target, mode = \"mse\"):\n",
    "        if mode == \"mse\":\n",
    "            loss = 1/len(output)*np.sum((output-target)**2)\n",
    "            return loss\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            input_data = self.X\n",
    "            print(input_data.shape)\n",
    "            # Forward pass\n",
    "            print(\"Forward pass epoch {}\".format(i))\n",
    "            for index, layer in enumerate(self.layer_list):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                output_data = layer.forward_pass(input_data)\n",
    "                input_data = output_data\n",
    "                \n",
    "            # Calculate loss \n",
    "            print(output_data)\n",
    "            loss_cost = self.loss(output_data, self.Y, mode = \"mse\")\n",
    "            print(\"Loss: {}\".format(loss_cost))\n",
    "            \n",
    "            # Backward pass  \n",
    "            input_derivative = (output_data-self.Y)\n",
    "            print(\"Backward pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                output_derivative = layer.backward_pass(input_derivative, self.learning_rate)\n",
    "                input_derivative = output_derivative\n",
    "                \n",
    "            # Update pass  \n",
    "            print(\"Update pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                layer.update_weights(self.learning_rate)\n",
    "                                         \n",
    "    def predict(self, X):\n",
    "        input_data = X\n",
    "        for index, layer in enumerate(self.layer_list):\n",
    "            output_data = layer.forward_pass(input_data)\n",
    "            input_data = output_data\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "Sigmoid\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Sigmoid\n",
      "(5, 1)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998042531656\n",
      "Backward pass epoch 0\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 0\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.632784   0.46706017 0.93385604 0.85037096 0.1150004  0.35097062\n",
      "  0.20031614 0.78589255 0.18538369 0.68228723]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375919 0.9065173  0.96467438 0.80636183 0.37816993 0.27275617\n",
      "  0.96710213 0.04644228 0.83596316 0.55998957]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63278343 0.46705949 0.93385531 0.85037043 0.11499969 0.35097023\n",
      "  0.20031546 0.78589187 0.18538308 0.68228663]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375918 0.90651729 0.96467436 0.80636182 0.37816991 0.27275616\n",
      "  0.96710212 0.04644227 0.83596315 0.55998955]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963424 0.11547458 0.62437104 0.44478596 0.27484976]\n",
      " [0.76243812 0.88059849 0.40149327 0.84074346 0.63782747]\n",
      " [0.05734458 0.77539038 0.90409116 0.98774559 0.78344688]\n",
      " [0.62117126 0.62266526 0.07197997 0.59454246 0.50543351]\n",
      " [0.17747653 0.99762568 0.97424059 0.31407199 0.78160679]\n",
      " [0.12027566 0.08917068 0.44948754 0.068308   0.16767075]\n",
      " [0.73806141 0.52259559 0.82006847 0.01970342 0.77960685]\n",
      " [0.81624    0.82987615 0.88547518 0.71025996 0.07065196]\n",
      " [0.68264253 0.07957757 0.50563488 0.25354143 0.76687209]\n",
      " [0.92176613 0.3820169  0.71896993 0.47259234 0.04713947]]\n",
      "New_weights\n",
      "[[0.68963403 0.11547448 0.6243707  0.44478579 0.27484949]\n",
      " [0.76243793 0.8805984  0.40149296 0.84074331 0.63782723]\n",
      " [0.05734419 0.77539019 0.90409052 0.98774527 0.78344636]\n",
      " [0.621171   0.62266514 0.07197955 0.59454225 0.50543317]\n",
      " [0.17747648 0.99762565 0.97424051 0.31407195 0.78160673]\n",
      " [0.12027558 0.08917065 0.44948741 0.06830794 0.16767065]\n",
      " [0.73806133 0.52259555 0.82006834 0.01970335 0.77960674]\n",
      " [0.8162397  0.82987601 0.88547469 0.71025972 0.07065156]\n",
      " [0.68264246 0.07957754 0.50563477 0.25354137 0.766872  ]\n",
      " [0.9217659  0.38201679 0.71896955 0.47259215 0.04713916]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.39999980424913173\n",
      "Backward pass epoch 1\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 1\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63278343 0.46705949 0.93385531 0.85037043 0.11499969 0.35097023\n",
      "  0.20031546 0.78589187 0.18538308 0.68228663]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375918 0.90651729 0.96467436 0.80636182 0.37816991 0.27275616\n",
      "  0.96710212 0.04644227 0.83596315 0.55998955]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63278286 0.4670588  0.93385457 0.8503699  0.11499898 0.35096983\n",
      "  0.20031477 0.78589119 0.18538248 0.68228603]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375916 0.90651727 0.96467435 0.8063618  0.37816989 0.27275615\n",
      "  0.9671021  0.04644225 0.83596313 0.55998954]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963403 0.11547448 0.6243707  0.44478579 0.27484949]\n",
      " [0.76243793 0.8805984  0.40149296 0.84074331 0.63782723]\n",
      " [0.05734419 0.77539019 0.90409052 0.98774527 0.78344636]\n",
      " [0.621171   0.62266514 0.07197955 0.59454225 0.50543317]\n",
      " [0.17747648 0.99762565 0.97424051 0.31407195 0.78160673]\n",
      " [0.12027558 0.08917065 0.44948741 0.06830794 0.16767065]\n",
      " [0.73806133 0.52259555 0.82006834 0.01970335 0.77960674]\n",
      " [0.8162397  0.82987601 0.88547469 0.71025972 0.07065156]\n",
      " [0.68264246 0.07957754 0.50563477 0.25354137 0.766872  ]\n",
      " [0.9217659  0.38201679 0.71896955 0.47259215 0.04713916]]\n",
      "New_weights\n",
      "[[0.68963382 0.11547438 0.62437036 0.44478562 0.27484921]\n",
      " [0.76243774 0.88059831 0.40149266 0.84074316 0.63782698]\n",
      " [0.05734379 0.77539    0.90408988 0.98774495 0.78344585]\n",
      " [0.62117074 0.62266502 0.07197913 0.59454204 0.50543283]\n",
      " [0.17747643 0.99762563 0.97424043 0.31407191 0.78160667]\n",
      " [0.1202755  0.08917061 0.44948729 0.06830787 0.16767054]\n",
      " [0.73806124 0.52259551 0.8200682  0.01970328 0.77960663]\n",
      " [0.8162394  0.82987587 0.8854742  0.71025948 0.07065117]\n",
      " [0.68264239 0.07957751 0.50563465 0.25354132 0.76687191]\n",
      " [0.92176566 0.38201668 0.71896917 0.47259197 0.04713886]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998042450975\n",
      "Backward pass epoch 2\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 2\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63278286 0.4670588  0.93385457 0.8503699  0.11499898 0.35096983\n",
      "  0.20031477 0.78589119 0.18538248 0.68228603]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375916 0.90651727 0.96467435 0.8063618  0.37816989 0.27275615\n",
      "  0.9671021  0.04644225 0.83596313 0.55998954]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63278229 0.46705811 0.93385383 0.85036937 0.11499827 0.35096944\n",
      "  0.20031408 0.7858905  0.18538187 0.68228542]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375915 0.90651726 0.96467433 0.80636179 0.37816988 0.27275614\n",
      "  0.96710209 0.04644224 0.83596312 0.55998953]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963382 0.11547438 0.62437036 0.44478562 0.27484921]\n",
      " [0.76243774 0.88059831 0.40149266 0.84074316 0.63782698]\n",
      " [0.05734379 0.77539    0.90408988 0.98774495 0.78344585]\n",
      " [0.62117074 0.62266502 0.07197913 0.59454204 0.50543283]\n",
      " [0.17747643 0.99762563 0.97424043 0.31407191 0.78160667]\n",
      " [0.1202755  0.08917061 0.44948729 0.06830787 0.16767054]\n",
      " [0.73806124 0.52259551 0.8200682  0.01970328 0.77960663]\n",
      " [0.8162394  0.82987587 0.8854742  0.71025948 0.07065117]\n",
      " [0.68264239 0.07957751 0.50563465 0.25354132 0.76687191]\n",
      " [0.92176566 0.38201668 0.71896917 0.47259197 0.04713886]]\n",
      "New_weights\n",
      "[[0.68963361 0.11547428 0.62437003 0.44478545 0.27484894]\n",
      " [0.76243756 0.88059822 0.40149235 0.840743   0.63782674]\n",
      " [0.05734339 0.77538981 0.90408924 0.98774464 0.78344533]\n",
      " [0.62117048 0.62266489 0.07197871 0.59454183 0.5054325 ]\n",
      " [0.17747638 0.99762561 0.97424035 0.31407187 0.7816066 ]\n",
      " [0.12027542 0.08917057 0.44948716 0.06830781 0.16767044]\n",
      " [0.73806115 0.52259547 0.82006806 0.01970321 0.77960651]\n",
      " [0.81623909 0.82987572 0.88547371 0.71025924 0.07065078]\n",
      " [0.68264232 0.07957747 0.50563454 0.25354126 0.76687182]\n",
      " [0.92176543 0.38201657 0.71896879 0.47259178 0.04713855]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.39999980424106313\n",
      "Backward pass epoch 3\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 3\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63278229 0.46705811 0.93385383 0.85036937 0.11499827 0.35096944\n",
      "  0.20031408 0.7858905  0.18538187 0.68228542]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375915 0.90651726 0.96467433 0.80636179 0.37816988 0.27275614\n",
      "  0.96710209 0.04644224 0.83596312 0.55998953]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63278172 0.46705742 0.93385309 0.85036884 0.11499756 0.35096904\n",
      "  0.20031339 0.78588982 0.18538126 0.68228482]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375914 0.90651724 0.96467431 0.80636178 0.37816986 0.27275613\n",
      "  0.96710207 0.04644222 0.83596311 0.55998951]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963361 0.11547428 0.62437003 0.44478545 0.27484894]\n",
      " [0.76243756 0.88059822 0.40149235 0.840743   0.63782674]\n",
      " [0.05734339 0.77538981 0.90408924 0.98774464 0.78344533]\n",
      " [0.62117048 0.62266489 0.07197871 0.59454183 0.5054325 ]\n",
      " [0.17747638 0.99762561 0.97424035 0.31407187 0.7816066 ]\n",
      " [0.12027542 0.08917057 0.44948716 0.06830781 0.16767044]\n",
      " [0.73806115 0.52259547 0.82006806 0.01970321 0.77960651]\n",
      " [0.81623909 0.82987572 0.88547371 0.71025924 0.07065078]\n",
      " [0.68264232 0.07957747 0.50563454 0.25354126 0.76687182]\n",
      " [0.92176543 0.38201657 0.71896879 0.47259178 0.04713855]]\n",
      "New_weights\n",
      "[[0.6896334  0.11547418 0.62436969 0.44478529 0.27484867]\n",
      " [0.76243737 0.88059813 0.40149205 0.84074285 0.63782649]\n",
      " [0.057343   0.77538962 0.9040886  0.98774432 0.78344482]\n",
      " [0.62117022 0.62266477 0.07197829 0.59454163 0.50543216]\n",
      " [0.17747633 0.99762558 0.97424027 0.31407183 0.78160654]\n",
      " [0.12027534 0.08917053 0.44948703 0.06830774 0.16767034]\n",
      " [0.73806107 0.52259543 0.82006792 0.01970315 0.7796064 ]\n",
      " [0.81623879 0.82987558 0.88547322 0.710259   0.07065038]\n",
      " [0.68264225 0.07957744 0.50563443 0.2535412  0.76687173]\n",
      " [0.92176519 0.38201645 0.71896841 0.47259159 0.04713825]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998042370286\n",
      "Backward pass epoch 4\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 4\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63278172 0.46705742 0.93385309 0.85036884 0.11499756 0.35096904\n",
      "  0.20031339 0.78588982 0.18538126 0.68228482]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375914 0.90651724 0.96467431 0.80636178 0.37816986 0.27275613\n",
      "  0.96710207 0.04644222 0.83596311 0.55998951]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63278115 0.46705673 0.93385236 0.8503683  0.11499685 0.35096864\n",
      "  0.2003127  0.78588914 0.18538065 0.68228422]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375912 0.90651723 0.9646743  0.80636177 0.37816985 0.27275613\n",
      "  0.96710206 0.0464422  0.83596309 0.5599895 ]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.6896334  0.11547418 0.62436969 0.44478529 0.27484867]\n",
      " [0.76243737 0.88059813 0.40149205 0.84074285 0.63782649]\n",
      " [0.057343   0.77538962 0.9040886  0.98774432 0.78344482]\n",
      " [0.62117022 0.62266477 0.07197829 0.59454163 0.50543216]\n",
      " [0.17747633 0.99762558 0.97424027 0.31407183 0.78160654]\n",
      " [0.12027534 0.08917053 0.44948703 0.06830774 0.16767034]\n",
      " [0.73806107 0.52259543 0.82006792 0.01970315 0.7796064 ]\n",
      " [0.81623879 0.82987558 0.88547322 0.710259   0.07065038]\n",
      " [0.68264225 0.07957744 0.50563443 0.2535412  0.76687173]\n",
      " [0.92176519 0.38201645 0.71896841 0.47259159 0.04713825]]\n",
      "New_weights\n",
      "[[0.68963319 0.11547408 0.62436935 0.44478512 0.2748484 ]\n",
      " [0.76243718 0.88059804 0.40149174 0.8407427  0.63782625]\n",
      " [0.0573426  0.77538943 0.90408796 0.987744   0.7834443 ]\n",
      " [0.62116996 0.62266464 0.07197787 0.59454142 0.50543182]\n",
      " [0.17747628 0.99762556 0.97424019 0.31407179 0.78160647]\n",
      " [0.12027526 0.08917049 0.4494869  0.06830768 0.16767023]\n",
      " [0.73806098 0.52259538 0.82006778 0.01970308 0.77960629]\n",
      " [0.81623849 0.82987543 0.88547274 0.71025875 0.07064999]\n",
      " [0.68264218 0.07957741 0.50563432 0.25354115 0.76687164]\n",
      " [0.92176495 0.38201634 0.71896803 0.4725914  0.04713794]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.39999980423299397\n",
      "Backward pass epoch 5\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 5\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63278115 0.46705673 0.93385236 0.8503683  0.11499685 0.35096864\n",
      "  0.2003127  0.78588914 0.18538065 0.68228422]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375912 0.90651723 0.9646743  0.80636177 0.37816985 0.27275613\n",
      "  0.96710206 0.0464422  0.83596309 0.5599895 ]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63278058 0.46705605 0.93385162 0.85036777 0.11499614 0.35096825\n",
      "  0.20031201 0.78588845 0.18538005 0.68228361]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375911 0.90651721 0.96467428 0.80636175 0.37816983 0.27275612\n",
      "  0.96710204 0.04644219 0.83596308 0.55998949]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963319 0.11547408 0.62436935 0.44478512 0.2748484 ]\n",
      " [0.76243718 0.88059804 0.40149174 0.8407427  0.63782625]\n",
      " [0.0573426  0.77538943 0.90408796 0.987744   0.7834443 ]\n",
      " [0.62116996 0.62266464 0.07197787 0.59454142 0.50543182]\n",
      " [0.17747628 0.99762556 0.97424019 0.31407179 0.78160647]\n",
      " [0.12027526 0.08917049 0.4494869  0.06830768 0.16767023]\n",
      " [0.73806098 0.52259538 0.82006778 0.01970308 0.77960629]\n",
      " [0.81623849 0.82987543 0.88547274 0.71025875 0.07064999]\n",
      " [0.68264218 0.07957741 0.50563432 0.25354115 0.76687164]\n",
      " [0.92176495 0.38201634 0.71896803 0.4725914  0.04713794]]\n",
      "New_weights\n",
      "[[0.68963299 0.11547398 0.62436901 0.44478495 0.27484813]\n",
      " [0.76243699 0.88059795 0.40149144 0.84074255 0.637826  ]\n",
      " [0.05734221 0.77538924 0.90408732 0.98774369 0.78344379]\n",
      " [0.6211697  0.62266452 0.07197745 0.59454121 0.50543149]\n",
      " [0.17747623 0.99762553 0.97424011 0.31407175 0.78160641]\n",
      " [0.12027518 0.08917046 0.44948677 0.06830762 0.16767013]\n",
      " [0.73806089 0.52259534 0.82006764 0.01970301 0.77960618]\n",
      " [0.81623819 0.82987529 0.88547225 0.71025851 0.0706496 ]\n",
      " [0.68264211 0.07957737 0.5056342  0.25354109 0.76687154]\n",
      " [0.92176472 0.38201623 0.71896765 0.47259121 0.04713763]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.39999980422895925\n",
      "Backward pass epoch 6\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 6\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63278058 0.46705605 0.93385162 0.85036777 0.11499614 0.35096825\n",
      "  0.20031201 0.78588845 0.18538005 0.68228361]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375911 0.90651721 0.96467428 0.80636175 0.37816983 0.27275612\n",
      "  0.96710204 0.04644219 0.83596308 0.55998949]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63278001 0.46705536 0.93385088 0.85036724 0.11499543 0.35096785\n",
      "  0.20031132 0.78588777 0.18537944 0.68228301]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.8137591  0.90651719 0.96467426 0.80636174 0.37816981 0.27275611\n",
      "  0.96710202 0.04644217 0.83596306 0.55998947]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963299 0.11547398 0.62436901 0.44478495 0.27484813]\n",
      " [0.76243699 0.88059795 0.40149144 0.84074255 0.637826  ]\n",
      " [0.05734221 0.77538924 0.90408732 0.98774369 0.78344379]\n",
      " [0.6211697  0.62266452 0.07197745 0.59454121 0.50543149]\n",
      " [0.17747623 0.99762553 0.97424011 0.31407175 0.78160641]\n",
      " [0.12027518 0.08917046 0.44948677 0.06830762 0.16767013]\n",
      " [0.73806089 0.52259534 0.82006764 0.01970301 0.77960618]\n",
      " [0.81623819 0.82987529 0.88547225 0.71025851 0.0706496 ]\n",
      " [0.68264211 0.07957737 0.5056342  0.25354109 0.76687154]\n",
      " [0.92176472 0.38201623 0.71896765 0.47259121 0.04713763]]\n",
      "New_weights\n",
      "[[0.68963278 0.11547388 0.62436867 0.44478478 0.27484785]\n",
      " [0.7624368  0.88059786 0.40149113 0.8407424  0.63782576]\n",
      " [0.05734181 0.77538906 0.90408668 0.98774337 0.78344327]\n",
      " [0.62116944 0.6226644  0.07197703 0.594541   0.50543115]\n",
      " [0.17747618 0.99762551 0.97424003 0.31407171 0.78160634]\n",
      " [0.1202751  0.08917042 0.44948664 0.06830755 0.16767003]\n",
      " [0.73806081 0.5225953  0.8200675  0.01970294 0.77960607]\n",
      " [0.81623788 0.82987514 0.88547176 0.71025827 0.0706492 ]\n",
      " [0.68264204 0.07957734 0.50563409 0.25354104 0.76687145]\n",
      " [0.92176448 0.38201611 0.71896726 0.47259102 0.04713733]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.39999980422492426\n",
      "Backward pass epoch 7\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 7\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63278001 0.46705536 0.93385088 0.85036724 0.11499543 0.35096785\n",
      "  0.20031132 0.78588777 0.18537944 0.68228301]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.8137591  0.90651719 0.96467426 0.80636174 0.37816981 0.27275611\n",
      "  0.96710202 0.04644217 0.83596306 0.55998947]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277944 0.46705467 0.93385015 0.85036671 0.11499472 0.35096746\n",
      "  0.20031063 0.78588708 0.18537883 0.68228241]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375908 0.90651718 0.96467425 0.80636173 0.3781698  0.2727561\n",
      "  0.96710201 0.04644216 0.83596305 0.55998946]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963278 0.11547388 0.62436867 0.44478478 0.27484785]\n",
      " [0.7624368  0.88059786 0.40149113 0.8407424  0.63782576]\n",
      " [0.05734181 0.77538906 0.90408668 0.98774337 0.78344327]\n",
      " [0.62116944 0.6226644  0.07197703 0.594541   0.50543115]\n",
      " [0.17747618 0.99762551 0.97424003 0.31407171 0.78160634]\n",
      " [0.1202751  0.08917042 0.44948664 0.06830755 0.16767003]\n",
      " [0.73806081 0.5225953  0.8200675  0.01970294 0.77960607]\n",
      " [0.81623788 0.82987514 0.88547176 0.71025827 0.0706492 ]\n",
      " [0.68264204 0.07957734 0.50563409 0.25354104 0.76687145]\n",
      " [0.92176448 0.38201611 0.71896726 0.47259102 0.04713733]]\n",
      "New_weights\n",
      "[[0.68963257 0.11547378 0.62436834 0.44478462 0.27484758]\n",
      " [0.76243661 0.88059777 0.40149083 0.84074225 0.63782551]\n",
      " [0.05734141 0.77538887 0.90408604 0.98774305 0.78344276]\n",
      " [0.62116918 0.62266427 0.07197661 0.59454079 0.50543081]\n",
      " [0.17747613 0.99762549 0.97423995 0.31407167 0.78160628]\n",
      " [0.12027502 0.08917038 0.44948651 0.06830749 0.16766992]\n",
      " [0.73806072 0.52259526 0.82006736 0.01970287 0.77960595]\n",
      " [0.81623758 0.829875   0.88547127 0.71025803 0.07064881]\n",
      " [0.68264197 0.07957731 0.50563398 0.25354098 0.76687136]\n",
      " [0.92176425 0.382016   0.71896688 0.47259083 0.04713702]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998042208891\n",
      "Backward pass epoch 8\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 8\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277944 0.46705467 0.93385015 0.85036671 0.11499472 0.35096746\n",
      "  0.20031063 0.78588708 0.18537883 0.68228241]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375908 0.90651718 0.96467425 0.80636173 0.3781698  0.2727561\n",
      "  0.96710201 0.04644216 0.83596305 0.55998946]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277886 0.46705398 0.93384941 0.85036618 0.11499401 0.35096706\n",
      "  0.20030994 0.7858864  0.18537822 0.6822818 ]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375907 0.90651716 0.96467423 0.80636172 0.37816978 0.27275609\n",
      "  0.96710199 0.04644214 0.83596304 0.55998945]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963257 0.11547378 0.62436834 0.44478462 0.27484758]\n",
      " [0.76243661 0.88059777 0.40149083 0.84074225 0.63782551]\n",
      " [0.05734141 0.77538887 0.90408604 0.98774305 0.78344276]\n",
      " [0.62116918 0.62266427 0.07197661 0.59454079 0.50543081]\n",
      " [0.17747613 0.99762549 0.97423995 0.31407167 0.78160628]\n",
      " [0.12027502 0.08917038 0.44948651 0.06830749 0.16766992]\n",
      " [0.73806072 0.52259526 0.82006736 0.01970287 0.77960595]\n",
      " [0.81623758 0.829875   0.88547127 0.71025803 0.07064881]\n",
      " [0.68264197 0.07957731 0.50563398 0.25354098 0.76687136]\n",
      " [0.92176425 0.382016   0.71896688 0.47259083 0.04713702]]\n",
      "New_weights\n",
      "[[0.68963236 0.11547368 0.624368   0.44478445 0.27484731]\n",
      " [0.76243642 0.88059768 0.40149052 0.8407421  0.63782526]\n",
      " [0.05734102 0.77538868 0.9040854  0.98774273 0.78344224]\n",
      " [0.62116892 0.62266415 0.07197619 0.59454059 0.50543047]\n",
      " [0.17747608 0.99762546 0.97423987 0.31407163 0.78160622]\n",
      " [0.12027494 0.08917034 0.44948639 0.06830743 0.16766982]\n",
      " [0.73806064 0.52259522 0.82006722 0.0197028  0.77960584]\n",
      " [0.81623728 0.82987485 0.88547078 0.71025778 0.07064841]\n",
      " [0.6826419  0.07957727 0.50563386 0.25354092 0.76687127]\n",
      " [0.92176401 0.38201589 0.7189665  0.47259064 0.04713671]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998042168538\n",
      "Backward pass epoch 9\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 9\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277886 0.46705398 0.93384941 0.85036618 0.11499401 0.35096706\n",
      "  0.20030994 0.7858864  0.18537822 0.6822818 ]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375907 0.90651716 0.96467423 0.80636172 0.37816978 0.27275609\n",
      "  0.96710199 0.04644214 0.83596304 0.55998945]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277829 0.4670533  0.93384867 0.85036565 0.1149933  0.35096667\n",
      "  0.20030925 0.78588572 0.18537762 0.6822812 ]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375906 0.90651715 0.96467421 0.80636171 0.37816977 0.27275608\n",
      "  0.96710198 0.04644213 0.83596302 0.55998943]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963236 0.11547368 0.624368   0.44478445 0.27484731]\n",
      " [0.76243642 0.88059768 0.40149052 0.8407421  0.63782526]\n",
      " [0.05734102 0.77538868 0.9040854  0.98774273 0.78344224]\n",
      " [0.62116892 0.62266415 0.07197619 0.59454059 0.50543047]\n",
      " [0.17747608 0.99762546 0.97423987 0.31407163 0.78160622]\n",
      " [0.12027494 0.08917034 0.44948639 0.06830743 0.16766982]\n",
      " [0.73806064 0.52259522 0.82006722 0.0197028  0.77960584]\n",
      " [0.81623728 0.82987485 0.88547078 0.71025778 0.07064841]\n",
      " [0.6826419  0.07957727 0.50563386 0.25354092 0.76687127]\n",
      " [0.92176401 0.38201589 0.7189665  0.47259064 0.04713671]]\n",
      "New_weights\n",
      "[[0.68963215 0.11547358 0.62436766 0.44478428 0.27484704]\n",
      " [0.76243624 0.88059759 0.40149022 0.84074195 0.63782502]\n",
      " [0.05734062 0.77538849 0.90408476 0.98774242 0.78344173]\n",
      " [0.62116866 0.62266402 0.07197577 0.59454038 0.50543014]\n",
      " [0.17747603 0.99762544 0.97423979 0.31407159 0.78160615]\n",
      " [0.12027487 0.0891703  0.44948626 0.06830736 0.16766972]\n",
      " [0.73806055 0.52259518 0.82006708 0.01970273 0.77960573]\n",
      " [0.81623698 0.82987471 0.88547029 0.71025754 0.07064802]\n",
      " [0.68264183 0.07957724 0.50563375 0.25354087 0.76687118]\n",
      " [0.92176378 0.38201578 0.71896612 0.47259046 0.04713641]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998042128183\n",
      "Backward pass epoch 10\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 10\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277829 0.4670533  0.93384867 0.85036565 0.1149933  0.35096667\n",
      "  0.20030925 0.78588572 0.18537762 0.6822812 ]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375906 0.90651715 0.96467421 0.80636171 0.37816977 0.27275608\n",
      "  0.96710198 0.04644213 0.83596302 0.55998943]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277772 0.46705261 0.93384794 0.85036512 0.11499259 0.35096627\n",
      "  0.20030857 0.78588503 0.18537701 0.6822806 ]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375905 0.90651713 0.9646742  0.80636169 0.37816975 0.27275607\n",
      "  0.96710196 0.04644211 0.83596301 0.55998942]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963215 0.11547358 0.62436766 0.44478428 0.27484704]\n",
      " [0.76243624 0.88059759 0.40149022 0.84074195 0.63782502]\n",
      " [0.05734062 0.77538849 0.90408476 0.98774242 0.78344173]\n",
      " [0.62116866 0.62266402 0.07197577 0.59454038 0.50543014]\n",
      " [0.17747603 0.99762544 0.97423979 0.31407159 0.78160615]\n",
      " [0.12027487 0.0891703  0.44948626 0.06830736 0.16766972]\n",
      " [0.73806055 0.52259518 0.82006708 0.01970273 0.77960573]\n",
      " [0.81623698 0.82987471 0.88547029 0.71025754 0.07064802]\n",
      " [0.68264183 0.07957724 0.50563375 0.25354087 0.76687118]\n",
      " [0.92176378 0.38201578 0.71896612 0.47259046 0.04713641]]\n",
      "New_weights\n",
      "[[0.68963194 0.11547348 0.62436732 0.44478411 0.27484677]\n",
      " [0.76243605 0.88059749 0.40148991 0.8407418  0.63782477]\n",
      " [0.05734023 0.7753883  0.90408412 0.9877421  0.78344121]\n",
      " [0.6211684  0.6226639  0.07197536 0.59454017 0.5054298 ]\n",
      " [0.17747598 0.99762542 0.97423971 0.31407155 0.78160609]\n",
      " [0.12027479 0.08917027 0.44948613 0.0683073  0.16766961]\n",
      " [0.73806046 0.52259514 0.82006694 0.01970266 0.77960562]\n",
      " [0.81623667 0.82987456 0.8854698  0.7102573  0.07064763]\n",
      " [0.68264176 0.07957721 0.50563364 0.25354081 0.76687109]\n",
      " [0.92176354 0.38201566 0.71896574 0.47259027 0.0471361 ]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.39999980420878267\n",
      "Backward pass epoch 11\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 11\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277772 0.46705261 0.93384794 0.85036512 0.11499259 0.35096627\n",
      "  0.20030857 0.78588503 0.18537701 0.6822806 ]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375905 0.90651713 0.9646742  0.80636169 0.37816975 0.27275607\n",
      "  0.96710196 0.04644211 0.83596301 0.55998942]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277715 0.46705192 0.9338472  0.85036459 0.11499188 0.35096588\n",
      "  0.20030788 0.78588435 0.1853764  0.68227999]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375903 0.90651712 0.96467418 0.80636168 0.37816973 0.27275606\n",
      "  0.96710195 0.0464421  0.835963   0.5599894 ]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963194 0.11547348 0.62436732 0.44478411 0.27484677]\n",
      " [0.76243605 0.88059749 0.40148991 0.8407418  0.63782477]\n",
      " [0.05734023 0.7753883  0.90408412 0.9877421  0.78344121]\n",
      " [0.6211684  0.6226639  0.07197536 0.59454017 0.5054298 ]\n",
      " [0.17747598 0.99762542 0.97423971 0.31407155 0.78160609]\n",
      " [0.12027479 0.08917027 0.44948613 0.0683073  0.16766961]\n",
      " [0.73806046 0.52259514 0.82006694 0.01970266 0.77960562]\n",
      " [0.81623667 0.82987456 0.8854698  0.7102573  0.07064763]\n",
      " [0.68264176 0.07957721 0.50563364 0.25354081 0.76687109]\n",
      " [0.92176354 0.38201566 0.71896574 0.47259027 0.0471361 ]]\n",
      "New_weights\n",
      "[[0.68963173 0.11547338 0.62436698 0.44478395 0.27484649]\n",
      " [0.76243586 0.8805974  0.40148961 0.84074165 0.63782453]\n",
      " [0.05733983 0.77538811 0.90408347 0.98774178 0.7834407 ]\n",
      " [0.62116814 0.62266378 0.07197494 0.59453996 0.50542946]\n",
      " [0.17747593 0.99762539 0.97423963 0.31407151 0.78160602]\n",
      " [0.12027471 0.08917023 0.449486   0.06830724 0.16766951]\n",
      " [0.73806038 0.5225951  0.8200668  0.01970259 0.77960551]\n",
      " [0.81623637 0.82987442 0.88546931 0.71025706 0.07064723]\n",
      " [0.68264169 0.07957717 0.50563353 0.25354076 0.766871  ]\n",
      " [0.9217633  0.38201555 0.71896536 0.47259008 0.04713579]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.39999980420474684\n",
      "Backward pass epoch 12\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 12\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277715 0.46705192 0.9338472  0.85036459 0.11499188 0.35096588\n",
      "  0.20030788 0.78588435 0.1853764  0.68227999]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375903 0.90651712 0.96467418 0.80636168 0.37816973 0.27275606\n",
      "  0.96710195 0.0464421  0.835963   0.5599894 ]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277658 0.46705123 0.93384646 0.85036406 0.11499117 0.35096548\n",
      "  0.20030719 0.78588366 0.18537579 0.68227939]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375902 0.9065171  0.96467416 0.80636167 0.37816972 0.27275605\n",
      "  0.96710193 0.04644208 0.83596298 0.55998939]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963173 0.11547338 0.62436698 0.44478395 0.27484649]\n",
      " [0.76243586 0.8805974  0.40148961 0.84074165 0.63782453]\n",
      " [0.05733983 0.77538811 0.90408347 0.98774178 0.7834407 ]\n",
      " [0.62116814 0.62266378 0.07197494 0.59453996 0.50542946]\n",
      " [0.17747593 0.99762539 0.97423963 0.31407151 0.78160602]\n",
      " [0.12027471 0.08917023 0.449486   0.06830724 0.16766951]\n",
      " [0.73806038 0.5225951  0.8200668  0.01970259 0.77960551]\n",
      " [0.81623637 0.82987442 0.88546931 0.71025706 0.07064723]\n",
      " [0.68264169 0.07957717 0.50563353 0.25354076 0.766871  ]\n",
      " [0.9217633  0.38201555 0.71896536 0.47259008 0.04713579]]\n",
      "New_weights\n",
      "[[0.68963152 0.11547328 0.62436665 0.44478378 0.27484622]\n",
      " [0.76243567 0.88059731 0.4014893  0.84074149 0.63782428]\n",
      " [0.05733943 0.77538792 0.90408283 0.98774147 0.78344018]\n",
      " [0.62116789 0.62266365 0.07197452 0.59453976 0.50542913]\n",
      " [0.17747588 0.99762537 0.97423955 0.31407147 0.78160596]\n",
      " [0.12027463 0.08917019 0.44948587 0.06830717 0.16766941]\n",
      " [0.73806029 0.52259505 0.82006666 0.01970252 0.77960539]\n",
      " [0.81623607 0.82987427 0.88546882 0.71025682 0.07064684]\n",
      " [0.68264162 0.07957714 0.50563341 0.2535407  0.76687091]\n",
      " [0.92176307 0.38201544 0.71896498 0.47258989 0.04713549]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998042007109\n",
      "Backward pass epoch 13\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 13\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277658 0.46705123 0.93384646 0.85036406 0.11499117 0.35096548\n",
      "  0.20030719 0.78588366 0.18537579 0.68227939]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375902 0.9065171  0.96467416 0.80636167 0.37816972 0.27275605\n",
      "  0.96710193 0.04644208 0.83596298 0.55998939]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277601 0.46705054 0.93384573 0.85036353 0.11499046 0.35096508\n",
      "  0.2003065  0.78588298 0.18537519 0.68227879]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375901 0.90651708 0.96467414 0.80636166 0.3781697  0.27275604\n",
      "  0.96710191 0.04644206 0.83596297 0.55998938]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963152 0.11547328 0.62436665 0.44478378 0.27484622]\n",
      " [0.76243567 0.88059731 0.4014893  0.84074149 0.63782428]\n",
      " [0.05733943 0.77538792 0.90408283 0.98774147 0.78344018]\n",
      " [0.62116789 0.62266365 0.07197452 0.59453976 0.50542913]\n",
      " [0.17747588 0.99762537 0.97423955 0.31407147 0.78160596]\n",
      " [0.12027463 0.08917019 0.44948587 0.06830717 0.16766941]\n",
      " [0.73806029 0.52259505 0.82006666 0.01970252 0.77960539]\n",
      " [0.81623607 0.82987427 0.88546882 0.71025682 0.07064684]\n",
      " [0.68264162 0.07957714 0.50563341 0.2535407  0.76687091]\n",
      " [0.92176307 0.38201544 0.71896498 0.47258989 0.04713549]]\n",
      "New_weights\n",
      "[[0.68963131 0.11547318 0.62436631 0.44478361 0.27484595]\n",
      " [0.76243548 0.88059722 0.401489   0.84074134 0.63782404]\n",
      " [0.05733904 0.77538773 0.90408219 0.98774115 0.78343967]\n",
      " [0.62116763 0.62266353 0.0719741  0.59453955 0.50542879]\n",
      " [0.17747584 0.99762535 0.97423947 0.31407143 0.7816059 ]\n",
      " [0.12027455 0.08917015 0.44948574 0.06830711 0.16766931]\n",
      " [0.73806021 0.52259501 0.82006653 0.01970246 0.77960528]\n",
      " [0.81623577 0.82987413 0.88546833 0.71025657 0.07064645]\n",
      " [0.68264155 0.07957711 0.5056333  0.25354064 0.76687082]\n",
      " [0.92176283 0.38201533 0.7189646  0.4725897  0.04713518]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998041966748\n",
      "Backward pass epoch 14\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 14\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277601 0.46705054 0.93384573 0.85036353 0.11499046 0.35096508\n",
      "  0.2003065  0.78588298 0.18537519 0.68227879]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375901 0.90651708 0.96467414 0.80636166 0.3781697  0.27275604\n",
      "  0.96710191 0.04644206 0.83596297 0.55998938]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277544 0.46704985 0.93384499 0.85036299 0.11498975 0.35096469\n",
      "  0.20030581 0.7858823  0.18537458 0.68227818]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375899 0.90651707 0.96467413 0.80636165 0.37816968 0.27275604\n",
      "  0.9671019  0.04644205 0.83596295 0.55998936]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963131 0.11547318 0.62436631 0.44478361 0.27484595]\n",
      " [0.76243548 0.88059722 0.401489   0.84074134 0.63782404]\n",
      " [0.05733904 0.77538773 0.90408219 0.98774115 0.78343967]\n",
      " [0.62116763 0.62266353 0.0719741  0.59453955 0.50542879]\n",
      " [0.17747584 0.99762535 0.97423947 0.31407143 0.7816059 ]\n",
      " [0.12027455 0.08917015 0.44948574 0.06830711 0.16766931]\n",
      " [0.73806021 0.52259501 0.82006653 0.01970246 0.77960528]\n",
      " [0.81623577 0.82987413 0.88546833 0.71025657 0.07064645]\n",
      " [0.68264155 0.07957711 0.5056333  0.25354064 0.76687082]\n",
      " [0.92176283 0.38201533 0.7189646  0.4725897  0.04713518]]\n",
      "New_weights\n",
      "[[0.6896311  0.11547308 0.62436597 0.44478344 0.27484568]\n",
      " [0.76243529 0.88059713 0.40148869 0.84074119 0.63782379]\n",
      " [0.05733864 0.77538754 0.90408155 0.98774083 0.78343915]\n",
      " [0.62116737 0.6226634  0.07197368 0.59453934 0.50542845]\n",
      " [0.17747579 0.99762532 0.97423939 0.31407139 0.78160583]\n",
      " [0.12027447 0.08917011 0.44948562 0.06830704 0.1676692 ]\n",
      " [0.73806012 0.52259497 0.82006639 0.01970239 0.77960517]\n",
      " [0.81623546 0.82987398 0.88546784 0.71025633 0.07064605]\n",
      " [0.68264148 0.07957707 0.50563319 0.25354059 0.76687073]\n",
      " [0.9217626  0.38201521 0.71896422 0.47258951 0.04713487]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998041926385\n",
      "Backward pass epoch 15\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 15\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277544 0.46704985 0.93384499 0.85036299 0.11498975 0.35096469\n",
      "  0.20030581 0.7858823  0.18537458 0.68227818]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375899 0.90651707 0.96467413 0.80636165 0.37816968 0.27275604\n",
      "  0.9671019  0.04644205 0.83596295 0.55998936]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277487 0.46704917 0.93384425 0.85036246 0.11498904 0.35096429\n",
      "  0.20030512 0.78588161 0.18537397 0.68227758]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375898 0.90651705 0.96467411 0.80636163 0.37816967 0.27275603\n",
      "  0.96710188 0.04644203 0.83596294 0.55998935]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.6896311  0.11547308 0.62436597 0.44478344 0.27484568]\n",
      " [0.76243529 0.88059713 0.40148869 0.84074119 0.63782379]\n",
      " [0.05733864 0.77538754 0.90408155 0.98774083 0.78343915]\n",
      " [0.62116737 0.6226634  0.07197368 0.59453934 0.50542845]\n",
      " [0.17747579 0.99762532 0.97423939 0.31407139 0.78160583]\n",
      " [0.12027447 0.08917011 0.44948562 0.06830704 0.1676692 ]\n",
      " [0.73806012 0.52259497 0.82006639 0.01970239 0.77960517]\n",
      " [0.81623546 0.82987398 0.88546784 0.71025633 0.07064605]\n",
      " [0.68264148 0.07957707 0.50563319 0.25354059 0.76687073]\n",
      " [0.9217626  0.38201521 0.71896422 0.47258951 0.04713487]]\n",
      "New_weights\n",
      "[[0.68963089 0.11547298 0.62436563 0.44478328 0.27484541]\n",
      " [0.7624351  0.88059704 0.40148839 0.84074104 0.63782355]\n",
      " [0.05733825 0.77538735 0.90408091 0.98774052 0.78343864]\n",
      " [0.62116711 0.62266328 0.07197326 0.59453913 0.50542811]\n",
      " [0.17747574 0.9976253  0.97423931 0.31407135 0.78160577]\n",
      " [0.12027439 0.08917008 0.44948549 0.06830698 0.1676691 ]\n",
      " [0.73806003 0.52259493 0.82006625 0.01970232 0.77960506]\n",
      " [0.81623516 0.82987384 0.88546735 0.71025609 0.07064566]\n",
      " [0.68264141 0.07957704 0.50563307 0.25354053 0.76687064]\n",
      " [0.92176236 0.3820151  0.71896383 0.47258932 0.04713457]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.399999804188602\n",
      "Backward pass epoch 16\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 16\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277487 0.46704917 0.93384425 0.85036246 0.11498904 0.35096429\n",
      "  0.20030512 0.78588161 0.18537397 0.68227758]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375898 0.90651705 0.96467411 0.80636163 0.37816967 0.27275603\n",
      "  0.96710188 0.04644203 0.83596294 0.55998935]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277429 0.46704848 0.93384351 0.85036193 0.11498833 0.3509639\n",
      "  0.20030443 0.78588093 0.18537336 0.68227698]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375897 0.90651704 0.96467409 0.80636162 0.37816965 0.27275602\n",
      "  0.96710187 0.04644202 0.83596293 0.55998934]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963089 0.11547298 0.62436563 0.44478328 0.27484541]\n",
      " [0.7624351  0.88059704 0.40148839 0.84074104 0.63782355]\n",
      " [0.05733825 0.77538735 0.90408091 0.98774052 0.78343864]\n",
      " [0.62116711 0.62266328 0.07197326 0.59453913 0.50542811]\n",
      " [0.17747574 0.9976253  0.97423931 0.31407135 0.78160577]\n",
      " [0.12027439 0.08917008 0.44948549 0.06830698 0.1676691 ]\n",
      " [0.73806003 0.52259493 0.82006625 0.01970232 0.77960506]\n",
      " [0.81623516 0.82987384 0.88546735 0.71025609 0.07064566]\n",
      " [0.68264141 0.07957704 0.50563307 0.25354053 0.76687064]\n",
      " [0.92176236 0.3820151  0.71896383 0.47258932 0.04713457]]\n",
      "New_weights\n",
      "[[0.68963068 0.11547288 0.62436529 0.44478311 0.27484513]\n",
      " [0.76243491 0.88059695 0.40148808 0.84074089 0.6378233 ]\n",
      " [0.05733785 0.77538716 0.90408027 0.9877402  0.78343812]\n",
      " [0.62116685 0.62266315 0.07197284 0.59453893 0.50542778]\n",
      " [0.17747569 0.99762528 0.97423923 0.31407131 0.7816057 ]\n",
      " [0.12027431 0.08917004 0.44948536 0.06830692 0.167669  ]\n",
      " [0.73805995 0.52259489 0.82006611 0.01970225 0.77960495]\n",
      " [0.81623486 0.82987369 0.88546687 0.71025585 0.07064527]\n",
      " [0.68264134 0.07957701 0.50563296 0.25354048 0.76687055]\n",
      " [0.92176212 0.38201499 0.71896345 0.47258913 0.04713426]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998041845654\n",
      "Backward pass epoch 17\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 17\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277429 0.46704848 0.93384351 0.85036193 0.11498833 0.3509639\n",
      "  0.20030443 0.78588093 0.18537336 0.68227698]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375897 0.90651704 0.96467409 0.80636162 0.37816965 0.27275602\n",
      "  0.96710187 0.04644202 0.83596293 0.55998934]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277372 0.46704779 0.93384278 0.8503614  0.11498762 0.3509635\n",
      "  0.20030374 0.78588024 0.18537275 0.68227637]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375895 0.90651702 0.96467408 0.80636161 0.37816964 0.27275601\n",
      "  0.96710185 0.046442   0.83596291 0.55998932]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963068 0.11547288 0.62436529 0.44478311 0.27484513]\n",
      " [0.76243491 0.88059695 0.40148808 0.84074089 0.6378233 ]\n",
      " [0.05733785 0.77538716 0.90408027 0.9877402  0.78343812]\n",
      " [0.62116685 0.62266315 0.07197284 0.59453893 0.50542778]\n",
      " [0.17747569 0.99762528 0.97423923 0.31407131 0.7816057 ]\n",
      " [0.12027431 0.08917004 0.44948536 0.06830692 0.167669  ]\n",
      " [0.73805995 0.52259489 0.82006611 0.01970225 0.77960495]\n",
      " [0.81623486 0.82987369 0.88546687 0.71025585 0.07064527]\n",
      " [0.68264134 0.07957701 0.50563296 0.25354048 0.76687055]\n",
      " [0.92176212 0.38201499 0.71896345 0.47258913 0.04713426]]\n",
      "New_weights\n",
      "[[0.68963048 0.11547278 0.62436495 0.44478294 0.27484486]\n",
      " [0.76243473 0.88059686 0.40148778 0.84074074 0.63782306]\n",
      " [0.05733745 0.77538697 0.90407963 0.98773988 0.78343761]\n",
      " [0.62116659 0.62266303 0.07197242 0.59453872 0.50542744]\n",
      " [0.17747564 0.99762525 0.97423915 0.31407127 0.78160564]\n",
      " [0.12027423 0.08917    0.44948523 0.06830685 0.16766889]\n",
      " [0.73805986 0.52259485 0.82006597 0.01970218 0.77960483]\n",
      " [0.81623455 0.82987355 0.88546638 0.7102556  0.07064487]\n",
      " [0.68264127 0.07957697 0.50563285 0.25354042 0.76687045]\n",
      " [0.92176189 0.38201487 0.71896307 0.47258894 0.04713395]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998041805286\n",
      "Backward pass epoch 18\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 18\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277372 0.46704779 0.93384278 0.8503614  0.11498762 0.3509635\n",
      "  0.20030374 0.78588024 0.18537275 0.68227637]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375895 0.90651702 0.96467408 0.80636161 0.37816964 0.27275601\n",
      "  0.96710185 0.046442   0.83596291 0.55998932]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277315 0.4670471  0.93384204 0.85036087 0.11498691 0.35096311\n",
      "  0.20030305 0.78587956 0.18537215 0.68227577]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375894 0.90651701 0.96467406 0.8063616  0.37816962 0.272756\n",
      "  0.96710184 0.04644199 0.8359629  0.55998931]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963048 0.11547278 0.62436495 0.44478294 0.27484486]\n",
      " [0.76243473 0.88059686 0.40148778 0.84074074 0.63782306]\n",
      " [0.05733745 0.77538697 0.90407963 0.98773988 0.78343761]\n",
      " [0.62116659 0.62266303 0.07197242 0.59453872 0.50542744]\n",
      " [0.17747564 0.99762525 0.97423915 0.31407127 0.78160564]\n",
      " [0.12027423 0.08917    0.44948523 0.06830685 0.16766889]\n",
      " [0.73805986 0.52259485 0.82006597 0.01970218 0.77960483]\n",
      " [0.81623455 0.82987355 0.88546638 0.7102556  0.07064487]\n",
      " [0.68264127 0.07957697 0.50563285 0.25354042 0.76687045]\n",
      " [0.92176189 0.38201487 0.71896307 0.47258894 0.04713395]]\n",
      "New_weights\n",
      "[[0.68963027 0.11547268 0.62436462 0.44478277 0.27484459]\n",
      " [0.76243454 0.88059677 0.40148747 0.84074059 0.63782281]\n",
      " [0.05733706 0.77538678 0.90407899 0.98773956 0.78343709]\n",
      " [0.62116633 0.62266291 0.071972   0.59453851 0.5054271 ]\n",
      " [0.17747559 0.99762523 0.97423907 0.31407124 0.78160557]\n",
      " [0.12027415 0.08916996 0.4494851  0.06830679 0.16766879]\n",
      " [0.73805978 0.52259481 0.82006583 0.01970211 0.77960472]\n",
      " [0.81623425 0.8298734  0.88546589 0.71025536 0.07064448]\n",
      " [0.6826412  0.07957694 0.50563274 0.25354037 0.76687036]\n",
      " [0.92176165 0.38201476 0.71896269 0.47258876 0.04713365]]\n",
      "Layer 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "[[0.99999952]\n",
      " [0.99999876]\n",
      " [0.99999999]\n",
      " [0.99999999]\n",
      " [0.99999994]]\n",
      "Loss: 0.3999998041764916\n",
      "Backward pass epoch 19\n",
      "Layer 2\n",
      "Layer 1\n",
      "Layer 0\n",
      "Last backwards pass layer\n",
      "Update pass epoch 19\n",
      "Layer 2\n",
      "Old_weights\n",
      "[[0.63277315 0.4670471  0.93384204 0.85036087 0.11498691 0.35096311\n",
      "  0.20030305 0.78587956 0.18537215 0.68227577]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375894 0.90651701 0.96467406 0.8063616  0.37816962 0.272756\n",
      "  0.96710184 0.04644199 0.8359629  0.55998931]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "New_weights\n",
      "[[0.63277258 0.46704641 0.9338413  0.85036034 0.1149862  0.35096271\n",
      "  0.20030236 0.78587888 0.18537154 0.68227517]\n",
      " [0.30507473 0.66590934 0.76484011 0.77217924 0.49771703 0.37782773\n",
      "  0.40090751 0.44507912 0.10012688 0.43765348]\n",
      " [0.87599545 0.4934977  0.83640497 0.33341877 0.54231229 0.2480071\n",
      "  0.77707947 0.98752362 0.71695944 0.54451965]\n",
      " [0.81375893 0.90651699 0.96467404 0.80636159 0.3781696  0.27275599\n",
      "  0.96710182 0.04644197 0.83596288 0.55998929]\n",
      " [0.16482599 0.99792866 0.45327461 0.81125635 0.49840745 0.74395175\n",
      "  0.39139552 0.9218635  0.18641905 0.88974352]]\n",
      "Layer 1\n",
      "Old_weights\n",
      "[[0.68963027 0.11547268 0.62436462 0.44478277 0.27484459]\n",
      " [0.76243454 0.88059677 0.40148747 0.84074059 0.63782281]\n",
      " [0.05733706 0.77538678 0.90407899 0.98773956 0.78343709]\n",
      " [0.62116633 0.62266291 0.071972   0.59453851 0.5054271 ]\n",
      " [0.17747559 0.99762523 0.97423907 0.31407124 0.78160557]\n",
      " [0.12027415 0.08916996 0.4494851  0.06830679 0.16766879]\n",
      " [0.73805978 0.52259481 0.82006583 0.01970211 0.77960472]\n",
      " [0.81623425 0.8298734  0.88546589 0.71025536 0.07064448]\n",
      " [0.6826412  0.07957694 0.50563274 0.25354037 0.76687036]\n",
      " [0.92176165 0.38201476 0.71896269 0.47258876 0.04713365]]\n",
      "New_weights\n",
      "[[0.68963006 0.11547258 0.62436428 0.44478261 0.27484432]\n",
      " [0.76243435 0.88059668 0.40148717 0.84074044 0.63782257]\n",
      " [0.05733666 0.77538659 0.90407835 0.98773925 0.78343658]\n",
      " [0.62116607 0.62266278 0.07197158 0.5945383  0.50542676]\n",
      " [0.17747554 0.9976252  0.97423899 0.3140712  0.78160551]\n",
      " [0.12027407 0.08916992 0.44948497 0.06830673 0.16766869]\n",
      " [0.73805969 0.52259477 0.82006569 0.01970204 0.77960461]\n",
      " [0.81623395 0.82987326 0.8854654  0.71025512 0.07064409]\n",
      " [0.68264113 0.07957691 0.50563262 0.25354031 0.76687027]\n",
      " [0.92176142 0.38201465 0.71896231 0.47258857 0.04713334]]\n",
      "Layer 0\n",
      "No weights in input layer\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "model = NeuralNetwork(x, y, learning_rate = 0.5, dropout_rate = 0, batch_size = 1, epochs = 20)\n",
    "model.addLayer(5, 5, 'sigmoid', 'input')\n",
    "model.addLayer(5, 10, 'relu', 'hidden')\n",
    "model.addLayer(10, 5, 'sigmoid', 'output')\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e - Implement optimizer\n",
    "Implement any two optimizers of your choice. Briefly present the optimizers \n",
    "in the report. The optimizers can be flavours of gradient descent. For \n",
    "instance: Stochastic gradient descent (SGD) and SGD with momentum. \n",
    "SGD and mini-batch gradient descent, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f - Evaluate different neural network architectures/parameters, present and discuss your results.\n",
    "Be creative in the analysis and discussion. Evaluate different\n",
    "hyperparameters. For instance: different network architectures, activation \n",
    "functions, comparison of optimizers, L1/L2 performance comparison with \n",
    "dropout, etc. Support your results with plots/graph and discussion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
