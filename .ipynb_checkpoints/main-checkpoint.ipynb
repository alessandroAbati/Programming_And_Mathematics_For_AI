{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Mathematics for AI - coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The task is about classification on the MNIST dataset. \n",
    "You can use other APIâ€™s/libraries for loading the dataset, but not for the neural network \n",
    "implementation. The point of this task is to develop a multi-layer neural network for \n",
    "classification using numpy. The task requires following sub-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Implement sigmoid and ReLU layers\n",
    "For this sub-task, you should implement forward and backward pass for \n",
    "sigmoid and ReLU. You should consider presenting these activation\n",
    "functions in the report with any pros cons if they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLu(x):\n",
    "    '''\n",
    "    Implementation of reLu function.\n",
    "    '''\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Implementation of Sigmoid function.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Implementation of Softmax function\n",
    "    '''\n",
    "    normalization = np.sum(np.exp(x))\n",
    "    return [np.exp(el)/normalization for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ReLU activation function')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, reLu(x))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.title(\"ReLU activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2657c1750>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2659e4710>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, softmax(x))\n",
    "# How do I test my implementation of the softmax function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.input = x # store the input to use it in the backward pass\n",
    "        return np.maximum(0, x)  # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return np.where(self.input > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "* Advatages:\n",
    "    - No saturation of neurons (at least for positive values)\n",
    "    - Converge fast\n",
    "    - Computationally efficent (very simple to calculate, both the reLu and its derivative)\n",
    "\n",
    "* Disadvantages:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('gradient_values'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        \n",
    "        sigmoid_derivative = np.multiply(self.output, (1 - self.output)) # calculate the derivative of Sigmoid: f(x) * (1 - f(x)) where f(x) is the Sigmoid function\n",
    "        return sigmoid_derivative  # multiply the gradient of the loss function by the derivative of Sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note - __Sigmoid Problem__:\n",
    "\n",
    "Vanishing gradient and saturation of neurons:\n",
    "the sigmoid function usually have the output very close to zero or one and in this region the derivative of the sigmoid is very small, meaning that the (local) gradient will be small and the network will now learn efficently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - Implement softmax layer\n",
    "Implement softmax with both forward and backward pass. Present the \n",
    "softmax in the report along with any numerical issues when calculating the \n",
    "softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'x', with the\n",
    "                         same shape as 'x'.\n",
    "        '''        \n",
    "#         x = np.asarray(x)\n",
    "# #         print (\"Shape of inputs {}\".format(x.shape))\n",
    "# #         print(np.max(x))\n",
    "#         reg = x - np.max(x)\n",
    "# #         print(\"Reg:\")\n",
    "# #         print(reg[0])\n",
    "# #         e_x = np.exp(reg)\n",
    "#         e_x = np.clip(np.exp(reg), 0.000001, 1-0.000001)\n",
    "\n",
    "# #         print(\"Exp:\")\n",
    "# #         print(e_x[0])\n",
    "# #         print(\"Max exp\")\n",
    "# #         print(np.max(e_x))\n",
    "#         exp_sum = np.sum(e_x, axis=-1, keepdims = True)\n",
    "# #         exp_sum = np.clip(exp_sum, 0.000001, 1-0.000001)\n",
    "# #         print(exp_sum[0])\n",
    "# #         print(\"Max sum\")\n",
    "# #         print(np.max(exp_sum))\n",
    "        \n",
    "#         return e_x / exp_sum\n",
    "\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "        self.output = e_x / np.sum(e_x, axis=1, keepdims = True)\n",
    "        return self.output\n",
    "#         e_x = np.exp(x - np.max(x, axis=-1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "#         self.output = e_x / np.sum(e_x) # apply the softmax function: f(xi) = exp(xi) / sum(exp(x)) for x=[x1,...,xK]\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        # Gradient values not used -> Remove!!\n",
    "        softmax_jacobian = self.output * (np.eye(self.output.shape[0]) - self.output.T)\n",
    "        #print(softmax_jacobian)\n",
    "        print(softmax_jacobian.shape)\n",
    "        return softmax_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    weights = 0\n",
    "    new_weights = 0\n",
    "    bias = 0\n",
    "    activation = 0\n",
    "    layer_input = 0\n",
    "    softmax = False\n",
    "    \n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        # Weight initialisation crucial for performance\n",
    "        #self.weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        #self.new_weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        self.weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.new_weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.layer_input = 0\n",
    "        self.bias = 0\n",
    "        self.softmax = False\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = []\n",
    "        '''\n",
    "        Set activation function for the layer\n",
    "        '''   \n",
    "        if activation == 'relu':\n",
    "            print(\"ReLU\")\n",
    "            self.activation = ReLu()\n",
    "        elif activation == 'sigmoid':\n",
    "            print(\"Sigmoid\")\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'softmax':\n",
    "            print(\"Softmax\")\n",
    "            self.softmax = True\n",
    "            self.activation = Softmax()\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Weights combined with input and bias\n",
    "        '''\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        '''\n",
    "        Pass z through activation function\n",
    "        '''\n",
    "        output = self.activation.forward_pass(z)\n",
    "        self.mask = 1\n",
    "        if (self.dropout_rate != 0):\n",
    "            self.mask = (np.random.rand(*output.shape) < self.dropout_rate) / self.dropout_rate\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        print(\"Output of hidden layer\")\n",
    "        print(output)\n",
    "        return output * self.mask\n",
    "        \n",
    "    '''\n",
    "    Idea is to have backward pass for activation functions just return the derivative of the activation,\n",
    "    and backward_pass for layer perform any other calculation (dot product of activation function with loss for example)\n",
    "    '''   \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            derivative_final = np.multiply(x, activation_derivative)*self.mask\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = -(learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "#         print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        self.weights += self.new_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass of layer\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        super().__init__(output_units, input_units, activation, dropout_rate)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        return x\n",
    "    \n",
    "    # No weights in input layer\n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print(\"Last backwards pass layer\")\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"End of Backwards pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        super().__init__(output_units, input_units, activation, dropout_rate)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        print(\"Weights and biases\")\n",
    "        print(z[0])\n",
    "        output = self.activation.forward_pass(z)\n",
    "        self.mask = 1\n",
    "        if (self.dropout_rate != 0):\n",
    "            self.mask = (np.random.rand(*output.shape) < self.dropout_rate) / self.dropout_rate\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output*self.mask\n",
    "    \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            activation_derivative = self.activation.backward_pass(x)\n",
    "            derivative_final = np.multiply(x, activation_derivative)*self.mask\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = -(learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "        print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def mse_loss(self, output, target):\n",
    "        loss = 1/len(output)*np.sum((output-target)**2)\n",
    "        return loss\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"Old_weights\")\n",
    "        print(self.weights[:10])\n",
    "        print(\"New_weights\")\n",
    "        print(self.new_weights[:10])\n",
    "        self.weights += self.new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY\n",
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "prediction = softmax.forward_pass(x)\n",
    "loss = np.sum((prediction - y) ** 2)\n",
    "loss_derivative = (prediction -y)\n",
    "prediction, loss, np.sum(prediction)\n",
    "loss_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_derivative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient_softmax = softmax.backward_pass(loss_derivative.T, learning_rate)\n",
    "#gradient_softmax.shape, gradient_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - Implement dropout \n",
    "Present dropout in the report. Implement inverted dropout. Forward and \n",
    "backward pass should be implemented.\n",
    "Note: Since the test performance is critical, it is also preferable to leaving \n",
    "the forward pass unchanged at test time. Therefore, in most \n",
    "implementations inverted dropout is employed to overcome the \n",
    "undesirable property of the original dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of \n",
    "hidden layers, units, activation functions can be changed. In addition, you \n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used \n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots \n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "    A class representing the Fully Parametrizable Neural Network.\n",
    "    '''\n",
    "    layer_list = []\n",
    "    X = 0\n",
    "    Y = 0\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 8\n",
    "    epochs = 100   \n",
    "    loss_history = []\n",
    "    \n",
    "    def __init__(self, X, Y, learning_rate, dropout_rate = 0, batch_size = 4, epochs = 10):\n",
    "        self.layer_list = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def addLayer(self, input_units, output_units, activation, mode = \"input\"):\n",
    "        if mode == \"input\":\n",
    "            print(\"Added input\")\n",
    "            layer = InputLayer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        elif mode == \"output\":\n",
    "            print(\"Added output\")\n",
    "            layer = OutputLayer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        else:\n",
    "            print(\"Added hidden\")\n",
    "            layer = Layer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        self.layer_list.append(layer)\n",
    "        \n",
    "    def loss(self, output, target, mode):\n",
    "        if mode == \"mse\":\n",
    "            loss = 1/len(output)*np.sum((np.sum(output-target))**2)\n",
    "            return loss\n",
    "        elif mode == \"cross_entropy\":\n",
    "            output = np.clip(output, 0.000001, 1-0.000001)\n",
    "#             loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n",
    "            loss = -np.sum(target * np.log(output))\n",
    "            print(\"Cross Loss: {}\".format(loss))\n",
    "            print(loss.shape)\n",
    "            return loss\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            input_data = self.X\n",
    "            print(input_data.shape)\n",
    "            # Forward pass\n",
    "            print(\"Forward pass epoch {}\".format(i))\n",
    "            for index, layer in enumerate(self.layer_list):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                output_data = layer.forward_pass(input_data)\n",
    "                input_data = output_data\n",
    "                \n",
    "            # Calculate loss \n",
    "            #output_data = np.around(output_data, 6)\n",
    "            print(\"Output layer\")\n",
    "            print(output_data[:10])\n",
    "            print(\"Sums to 1: \")\n",
    "            print(np.sum(output_data[0]))\n",
    "            print(\"At least one output is closer to 1: \")\n",
    "            print(np.max(output_data))\n",
    "            # For softmax, not exactly 0 nor 1\n",
    "            print(\"Model output shape: {}\".format (output_data.shape))\n",
    "            print(\"Model target shape: {}\".format (self.Y.shape))\n",
    "            loss_cost = self.loss(output_data, self.Y, mode = \"cross_entropy\")\n",
    "#             loss_cost = np.around(loss_cost, 6)\n",
    "            self.loss_history.append(loss_cost)\n",
    "            #print(\"Loss: {}\".format(loss_cost))\n",
    "            \n",
    "            # Backward pass  \n",
    "            # MSE derivative\n",
    "#             input_derivative = (self.Y - output_data)\n",
    "            input_derivative = np.asarray(output_data - self.Y)\n",
    "            print(\"Backward pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                output_derivative = layer.backward_pass(input_derivative, self.learning_rate)\n",
    "                input_derivative = output_derivative\n",
    "                \n",
    "            # Update pass. Supposedly update weights after backward pass completed\n",
    "            # Weights barely updating??\n",
    "            print(\"Update pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                layer.update_weights(self.learning_rate)\n",
    "                                         \n",
    "    def predict(self, X):\n",
    "        input_data = X\n",
    "        for index, layer in enumerate(self.layer_list):\n",
    "            output_data = layer.forward_pass(input_data)\n",
    "            input_data = output_data\n",
    "        return output_data\n",
    "    \n",
    "    def show_loss(self):\n",
    "        plt.plot(self.loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY DATASET\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "dataset = load_digits()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Softmax\n",
      "(1797, 64)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.03111673 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.01585831 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02170257 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02215297 0.         0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[1.53702214e-04 0.00000000e+00 9.64110528e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.34767321e-03]\n",
      " [1.44590373e-04 3.23959880e-04 9.29935424e-04 ... 3.02619661e-04\n",
      "  1.18830835e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.48097490e-03 ... 0.00000000e+00\n",
      "  1.32492198e-03 0.00000000e+00]\n",
      " ...\n",
      " [6.69435617e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.62085754e-05 2.91373628e-03 ... 1.47890493e-03\n",
      "  3.13806942e-03 0.00000000e+00]\n",
      " [0.00000000e+00 8.54674849e-04 0.00000000e+00 ... 2.88005317e-04\n",
      "  3.31044350e-04 1.80225174e-03]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[-1.63425035e-05 -1.62163706e-05 -1.88836702e-05 -8.18858967e-06\n",
      " -2.43194665e-05 -1.59282362e-05 -7.47787867e-06 -1.09355185e-05\n",
      " -1.14361616e-05  5.12322300e-06]\n",
      "Output layer\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  1.00000498 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.9999861\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99994833 0.         0.         0.        ]\n",
      " [0.         0.         0.         1.00001123 1.00003872 0.\n",
      "  0.         0.         1.00000212 0.        ]\n",
      " [0.         0.99994714 0.         0.         0.         0.99995858\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.00002087 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.99997795 0.         0.         0.         0.99998399 0.\n",
      "  0.         1.00001361 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Sums to 1: \n",
      "1.0000049826220656\n",
      "At least one output is closer to 1: \n",
      "1.0001389971378618\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22021.92643439653\n",
      "()\n",
      "Backward pass epoch 0\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[ 6.21626447e-05  6.15016103e-05 -2.77129828e-04  8.89730100e-04\n",
      "  -5.51380355e-04 -6.25924614e-04  9.33019273e-06 -9.49637405e-04\n",
      "   1.27387730e-03 -4.96877034e-04]\n",
      " [ 9.69117574e-05  2.93038089e-04  7.16539493e-04  5.82621633e-04\n",
      "  -4.99124019e-04  4.28119372e-05 -3.84365985e-04 -5.39518285e-04\n",
      "   7.57052568e-04 -8.56013643e-04]\n",
      " [-1.20243134e-03 -1.22858238e-03 -7.77132410e-04  2.18986604e-04\n",
      "  -8.07588772e-04 -1.10609959e-03  5.54459471e-04 -1.88604782e-04\n",
      "  -4.46604700e-04 -1.47868458e-04]\n",
      " [-3.95649710e-04  3.37920008e-04  2.95854682e-04 -3.77580159e-04\n",
      "  -2.30424497e-04  6.87345389e-04 -2.80030978e-04  7.45871030e-04\n",
      "   3.18031462e-04 -7.13640853e-04]\n",
      " [-1.48039100e-04 -8.31423948e-04  1.92499853e-04  6.86821333e-05\n",
      "   6.60900104e-04  1.58086359e-03 -3.25730917e-04 -9.09475458e-06\n",
      "  -2.55031847e-04 -4.59104589e-04]\n",
      " [-4.78326390e-04  8.89727931e-04  8.42085637e-04  3.89352924e-04\n",
      "  -1.03418006e-03  1.43031187e-04  9.63447130e-06 -7.72813309e-04\n",
      "   7.08601333e-05 -1.26026310e-03]\n",
      " [ 9.00198616e-05 -7.15707923e-04  3.17156528e-05  2.25881462e-04\n",
      "  -5.21215893e-04 -3.64502064e-04 -2.51675885e-04 -5.12608859e-04\n",
      "  -6.72067570e-04  4.58125197e-04]\n",
      " [-4.35052273e-04  2.01759616e-04  2.97814019e-04  1.80586578e-04\n",
      "  -1.53326142e-05  1.26000891e-03  5.32098822e-04  1.44559355e-04\n",
      "  -3.76203974e-04  7.12871707e-04]\n",
      " [ 9.31410989e-04  5.75191177e-05 -2.45580441e-04  1.32360446e-03\n",
      "   6.84595001e-04  1.38888776e-03 -9.80546486e-04  3.03350981e-04\n",
      "  -1.49645703e-04 -2.55939914e-04]\n",
      " [-5.35822378e-04 -1.02914436e-03 -3.71627856e-04 -1.22398588e-05\n",
      "   1.08054898e-03  5.48309742e-04  1.80954664e-04  4.18196334e-04\n",
      "   2.27485116e-04 -1.10324041e-04]]\n",
      "New_weights\n",
      "[[ 0.01444692 -0.01704224  0.05073533 -0.0129249  -0.00896795 -0.01449987\n",
      "  -0.02143932 -0.01578525  0.01278418  0.00246185]\n",
      " [ 0.00114735  0.0108321  -0.01177184 -0.02944972  0.026881   -0.02293361\n",
      "  -0.0098561   0.02677396 -0.02861263  0.01421702]\n",
      " [-0.0056348   0.02481386  0.01070071  0.0162123  -0.0409843   0.03453413\n",
      "   0.0119207   0.02502494  0.01962335 -0.00131734]\n",
      " [-0.00260693 -0.0468377  -0.02977221 -0.00502483  0.01347048 -0.01538714\n",
      "  -0.01893769 -0.02316292  0.00063898  0.00439414]\n",
      " [-0.04248657  0.00473576  0.00421661  0.03754023 -0.02093058  0.0490623\n",
      "   0.02053452 -0.00579275  0.01048597 -0.01107155]\n",
      " [ 0.00511106 -0.01000122  0.00438579  0.00200084  0.00636148  0.00767915\n",
      "   0.01296307  0.00223775  0.00444261 -0.00544645]\n",
      " [ 0.02421886 -0.00373358  0.0294641  -0.03312676  0.04126235  0.0193377\n",
      "   0.00214464 -0.01452119  0.03759389 -0.03752727]\n",
      " [-0.00889404  0.00543593  0.03837244  0.00863623  0.00211631  0.00966072\n",
      "  -0.00654533 -0.00663921  0.01747879  0.00655218]\n",
      " [-0.04110463 -0.02184861  0.05264453  0.00442444  0.10466044 -0.03900812\n",
      "  -0.03270597 -0.01097521 -0.07273696  0.01329946]\n",
      " [-0.00405128  0.04766027  0.01550444  0.02782784  0.00879147 -0.01119883\n",
      "   0.01978086  0.02086895 -0.02159958 -0.02104908]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.         0.         0.         ... 0.25384893 0.         0.02309058]\n",
      " [0.         0.         0.         ... 0.         0.         0.01401868]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.02130586]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.         0.         0.12305244 ... 0.         0.         0.4940914 ]\n",
      " [0.         0.         0.27544285 ... 0.96151475 0.44797219 0.32921751]\n",
      " [0.         0.         0.         ... 0.         0.07803508 0.        ]\n",
      " ...\n",
      " [0.14063544 0.         0.         ... 0.         0.20514512 0.        ]\n",
      " [0.         0.1895526  0.         ... 0.         0.         0.40774607]\n",
      " [0.         0.         2.34257174 ... 0.         0.         3.33582291]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[-1.24753487 -1.50836359  1.57505789  0.83809215 -0.69374389 -1.32794433\n",
      " -0.31241651  0.73735525 -0.58004319  0.29600877]\n",
      "Output layer\n",
      "[[0.         0.         0.         0.         0.         0.20165054\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.55107054]\n",
      " [0.         0.         0.         0.         0.         0.44268434\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.1101749  0.15441924\n",
      "  0.         0.         0.         2.42057982]\n",
      " [0.66231784 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         5.77404061 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.93967993 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Sums to 1: \n",
      "0.20165054363624946\n",
      "At least one output is closer to 1: \n",
      "6.697340017719799\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22612.823230913502\n",
      "()\n",
      "Backward pass epoch 1\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[ 0.01450908 -0.01698074  0.0504582  -0.01203517 -0.00951934 -0.01512579\n",
      "  -0.02142999 -0.01673489  0.01405805  0.00196497]\n",
      " [ 0.00124426  0.01112514 -0.0110553  -0.0288671   0.02638187 -0.0228908\n",
      "  -0.01024047  0.02623444 -0.02785558  0.013361  ]\n",
      " [-0.00683724  0.02358528  0.00992357  0.01643128 -0.04179189  0.03342803\n",
      "   0.01247516  0.02483633  0.01917674 -0.00146521]\n",
      " [-0.00300258 -0.04649978 -0.02947636 -0.00540241  0.01324005 -0.0146998\n",
      "  -0.01921772 -0.02241705  0.00095701  0.0036805 ]\n",
      " [-0.04263461  0.00390434  0.00440911  0.03760891 -0.02026968  0.05064316\n",
      "   0.02020879 -0.00580184  0.01023094 -0.01153065]\n",
      " [ 0.00463273 -0.00911149  0.00522787  0.00239019  0.0053273   0.00782219\n",
      "   0.0129727   0.00146494  0.00451347 -0.00670672]\n",
      " [ 0.02430888 -0.00444929  0.02949581 -0.03290088  0.04074113  0.01897319\n",
      "   0.00189297 -0.0150338   0.03692183 -0.03706914]\n",
      " [-0.0093291   0.00563769  0.03867025  0.00881682  0.00210098  0.01092073\n",
      "  -0.00601323 -0.00649465  0.01710259  0.00726506]\n",
      " [-0.04017322 -0.02179109  0.05239895  0.00574805  0.10534504 -0.03761923\n",
      "  -0.03368652 -0.01067186 -0.07288661  0.01304352]\n",
      " [-0.0045871   0.04663113  0.01513281  0.0278156   0.00987202 -0.01065052\n",
      "   0.01996182  0.02128714 -0.02137209 -0.0211594 ]]\n",
      "New_weights\n",
      "[[ 4.75924676e-01  3.57268115e+00 -2.39715546e+00  8.86185808e-02\n",
      "   1.74556987e+00 -1.28814140e+00  1.18638984e+00  1.09048568e+00\n",
      "  -2.39040649e+00 -3.97455570e+00]\n",
      " [ 2.61135173e+00  9.57885228e-01  2.21484148e-01  3.42760226e+00\n",
      "  -6.88888407e-01  5.93360301e-01  1.80798789e+00 -4.30717587e-01\n",
      "  -2.76440603e-01  1.59950695e+00]\n",
      " [ 1.95273589e+01 -1.54514477e+01 -3.12088903e+01  7.48456600e+00\n",
      "   3.71175599e+00 -5.22088728e+00 -4.03597111e+01  1.21225404e+01\n",
      "   1.28981863e+01  1.13831138e+00]\n",
      " [ 9.85461375e+00  1.66357471e-01  1.00835830e+01  7.27669096e+00\n",
      "  -1.28911676e+01  1.10160538e+01  7.31686454e+00 -3.32003333e+00\n",
      "   4.05506450e+00  1.08695357e+01]\n",
      " [ 2.51146851e+01  3.25771219e+01  6.57760023e+00  5.04065707e+00\n",
      "  -4.42874316e-01 -4.18463329e+00 -3.07724999e+00 -2.02499143e+00\n",
      "   1.42324449e+01 -7.07998907e-01]\n",
      " [ 7.75992481e-01 -3.26349203e-01  7.26625951e-01 -7.08196556e-01\n",
      "  -2.14608682e+00  3.11092761e-01 -1.69166226e+00 -1.91556329e+00\n",
      "   5.33850856e-03  3.99068784e+00]\n",
      " [ 7.15187257e-01 -1.58533179e+00  3.36488840e+00  5.09832642e+00\n",
      "  -1.48819914e+01 -3.73333789e+00 -5.11888086e+00  3.50485923e+00\n",
      "   2.79724660e+00 -1.06458873e+00]\n",
      " [ 1.71026930e+00  1.86496585e+00 -3.05650993e-01 -8.69702526e+00\n",
      "   9.79811046e-01 -2.43567720e+00 -4.10055752e+00 -7.92820663e-01\n",
      "   7.82949681e+00  1.55814556e+00]\n",
      " [ 6.70034276e+00  1.86936712e+01 -3.12361439e+01 -2.32460454e+01\n",
      "  -3.55650804e+01  2.58664119e+01 -9.00952032e+00  6.42740188e+00\n",
      "   7.46624543e+00  4.50400277e-01]\n",
      " [ 1.17303846e+01 -4.22340059e+00 -4.93672275e+00  1.41435868e+01\n",
      "   5.96862008e+00 -4.54049612e+00  1.31290358e+01  4.24379713e-02\n",
      "   2.22038927e+00  1.63196358e+01]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[     0.          12153.07002385      0.         ...   4161.06879894\n",
      "  116088.95325086      0.        ]\n",
      " [     0.           9009.47562205      0.         ...  12569.44151004\n",
      "  114638.34360678      0.        ]\n",
      " [     0.              0.          34780.86619262 ... 175976.38995215\n",
      "       0.              0.        ]\n",
      " ...\n",
      " [     0.              0.          67460.48493826 ... 166082.31303289\n",
      "       0.              0.        ]\n",
      " [     0.          14266.12918089      0.         ...      0.\n",
      "  151415.45613813      0.        ]\n",
      " [     0.              0.           4292.19251672 ...  13889.36496331\n",
      "    3818.34024161      0.        ]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 1.18181746e+08  1.01550481e+08  2.04810969e+07  2.85910490e+07\n",
      " -3.06343333e+07  5.41538066e+07  8.91043359e+06 -6.60974849e+06\n",
      "  1.33190534e+08 -5.10147254e+06]\n",
      "Output layer\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "10.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 24453.45371459678\n",
      "()\n",
      "Backward pass epoch 2\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[ 4.90433758e-01  3.55570041e+00 -2.34669726e+00  7.65834149e-02\n",
      "   1.73605054e+00 -1.30326719e+00  1.16495986e+00  1.07375079e+00\n",
      "  -2.37634844e+00 -3.97259073e+00]\n",
      " [ 2.61259599e+00  9.69010368e-01  2.10428852e-01  3.39873515e+00\n",
      "  -6.62506534e-01  5.70469501e-01  1.79774742e+00 -4.04483146e-01\n",
      "  -3.04296179e-01  1.61286796e+00]\n",
      " [ 1.95205217e+01 -1.54278624e+01 -3.11989668e+01  7.50099728e+00\n",
      "   3.66996410e+00 -5.18745926e+00 -4.03472360e+01  1.21473768e+01\n",
      "   1.29173630e+01  1.13684618e+00]\n",
      " [ 9.85161117e+00  1.19857691e-01  1.00541066e+01  7.27128855e+00\n",
      "  -1.28779276e+01  1.10013540e+01  7.29764682e+00 -3.34245038e+00\n",
      "   4.05602152e+00  1.08732162e+01]\n",
      " [ 2.50720505e+01  3.25810263e+01  6.58200934e+00  5.07826598e+00\n",
      "  -4.63143994e-01 -4.13399013e+00 -3.05704120e+00 -2.03079327e+00\n",
      "   1.42426759e+01 -7.19529559e-01]\n",
      " [ 7.80625212e-01 -3.35460694e-01  7.31853824e-01 -7.05806363e-01\n",
      "  -2.14075952e+00  3.18914947e-01 -1.67868956e+00 -1.91409835e+00\n",
      "   9.85197994e-03  3.98398113e+00]\n",
      " [ 7.39496139e-01 -1.58978109e+00  3.39438422e+00  5.06542554e+00\n",
      "  -1.48412503e+01 -3.71436470e+00 -5.11698789e+00  3.48982543e+00\n",
      "   2.83416843e+00 -1.10165788e+00]\n",
      " [ 1.70094020e+00  1.87060354e+00 -2.66980738e-01 -8.68820844e+00\n",
      "   9.81912028e-01 -2.42475646e+00 -4.10657074e+00 -7.99315311e-01\n",
      "   7.84659940e+00  1.56541062e+00]\n",
      " [ 6.66016954e+00  1.86718801e+01 -3.11837449e+01 -2.32402974e+01\n",
      "  -3.54597354e+01  2.58287927e+01 -9.04320683e+00  6.41673002e+00\n",
      "   7.39335882e+00  4.63443801e-01]\n",
      " [ 1.17257975e+01 -4.17676946e+00 -4.92158994e+00  1.41714024e+01\n",
      "   5.97849210e+00 -4.55114664e+00  1.31489976e+01  6.37251126e-02\n",
      "   2.19901718e+00  1.62984764e+01]]\n",
      "New_weights\n",
      "[[ -241521.34373445  -787755.24359091    60966.41308171    88868.65386076\n",
      "    104115.22523798  -701707.71339716   212840.76645711   -88057.15817037\n",
      "    203518.30850456   114036.51036841]\n",
      " [  138696.34671195  -306226.82215644   105538.58883992    64318.56924973\n",
      "     36778.09411273  -367650.36301269    73770.07409269    43679.03797946\n",
      "     41065.65345744   152710.4844081 ]\n",
      " [ -674289.28997769  -563077.79505454  1394268.54367204 -1072319.57828918\n",
      "    185218.54330596  -788849.77843496   320619.57083052   451651.14601599\n",
      "   -259917.98827022   384158.37025887]\n",
      " [ 1816828.30520735 -5295315.3633671    206324.41416326 -4357040.50158335\n",
      "   1309025.47465333   875434.19705454  2063553.75561952  1374243.24393069\n",
      "  -5244454.84113683   764102.18014441]\n",
      " [  643130.1339268    169254.27734271  1463124.86916589   897826.54587725\n",
      "    198369.6845469    707991.00834372   758253.0954198   -928556.24129734\n",
      "    335060.05448602   183152.50674472]\n",
      " [ -928285.10885737  -137863.11911633   323504.22691494   236785.13103374\n",
      "    339269.69091531  -324726.48521195   108407.0680422   -472772.60738919\n",
      "    130036.6432125    223789.57624847]\n",
      " [ -429139.75252581   298391.16137395    30187.50448538   423298.87520977\n",
      "     27337.33107454    80796.73209232   354610.07198077 -1115235.97670317\n",
      "   -273831.73976756   223409.73572311]\n",
      " [  158848.3957647    416740.13301562    68485.3778504    317616.57052108\n",
      "    381153.32105404   163574.39594454   230248.69321116    83892.096287\n",
      "     12489.50576756   245715.01072622]\n",
      " [ 3308336.87256031 -4797012.10669437   932498.87577277  2834735.42295906\n",
      "   1027530.90585471 -6440021.89744689   869446.43400561  1747269.09288785\n",
      "    166287.00015318   998836.87524189]\n",
      " [ 1241439.00584938 -5811122.0355009   1225027.78685219  2204998.33736354\n",
      "    951422.25552835  1133711.69888744  1158639.16671812   330575.63689294\n",
      "   1197429.10921042   549151.1233987 ]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.19989006e+12 1.50207906e+12 0.00000000e+00 ... 1.75813662e+14\n",
      "  1.08770691e+12 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 9.53759809e+13 1.35677739e+15 ... 0.00000000e+00\n",
      "  9.60594966e+13 0.00000000e+00]\n",
      " [0.00000000e+00 1.03389600e+14 1.47077566e+15 ... 0.00000000e+00\n",
      "  1.04130545e+14 0.00000000e+00]\n",
      " [6.65737642e+09 5.49679224e+09 0.00000000e+00 ... 5.45638918e+10\n",
      "  0.00000000e+00 1.19330655e+11]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "10.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 23168.611325706148\n",
      "()\n",
      "Backward pass epoch 3\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[ -241520.8533007   -787751.6878905     60964.06638444    88868.73044417\n",
      "    104116.96128852  -701709.01666435   212841.93141696   -88056.08441958\n",
      "    203515.93215612   114032.53777768]\n",
      " [  138698.95930794  -306225.85314607   105538.79926878    64321.96798489\n",
      "     36777.43160619  -367649.79254319    73771.87184011    43678.63349631\n",
      "     41065.34916126   152712.09727606]\n",
      " [ -674269.769456    -563093.22291696  1394237.34470529 -1072312.0772919\n",
      "    185222.21327006  -788854.96589422   320579.22359453   451663.29339275\n",
      "   -259905.07090722   384159.50710505]\n",
      " [ 1816838.15681852 -5295315.24350941   206334.46826989 -4357033.23029479\n",
      "   1309012.59672575   875445.19840857  2063561.05326634  1374239.90148031\n",
      "  -5244450.78511531   764113.05336057]\n",
      " [  643155.20597729   169286.85836897  1463131.45117523   897831.62414323\n",
      "    198369.22140291   707986.87435359   758250.0383786   -928558.27209061\n",
      "    335074.29716188   183151.78721516]\n",
      " [ -928284.32823216  -137863.45457703   323504.95876876   236784.42522738\n",
      "    339267.55015579  -324726.16629701   108405.38935265  -472774.52148755\n",
      "    130036.65306448   223793.56022959]\n",
      " [ -429139.01302967   298389.57159286    30190.8988696    423303.94063531\n",
      "     27322.48982424    80793.01772762   354604.95499288 -1115232.48687774\n",
      "   -273828.90559913   223408.63406523]\n",
      " [  158850.0967049    416742.00361916    68485.11086966   317607.88231265\n",
      "    381154.30296607   163571.97118808   230244.58664042    83891.29697169\n",
      "     12497.35236696   245716.57613684]\n",
      " [ 3308343.53272985 -4796993.43481429   932467.69202782  2834712.18266171\n",
      "   1027495.44611935 -6439996.06865418   869437.39079878  1747275.50961787\n",
      "    166294.393512     998837.33868569]\n",
      " [ 1241450.7316469  -5811126.21227036  1225022.86526225  2205012.50876598\n",
      "    951428.23402044  1133707.1477408   1158652.31571571   330575.70061805\n",
      "   1197431.3082276    549167.42187514]]\n",
      "New_weights\n",
      "[[-1.02680680e+14  1.55464131e+13  1.18522869e+13  1.21785912e+13\n",
      "   2.05926000e+13  2.12777581e+13 -2.60454614e+14  2.35346129e+13\n",
      "   2.09586248e+13  2.10235003e+13]\n",
      " [ 3.97705236e+14  3.95324004e+14 -3.17313048e+15  7.82938769e+14\n",
      "   4.57005035e+14  7.36868105e+14 -6.71943072e+15  7.90392887e+14\n",
      "   1.27014293e+15  9.33631170e+12]\n",
      " [ 4.23958256e+15  1.51370317e+16 -4.78177055e+16  1.83500473e+14\n",
      "   7.17040957e+15  1.32923879e+14  8.53241480e+15  1.70552726e+16\n",
      "   2.06282736e+16  1.18579023e+16]\n",
      " [ 1.63527746e+10  1.00187000e+11  6.15291778e+10 -1.52917233e+11\n",
      "  -3.42996059e+11  5.39625518e+10 -0.00000000e+00  1.68106299e+10\n",
      "   5.72900508e+10  7.33044930e+09]\n",
      " [ 5.52633550e+06  1.02128568e+16  3.28619648e+16  2.23416399e+16\n",
      "   2.48508219e+16  2.03752081e+16  2.14997013e+16  7.35920723e+15\n",
      "   2.02562645e+16  3.74801622e+16]\n",
      " [ 6.22791422e+11 -4.21555409e+12  1.20367953e+12 -1.11345783e+10\n",
      "  -3.46000354e+12  3.70971662e+11  1.16582138e+12  9.28262452e+11\n",
      "   3.38193394e+09  3.68239797e+11]\n",
      " [-0.00000000e+00  5.04052739e+10  5.03265787e+10 -0.00000000e+00\n",
      "   8.11212368e+10  3.74446269e+10  5.06511789e+10  9.40789650e+09\n",
      "   3.30685665e+10  1.35698655e+10]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00  4.87352522e+13\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  4.57478579e+12\n",
      "   9.75505761e-06  1.92584004e+12]\n",
      " [ 1.87356966e+15  3.67418200e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377221e+14 -2.19246670e+15  3.56518178e+15\n",
      "   4.27914883e+15  2.26782526e+15]\n",
      " [ 5.52830747e+10  4.50715705e+14 -0.00000000e+00 -1.81546466e+15\n",
      "   4.15493548e+14  5.44000850e+14  1.41277932e+15  8.69680423e+14\n",
      "   1.19027424e+15  2.41042402e+14]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.68977682e+31 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.63821247e+31]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 2.21676592e+48  1.70804291e+48  1.11360954e+48  4.36192807e+47\n",
      "  2.19925519e+48  8.59143824e+47 -1.09649878e+49  3.56629591e+48\n",
      "  4.76706747e+48  3.52002445e+48]\n",
      "Output layer\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Sums to 1: \n",
      "10.0\n",
      "At least one output is closer to 1: \n",
      "10.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22961.37868233669\n",
      "()\n",
      "Backward pass epoch 4\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[-1.02680680e+14  1.55464123e+13  1.18522870e+13  1.21785913e+13\n",
      "   2.05926001e+13  2.12777574e+13 -2.60454614e+14  2.35346128e+13\n",
      "   2.09586250e+13  2.10235004e+13]\n",
      " [ 3.97705236e+14  3.95324003e+14 -3.17313048e+15  7.82938769e+14\n",
      "   4.57005035e+14  7.36868105e+14 -6.71943072e+15  7.90392887e+14\n",
      "   1.27014293e+15  9.33631185e+12]\n",
      " [ 4.23958256e+15  1.51370317e+16 -4.78177055e+16  1.83500472e+14\n",
      "   7.17040957e+15  1.32923878e+14  8.53241480e+15  1.70552726e+16\n",
      "   2.06282736e+16  1.18579023e+16]\n",
      " [ 1.63545914e+10  1.00181704e+11  6.15293841e+10 -1.52921590e+11\n",
      "  -3.42994750e+11  5.39634273e+10  2.06356105e+06  1.68120041e+10\n",
      "   5.72848063e+10  7.33121341e+09]\n",
      " [ 6.16949071e+06  1.02128568e+16  3.28619648e+16  2.23416399e+16\n",
      "   2.48508219e+16  2.03752081e+16  2.14997013e+16  7.35920723e+15\n",
      "   2.02562645e+16  3.74801622e+16]\n",
      " [ 6.22790494e+11 -4.21555423e+12  1.20367986e+12 -1.11343415e+10\n",
      "  -3.46000320e+12  3.70971337e+11  1.16582148e+12  9.28261979e+11\n",
      "   3.38206397e+09  3.68240021e+11]\n",
      " [-4.29139013e+05  5.04055723e+10  5.03266089e+10  4.23303941e+05\n",
      "   8.11212642e+10  3.74447077e+10  5.06515335e+10  9.40678126e+09\n",
      "   3.30682926e+10  1.35700889e+10]\n",
      " [ 1.58850097e+05  4.16742004e+05  6.84851109e+04  4.87352526e+13\n",
      "   3.81154303e+05  1.63571971e+05  2.30244587e+05  4.57478587e+12\n",
      "   1.24973524e+04  1.92584028e+12]\n",
      " [ 1.87356966e+15  3.67418200e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246670e+15  3.56518178e+15\n",
      "   4.27914883e+15  2.26782526e+15]\n",
      " [ 5.52843162e+10  4.50715699e+14  1.22502287e+06 -1.81546466e+15\n",
      "   4.15493549e+14  5.44000851e+14  1.41277932e+15  8.69680424e+14\n",
      "   1.19027424e+15  2.41042403e+14]]\n",
      "New_weights\n",
      "[[ 1.94999081e+07  1.43271459e+07  3.17659793e+07  6.63492068e+06\n",
      "   6.82229110e+06  2.69010400e+07  8.82983141e+06  8.72945439e+06\n",
      "  -7.33086799e+07 -8.25400194e+07]\n",
      " [ 1.24181365e+07  9.25738209e+06  6.03592350e+06  8.46133001e+06\n",
      "   4.88668366e+06  8.43097794e+06  6.62502963e+06 -1.74151914e+07\n",
      "  -0.00000000e+00  7.97983577e+06]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 7.91400217e+06  1.09339118e+07  2.42971890e+07 -0.00000000e+00\n",
      "   1.24049685e+07  9.06680142e+06  8.75915254e+06  1.54284144e+07\n",
      "   6.90618688e+06 -9.45613638e+07]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32 -0.00000000e+00  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 2.45521895e+07  7.93159037e+06  4.48770378e+06 -0.00000000e+00\n",
      "   1.11979570e+07 -0.00000000e+00  2.59226433e+07  5.20961814e+06\n",
      "  -4.65764952e+07  1.26370519e+07]\n",
      " [ 1.26449917e+06  3.05380324e+07  7.59398325e+06  1.52241877e+07\n",
      "  -2.09843329e+06 -5.72224609e+07  4.33547554e+06  1.17683516e+07\n",
      "  -1.90267542e+07  2.02013594e+07]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 2.32633528e+17 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.89707515e+17 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.41735709e+17 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 6.33845675e+17 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.26536181e+17 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.28080592e+17 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.67895572e+15 7.75610172e+14 0.00000000e+00 ... 6.52356183e+15\n",
      "  1.04447623e+15 5.34165231e+15]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "10.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22450.204828692033\n",
      "()\n",
      "Backward pass epoch 5\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[-1.02680660e+14  1.55464267e+13  1.18523187e+13  1.21785979e+13\n",
      "   2.05926070e+13  2.12777843e+13 -2.60454605e+14  2.35346216e+13\n",
      "   2.09585517e+13  2.10234179e+13]\n",
      " [ 3.97705249e+14  3.95324013e+14 -3.17313047e+15  7.82938778e+14\n",
      "   4.57005040e+14  7.36868113e+14 -6.71943072e+15  7.90392869e+14\n",
      "   1.27014293e+15  9.33631983e+12]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 1.63625054e+10  1.00192638e+11  6.15536813e+10 -1.52921590e+11\n",
      "  -3.42982345e+11  5.39724941e+10  1.08227136e+07  1.68274325e+10\n",
      "   5.72917125e+10  7.23665205e+09]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32  3.70971337e+11  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 1.87356968e+15  3.67418201e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246667e+15  3.56518179e+15\n",
      "   4.27914878e+15  2.26782528e+15]\n",
      " [ 5.52855807e+10  4.50715729e+14  8.81900611e+06 -1.81546464e+15\n",
      "   4.15493547e+14  5.44000794e+14  1.41277932e+15  8.69680435e+14\n",
      "   1.19027422e+15  2.41042423e+14]]\n",
      "New_weights\n",
      "[[ 9.31121846e+15  1.43157221e+16  1.90550029e+16  1.17297988e+16\n",
      "   5.11185578e+15  1.76152214e+16  1.00468963e+16  1.22539298e+16\n",
      "   8.08929864e+15  4.44248368e+15]\n",
      " [ 5.05696373e+15  3.64649822e+15  5.82418696e+15  2.78154884e+15\n",
      "   4.56103998e+15  7.29737224e+15  1.59993756e+16  1.11684948e+16\n",
      "   9.15708633e+15  1.81012172e+15]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 1.66409518e+27  3.37747256e+27  1.39271461e+28 -6.78270741e+28\n",
      "  -0.00000000e+00  5.95657368e+27  7.28390725e+27  7.29869191e+27\n",
      "   3.80951306e+27  2.61359866e+27]\n",
      " [ 1.73684949e+15 -0.00000000e+00  2.50528905e+15 -2.65369473e+16\n",
      "   8.12583965e+15  1.67145038e+15  4.87349151e+15  4.59554528e+15\n",
      "   5.70229948e+15  2.00096129e+15]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 6.73564988e+15 -5.88335622e+16  5.91273628e+15 -2.03062434e+16\n",
      "  -2.18486963e+16  6.76421383e+15  8.18016931e+15  2.14637632e+15\n",
      "   6.79141758e+15 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 1.55203776e+31  3.26666994e+31  1.67546171e+31 -1.33002245e+32\n",
      "   1.57642692e+31  1.17880963e+31  3.17872114e+31  3.98430264e+31\n",
      "   5.93987021e+31  2.55864510e+31]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 1.92273241e+51 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.04147571e+51 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.21687342e+51 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 2.50266421e+51 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.16783627e+51 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.45673135e+51 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "10.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22325.865242670356\n",
      "()\n",
      "Backward pass epoch 6\n",
      "%Shape of output derivative_error(1797, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[ 9.20853780e+15  1.43312685e+16  1.90668552e+16  1.17419774e+16\n",
      "   5.13244839e+15  1.76364991e+16  9.78644168e+15  1.22774644e+16\n",
      "   8.11025720e+15  4.46350710e+15]\n",
      " [ 5.45466898e+15  4.04182223e+15  2.65105649e+15  3.56448762e+15\n",
      "   5.01804502e+15  8.03424035e+15  9.27994488e+15  1.19588876e+16\n",
      "   1.04272293e+16  1.81945804e+15]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 1.66409518e+27  3.37747256e+27  1.39271461e+28 -6.78270741e+28\n",
      "  -3.42982345e+11  5.95657368e+27  7.28390725e+27  7.29869191e+27\n",
      "   3.80951306e+27  2.61359866e+27]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32  3.70971337e+11  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 1.87356968e+15  3.67418201e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246667e+15  3.56518179e+15\n",
      "   4.27914878e+15  2.26782528e+15]\n",
      " [ 1.55203776e+31  3.26666994e+31  1.67546171e+31 -1.33002245e+32\n",
      "   1.57642692e+31  1.17880963e+31  3.17872114e+31  3.98430264e+31\n",
      "   5.93987021e+31  2.55864510e+31]]\n",
      "New_weights\n",
      "[[-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 5.50270460e+84  1.07022572e+85 -6.21710682e+85  3.81113798e+84\n",
      "   1.95690867e+85  6.46849207e+84  1.44501389e+85  1.22904479e+85\n",
      "   6.22629886e+84  1.07803851e+85]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 9.48489406e+88  2.04964348e+89 -0.00000000e+00  3.82769178e+88\n",
      "  -0.00000000e+00  8.82714712e+88  1.06755860e+89  3.53501534e+88\n",
      "   4.90612526e+88  9.22870303e+88]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22339.68075222832\n",
      "()\n",
      "Backward pass epoch 7\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[ 9.20853780e+15  1.43312685e+16  1.90668552e+16  1.17419774e+16\n",
      "   5.13244839e+15  1.76364991e+16  9.78644168e+15  1.22774644e+16\n",
      "   8.11025720e+15  4.46350710e+15]\n",
      " [ 5.45466898e+15  4.04182223e+15  2.65105649e+15  3.56448762e+15\n",
      "   5.01804502e+15  8.03424035e+15  9.27994488e+15  1.19588876e+16\n",
      "   1.04272293e+16  1.81945804e+15]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 5.50270460e+84  1.07022572e+85 -6.21710682e+85  3.81113798e+84\n",
      "   1.95690867e+85  6.46849207e+84  1.44501389e+85  1.22904479e+85\n",
      "   6.22629886e+84  1.07803851e+85]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32  3.70971337e+11  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 1.87356968e+15  3.67418201e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246667e+15  3.56518179e+15\n",
      "   4.27914878e+15  2.26782528e+15]\n",
      " [ 9.48489406e+88  2.04964348e+89  1.67546171e+31  3.82769178e+88\n",
      "   1.57642692e+31  8.82714712e+88  1.06755860e+89  3.53501534e+88\n",
      "   4.90612526e+88  9.22870303e+88]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "3.0\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22408.758300018144\n",
      "()\n",
      "Backward pass epoch 8\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[ 9.20853780e+15  1.43312685e+16  1.90668552e+16  1.17419774e+16\n",
      "   5.13244839e+15  1.76364991e+16  9.78644168e+15  1.22774644e+16\n",
      "   8.11025720e+15  4.46350710e+15]\n",
      " [ 5.45466898e+15  4.04182223e+15  2.65105649e+15  3.56448762e+15\n",
      "   5.01804502e+15  8.03424035e+15  9.27994488e+15  1.19588876e+16\n",
      "   1.04272293e+16  1.81945804e+15]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 5.50270460e+84  1.07022572e+85 -6.21710682e+85  3.81113798e+84\n",
      "   1.95690867e+85  6.46849207e+84  1.44501389e+85  1.22904479e+85\n",
      "   6.22629886e+84  1.07803851e+85]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32  3.70971337e+11  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 1.87356968e+15  3.67418201e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246667e+15  3.56518179e+15\n",
      "   4.27914878e+15  2.26782528e+15]\n",
      " [ 9.48489406e+88  2.04964348e+89  1.67546171e+31  3.82769178e+88\n",
      "   1.57642692e+31  8.82714712e+88  1.06755860e+89  3.53501534e+88\n",
      "   4.90612526e+88  9.22870303e+88]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22270.603204438507\n",
      "()\n",
      "Backward pass epoch 9\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[ 9.20853780e+15  1.43312685e+16  1.90668552e+16  1.17419774e+16\n",
      "   5.13244839e+15  1.76364991e+16  9.78644168e+15  1.22774644e+16\n",
      "   8.11025720e+15  4.46350710e+15]\n",
      " [ 5.45466898e+15  4.04182223e+15  2.65105649e+15  3.56448762e+15\n",
      "   5.01804502e+15  8.03424035e+15  9.27994488e+15  1.19588876e+16\n",
      "   1.04272293e+16  1.81945804e+15]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 5.50270460e+84  1.07022572e+85 -6.21710682e+85  3.81113798e+84\n",
      "   1.95690867e+85  6.46849207e+84  1.44501389e+85  1.22904479e+85\n",
      "   6.22629886e+84  1.07803851e+85]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32  3.70971337e+11  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 1.87356968e+15  3.67418201e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246667e+15  3.56518179e+15\n",
      "   4.27914878e+15  2.26782528e+15]\n",
      " [ 9.48489406e+88  2.04964348e+89  1.67546171e+31  3.82769178e+88\n",
      "   1.57642692e+31  8.82714712e+88  1.06755860e+89  3.53501534e+88\n",
      "   4.90612526e+88  9.22870303e+88]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "10.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22325.86524267036\n",
      "()\n",
      "Backward pass epoch 10\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 10\n",
      "Old_weights\n",
      "[[ 9.20853780e+15  1.43312685e+16  1.90668552e+16  1.17419774e+16\n",
      "   5.13244839e+15  1.76364991e+16  9.78644168e+15  1.22774644e+16\n",
      "   8.11025720e+15  4.46350710e+15]\n",
      " [ 5.45466898e+15  4.04182223e+15  2.65105649e+15  3.56448762e+15\n",
      "   5.01804502e+15  8.03424035e+15  9.27994488e+15  1.19588876e+16\n",
      "   1.04272293e+16  1.81945804e+15]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 5.50270460e+84  1.07022572e+85 -6.21710682e+85  3.81113798e+84\n",
      "   1.95690867e+85  6.46849207e+84  1.44501389e+85  1.22904479e+85\n",
      "   6.22629886e+84  1.07803851e+85]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32  3.70971337e+11  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 1.87356968e+15  3.67418201e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246667e+15  3.56518179e+15\n",
      "   4.27914878e+15  2.26782528e+15]\n",
      " [ 9.48489406e+88  2.04964348e+89  1.67546171e+31  3.82769178e+88\n",
      "   1.57642692e+31  8.82714712e+88  1.06755860e+89  3.53501534e+88\n",
      "   4.90612526e+88  9.22870303e+88]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 1.19215919e+199 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 9.56850447e+198 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.13615894e+199 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 1.35854456e+199 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.35423684e+199 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.57123782e+199 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 11\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 11\n",
      "Old_weights\n",
      "[[ 9.20853780e+15  1.43312685e+16  1.90668552e+16  1.17419774e+16\n",
      "   5.13244839e+15  1.76364991e+16  9.78644168e+15  1.22774644e+16\n",
      "   8.11025720e+15  4.46350710e+15]\n",
      " [ 5.45466898e+15  4.04182223e+15  2.65105649e+15  3.56448762e+15\n",
      "   5.01804502e+15  8.03424035e+15  9.27994488e+15  1.19588876e+16\n",
      "   1.04272293e+16  1.81945804e+15]\n",
      " [ 1.71588326e+32  2.90049215e+32  2.14103191e+32  1.93994378e+32\n",
      "   2.91461064e+32  1.88566158e+32  5.13109628e+32 -3.37295695e+33\n",
      "  -1.01661889e+33 -1.58358245e+33]\n",
      " [ 5.50270460e+84  1.07022572e+85 -6.21710682e+85  3.81113798e+84\n",
      "   1.95690867e+85  6.46849207e+84  1.44501389e+85  1.22904479e+85\n",
      "   6.22629886e+84  1.07803851e+85]\n",
      " [ 1.22455379e+33  6.73556154e+32  2.57837781e+33  1.78508585e+33\n",
      "   2.01555343e+33  6.30138881e+32  2.07558443e+33  5.46201596e+33\n",
      "   1.01942640e+33 -3.10856326e+34]\n",
      " [ 1.09779408e+32  6.12876709e+31  2.46620735e+32  1.05687931e+32\n",
      "   1.31778418e+32  3.70971337e+11  4.29297199e+31  2.27833843e+32\n",
      "  -8.65240811e+32 -1.78548912e+32]\n",
      " [ 6.70611976e+32  2.73500384e+32  6.46712252e+32  9.73989765e+32\n",
      "   6.08048688e+32  4.31791293e+32  2.23851538e+32  8.82985027e+32\n",
      "   1.50048361e+32  2.79245875e+32]\n",
      " [ 2.02577197e+34  4.64187858e+34  3.08786601e+34  6.84280930e+31\n",
      "   3.96314563e+34  1.75065533e+34  3.86327967e+31  1.55327293e+34\n",
      "  -3.90923759e+32 -3.98561459e+34]\n",
      " [ 1.87356968e+15  3.67418201e+15 -3.49413862e+16 -1.21029053e+16\n",
      "  -1.71945962e+16  5.91377215e+14 -2.19246667e+15  3.56518179e+15\n",
      "   4.27914878e+15  2.26782528e+15]\n",
      " [ 9.48489406e+88  2.04964348e+89  1.67546171e+31  3.82769178e+88\n",
      "   1.57642692e+31  8.82714712e+88  1.06755860e+89  3.53501534e+88\n",
      "   4.90612526e+88  9.22870303e+88]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 12\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 12\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 13\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 13\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\4134175186.py:53: RuntimeWarning: invalid value encountered in multiply\n",
      "  return output * self.mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 14\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 14\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 15\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 15\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 16\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 16\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 17\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 17\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 18\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 18\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 19\n",
      "%Shape of output derivative_error(1797, 256)\n",
      "Update pass epoch 19\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.4, dropout_rate = 0.1, batch_size = 1, epochs = 20)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 128, 'relu', 'hidden')\n",
    "model.addLayer(128, 256, 'relu', 'hidden')\n",
    "model.addLayer(256, 10, 'softmax', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 1)\n"
     ]
    }
   ],
   "source": [
    "y.shape\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Sigmoid\n",
      "(569, 30)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[2.21613348 0.         0.         ... 3.72311489 0.         0.94676015]\n",
      " [3.7304495  0.         0.         ... 4.03361165 0.         0.65290222]\n",
      " [3.39051892 0.         0.         ... 3.43332559 0.         0.54207312]\n",
      " ...\n",
      " [2.51239161 0.         0.         ... 2.24068313 0.         0.26618449]\n",
      " [3.52647021 0.         0.         ... 3.62733276 0.         0.55609423]\n",
      " [0.46854619 0.         0.         ... 0.39847489 0.         0.03991069]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-0.06098279]\n",
      "Output layer\n",
      "[[0.48475902]\n",
      " [0.48628978]\n",
      " [0.48780721]\n",
      " [0.49560722]\n",
      " [0.48897652]\n",
      " [0.4944544 ]\n",
      " [0.48854531]\n",
      " [0.49326304]\n",
      " [0.4945327 ]\n",
      " [0.49472082]]\n",
      "Sums to 1: \n",
      "0.48475902439676466\n",
      "At least one output is closer to 1: \n",
      "0.4984540518173882\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.4400324460485686\n",
      "()\n",
      "Backward pass epoch 0\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[-0.00038111]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.00024587]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 1\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 2\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 3\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 4\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 5\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 6\n",
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 7\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 8\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 9\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 10\n",
      "Update pass epoch 10\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 11\n",
      "Update pass epoch 11\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 12\n",
      "Update pass epoch 12\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 13\n",
      "Update pass epoch 13\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 14\n",
      "Update pass epoch 14\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 15\n",
      "Update pass epoch 15\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 16\n",
      "Update pass epoch 16\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 17\n",
      "Update pass epoch 17\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 18\n",
      "Update pass epoch 18\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 19\n",
      "Update pass epoch 19\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 20\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 20\n",
      "Update pass epoch 20\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 21\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 21\n",
      "Update pass epoch 21\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 22\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 22\n",
      "Update pass epoch 22\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 23\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 23\n",
      "Update pass epoch 23\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 24\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 24\n",
      "Update pass epoch 24\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 25\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 25\n",
      "Update pass epoch 25\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 26\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 26\n",
      "Update pass epoch 26\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 27\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 27\n",
      "Update pass epoch 27\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 28\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 28\n",
      "Update pass epoch 28\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 29\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 29\n",
      "Update pass epoch 29\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 30\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 30\n",
      "Update pass epoch 30\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 31\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 31\n",
      "Update pass epoch 31\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 32\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 32\n",
      "Update pass epoch 32\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 33\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 33\n",
      "Update pass epoch 33\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 34\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 34\n",
      "Update pass epoch 34\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 35\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 35\n",
      "Update pass epoch 35\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 36\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 36\n",
      "Update pass epoch 36\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 37\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 37\n",
      "Update pass epoch 37\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 38\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 38\n",
      "Update pass epoch 38\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 39\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 39\n",
      "Update pass epoch 39\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 40\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 40\n",
      "Update pass epoch 40\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 41\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 41\n",
      "Update pass epoch 41\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 42\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 42\n",
      "Update pass epoch 42\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 43\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 43\n",
      "Update pass epoch 43\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 44\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 44\n",
      "Update pass epoch 44\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 45\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 45\n",
      "Update pass epoch 45\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 46\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 46\n",
      "Update pass epoch 46\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 47\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 47\n",
      "Update pass epoch 47\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 48\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 48\n",
      "Update pass epoch 48\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 49\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 49\n",
      "Update pass epoch 49\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\3075896579.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\971627139.py:42: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\971627139.py:42: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.01, dropout_rate = 0, batch_size = 1, epochs = 50)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 1, 'sigmoid', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e - Implement optimizer\n",
    "Implement any two optimizers of your choice. Briefly present the optimizers \n",
    "in the report. The optimizers can be flavours of gradient descent. For \n",
    "instance: Stochastic gradient descent (SGD) and SGD with momentum. \n",
    "SGD and mini-batch gradient descent, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f - Evaluate different neural network architectures/parameters, present and discuss your results.\n",
    "Be creative in the analysis and discussion. Evaluate different\n",
    "hyperparameters. For instance: different network architectures, activation \n",
    "functions, comparison of optimizers, L1/L2 performance comparison with \n",
    "dropout, etc. Support your results with plots/graph and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
