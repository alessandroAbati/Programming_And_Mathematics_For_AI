{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Mathematics for AI - coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The task is about classification on the MNIST dataset. \n",
    "You can use other APIâ€™s/libraries for loading the dataset, but not for the neural network \n",
    "implementation. The point of this task is to develop a multi-layer neural network for \n",
    "classification using numpy. The task requires following sub-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Implement sigmoid and ReLU layers\n",
    "For this sub-task, you should implement forward and backward pass for \n",
    "sigmoid and ReLU. You should consider presenting these activation\n",
    "functions in the report with any pros cons if they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLu(x):\n",
    "    '''\n",
    "    Implementation of reLu function.\n",
    "    '''\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Implementation of Sigmoid function.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Implementation of Softmax function\n",
    "    '''\n",
    "    normalization = np.sum(np.exp(x))\n",
    "    return [np.exp(el)/normalization for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ReLU activation function')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, reLu(x))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.title(\"ReLU activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2657c1750>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2659e4710>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, softmax(x))\n",
    "# How do I test my implementation of the softmax function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.input = x # store the input to use it in the backward pass\n",
    "        return np.maximum(0, x)  # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return np.where(self.input > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "* Advatages:\n",
    "    - No saturation of neurons (at least for positive values)\n",
    "    - Converge fast\n",
    "    - Computationally efficent (very simple to calculate, both the reLu and its derivative)\n",
    "\n",
    "* Disadvantages:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('gradient_values'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        \n",
    "        sigmoid_derivative = np.multiply(self.output, (1 - self.output)) # calculate the derivative of Sigmoid: f(x) * (1 - f(x)) where f(x) is the Sigmoid function\n",
    "        return sigmoid_derivative  # multiply the gradient of the loss function by the derivative of Sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note - __Sigmoid Problem__:\n",
    "\n",
    "Vanishing gradient and saturation of neurons:\n",
    "the sigmoid function usually have the output very close to zero or one and in this region the derivative of the sigmoid is very small, meaning that the (local) gradient will be small and the network will now learn efficently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - Implement softmax layer\n",
    "Implement softmax with both forward and backward pass. Present the \n",
    "softmax in the report along with any numerical issues when calculating the \n",
    "softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'x', with the\n",
    "                         same shape as 'x'.\n",
    "        '''        \n",
    "#         x = np.asarray(x)\n",
    "# #         print (\"Shape of inputs {}\".format(x.shape))\n",
    "# #         print(np.max(x))\n",
    "#         reg = x - np.max(x)\n",
    "# #         print(\"Reg:\")\n",
    "# #         print(reg[0])\n",
    "# #         e_x = np.exp(reg)\n",
    "#         e_x = np.clip(np.exp(reg), 0.000001, 1-0.000001)\n",
    "\n",
    "# #         print(\"Exp:\")\n",
    "# #         print(e_x[0])\n",
    "# #         print(\"Max exp\")\n",
    "# #         print(np.max(e_x))\n",
    "#         exp_sum = np.sum(e_x, axis=-1, keepdims = True)\n",
    "# #         exp_sum = np.clip(exp_sum, 0.000001, 1-0.000001)\n",
    "# #         print(exp_sum[0])\n",
    "# #         print(\"Max sum\")\n",
    "# #         print(np.max(exp_sum))\n",
    "        \n",
    "#         return e_x / exp_sum\n",
    "\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "        self.output = e_x / np.sum(e_x, axis=1, keepdims = True)\n",
    "        return self.output\n",
    "#         e_x = np.exp(x - np.max(x, axis=-1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "#         self.output = e_x / np.sum(e_x) # apply the softmax function: f(xi) = exp(xi) / sum(exp(x)) for x=[x1,...,xK]\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        # Gradient values not used -> Remove!!\n",
    "        softmax_jacobian = self.output * (np.eye(self.output.shape[0]) - self.output.T)\n",
    "        #print(softmax_jacobian)\n",
    "        print(softmax_jacobian.shape)\n",
    "        return softmax_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    weights = 0\n",
    "    new_weights = 0\n",
    "    bias = 0\n",
    "    activation = 0\n",
    "    layer_input = 0\n",
    "    softmax = False\n",
    "    \n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        # Weight initialisation crucial for performance\n",
    "        #self.weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        #self.new_weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        self.weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.new_weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.layer_input = 0\n",
    "        self.bias = 0\n",
    "        self.softmax = False\n",
    "        self.dropout_rate = dropout_rate\n",
    "        '''\n",
    "        Set activation function for the layer\n",
    "        '''   \n",
    "        if activation == 'relu':\n",
    "            print(\"ReLU\")\n",
    "            self.activation = ReLu()\n",
    "        elif activation == 'sigmoid':\n",
    "            print(\"Sigmoid\")\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'softmax':\n",
    "            print(\"Softmax\")\n",
    "            self.softmax = True\n",
    "            self.activation = Softmax()\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Weights combined with input and bias\n",
    "        '''\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        '''\n",
    "        Pass z through activation function\n",
    "        '''\n",
    "        output = self.activation.forward_pass(z)\n",
    "        mask = 1\n",
    "        if (self.dropout_rate != 0):\n",
    "            mask = (np.random.rand(output.shape) < self.dropout_rate) / self.dropout_rate\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        print(\"Output of hidden layer\")\n",
    "        print(output)\n",
    "        return output * mask\n",
    "        \n",
    "    '''\n",
    "    Idea is to have backward pass for activation functions just return the derivative of the activation,\n",
    "    and backward_pass for layer perform any other calculation (dot product of activation function with loss for example)\n",
    "    '''   \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            derivative_final = np.multiply(x, activation_derivative)\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = - (learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "#         print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        self.weights += self.new_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass of layer\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        super().__init__(output_units, input_units, activation, dropout_rate)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        return x\n",
    "    \n",
    "    # No weights in input layer\n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print(\"Last backwards pass layer\")\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"End of Backwards pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        super().__init__(output_units, input_units, activation, dropout_rate)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        print(\"Weights and biases\")\n",
    "        print(z[0])\n",
    "        output = self.activation.forward_pass(z)\n",
    "        mask = 1\n",
    "        if (self.dropout_rate != 0):\n",
    "            mask = (np.random.rand(output.shape) < self.dropout_rate) / self.dropout_rate\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output*mask\n",
    "    \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            activation_derivative = self.activation.backward_pass(x)\n",
    "            derivative_final = np.multiply(x, activation_derivative)\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = - (learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "        print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def mse_loss(self, output, target):\n",
    "        loss = 1/len(output)*np.sum((output-target)**2)\n",
    "        return loss\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"Old_weights\")\n",
    "        print(self.weights[:10])\n",
    "        print(\"New_weights\")\n",
    "        print(self.new_weights[:10])\n",
    "        self.weights += self.new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY\n",
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "prediction = softmax.forward_pass(x)\n",
    "loss = np.sum((prediction - y) ** 2)\n",
    "loss_derivative = (prediction -y)\n",
    "prediction, loss, np.sum(prediction)\n",
    "loss_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_derivative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient_softmax = softmax.backward_pass(loss_derivative.T, learning_rate)\n",
    "#gradient_softmax.shape, gradient_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - Implement dropout \n",
    "Present dropout in the report. Implement inverted dropout. Forward and \n",
    "backward pass should be implemented.\n",
    "Note: Since the test performance is critical, it is also preferable to leaving \n",
    "the forward pass unchanged at test time. Therefore, in most \n",
    "implementations inverted dropout is employed to overcome the \n",
    "undesirable property of the original dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of \n",
    "hidden layers, units, activation functions can be changed. In addition, you \n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used \n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots \n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "    A class representing the Fully Parametrizable Neural Network.\n",
    "    '''\n",
    "    layer_list = []\n",
    "    X = 0\n",
    "    Y = 0\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 8\n",
    "    epochs = 100   \n",
    "    loss_history = []\n",
    "    \n",
    "    def __init__(self, X, Y, learning_rate, dropout_rate = 0, batch_size = 4, epochs = 10):\n",
    "        self.layer_list = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def addLayer(self, input_units, output_units, activation, mode = \"input\"):\n",
    "        if mode == \"input\":\n",
    "            print(\"Added input\")\n",
    "            layer = InputLayer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        elif mode == \"output\":\n",
    "            print(\"Added output\")\n",
    "            layer = OutputLayer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        else:\n",
    "            print(\"Added hidden\")\n",
    "            layer = Layer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        self.layer_list.append(layer)\n",
    "        \n",
    "    def loss(self, output, target, mode):\n",
    "        if mode == \"mse\":\n",
    "            loss = 1/len(output)*np.sum((np.sum(output-target))**2)\n",
    "            return loss\n",
    "        elif mode == \"cross_entropy\":\n",
    "            output = np.clip(output, 0.000001, 1-0.000001)\n",
    "#             loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n",
    "            loss = -np.sum(target * np.log(output))\n",
    "            print(\"Cross Loss: {}\".format(loss))\n",
    "            print(loss.shape)\n",
    "            return loss\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            input_data = self.X\n",
    "            print(input_data.shape)\n",
    "            # Forward pass\n",
    "            print(\"Forward pass epoch {}\".format(i))\n",
    "            for index, layer in enumerate(self.layer_list):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                output_data = layer.forward_pass(input_data)\n",
    "                input_data = output_data\n",
    "                \n",
    "            # Calculate loss \n",
    "            #output_data = np.around(output_data, 6)\n",
    "            print(\"Output layer\")\n",
    "            print(output_data[:10])\n",
    "            print(\"Sums to 1: \")\n",
    "            print(np.sum(output_data[0]))\n",
    "            print(\"At least one output is closer to 1: \")\n",
    "            print(np.max(output_data))\n",
    "            # For softmax, not exactly 0 nor 1\n",
    "            print(\"Model output shape: {}\".format (output_data.shape))\n",
    "            print(\"Model target shape: {}\".format (self.Y.shape))\n",
    "            loss_cost = self.loss(output_data, self.Y, mode = \"cross_entropy\")\n",
    "#             loss_cost = np.around(loss_cost, 6)\n",
    "            self.loss_history.append(loss_cost)\n",
    "            #print(\"Loss: {}\".format(loss_cost))\n",
    "            \n",
    "            # Backward pass  \n",
    "            # MSE derivative\n",
    "#             input_derivative = (self.Y - output_data)\n",
    "            input_derivative = np.asarray(output_data - self.Y)\n",
    "            print(\"Backward pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                output_derivative = layer.backward_pass(input_derivative, self.learning_rate)\n",
    "                input_derivative = output_derivative\n",
    "                \n",
    "            # Update pass. Supposedly update weights after backward pass completed\n",
    "            # Weights barely updating??\n",
    "            print(\"Update pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                layer.update_weights(self.learning_rate)\n",
    "                                         \n",
    "    def predict(self, X):\n",
    "        input_data = X\n",
    "        for index, layer in enumerate(self.layer_list):\n",
    "            output_data = layer.forward_pass(input_data)\n",
    "            input_data = output_data\n",
    "        return output_data\n",
    "    \n",
    "    def show_loss(self):\n",
    "        plt.plot(self.loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY DATASET\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "dataset = load_digits()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Softmax\n",
      "(1797, 64)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.         0.10888241 0.         ... 0.08223022 0.11750173 0.05583994]\n",
      " [0.         0.01168312 0.0034765  ... 0.         0.00470197 0.10684088]\n",
      " [0.         0.06734214 0.02738469 ... 0.0030578  0.08528334 0.12762268]\n",
      " ...\n",
      " [0.         0.05662658 0.         ... 0.02752884 0.0239913  0.10225523]\n",
      " [0.00820122 0.0841763  0.         ... 0.04066404 0.05564451 0.06388078]\n",
      " [0.         0.06532674 0.01825462 ... 0.         0.02567017 0.08813149]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-9.77190091e-04 -6.49211856e-04 -9.92142770e-05 -8.19339957e-05\n",
      " -7.39567752e-04 -5.84468606e-04 -3.76128551e-04  9.31805813e-04\n",
      "  2.24516556e-04 -4.47317078e-04]\n",
      "Output layer\n",
      "[[0.09993028 0.09996306 0.10001805 0.10001978 0.09995403 0.09996953\n",
      "  0.09999036 0.10012123 0.10005044 0.09998324]\n",
      " [0.09998007 0.09994679 0.0999925  0.09995045 0.10000711 0.10002672\n",
      "  0.10003886 0.10008183 0.10000233 0.09997333]\n",
      " [0.0999201  0.09993636 0.10008385 0.09997352 0.10002674 0.09999449\n",
      "  0.09998898 0.10009813 0.09998257 0.09999526]\n",
      " [0.0999447  0.10000216 0.09997157 0.09996856 0.09999688 0.09997585\n",
      "  0.10002985 0.10012171 0.10003235 0.09995637]\n",
      " [0.09995879 0.09994211 0.0999899  0.09995582 0.0999978  0.10003106\n",
      "  0.09999413 0.1001034  0.10004679 0.09998019]\n",
      " [0.0999221  0.09996594 0.09995655 0.09998651 0.0999895  0.09999363\n",
      "  0.10002992 0.10013975 0.1000622  0.09995392]\n",
      " [0.09994679 0.09996103 0.10003318 0.09997698 0.09997619 0.10003426\n",
      "  0.10000486 0.10007773 0.0999832  0.10000579]\n",
      " [0.09999605 0.09991822 0.09997637 0.09999414 0.10001095 0.09996587\n",
      "  0.10003895 0.10007791 0.10008251 0.09993903]\n",
      " [0.09991341 0.09995246 0.1000479  0.09998891 0.09999413 0.0999505\n",
      "  0.10005243 0.10010897 0.10001419 0.0999771 ]\n",
      " [0.09995812 0.09995898 0.09996202 0.09998909 0.09996114 0.09998427\n",
      "  0.10006378 0.10011076 0.10007758 0.09993426]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.1002325179006317\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 4137.799392218531\n",
      "()\n",
      "Backward pass epoch 0\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[ 1.56413659e-04 -4.38305189e-04  2.38625940e-04  4.79549419e-04\n",
      "  -8.93486333e-04 -2.43524637e-04  1.55305856e-03  1.40971740e-04\n",
      "   1.08594968e-03 -1.35038027e-03]\n",
      " [-2.59183388e-03 -1.16002585e-04  2.08239517e-03  4.81307263e-04\n",
      "  -9.72458526e-04 -5.98019581e-04  5.00480356e-04  3.55738304e-03\n",
      "   1.24678583e-03 -8.49873096e-04]\n",
      " [-2.64361498e-04  1.02024243e-03  3.85509061e-04  3.94522394e-04\n",
      "   4.05552016e-04  6.81464364e-04 -7.53014007e-04  1.78575629e-03\n",
      "  -6.65179391e-05 -1.56320102e-03]\n",
      " [-2.11958072e-04  2.58646909e-03  8.64022019e-04  7.87490073e-04\n",
      "   6.93564618e-04 -3.33712704e-03  5.35148433e-04  3.35737726e-04\n",
      "  -6.77190607e-04  1.33598390e-03]\n",
      " [ 4.78791724e-04 -6.18805720e-04 -3.53795282e-04  8.46784818e-04\n",
      "  -1.50516851e-03 -2.10786027e-03  1.82475271e-03 -3.59950550e-04\n",
      "   2.21519081e-07  7.03908891e-04]\n",
      " [-1.06715900e-04 -1.34662042e-05 -2.20088220e-03 -1.18094486e-03\n",
      "  -1.51435778e-05 -9.37319445e-04 -2.25608913e-03  1.02354306e-03\n",
      "   1.28299346e-03 -4.05887431e-04]\n",
      " [ 4.47311806e-04 -3.61697113e-04  4.73073422e-04  2.21910182e-03\n",
      "   4.49775387e-04 -2.30975586e-03  8.15816525e-05  8.62647844e-04\n",
      "   3.05428700e-05  4.53459878e-04]\n",
      " [-4.08492299e-04  2.87614507e-04  1.36624309e-03 -1.01650452e-03\n",
      "   1.24662023e-04  5.89408247e-04  1.10049251e-03  1.15963373e-03\n",
      "   2.34111735e-04  1.00034687e-03]\n",
      " [ 6.12419225e-04  1.22038908e-03  5.78869466e-04  2.44484691e-04\n",
      "  -2.28508410e-03 -3.51105876e-04 -2.18719277e-03 -9.69340397e-04\n",
      "  -1.27758427e-04  2.71352527e-04]\n",
      " [-1.25842388e-03 -7.94390463e-04 -2.56549589e-03  4.31847736e-04\n",
      "  -1.77985047e-03 -1.48978325e-03  2.59433792e-03  4.13716139e-03\n",
      "  -4.40194788e-04 -3.34243274e-04]]\n",
      "New_weights\n",
      "[[-8.01929241e-02  3.08259021e-01 -1.28942280e-01 -5.73243866e-02\n",
      "   1.15962961e-01 -3.98998691e-02 -1.11987741e-01 -1.26685558e-01\n",
      "  -9.69968290e-02  2.17807606e-01]\n",
      " [ 4.68470412e-01 -5.77143026e-01  1.72539331e-01  2.57941761e-01\n",
      "  -5.27712038e-01 -2.63303914e-01 -5.91560896e-01  6.99177935e-02\n",
      "   1.24908517e-01  8.65942060e-01]\n",
      " [-1.25909187e-01  8.65812265e-02  8.74248778e-02  3.58950055e-01\n",
      "  -1.30250198e-01  3.75409307e-02 -1.22921787e-01 -1.31941224e-01\n",
      "  -5.50303214e-02 -4.44437225e-03]\n",
      " [-2.78468430e-01 -7.83074567e-01  7.69939354e-02  7.44341031e-01\n",
      "  -7.72865804e-01  3.81424432e-01 -1.78669773e-01  1.97790609e-01\n",
      "   3.71907937e-02  5.75337774e-01]\n",
      " [-1.25983827e-01 -9.97524834e-02 -4.08368796e-02 -9.23933872e-02\n",
      "   1.62168145e-01 -1.25697742e-01 -1.22716427e-01  6.00123849e-01\n",
      "  -1.08228034e-01 -4.66832148e-02]\n",
      " [-1.11855096e-01  1.42024178e-01  3.72833616e-04 -7.02109172e-02\n",
      "  -9.23212891e-02 -8.74502879e-02 -8.78871206e-02  4.09059078e-01\n",
      "   7.60810856e-03 -1.09339488e-01]\n",
      " [-3.92174110e-02 -8.67857669e-02 -3.63243978e-01 -3.13175805e-01\n",
      "   4.37072104e-01  5.83543050e-01 -3.18376327e-01  2.76229253e-01\n",
      "   7.09507811e-02 -2.46995902e-01]\n",
      " [-1.46357437e-01 -4.86076442e-01 -1.69800310e-01  2.88696816e-01\n",
      "  -8.38178109e-03  9.00594612e-02 -1.10233591e-01  3.32307012e-01\n",
      "  -5.32048525e-02  2.62991124e-01]\n",
      " [ 6.82996973e-01 -3.52978363e-01  2.38342770e-03 -6.29122714e-01\n",
      "   4.90362361e-01  2.89718741e-01  5.80855217e-01 -3.98238701e-01\n",
      "  -6.81295139e-02 -5.97847428e-01]\n",
      " [-9.05118992e-01  4.28688551e-01 -2.11129708e-01  5.36225077e-01\n",
      "  -9.06355291e-01  2.26553496e-02 -5.28979537e-01  3.66303074e-01\n",
      "   5.53098983e-01  6.44612492e-01]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[ 0.          0.          0.         ... 57.26693653  0.\n",
      "  30.02985178]\n",
      " [ 0.         40.77442046  6.14796109 ... 77.54325887  2.5493764\n",
      "  14.09974212]\n",
      " [ 0.         36.53019146  1.44029587 ... 76.08938225  0.\n",
      "  20.3547645 ]\n",
      " ...\n",
      " [ 0.         16.81141161  1.15191943 ... 88.95833395  0.\n",
      "  21.20518694]\n",
      " [ 0.          0.          0.         ... 74.90596906  0.\n",
      "  27.64442982]\n",
      " [ 0.          2.92468912  0.         ... 79.87299699  0.\n",
      "  23.03331881]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[  43.86110627    4.75228594 -145.28716333    8.07210664    1.84564078\n",
      "   35.7697694  -142.06414985   98.14356689  -16.49596066  110.42389815]\n",
      "Output layer\n",
      "[[1.23635951e-029 1.28055993e-046 8.83273141e-112 3.54143861e-045\n",
      "  6.99938616e-048 3.78548752e-033 2.21733847e-110 4.64213623e-006\n",
      "  7.57536671e-056 9.99995358e-001]\n",
      " [1.79881742e-058 2.25014828e-083 3.02025128e-147 2.57384469e-064\n",
      "  2.95094341e-060 2.77814258e-071 9.41977741e-150 2.44269898e-045\n",
      "  5.21840756e-078 1.00000000e+000]\n",
      " [5.96059373e-067 4.24470869e-094 2.33237177e-144 1.24104435e-060\n",
      "  1.07340664e-078 4.18260745e-075 1.37458752e-151 6.60787950e-039\n",
      "  8.82238782e-079 1.00000000e+000]\n",
      " [7.84581110e-034 4.64058832e-061 1.19249094e-117 5.56086285e-052\n",
      "  2.19309029e-068 1.82343650e-039 3.91467250e-115 2.65799679e-032\n",
      "  2.69245783e-062 1.00000000e+000]\n",
      " [1.38893704e-032 1.59389512e-036 3.20935508e-093 4.65373739e-035\n",
      "  9.78347042e-019 4.03658952e-034 1.34867555e-087 4.14955043e-009\n",
      "  7.41953788e-048 9.99999996e-001]\n",
      " [5.25720658e-047 2.18339579e-072 4.16523220e-154 1.02806119e-064\n",
      "  9.96389818e-081 1.21998155e-050 5.72038625e-146 1.76894406e-037\n",
      "  1.67984490e-082 1.00000000e+000]\n",
      " [4.60446834e-028 3.49772555e-043 2.14386886e-106 5.81695502e-042\n",
      "  2.92250377e-027 3.38380907e-032 5.01664868e-100 5.50726664e-011\n",
      "  2.65603576e-050 1.00000000e+000]\n",
      " [5.30400361e-090 5.82586932e-085 1.29244072e-145 2.37455580e-066\n",
      "  2.57202043e-092 1.08064264e-094 3.65631293e-179 5.57301551e-051\n",
      "  1.90834880e-078 1.00000000e+000]\n",
      " [6.56285832e-052 2.74866648e-082 3.82384423e-158 4.08319919e-069\n",
      "  6.75812076e-079 7.75754937e-061 2.28948336e-158 4.04301788e-035\n",
      "  5.35495439e-085 1.00000000e+000]\n",
      " [1.03507436e-046 8.53765286e-067 6.68967494e-146 3.67223817e-060\n",
      "  1.87258797e-071 2.01970780e-050 1.62159224e-142 1.10279844e-027\n",
      "  4.80418987e-080 1.00000000e+000]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22211.078849619345\n",
      "()\n",
      "Backward pass epoch 1\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[-0.08003651  0.30782072 -0.12870365 -0.05684484  0.11506947 -0.04014339\n",
      "  -0.11043468 -0.12654459 -0.09591088  0.21645723]\n",
      " [ 0.46587858 -0.57725903  0.17462173  0.25842307 -0.5286845  -0.26390193\n",
      "  -0.59106042  0.07347518  0.1261553   0.86509219]\n",
      " [-0.12617355  0.08760147  0.08781039  0.35934458 -0.12984465  0.0382224\n",
      "  -0.1236748  -0.13015547 -0.05509684 -0.00600757]\n",
      " [-0.27868039 -0.7804881   0.07785796  0.74512852 -0.77217224  0.3780873\n",
      "  -0.17813463  0.19812635  0.0365136   0.57667376]\n",
      " [-0.12550503 -0.10037129 -0.04119067 -0.0915466   0.16066298 -0.1278056\n",
      "  -0.12089167  0.5997639  -0.10822781 -0.04597931]\n",
      " [-0.11196181  0.14201071 -0.00182805 -0.07139186 -0.09233643 -0.08838761\n",
      "  -0.09014321  0.41008262  0.0088911  -0.10974537]\n",
      " [-0.0387701  -0.08714746 -0.3627709  -0.3109567   0.43752188  0.58123329\n",
      "  -0.31829475  0.2770919   0.07098132 -0.24654244]\n",
      " [-0.14676593 -0.48578883 -0.16843407  0.28768031 -0.00825712  0.09064887\n",
      "  -0.1091331   0.33346665 -0.05297074  0.26399147]\n",
      " [ 0.68360939 -0.35175797  0.0029623  -0.62887823  0.48807728  0.28936764\n",
      "   0.57866802 -0.39920804 -0.06825727 -0.59757608]\n",
      " [-0.90637742  0.42789416 -0.2136952   0.53665692 -0.90813514  0.02116557\n",
      "  -0.5263852   0.37044024  0.55265879  0.64427825]]\n",
      "New_weights\n",
      "[[-0.00000000e+000 -0.00000000e+000 -0.00000000e+000 -0.00000000e+000\n",
      "  -0.00000000e+000 -0.00000000e+000 -0.00000000e+000 -0.00000000e+000\n",
      "  -0.00000000e+000 -0.00000000e+000]\n",
      " [-2.07140579e-020  5.28667452e+002  6.73776422e+002  3.88902429e+002\n",
      "   7.26282672e+001  1.94720381e+002  1.58560153e+001  9.06928789e+002\n",
      "   3.60034734e+002 -3.14151449e+003]\n",
      " [-3.47395047e-023  6.13446604e+001  1.79253017e+001  5.04939170e+000\n",
      "   2.30086241e+001  3.34546165e+001  9.32908385e+000  7.54537035e+000\n",
      "   9.88734947e+000 -1.67544398e+002]\n",
      " [ 2.86169577e-001  2.81324157e+002  6.63073974e+001  2.54381361e+001\n",
      "   7.57257131e+001  1.48757495e-001  3.87655115e+001  1.46084182e+001\n",
      "   4.29936104e+001 -5.45597871e+002]\n",
      " [-0.00000000e+000 -0.00000000e+000 -0.00000000e+000 -0.00000000e+000\n",
      "  -0.00000000e+000 -0.00000000e+000 -0.00000000e+000 -0.00000000e+000\n",
      "  -0.00000000e+000 -0.00000000e+000]\n",
      " [ 7.02404168e+002  9.25188630e+002  6.85876203e+002  7.85110455e+002\n",
      "   9.07101985e+002  8.23026658e+002  6.63340381e+002  1.02027974e+003\n",
      "   9.07056413e+002 -7.41938464e+003]\n",
      " [-0.00000000e+000 -0.00000000e+000 -0.00000000e+000 -0.00000000e+000\n",
      "  -0.00000000e+000 -0.00000000e+000 -0.00000000e+000 -0.00000000e+000\n",
      "  -0.00000000e+000 -0.00000000e+000]\n",
      " [-1.74482918e-020  4.81149970e+001  3.05784777e+001  9.57931516e-002\n",
      "   2.43098317e+001  2.72883891e+001  4.38623851e+001  3.75910714e+001\n",
      "   5.28444025e+000 -2.17125385e+002]\n",
      " [-1.85324078e-020  4.86087424e-001  3.77470699e+001  1.21787718e+002\n",
      "  -3.45734693e-054  9.63084123e-001 -5.59129464e-101  1.24629019e-002\n",
      "   6.81430555e-001 -1.61677853e+002]\n",
      " [ 1.79140075e-001  6.22068976e+001  1.48255332e+001  3.04600311e+001\n",
      "   1.45938076e+002  2.18478505e+001  1.38953288e+002  6.17864363e+002\n",
      "   6.87830210e+001 -1.10105820e+003]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.18052293e+04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.08831517e+03 ... 7.88103418e+04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.10010639e+02 ... 8.15545481e+04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 3.68996595e+02 ... 9.91996921e+04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.38673753e+01 ... 8.50094805e+04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.73136287e+02 ... 9.33565078e+04\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[ 2.56516016e+08  3.14259447e+08  2.64376759e+08  2.72626429e+08\n",
      "  2.99271465e+08  2.93705326e+08  2.48203650e+08  3.03297535e+08\n",
      "  2.88020146e+08 -2.54027813e+09]\n",
      "Output layer\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22312.049733112395\n",
      "()\n",
      "Backward pass epoch 2\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [-1.26173548e-01  6.14322619e+01  1.80131121e+01  5.40873627e+00\n",
      "   2.28787794e+01  3.34928389e+01  9.20540905e+00  7.41521488e+00\n",
      "   9.83225263e+00 -1.67550406e+02]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.02292207e+02  9.25330641e+02  6.85874375e+02  7.85039063e+02\n",
      "   9.07009649e+02  8.22938270e+02  6.63250238e+02  1.02068983e+03\n",
      "   9.07065304e+02 -7.41949438e+03]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [ 6.83609392e-01  1.34329450e-01  3.77500322e+01  1.21158840e+02\n",
      "   4.88077277e-01  1.25245176e+00  5.78668025e-01 -3.86745139e-01\n",
      "   6.13173283e-01 -1.62275429e+02]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 4.59725881e+02 -1.03316150e+05  3.35662621e+04  2.62120228e+04\n",
      "   3.22611536e+02  1.40891804e+04  2.86158025e+02  2.55132356e+03\n",
      "   1.27479608e+04  1.30809046e+04]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 7.94632851e+05 -7.95732649e+06  8.90285566e+05  9.11743194e+05\n",
      "   8.69738957e+05  8.80105299e+05  8.36150607e+05  9.51823112e+05\n",
      "   9.56339539e+05  8.66507367e+05]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 2.43819189e+05 -2.38028901e+06  3.16183250e+05  2.91327837e+05\n",
      "   2.21428340e+05  2.63647620e+05  2.51737650e+05  2.49866427e+05\n",
      "   2.81922458e+05  2.60356240e+05]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 13221.443993972005\n",
      "()\n",
      "Backward pass epoch 3\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [ 4.59599707e+02 -1.03254718e+05  3.35842752e+04  2.62174316e+04\n",
      "   3.45490315e+02  1.41226732e+04  2.95363434e+02  2.55873878e+03\n",
      "   1.27577931e+04  1.29133542e+04]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.95335143e+05 -7.95640116e+06  8.90971440e+05  9.12528233e+05\n",
      "   8.70645967e+05  8.80928238e+05  8.36813857e+05  9.52843802e+05\n",
      "   9.57246604e+05  8.59087873e+05]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [ 2.43819872e+05 -2.38028888e+06  3.16221000e+05  2.91448996e+05\n",
      "   2.21428828e+05  2.63648872e+05  2.51738228e+05  2.49866040e+05\n",
      "   2.81923071e+05  2.60193965e+05]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]\n",
      " [ -6279950.22154823   7966902.17263494 -16792385.43364735\n",
      "   10904929.89727921  -4345546.74310774   3109378.68870696\n",
      "   -2434909.3405512    4366741.01422031   3438947.33163059\n",
      "      65892.63438248]\n",
      " [       -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.                -0.                -0.\n",
      "         -0.        ]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.1\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 4137.7454121103\n",
      "()\n",
      "Backward pass epoch 4\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [ 4.59599707e+02 -1.03254718e+05  3.35842752e+04  2.62174316e+04\n",
      "   3.45490315e+02  1.41226732e+04  2.95363434e+02  2.55873878e+03\n",
      "   1.27577931e+04  1.29133542e+04]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.95335143e+05 -7.95640116e+06  8.90971440e+05  9.12528233e+05\n",
      "   8.70645967e+05  8.80928238e+05  8.36813857e+05  9.52843802e+05\n",
      "   9.57246604e+05  8.59087873e+05]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [-6.03613035e+06  5.58661330e+06 -1.64761644e+07  1.11963789e+07\n",
      "  -4.12411792e+06  3.37302756e+06 -2.18317111e+06  4.61660705e+06\n",
      "   3.72087040e+06  3.26086599e+05]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.1\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 4137.7454121103\n",
      "()\n",
      "Backward pass epoch 5\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [ 4.59599707e+02 -1.03254718e+05  3.35842752e+04  2.62174316e+04\n",
      "   3.45490315e+02  1.41226732e+04  2.95363434e+02  2.55873878e+03\n",
      "   1.27577931e+04  1.29133542e+04]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.95335143e+05 -7.95640116e+06  8.90971440e+05  9.12528233e+05\n",
      "   8.70645967e+05  8.80928238e+05  8.36813857e+05  9.52843802e+05\n",
      "   9.57246604e+05  8.59087873e+05]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [-6.03613035e+06  5.58661330e+06 -1.64761644e+07  1.11963789e+07\n",
      "  -4.12411792e+06  3.37302756e+06 -2.18317111e+06  4.61660705e+06\n",
      "   3.72087040e+06  3.26086599e+05]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.1\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 4137.7454121103\n",
      "()\n",
      "Backward pass epoch 6\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [ 4.59599707e+02 -1.03254718e+05  3.35842752e+04  2.62174316e+04\n",
      "   3.45490315e+02  1.41226732e+04  2.95363434e+02  2.55873878e+03\n",
      "   1.27577931e+04  1.29133542e+04]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.95335143e+05 -7.95640116e+06  8.90971440e+05  9.12528233e+05\n",
      "   8.70645967e+05  8.80928238e+05  8.36813857e+05  9.52843802e+05\n",
      "   9.57246604e+05  8.59087873e+05]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [-6.03613035e+06  5.58661330e+06 -1.64761644e+07  1.11963789e+07\n",
      "  -4.12411792e+06  3.37302756e+06 -2.18317111e+06  4.61660705e+06\n",
      "   3.72087040e+06  3.26086599e+05]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.1\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 4137.7454121103\n",
      "()\n",
      "Backward pass epoch 7\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [ 4.59599707e+02 -1.03254718e+05  3.35842752e+04  2.62174316e+04\n",
      "   3.45490315e+02  1.41226732e+04  2.95363434e+02  2.55873878e+03\n",
      "   1.27577931e+04  1.29133542e+04]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.95335143e+05 -7.95640116e+06  8.90971440e+05  9.12528233e+05\n",
      "   8.70645967e+05  8.80928238e+05  8.36813857e+05  9.52843802e+05\n",
      "   9.57246604e+05  8.59087873e+05]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [-6.03613035e+06  5.58661330e+06 -1.64761644e+07  1.11963789e+07\n",
      "  -4.12411792e+06  3.37302756e+06 -2.18317111e+06  4.61660705e+06\n",
      "   3.72087040e+06  3.26086599e+05]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.1\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 4137.7454121103\n",
      "()\n",
      "Backward pass epoch 8\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [ 4.59599707e+02 -1.03254718e+05  3.35842752e+04  2.62174316e+04\n",
      "   3.45490315e+02  1.41226732e+04  2.95363434e+02  2.55873878e+03\n",
      "   1.27577931e+04  1.29133542e+04]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.95335143e+05 -7.95640116e+06  8.90971440e+05  9.12528233e+05\n",
      "   8.70645967e+05  8.80928238e+05  8.36813857e+05  9.52843802e+05\n",
      "   9.57246604e+05  8.59087873e+05]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [-6.03613035e+06  5.58661330e+06 -1.64761644e+07  1.11963789e+07\n",
      "  -4.12411792e+06  3.37302756e+06 -2.18317111e+06  4.61660705e+06\n",
      "   3.72087040e+06  3.26086599e+05]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.1\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 4137.7454121103\n",
      "()\n",
      "Backward pass epoch 9\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[-8.00365105e-02  3.07820715e-01 -1.28703654e-01 -5.68448371e-02\n",
      "   1.15069475e-01 -4.01433937e-02 -1.10434682e-01 -1.26544586e-01\n",
      "  -9.59108793e-02  2.16457226e-01]\n",
      " [ 4.65878578e-01  5.28090193e+02  6.73951044e+02  3.89160852e+02\n",
      "   7.20995827e+01  1.94456479e+02  1.52649549e+01  9.07002264e+02\n",
      "   3.60160889e+02 -3.14064940e+03]\n",
      " [ 4.59599707e+02 -1.03254718e+05  3.35842752e+04  2.62174316e+04\n",
      "   3.45490315e+02  1.41226732e+04  2.95363434e+02  2.55873878e+03\n",
      "   1.27577931e+04  1.29133542e+04]\n",
      " [ 7.48918881e-03  2.80543669e+02  6.63852554e+01  2.61832646e+01\n",
      "   7.49535409e+01  5.26844800e-01  3.85873769e+01  1.48065446e+01\n",
      "   4.30301240e+01 -5.45021197e+02]\n",
      " [-1.25505035e-01 -1.00371289e-01 -4.11906749e-02 -9.15466024e-02\n",
      "   1.60662977e-01 -1.27805602e-01 -1.20891674e-01  5.99763898e-01\n",
      "  -1.08227812e-01 -4.59793059e-02]\n",
      " [ 7.95335143e+05 -7.95640116e+06  8.90971440e+05  9.12528233e+05\n",
      "   8.70645967e+05  8.80928238e+05  8.36813857e+05  9.52843802e+05\n",
      "   9.57246604e+05  8.59087873e+05]\n",
      " [-3.87700992e-02 -8.71474640e-02 -3.62770905e-01 -3.10956703e-01\n",
      "   4.37521880e-01  5.81233294e-01 -3.18294745e-01  2.77091901e-01\n",
      "   7.09813240e-02 -2.46542442e-01]\n",
      " [-1.46765929e-01  4.76292082e+01  3.04100436e+01  3.83473463e-01\n",
      "   2.43015746e+01  2.73790380e+01  4.37532520e+01  3.79245380e+01\n",
      "   5.23146951e+00 -2.16861394e+02]\n",
      " [-6.03613035e+06  5.58661330e+06 -1.64761644e+07  1.11963789e+07\n",
      "  -4.12411792e+06  3.37302756e+06 -2.18317111e+06  4.61660705e+06\n",
      "   3.72087040e+06  3.26086599e+05]\n",
      " [-7.27237341e-01  6.26347918e+01  1.46118380e+01  3.09966880e+01\n",
      "   1.45029941e+02  2.18690161e+01  1.38426903e+02  6.18234803e+02\n",
      "   6.93356798e+01 -1.10041392e+03]]\n",
      "New_weights\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]\n",
      "End of Backwards pass\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.1, dropout_rate = 0, batch_size = 1, epochs = 10)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 10, 'softmax', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 1)\n"
     ]
    }
   ],
   "source": [
    "y.shape\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Sigmoid\n",
      "(569, 30)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[2.21613348 0.         0.         ... 3.72311489 0.         0.94676015]\n",
      " [3.7304495  0.         0.         ... 4.03361165 0.         0.65290222]\n",
      " [3.39051892 0.         0.         ... 3.43332559 0.         0.54207312]\n",
      " ...\n",
      " [2.51239161 0.         0.         ... 2.24068313 0.         0.26618449]\n",
      " [3.52647021 0.         0.         ... 3.62733276 0.         0.55609423]\n",
      " [0.46854619 0.         0.         ... 0.39847489 0.         0.03991069]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-0.06098279]\n",
      "Output layer\n",
      "[[0.48475902]\n",
      " [0.48628978]\n",
      " [0.48780721]\n",
      " [0.49560722]\n",
      " [0.48897652]\n",
      " [0.4944544 ]\n",
      " [0.48854531]\n",
      " [0.49326304]\n",
      " [0.4945327 ]\n",
      " [0.49472082]]\n",
      "Sums to 1: \n",
      "0.48475902439676466\n",
      "At least one output is closer to 1: \n",
      "0.4984540518173882\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.4400324460485686\n",
      "()\n",
      "Backward pass epoch 0\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[-0.00038111]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.00024587]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 1\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 2\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 3\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 4\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 5\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 6\n",
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 7\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 8\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 9\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 10\n",
      "Update pass epoch 10\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 11\n",
      "Update pass epoch 11\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 12\n",
      "Update pass epoch 12\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 13\n",
      "Update pass epoch 13\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 14\n",
      "Update pass epoch 14\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 15\n",
      "Update pass epoch 15\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 16\n",
      "Update pass epoch 16\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 17\n",
      "Update pass epoch 17\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 18\n",
      "Update pass epoch 18\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 19\n",
      "Update pass epoch 19\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 20\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 20\n",
      "Update pass epoch 20\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 21\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 21\n",
      "Update pass epoch 21\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 22\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 22\n",
      "Update pass epoch 22\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 23\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 23\n",
      "Update pass epoch 23\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 24\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 24\n",
      "Update pass epoch 24\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 25\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 25\n",
      "Update pass epoch 25\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 26\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 26\n",
      "Update pass epoch 26\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 27\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 27\n",
      "Update pass epoch 27\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 28\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 28\n",
      "Update pass epoch 28\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 29\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 29\n",
      "Update pass epoch 29\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 30\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 30\n",
      "Update pass epoch 30\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 31\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 31\n",
      "Update pass epoch 31\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 32\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 32\n",
      "Update pass epoch 32\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 33\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 33\n",
      "Update pass epoch 33\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 34\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 34\n",
      "Update pass epoch 34\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 35\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 35\n",
      "Update pass epoch 35\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 36\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 36\n",
      "Update pass epoch 36\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 37\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 37\n",
      "Update pass epoch 37\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 38\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 38\n",
      "Update pass epoch 38\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 39\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 39\n",
      "Update pass epoch 39\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 40\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 40\n",
      "Update pass epoch 40\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 41\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 41\n",
      "Update pass epoch 41\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 42\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 42\n",
      "Update pass epoch 42\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 43\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 43\n",
      "Update pass epoch 43\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 44\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 44\n",
      "Update pass epoch 44\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 45\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 45\n",
      "Update pass epoch 45\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 46\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 46\n",
      "Update pass epoch 46\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 47\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 47\n",
      "Update pass epoch 47\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 48\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 48\n",
      "Update pass epoch 48\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 49\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 49\n",
      "Update pass epoch 49\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\3075896579.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\971627139.py:42: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\971627139.py:42: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.01, dropout_rate = 0, batch_size = 1, epochs = 50)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 1, 'sigmoid', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e - Implement optimizer\n",
    "Implement any two optimizers of your choice. Briefly present the optimizers \n",
    "in the report. The optimizers can be flavours of gradient descent. For \n",
    "instance: Stochastic gradient descent (SGD) and SGD with momentum. \n",
    "SGD and mini-batch gradient descent, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f - Evaluate different neural network architectures/parameters, present and discuss your results.\n",
    "Be creative in the analysis and discussion. Evaluate different\n",
    "hyperparameters. For instance: different network architectures, activation \n",
    "functions, comparison of optimizers, L1/L2 performance comparison with \n",
    "dropout, etc. Support your results with plots/graph and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
