{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Mathematics for AI - coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The task is about classification on the MNIST dataset. \n",
    "You can use other APIâ€™s/libraries for loading the dataset, but not for the neural network \n",
    "implementation. The point of this task is to develop a multi-layer neural network for \n",
    "classification using numpy. The task requires following sub-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Implement sigmoid and ReLU layers\n",
    "For this sub-task, you should implement forward and backward pass for \n",
    "sigmoid and ReLU. You should consider presenting these activation\n",
    "functions in the report with any pros cons if they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLu(x):\n",
    "    '''\n",
    "    Implementation of reLu function.\n",
    "    '''\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Implementation of Sigmoid function.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Implementation of Softmax function\n",
    "    '''\n",
    "    normalization = np.sum(np.exp(x))\n",
    "    return [np.exp(el)/normalization for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ReLU activation function')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKoUlEQVR4nO3deVxU9f4/8NewDfsAsokimwoqi5ZJam5JuZZ72vXeTLMytTKXXEoRLXHNbua3rNtVy0rFPbO8rpm55IorqIgKyiIiuwww8/n9gcxPZBGGgTPL6/l48HjEmXNmXjNH4NV5nzMjE0IIEBERERkgM6kDEBEREWmLRYaIiIgMFosMERERGSwWGSIiIjJYLDJERERksFhkiIiIyGCxyBAREZHBYpEhIiIig8UiQ0RERAaLRYaIdO7111+Hr6+vJI89d+5cyGQySR47Ly8PY8eOhaenJ2QyGSZNmiRJjieR8jUi0jUWGaJaWrNmDWQymebLwsICTZo0weuvv47bt29rdZ8HDx6ETCbDpk2bqlxHJpNh4sSJld62adMmyGQyHDx4UKvH18adO3cwd+5cnD17tsEes0xBQQHmzp3boM+3JhYsWIA1a9bgnXfewQ8//IB//etfkmXR19eISNcspA5AZKjmzZsHPz8/FBYW4tixY1izZg0OHz6MCxcuwNraWup49e7OnTuIioqCr68v2rZtW+62b7/9Fmq1ut4eu6CgAFFRUQCA7t27l7vt448/xowZM+rtsauzf/9+PPvss4iMjJTk8R+lr68Rka6xyBBpqU+fPmjfvj0AYOzYsXB1dcWiRYuwY8cOvPLKKxKnk5alpaVkj21hYQELC2l+taWnp6N169aSPHZtSPkaEekaR0tEOtKlSxcAQEJCQrnlcXFxGDp0KFxcXGBtbY327dtjx44dUkTEzZs3MX78eAQGBsLGxgaNGjXCsGHDcOPGjQrrZmVl4YMPPoCvry/kcjmaNm2K1157DRkZGTh48CCeeeYZAMDo0aM1Y7Y1a9YAKH+OTHFxMVxcXDB69OgKj5GTkwNra2tMnToVAFBUVIQ5c+bg6aefhkKhgJ2dHbp06YIDBw5otrlx4wbc3NwAAFFRUZrHnjt3LoDKz/8oKSnB/PnzERAQALlcDl9fX8yaNQtKpbLcer6+vujfvz8OHz6MDh06wNraGv7+/vj++++rfV3LRoOJiYn49ddfNZlu3LihGUU+/hqXbfPo6Kd79+4IDg7GpUuX0KNHD9ja2qJJkyZYvHhxhccsLCzE3Llz0bJlS1hbW6Nx48YYPHgwEhIS9PI1IqovLDJEOlL2h8rZ2Vmz7OLFi3j22Wdx+fJlzJgxA8uWLYOdnR0GDhyIrVu3NnjGEydO4MiRIxgxYgS++OILjBs3Dvv27UP37t1RUFCgWS8vLw9dunTBihUr8OKLL+Lf//43xo0bh7i4OCQnJ6NVq1aYN28eAOCtt97CDz/8gB9++AFdu3at8JiWlpYYNGgQtm3bhqKionK3bdu2DUqlEiNGjABQWmz+85//oHv37li0aBHmzp2Lu3fvolevXppzcdzc3PDVV18BAAYNGqR57MGDB1f5vMeOHYs5c+bgqaeewvLly9GtWzdER0drHvdR165dw9ChQ/HCCy9g2bJlcHZ2xuuvv46LFy9Wef+tWrXCDz/8AFdXV7Rt21aTqaxM1Mb9+/fRu3dvhIWFYdmyZQgKCsL06dPx22+/adZRqVTo378/oqKi8PTTT2PZsmV4//33kZ2djQsXLujla0RUbwQR1crq1asFALF3715x9+5dkZSUJDZt2iTc3NyEXC4XSUlJmnV79uwpQkJCRGFhoWaZWq0WnTp1Ei1atNAsO3DggAAgYmJiqnxcAGLChAmV3hYTEyMAiAMHDlSbvaCgoMKyo0ePCgDi+++/1yybM2eOACC2bNlSYX21Wi2EEOLEiRMCgFi9enWFdUaNGiV8fHw03+/evVsAEL/88ku59fr27Sv8/f0135eUlAilUllunfv37wsPDw8xZswYzbK7d+8KACIyMrLCY0dGRopHf7WdPXtWABBjx44tt97UqVMFALF//37NMh8fHwFAHDp0SLMsPT1dyOVyMWXKlAqP9TgfHx/Rr1+/csvK/r0kJiaWW162zx/dZ926dauwL5RKpfD09BRDhgzRLPvvf/8rAIjPPvusQoay/aOvrxGRrvGIDJGWIiIi4ObmBm9vbwwdOhR2dnbYsWMHmjZtCgDIzMzE/v378corryA3NxcZGRnIyMjAvXv30KtXL1y9elXrq5y0ZWNjo/nv4uJi3Lt3D82bN4eTkxNOnz6tuW3z5s0ICwvDoEGDKtyHNpftPv/883B1dcWGDRs0y+7fv489e/Zg+PDhmmXm5uawsrICAKjVamRmZqKkpATt27cvl682du3aBQCYPHlyueVTpkwBAPz666/llrdu3VozJgRKjwAFBgbi+vXrWj1+bdnb2+Of//yn5nsrKyt06NCh3ONv3rwZrq6uePfddytsr83+MbTXiOhRLDJEWlq5ciX27NmDTZs2oW/fvsjIyIBcLtfcfu3aNQghMHv2bLi5uZX7KruqJT09XaeZnvRH7MGDB5gzZw68vb0hl8vh6uoKNzc3ZGVlITs7W7NeQkICgoODdZbLwsICQ4YMwfbt2zXnXGzZsgXFxcXligwArF27FqGhobC2tkajRo3g5uaGX3/9tVy+2rh58ybMzMzQvHnzcss9PT3h5OSEmzdvllverFmzCvfh7OyM+/fva/X4tdW0adMK+/Hxx09ISEBgYKDOTtg1tNeI6FE8bZ1ISx06dNBctTRw4EA899xz+Mc//oH4+HjY29trLj+eOnUqevXqVel9PP6HozpyuRwPHjyo9Lay81uedNn3u+++i9WrV2PSpEno2LEjFAoFZDIZRowYUa+XSwPAiBEjsGrVKvz2228YOHAgNm7ciKCgIISFhWnWWbduHV5//XUMHDgQ06ZNg7u7O8zNzREdHV3hJOraqumRCnNz80qXCyF0+rgqlapBHr82pHqNiOqCRYZIB8r+2Pbo0QNffvklZsyYAX9/fwClJ7tGRETU+TF8fHwQHx9f6W1ly318fKq9j02bNmHUqFFYtmyZZllhYSGysrLKrRcQEIALFy5Ue1+1HWF07doVjRs3xoYNG/Dcc89h//79+Oijjyrk8/f3x5YtW8rd/+Pvy1Kbx/bx8YFarcbVq1fRqlUrzfK0tDRkZWU98TWrq7KTvx9/jR8/ylEbAQEBOH78OIqLi6u81N2QXiOiuuBoiUhHunfvjg4dOuDzzz9HYWEh3N3d0b17d6xatQopKSkV1r97926t7r9v3744duwYTp06VW55VlYWfvzxR7Rt2xaenp7V3oe5uXmF/2tesWJFhaMDQ4YMQWxsbKVXVpVtb2dnp3n8mjAzM8PQoUPxyy+/4IcffkBJSUmFsVLZ/+k/mvH48eM4evRoufVsbW1r/Nh9+/YFAHz++eflln/22WcAgH79+tUov7YCAgIAAIcOHdIsU6lU+Oabb7S+zyFDhiAjIwNffvllhdvKXjtDeo2I6oJHZIh0aNq0aRg2bBjWrFmDcePGYeXKlXjuuecQEhKCN998E/7+/khLS8PRo0eRnJyM2NjYcttv3rwZcXFxFe531KhRmDFjBmJiYtC1a1e8/fbbCAoKwp07d7BmzRqkpKRg9erVT8zXv39//PDDD1AoFGjdujWOHj2KvXv3olGjRhWex6ZNmzBs2DCMGTMGTz/9NDIzM7Fjxw58/fXXCAsLQ0BAAJycnPD111/DwcEBdnZ2CA8Ph5+fX5WPP3z4cKxYsQKRkZEICQkp93//Zfm2bNmCQYMGoV+/fkhMTMTXX3+N1q1bIy8vT7OejY0NWrdujQ0bNqBly5ZwcXFBcHBwpef1hIWFYdSoUfjmm2+QlZWFbt264e+//8batWsxcOBA9OjR44mvW120adMGzz77LGbOnInMzEy4uLhg/fr1KCkp0fo+X3vtNXz//feYPHky/v77b3Tp0gX5+fnYu3cvxo8fjwEDBhjUa0RUJ9JdMEVkmMoupz1x4kSF21QqlQgICBABAQGipKRECCFEQkKCeO2114Snp6ewtLQUTZo0Ef379xebNm3SbFd2KW5VX3/++acQQojk5GQxduxY0aRJE2FhYSFcXFxE//79xbFjx2qU/f79+2L06NHC1dVV2Nvbi169eom4uDjh4+MjRo0aVW7de/fuiYkTJ4omTZoIKysr0bRpUzFq1CiRkZGhWWf79u2idevWwsLCotyl2I9ffl1GrVYLb29vAUB88sknld6+YMEC4ePjI+RyuWjXrp3YuXNnpfd35MgR8fTTTwsrK6tylxk/fmmxEEIUFxeLqKgo4efnJywtLYW3t7eYOXNmucvihaj88mkhSi+L7tatW+Uvag22T0hIEBEREUIulwsPDw8xa9YssWfPnkovv27Tpk2F7St7/gUFBeKjjz7SPCdPT08xdOhQkZCQoFlHH18jIl2TCcGzs4iIiMgw8RwZIiIiMlgsMkRERGSwWGSIiIjIYLHIEBERkcFikSEiIiKDxSJDREREBsvo3xBPrVbjzp07cHBw0OpTYYmIiKjhCSGQm5sLLy8vmJlVfdzF6IvMnTt34O3tLXUMIiIi0kJSUhKaNm1a5e1GX2QcHBwAlL4Qjo6OEqchIiKimsjJyYG3t7fm73hVjL7IlI2THB0dWWSIiIgMzJNOC+HJvkRERGSwWGSIiIjIYLHIEBERkcFikSEiIiKDxSJDREREBotFhoiIiAwWiwwREREZLBYZIiIiMlgsMkRERGSwWGSIiIjIYElaZA4dOoSXXnoJXl5ekMlk2LZtW7nbhRCYM2cOGjduDBsbG0RERODq1avShCUiIiK9I2mRyc/PR1hYGFauXFnp7YsXL8YXX3yBr7/+GsePH4ednR169eqFwsLCBk5KRERE+kjSD43s06cP+vTpU+ltQgh8/vnn+PjjjzFgwAAAwPfffw8PDw9s27YNI0aMaMioRERE9JicwmLEpeSig5+LZBn09hyZxMREpKamIiIiQrNMoVAgPDwcR48erXI7pVKJnJyccl9ERESke5/svIRXVh3FVwcTJMugt0UmNTUVAODh4VFuuYeHh+a2ykRHR0OhUGi+vL296zUnERGRKToQl46NJ5MhkwHP+DpLlkNvi4y2Zs6ciezsbM1XUlKS1JGIiIiMSnZBMWZsOQcAeKOzH9r7crRUgaenJwAgLS2t3PK0tDTNbZWRy+VwdHQs90VERES6E7XzItJylPB3tcPUXoGSZtHbIuPn5wdPT0/s27dPsywnJwfHjx9Hx44dJUxGRERkuvZeSsOW07dhJgOWvhIGa0tzSfNIetVSXl4erl27pvk+MTERZ8+ehYuLC5o1a4ZJkybhk08+QYsWLeDn54fZs2fDy8sLAwcOlC40ERGRicoqKMLMrecBAG929cdTzaQ7N6aMpEXm5MmT6NGjh+b7yZMnAwBGjRqFNWvW4MMPP0R+fj7eeustZGVl4bnnnsPvv/8Oa2trqSITERGZrLk7LuJurhLN3e3xQURLqeMAAGRCCCF1iPqUk5MDhUKB7Oxsni9DRESkpd8vpGLculMwkwFbxndGW2+nen28mv791ttzZIiIiEg/ZOYX4eNtpSOlcd0C6r3E1AaLDBEREVUrcsdFZOQVoaWHPd6PaCF1nHJYZIiIiKhKu86n4JfYOzA3k2HZsLaQW0h7ldLjWGSIiIioUhl5Sny87QIAYHz3AIQ0VUicqCIWGSIiIqpACIHZ2y4gM78IQZ4OePd5/RoplWGRISIiogp2nkvBbxdSYWEmw9JhYbCy0M/KoJ+piIiISDJ3c5WYs710pDTx+eYIbqJ/I6UyLDJERESkIYTAx9vO435BMVo3dsSEHs2ljlQtFhkiIiLS2BF7B7svpsHSvHSkZGmu31VBv9MRERFRg0nPKcSc7RcBAO893wKtvfT/HfFZZIiIiAhCCMzaeh7ZD4oR0kSBcd0DpI5UIywyREREhK1nbmPv5XRYmZsZxEipjGGkJCIionqTml2IuTtKR0rvR7RAoKeDxIlqjkWGiIjIhAkhMHPLOeQUliCsqQJvd/WXOlKtsMgQERGZsJhTyTgQfxdWFqUjJQsDGSmVMay0REREpDMp2Q8w/5dLAIApL7RECw/DGSmVYZEhIiIyQUIITN98HrnKErRr5oSxXQxrpFSGRYaIiMgEbTiRhENX7kL+cKRkbiaTOpJWWGSIiIhMzO2sB/jk18sAgGm9AhHgZi9xIu2xyBAREZkQIQSmbzqHPGUJ2vs4Y3RnP6kj1QmLDBERkQn56e9bOHwtA9aWZlhiwCOlMiwyREREJiIpswCfPhwpfdgrCH6udhInqjsWGSIiIhOgVgt8uOkcCopU6ODrgtc7+UodSSdYZIiIiEzAuuM3cfT6PdhYmmPJsFCYGfhIqQyLDBERkZG7da8A0bviAAAz+wbBp5Hhj5TKsMgQEREZMbVaYOqmWDwoVuFZfxf8M9xH6kg6xSJDRERkxNYevYG/EzNha2WOJUPDjGakVIZFhoiIyEglZuRj0e+lI6VZfVvB28VW4kS6xyJDRERkhFRqgWkxsSgsVuO55q4YGd5M6kj1gkWGiIjICK3+KxEnb96HvdwCC4eEQCYzrpFSGRYZIiIiI5NwNw9LdscDAD7q1wpNnY1vpFSGRYaIiMiIqNQCU2NioSxRo0sLV4x4xlvqSPWKRYaIiMiI/OfP6zhzKwsOcgssGhJqtCOlMiwyRERERuJaei6W7bkCAJj9Umt4OdlInKj+scgQEREZgRKVGlNizqGoRI0egW4Y9nRTqSM1CBYZIiIiI/DNn9cRm5QFB2sLRA82/pFSGRYZIiIiAxefmovP91wFAMx9qQ08FdYSJ2o4LDJEREQGrFilxtSYWBSp1Iho5Y7BTzWROlKDYpEhIiIyYKv+SMD529lQ2FhiwSDjfeO7qrDIEBERGajLKTn4977SkVLUy23g7mg6I6UyLDJEREQGqFilxpSNsShWCbzY2gMD2npJHUkSLDJEREQGaOWBa7iUkgNnW0t8aoIjpTIsMkRERAbm4p1sfLn/GgBg3oBguDnIJU4kHRYZIiIiA1JUUjpSKlEL9An2RP/QxlJHkhSLDBERkQH5cv9VxKXmwsXOCvMHBpvsSKkMiwwREZGBOJ+cjZUHEwAA8wcEw9XedEdKZVhkiIiIDICyRIWpMbFQqQX6hzZGPxMfKZVhkSEiIjIAX+y7ivi0XLjaW2HegGCp4+gNFhkiIiI9F5uUha8ejpQ+GRgCFzsriRPpDxYZIiIiPVZYrMKUmFioBTCgrRd6B3tKHUmvsMgQERHpseV7r+Baeh7cHOSY+1IbqePoHRYZIiIiPXX61n18e+g6AGDBoBA4c6RUAYsMERGRHiosLr1KSS2Awe2a4IXWHlJH0kssMkRERHpo2f/icf1uPtwd5IjkSKlKLDJERER65uSNTPzncCIAYOGQEChsLSVOpL9YZIiIiPTIgyIVpm06ByGAYU83xfNBHClVR6+LjEqlwuzZs+Hn5wcbGxsEBARg/vz5EEJIHY2IiKheLNkdj8SMfHg6WuPj/q2ljqP3LKQOUJ1Fixbhq6++wtq1a9GmTRucPHkSo0ePhkKhwHvvvSd1PCIiIp06fv0eVh95ZKRkw5HSk+h1kTly5AgGDBiAfv36AQB8fX3x888/4++//5Y4GRERkW4VFJVoRkojnvFG90B3qSMZBL0eLXXq1An79u3DlStXAACxsbE4fPgw+vTpU+U2SqUSOTk55b6IiIj03aLf4nArswBeCmt81K+V1HEMhl4fkZkxYwZycnIQFBQEc3NzqFQqfPrppxg5cmSV20RHRyMqKqoBUxIREdXN0YR7WHv0JgBg0dBQOFhzpFRTen1EZuPGjfjxxx/x008/4fTp01i7di2WLl2KtWvXVrnNzJkzkZ2drflKSkpqwMRERES1k68swbRNsQCAf4Q3Q5cWbhInMix6fURm2rRpmDFjBkaMGAEACAkJwc2bNxEdHY1Ro0ZVuo1cLodcLm/ImERERFqL/u0yku8/QBMnG8zqy5FSben1EZmCggKYmZWPaG5uDrVaLVEiIiIi3fnrWgbWHbsFAFgyNBT2cr0+vqCX9PoVe+mll/Dpp5+iWbNmaNOmDc6cOYPPPvsMY8aMkToaERFRneQWFuPDTecAAK919EGn5q4SJzJMel1kVqxYgdmzZ2P8+PFIT0+Hl5cX3n77bcyZM0fqaERERHWyYFccbmc9gLeLDab3DpI6jsGSCSN/m9ycnBwoFApkZ2fD0dFR6jhEREQ4dOUuXvtv6XuirX/rWTzr30jiRPqnpn+/9focGSIiImOTU1iM6ZtLR0qvd/JliakjFhkiIqIG9MnOS0jJLoRvI1t82DtQ6jgGj0WGiIiogRyIT8fGk8mQyYAlw8Jga6XXp6oaBBYZIiKiBpBdUIwZD0dKYzr74RlfF4kTGQcWGSIiogYwb+clpOUo4e9qh6kvcqSkKywyRERE9WzvpTRsPp0Ms4cjJRsrc6kjGQ0WGSIionqUVVCEWVvPAwDe7OKPp32cJU5kXFhkiIiI6lHUL5eQnqtEgJsdPnihpdRxjA6LDBERUT3ZfTEVW8/chpkMWDosDNaWHCnpGosMERFRPcjML8JHD0dKb3cLQLtmHCnVBxYZIiKiehC54yIy8orQ0sMekyJaSB3HaLHIEBER6dhv51PwS+wdmJvJsHRYGOQWHCnVFxYZIiIiHbqXp8TH2y4AAN7pFoDQpk7SBjJyLDJEREQ6NGf7RdzLL0KQpwPe7dlc6jhGj0WGiIhIR3aeu4Nfz6fAgiOlBsMiQ0REpAN3c5WY/XCkNL5HcwQ3UUicyDSwyBAREdWREAIfbzuP+wXFaNXYERN7cKTUUFhkiIiI6mhH7B3svpgGCzMZlg0Lg5UF/7w2FL7SREREdZCeU4g52y8CAN7r2QKtvRwlTmRaWGSIiIi0JITArK0XkP2gGMFNHPFO9wCpI5kcFhkiIiItbTt7G3svp8HSvPQqJUtz/lltaHzFiYiItJCWU4jIhyOlSREtEeTJkZIUWGSIiIhqSQiBmVvOI6ewBKFNFXi7q7/UkUwWiwwREVEtbTqVjP1x6bAyN8OyYWGw4EhJMnzliYiIaiEl+wHm7bwEAPjghZZo4eEgcSLTxiJDRERUQ0IIzNh8HrmFJWjr7YQ3u/hJHcnkscgQERHV0MaTSfjjyl1YWZhhKUdKeoF7gIiIqAZuZz3A/J2XAQDTXgxEc3d7iRMRwCJDRET0RKUjpXPIU5bgaR9njHmOIyV9wSJDRET0BD//nYQ/r2ZAbmGGJUNDYW4mkzoSPcQiQ0REVI2kzAJ8+mvpVUof9g6CvxtHSvqERYaIiKgKarXA9M3nkF+kQgdfF4zu5Ct1JHoMiwwREVEVfjx+E0cS7sHG0hyLh4bCjCMlvcMiQ0REVIlb9woQ/VscAGB670D4utpJnIgqwyJDRET0GLVaYNqmWBQUqRDu54LXOvpKHYmqwCJDRET0mO+P3sDxxEzYWpljydAwjpT0GIsMERHRI25k5GPh76UjpZl9W6FZI1uJE1F1WGSIiIgeKhspFRar0SmgEUZ2aCZ1JHoCFhkiIqKHVh+5gRM37sPOyhyLhvAqJUPAIkNERATg+t08LH44UvqoX2t4u3CkZAhYZIiIyOSp1AJTY2KhLFGjSwtXvNrBW+pIVEMsMkREZPK+O3wdp29lwUFugUVDQiGTcaRkKFhkiIjIpF1Lz8PS/10BAHzcvxW8nGwkTkS1wSJDREQmq0SlxpSYWBSVqNGtpRteac+RkqFhkSEiIpP17Z+JiE3KgoO1BRYOCeFIyQCxyBARkUm6kpaL5XtKR0qRL7VBYwVHSoaIRYaIiExOiUqNqTGxKFKp8XyQO4Y81UTqSKQlFhkiIjI5qw5dx7nkbDhaWyB6MEdKhoxFhoiITEpcag4+31s6Uooa0AYejtYSJ6K6YJEhIiKTUaxSY8rGWBSrBF5o7YGBbTlSMnQsMkREZDL+70ACLt7JgZOtJT4dFMyRkhFgkSEiIpNw8U42Vuy/CgCIerkN3B04UjIGLDJERGT0ikrUmBpzDiVqgd5tPPFymJfUkUhHWGSIiMjofXngGi6n5MDFzgqfcKRkVFhkiIjIqF24nY2VB64BAOYPCIarvVziRKRLLDJERGS0lCUqTNkYC5VaoF9IY/QLbSx1JNIxvS8yt2/fxj//+U80atQINjY2CAkJwcmTJ6WORUREBmDFvmuIT8tFIzsrzBvQRuo4VA8spA5Qnfv376Nz587o0aMHfvvtN7i5ueHq1atwdnaWOhoREem52KQsfPVHAgDgk4HBaMSRklHS6yKzaNEieHt7Y/Xq1Zplfn5+EiYiIiJDUFiswtSY0pHSy2Fe6BPCkZKx0uvR0o4dO9C+fXsMGzYM7u7uaNeuHb799ttqt1EqlcjJySn3RUREpuXzvVdxNT0PrvZyRL3MkZIx0+sic/36dXz11Vdo0aIFdu/ejXfeeQfvvfce1q5dW+U20dHRUCgUmi9vb+8GTExERFI7c+s+vjlUOlJaMCgYznZWEiei+iQTQgipQ1TFysoK7du3x5EjRzTL3nvvPZw4cQJHjx6tdBulUgmlUqn5PicnB97e3sjOzoajo2O9ZyYiIukUFqvQ74s/kXA3H4PaNcHy4W2ljkRaysnJgUKheOLfb70+ItO4cWO0bt263LJWrVrh1q1bVW4jl8vh6OhY7ouIiEzDZ3uuIOFuPtwd5Ih8qfWTNyCDp9dFpnPnzoiPjy+37MqVK/Dx8ZEoERER6atTNzPx7Z/XAQDRg0PgZMuRkinQ6yLzwQcf4NixY1iwYAGuXbuGn376Cd988w0mTJggdTQiItIjD4pUmBpzDkIAQ55qip6tPKSORA1Er4vMM888g61bt+Lnn39GcHAw5s+fj88//xwjR46UOhoREemRpf+LR2JGPjwc5ZjDkZJJ0ev3kQGA/v37o3///lLHICIiPfV3Yib++1ciAGDhkFAobCwlTkQNSa+PyBAREVWnoKgE0zbFQghgeHtv9Ah0lzoSNTAWGSIiMliLf4/HzXsFaKywxkf9W0kdhyTAIkNERAbp2PV7WHPkBgBg0ZBQOFpzpGSKWGSIiMjg5CtLR0oA8GqHZuja0k3iRCQVFhkiIjI4C3+LQ1LmAzRxssFH/ThSMmUsMkREZFD+upaBH47dBAAsHhoKe7neX4BL9UirIjNv3jwUFBRUWP7gwQPMmzevzqGIiIgqk6cswYebzgEA/vlsM3Ru7ipxIpKaVh8aaW5ujpSUFLi7l7/M7d69e3B3d4dKpdJZwLqq6YdOERGR/pu19Tx+On4LTZ1tsHtSV9jxaIzRqtcPjRRCQCaTVVgeGxsLFxcXbe6SiIioWoeu3MVPx0s/NHjJ0DCWGAJQy3f2dXZ2hkwmg0wmQ8uWLcuVGZVKhby8PIwbN07nIYmIyLTlFBZjxubSkdLrnXzRMaCRxIlIX9SqyHz++ecQQmDMmDGIioqCQqHQ3GZlZQVfX1907NhR5yGJiMi0fbrzMu5kF8KnkS0+7B0odRzSI7UqMqNGjQIA+Pn5oVOnTrC05JsPERFR/ToYn44NJ5Mgk5WOlGytOFKi/0+rfw1+fn5ISUmp8vZmzZppHYiIiKhM9oNizNh8HgAwupMfOvjxPEwqT6si4+vrW+nJvmX06aolIiIyXPN3XkJqTiH8XO0wrRdHSlSRVkXmzJkz5b4vLi7GmTNn8Nlnn+HTTz/VSTAiIjJt+y6nYdOp5IcjpVDYWJlLHYn0kFZFJiwsrMKy9u3bw8vLC0uWLMHgwYPrHIyIiExXdkExZm4pHSmNfc4P7X05UqLK6fQjCgIDA3HixAld3iUREZmgqF8uIj1XCX83O0x5kSMlqppWR2RycnLKfS+EQEpKCubOnYsWLVroJBgREZmm/11MxZYzt2EmA5YOC4O1JUdKVDWtioyTk1OFk32FEPD29sb69et1EoyIiEzP/fwizNp6AQDwVtcAPNXMWeJEpO+0KjIHDhwo972ZmRnc3NzQvHlzWFjw+n4iItJO5I6LyMhTooW7PSZF8Ag/PZlWraNbt266zkFERCbu9wsp2BF7B+ZmMo6UqMa0PnwSHx+PFStW4PLlywCAVq1aYeLEiQgKCtJZOCIiMg338pT46OFIaVw3f4R5O0kbiAyGVlctbd68GcHBwTh16hTCwsIQFhaG06dPIyQkBJs3b9Z1RiIiMnJzdlzEvfwiBHo44L2eHClRzcmEEKK2GwUEBGDkyJGYN29eueWRkZFYt24dEhISdBawrnJycqBQKJCdnQ1HR0ep4xAR0WN2nruDiT+dgbmZDNvGd0ZIU8WTNyKjV9O/31odkUlJScFrr71WYfk///nPaj+DiYiI6FEZeUrM2X4RADChewBLDNWaVkWme/fu+PPPPyssP3z4MLp06VLnUEREZPyEEJi97QIy84sQ5OmAic9zpES1p9XJvi+//DKmT5+OU6dO4dlnnwUAHDt2DDExMYiKisKOHTvKrUtERPS4X86l4LcLqbAwk2HZK2GwstDpm82TidDqHBkzs5r9Y5PJZJJ/EjbPkSEi0j/puYV4cfkhZBUU44OIlnif7xlDj6np32+tjsio1WqtgxERkWkTQuCjrReQVVCMNl6OGN8jQOpIZMC0Oo73/fffQ6lUVlheVFSE77//vs6hiIjIeG0/ewd7LqXB0rz0je8szTlSIu1p9a9n9OjRyM7OrrA8NzcXo0ePrnMoIiIyTmk5hYjcUXqV0vs9W6BVY478qW60KjJCiAofGgkAycnJUCh46RwREVUkhMCsLeeR/aAYIU0UGNeNIyWqu1qdI9OuXTvIZDLIZDL07Nmz3AdEqlQqJCYmonfv3joPSUREhm/z6dvYF5cOK3MzLHslDBYcKZEO1KrIDBw4EABw9uxZ9OrVC/b29prbrKys4OvriyFDhug0IBERGb7U7EJE/VI6Upr0Qgu09HCQOBEZi1oVmcjISACAr68vhg8fDmtr63oJRURExkMIgRlbziG3sARh3k54q4u/1JHIiGh1+fWoUaN0nYOIiIxUzMlkHIy/CysLMywbFsqREumUVkXGzMys0pN9y0j9JnhERKQfbmc9wPydlwAAU19siebuHCmRbmlVZLZs2VKuyBQXF+PMmTNYu3YtoqKidBaOiIgMlxACMzafQ66yBE81c8Ibz3GkRLqnVZEpO+n3UUOHDkWbNm2wYcMGvPHGG3XNRUREBm79iST8eTUDcgszLBkWBnOzqo/kE2lLp4PKZ599Fvv27dPlXRIRkQFKvl+ATx6OlKb1CkSAm/0TtiDSjs6KzIMHD/DFF1+gSZMmurpLIiIyQGq1wIebziG/SIVnfJ0xurOf1JHIiGk1WnJ2di53jowQArm5ubC1tcW6det0Fo6IiAzPj3/fwpGEe7C2NMOSoRwpUf3SqsgsX768XJExMzODm5sbwsPD4ezsrLNwRERkWJIyCxC96zIAYHrvIPi62kmciIydVkXm9ddfR1ZWFr777jtcvlz6D7Z169bo2LGjTsMREZHhUKsFpm2KRUGRCh38XDCqo6/UkcgEaHWOzMmTJ9G8eXMsX74cmZmZyMzMxPLlyxEQEIDTp0/rOiMRERmAH47dxLHrmbC1MsfSoWEw40iJGoBWR2Q++OADvPTSS/j22281HxxZUlKCsWPHYtKkSTh06JBOQxIRkX67kZGPhb/FAQBm9AlCs0a2EiciU6FVkTl58mS5EgMAFhYW+PDDD9G+fXudhSMiIv1XdpXSg2IVOvo3wj/DfaSORCZEq9GSo6Mjbt26VWF5UlISHBz49tNERKZkzZEb+PtGJuyszLF4aChHStSgtCoyw4cPxxtvvIENGzYgKSkJSUlJWL9+PcaOHYtXX31V1xmJiEhPXb+bh8W7S0dKs/q1grcLR0rUsLQaLS1duhQymQyvvfYaSkpKAACWlpZ45513sHDhQp0GJCIi/aRSC0zbdA6FxWo819wV/+jQTOpIZIJkQgih7cYFBQVISEgAAAQEBMDWVv+aeE5ODhQKBbKzs+Ho6Ch1HCIio/Htoev4dNdl2MstsPuDrmjiZCN1JDIiNf37rdURmTK2trYICQmpy10QEZEBupaehyX/iwcAfNyvFUsMSUanHxpJRETGT6UWmBoTi6ISNbq2dMPwZ7yljkQmjEWGiIhq5ds/r+NsUhYcrC2waEhIuY+sIWpoLDJERFRjV9Ny8dn/rgAAZvdvjcYKjpRIWiwyRERUIyUqNabExKJIpUaPQDcMe7qp1JGIDKvILFy4EDKZDJMmTZI6ChGRyVl16DrOJWfD0doC0YNDOVIivWAwRebEiRNYtWoVQkNDpY5CRGRy4lJz8Pne0pHS3JfbwFNhLXEiolIGUWTy8vIwcuRIfPvtt3B2dpY6DhGRSSlWqTE1JhbFKoGIVh4Y1K6J1JGINAyiyEyYMAH9+vVDRESE1FGIiEzOVwcTcOF2DhQ2llgwKJgjJdIrdXpDvIawfv16nD59GidOnKjR+kqlEkqlUvN9Tk5OfUUjIjJ6l+7k4It9VwEA8wa0gbsjR0qkX/T6iExSUhLef/99/Pjjj7C2rtkPT3R0NBQKhebL25tv1EREpI2iktKRUolaoFcbD7wc5iV1JKIK6vRZS/Vt27ZtGDRoEMzNzTXLVCoVZDIZzMzMoFQqy90GVH5Extvbm5+1RERUS8v3XMG/912Fs60l/vdBN7g5yKWORCakQT5rqb717NkT58+fL7ds9OjRCAoKwvTp0yuUGACQy+WQy/nDRkRUFxduZ2PlgWsAgHkDglliSG/pdZFxcHBAcHBwuWV2dnZo1KhRheVERKQbj46U+oZ4on9oY6kjEVVJr8+RISKihrdi/1XEpeaikZ0V5g/gVUqk3/T6iExlDh48KHUEIiKjdS45C/93MAEA8MnAYDSy50iJ9BuPyBAREQBAWaLClI2xUKkF+oc2Rp8QjpRI/7HIEBERAODzvVdxNT0PrvZWmDeA5yGSYWCRISIinLl1H6v+KBsphcDFzkriREQ1wyJDRGTiCotVmBoTC7UABrb1Qu9gT6kjEdUYiwwRkYlbvucKEu7mw81Bjrkvt5E6DlGtsMgQEZmwUzcz8c2f1wEA0YNC4GTLkRIZFhYZIiITVViswrSYcxACGPxUE0S09pA6ElGtscgQEZmopbvjcT0jHx6OckT250iJDBOLDBGRCTpxIxPf/ZUIAFg4OBQKW0uJExFph0WGiMjEFBSVYFpMLIQAhj3dFD2C3KWORKQ1FhkiIhOz+Pd43LhXgMYKa3zcv7XUcYjqhEWGiMiEHLt+D2uO3AAALBwSCoUNR0pk2FhkiIhMRL6yBB9uOgcAeLWDN7q1dJM4EVHdscgQEZmIRb/H4VZmAZo42WBW31ZSxyHSCRYZIiITcORaBr4/ehMAsGhIKBysOVIi48AiQ0Rk5PKUJZj2cKQ0MrwZnmvhKnEiIt1hkSEiMnLRuy7jdtYDNHW2wUyOlMjIsMgQERmxP6/exY/HbwEAFg8Nhb3cQuJERLrFIkNEZKRyC4sx/eFI6bWOPugUwJESGR8WGSIiI/Xpr5dxJ7sQzVxsMb13kNRxiOoFiwwRkRE6GJ+O9SeSAABLhobCjiMlMlIsMkRERib7QTFmbD4PABjd2Rfh/o0kTkRUf1hkiIiMzCc7LyE1pxC+jWzxYS+OlMi4scgQERmR/XFpiDmVDJkMWDIsDDZW5lJHIqpXLDJEREYiu+D/j5Te6OyHZ3xdJE5EVP9YZIiIjETUzotIz1XC39UOU3sFSh2HqEGwyBARGYE9l9Kw5fRtmMmApa+EwdqSIyUyDSwyREQG7n5+EWZtLR0pvdnFH081c5Y4EVHDYZEhIjJwc3+5iLu5SgS42eGDF1pKHYeoQbHIEBEZsN8vpGL72TswkwHLXmnLkRKZHBYZIiIDlZlfhI+3lY6UxnULQFtvJ2kDEUmARYaIyEDN2X4BGXlFaOlhj/cjWkgdh0gSLDJERAbo13Mp2HkuBeZmMiwdFga5BUdKZJpYZIiIDExGnhKzt18AAIzvHoDQpk7SBiKSEIsMEZEBEUJg9rYLyMwvQpCnA959niMlMm0sMkREBmTnuRT8diEVFg9HSlYW/DVOpo0/AUREBiI9t1AzUprQozmCmygkTkQkPRYZIiIDIITAR1svIKugGK0bO2JCj+ZSRyLSCywyREQGYPvZO9hzKQ2W5hwpET2KPwlERHouPacQkTsuAgDee74FWns5SpyISH+wyBAR6TEhBGZtPY/sB8UIbuKIcd0DpI5EpFdYZIiI9NiW07ex93I6LM1lWDasLSzN+Wub6FH8iSAi0lOp2YWY+0vpSGlSREsEejpInIhI/7DIEBHpISEEZm45h9zCEoQ1VeDtrv5SRyLSSywyRER6KOZUMg7E34WVuRmWDguDBUdKRJXiTwYRkZ65k/UA83+5BACY/GJLtPDgSImoKiwyRER6RAiB6ZvPIVdZgnbNnPBmF46UiKrDIkNEpEfWn0jCn1czILcoHSmZm8mkjkSk11hkiIj0RPL9Anz662UAwLRegQhws5c4EZH+Y5EhItIDZSOlPGUJ2vs4Y3RnP6kjERkEFhkiIj3w4/Fb+OvaPVhbmmHx0FCOlIhqiEWGiEhiSZkFWLCrdKT0Ya8g+HOkRFRjLDJERBJSqwU+3HQOBUUqdPB1weudfKWORGRQWGSIiCS07vhNHL1+DzaW5lgyLBRmHCkR1QqLDBGRRG7ey0f0rjgAwIw+QfBpZCdxIiLDwyJDRCQBtVpgWsw5PChW4Vl/F/zrWR+pIxEZJL0uMtHR0XjmmWfg4OAAd3d3DBw4EPHx8VLHIiKqszVHbuDvG5mwtTLHkqFhHCkRaUmvi8wff/yBCRMm4NixY9izZw+Ki4vx4osvIj8/X+poRERaS8zIx+LdpSOlWX1bwdvFVuJERIbLQuoA1fn999/Lfb9mzRq4u7vj1KlT6Nq1q0SpiIi0p1ILTIuJRWGxGp2bN8LI8GZSRyIyaHp9ROZx2dnZAAAXFxeJkxARaWf1X4k4efM+7KzMsWhIKGQyjpSI6kKvj8g8Sq1WY9KkSejcuTOCg4OrXE+pVEKpVGq+z8nJaYh4RERPlHA3D0t2l57n93H/1mjqzJESUV0ZzBGZCRMm4MKFC1i/fn2160VHR0OhUGi+vL29GyghEVHVVGqBqTGxUJao0aWFK0Y8w99NRLpgEEVm4sSJ2LlzJw4cOICmTZtWu+7MmTORnZ2t+UpKSmqglEREVfvPn9dx5lYWHOQWHCkR6ZBej5aEEHj33XexdetWHDx4EH5+T/40WLlcDrlc3gDpiIhq5mpaLpbtuQIAmN2/NbycbCRORGQ89LrITJgwAT/99BO2b98OBwcHpKamAgAUCgVsbPiLgIj0X4lKjakxsSgqUaN7oBuGta/+qDIR1Y5ej5a++uorZGdno3v37mjcuLHma8OGDVJHIyKqkVWHriM2ORsO1hZYOJgjJSJd0+sjMkIIqSMQEWktPjUX/957FQAQ+VIbeCqsJU5EZHz0+ogMEZGhKi4bKanU6BnkjiFPNZE6EpFRYpEhIqoHXx9MwPnb2VDYWGLB4BCOlIjqCYsMEZGOXU7JwRf7S0dKUS+3gYcjR0pE9YVFhohIh4pVakzZGItilcCLrT0woK2X1JGIjBqLDBGRDq08cA2XUnLgZGuJTwYFc6REVM9YZIiIdOTC7Wx8uf8aAGDegGC4O3CkRFTfWGSIiHSgqKT0KqUStUCfYE+8FNpY6khEJoFFhohIB1bsv4q41Fy42Flh/kCOlIgaCosMEVEdnU/Oxv8dTAAAzB8QDFd7ft4bUUNhkSEiqgNliQpTYs5CpRboF9oY/ThSImpQLDJERHXw771XcSUtD672Vpg/IFjqOEQmh0WGiEhLZ5Oy8PUfpSOlTwaGwMXOSuJERKaHRYaISAuFxSpMjYmFWgAD2nqhd7Cn1JGITBKLDBGRFpbvvYJr6XlwtZdj7kttpI5DZLJYZIiIaunUzfv49tB1AMCCQcFw5kiJSDIsMkREtVBYrMK0hyOlwe2a4MU2HCkRSYlFhoioFpbujsf1jHy4O8gRyZESkeRYZIiIaujkjUx891ciAGDhkBAobC0lTkRELDJERDXwoKj0KiUhgKFPN8XzQR5SRyIisMgQEdXI4t1xuHGvAJ6O1pjdv7XUcYjoIRYZIqInOH79Hlb/dQPAw5GSDUdKRPqCRYaIqBoFRSWYtukcAGB4e290D3SXOBERPYpFhoioGot+i8OtzAJ4KazxUf9WUschosewyBARVeFIQgbWHr0JAFg0NBSO1hwpEekbFhkiokrkKUvw4cOR0j/Cm6FLCzeJExFRZVhkiIgqEb3rMpLvP0ATJxvM6suREpG+YpEhInrM4asZ+PH4LQDAkqGhsJdbSJyIiKrCIkNE9IjcwmJM31w6UvrXsz7o1NxV4kREVB0WGSKiRyzYdRm3sx7A28UGM/oESR2HiJ6ARYaI6KE/rtzFz38nAQCWDA2DHUdKRHqPRYaICEBOYTFmPBwpvd7JF8/6N5I4ERHVBIsMERGAT3ZeQkp2IXwa2eLD3oFSxyGiGmKRISKTdyAuHRtPJkMmKx0p2VpxpERkKFhkiMikZRcUY8aW0pHSmM5+6ODnInEiIqoNFhkiMmlROy8iLUcJf1c7TH2RIyUiQ8MiQ0Qma++lNGw5fbt0pDQsFDZW5lJHIqJaYpEhIpOUVVCEmVvPAwDe7OKPp304UiIyRCwyRGSS5u64iLu5SgS42WHyCy2ljkNEWmKRISKTs/tiKradvQMzGbB0WBisLTlSIjJULDJEZFIy84vw0cOR0ltdA9CumbPEiYioLlhkiMikRO64iIy8IrRwt8ekiBZSxyGiOmKRISKTset8Cn6JvQNzMxlHSkRGgkWGiExCRp4SH2+7AAB4p1sAwrydpA1ERDrBIkNEJmHO9gvIzC9CkKcD3u3ZXOo4RKQjLDJEZPR2nruDXedTNSMluQVHSkTGgkWGiIza3VwlZj8cKU3o0RzBTRQSJyIiXWKRISKjJYTAx9vO435BMVo1dsTEHhwpERkbFhkiMlo7Yu9g98U0WJjJsGxYGKws+CuPyNjwp5qIjFJ6TiHmbL8IAHj3+RZo7eUocSIiqg8sMkRkdIQQmLX1PLIfFKONlyPG9wiQOhIR1RMWGSIyOlvP3Mbey+mwNJdh2SthsDTnrzoiY8WfbiIyKqnZhZi7o3SkNCmiJYI8OVIiMmYsMkRkNIQQmLnlHHIKSxDaVIG3u/pLHYmI6hmLDBEZjU2nknEg/i6szM2wdFgYLDhSIjJ6/CknIqOQkv0A8365BAD44IWWaOnhIHEiImoILDJEZPCEEJi++TxylSVo6+2EN7v4SR2JiBoIiwwRGbwNJ5Jw6MpdWFlwpERkagzip33lypXw9fWFtbU1wsPD8ffff0sdiYj0xO2sB/jk18sAgKkvtkRzd3uJExFRQ9L7IrNhwwZMnjwZkZGROH36NMLCwtCrVy+kp6dLHY2IJCaEwPRN55CnLMFTzZzwxnO8SonI1MiEEELqENUJDw/HM888gy+//BIAoFar4e3tjXfffRczZsx44vY5OTlQKBTIzs6Go6Pu3k/ifn4R8otKdHZ/RFR728/ewZLd8ZBbmOG397vA341HY4iMRU3/fls0YKZaKyoqwqlTpzBz5kzNMjMzM0RERODo0aOVbqNUKqFUKjXf5+Tk1Eu2Jf+Lx0/Hb9XLfRNR7XzYO4glhshE6XWRycjIgEqlgoeHR7nlHh4eiIuLq3Sb6OhoREVF1Xs2SzMZ5PwkXSJJWZjJMPipphjdyVfqKEQkEb0uMtqYOXMmJk+erPk+JycH3t7eOn+cqAHBiBoQrPP7JSIioprT6yLj6uoKc3NzpKWllVuelpYGT0/PSreRy+WQy+UNEY+IiIgkptezESsrKzz99NPYt2+fZplarca+ffvQsWNHCZMRERGRPtDrIzIAMHnyZIwaNQrt27dHhw4d8PnnnyM/Px+jR4+WOhoRERFJTO+LzPDhw3H37l3MmTMHqampaNu2LX7//fcKJwATERGR6dH795Gpq/p6HxkiIiKqPzX9+63X58gQERERVYdFhoiIiAwWiwwREREZLBYZIiIiMlgsMkRERGSwWGSIiIjIYLHIEBERkcFikSEiIiKDxSJDREREBkvvP6KgrsreuDgnJ0fiJERERFRTZX+3n/QBBEZfZHJzcwEA3t7eEichIiKi2srNzYVCoajydqP/rCW1Wo07d+7AwcEBMplMZ/ebk5MDb29vJCUlGe1nOBn7czT25wcY/3Pk8zN8xv4c+fy0J4RAbm4uvLy8YGZW9ZkwRn9ExszMDE2bNq23+3d0dDTKf5yPMvbnaOzPDzD+58jnZ/iM/Tny+WmnuiMxZXiyLxERERksFhkiIiIyWCwyWpLL5YiMjIRcLpc6Sr0x9udo7M8PMP7nyOdn+Iz9OfL51T+jP9mXiIiIjBePyBAREZHBYpEhIiIig8UiQ0RERAaLRYaIiIgMFotMNT799FN06tQJtra2cHJyqnSdW7duoV+/frC1tYW7uzumTZuGkpKSau83MzMTI0eOhKOjI5ycnPDGG28gLy+vHp5B7Rw8eBAymazSrxMnTlS5Xffu3SusP27cuAZMXnO+vr4Vsi5cuLDabQoLCzFhwgQ0atQI9vb2GDJkCNLS0hoocc3duHEDb7zxBvz8/GBjY4OAgABERkaiqKio2u30ff+tXLkSvr6+sLa2Rnh4OP7+++9q14+JiUFQUBCsra0REhKCXbt2NVDS2omOjsYzzzwDBwcHuLu7Y+DAgYiPj692mzVr1lTYV9bW1g2UuPbmzp1bIW9QUFC12xjK/gMq/30ik8kwYcKEStc3hP136NAhvPTSS/Dy8oJMJsO2bdvK3S6EwJw5c9C4cWPY2NggIiICV69efeL91vbnuDZYZKpRVFSEYcOG4Z133qn0dpVKhX79+qGoqAhHjhzB2rVrsWbNGsyZM6fa+x05ciQuXryIPXv2YOfOnTh06BDeeuut+ngKtdKpUyekpKSU+xo7diz8/PzQvn37ard98803y223ePHiBkpde/PmzSuX9d133612/Q8++AC//PILYmJi8Mcff+DOnTsYPHhwA6Wtubi4OKjVaqxatQoXL17E8uXL8fXXX2PWrFlP3FZf99+GDRswefJkREZG4vTp0wgLC0OvXr2Qnp5e6fpHjhzBq6++ijfeeANnzpzBwIEDMXDgQFy4cKGBkz/ZH3/8gQkTJuDYsWPYs2cPiouL8eKLLyI/P7/a7RwdHcvtq5s3bzZQYu20adOmXN7Dhw9Xua4h7T8AOHHiRLnntmfPHgDAsGHDqtxG3/dffn4+wsLCsHLlykpvX7x4Mb744gt8/fXXOH78OOzs7NCrVy8UFhZWeZ+1/TmuNUFPtHr1aqFQKCos37VrlzAzMxOpqamaZV999ZVwdHQUSqWy0vu6dOmSACBOnDihWfbbb78JmUwmbt++rfPsdVFUVCTc3NzEvHnzql2vW7du4v3332+YUHXk4+Mjli9fXuP1s7KyhKWlpYiJidEsu3z5sgAgjh49Wg8JdWvx4sXCz8+v2nX0ef916NBBTJgwQfO9SqUSXl5eIjo6utL1X3nlFdGvX79yy8LDw8Xbb79drzl1IT09XQAQf/zxR5XrVPW7SF9FRkaKsLCwGq9vyPtPCCHef/99ERAQINRqdaW3G9r+AyC2bt2q+V6tVgtPT0+xZMkSzbKsrCwhl8vFzz//XOX91PbnuLZ4RKYOjh49ipCQEHh4eGiW9erVCzk5Obh48WKV2zg5OZU7whEREQEzMzMcP3683jPXxo4dO3Dv3j2MHj36iev++OOPcHV1RXBwMGbOnImCgoIGSKidhQsXolGjRmjXrh2WLFlS7Sjw1KlTKC4uRkREhGZZUFAQmjVrhqNHjzZE3DrJzs6Gi4vLE9fTx/1XVFSEU6dOlXvtzczMEBERUeVrf/To0XLrA6U/k4ayrwA8cX/l5eXBx8cH3t7eGDBgQJW/a/TF1atX4eXlBX9/f4wcORK3bt2qcl1D3n9FRUVYt24dxowZU+0HFBva/ntUYmIiUlNTy+0jhUKB8PDwKveRNj/HtWX0HxpZn1JTU8uVGACa71NTU6vcxt3dvdwyCwsLuLi4VLmNVL777jv06tXriR+6+Y9//AM+Pj7w8vLCuXPnMH36dMTHx2PLli0NlLTm3nvvPTz11FNwcXHBkSNHMHPmTKSkpOCzzz6rdP3U1FRYWVlVOEfKw8ND7/bX465du4YVK1Zg6dKl1a6nr/svIyMDKpWq0p+xuLi4Srep6mdS3/eVWq3GpEmT0LlzZwQHB1e5XmBgIP773/8iNDQU2dnZWLp0KTp16oSLFy/W64fjais8PBxr1qxBYGAgUlJSEBUVhS5duuDChQtwcHCosL6h7j8A2LZtG7KysvD6669XuY6h7b/Hle2H2uwjbX6Oa8vkisyMGTOwaNGiate5fPnyE09IMyTaPOfk5GTs3r0bGzdufOL9P3p+T0hICBo3boyePXsiISEBAQEB2gevodo8v8mTJ2uWhYaGwsrKCm+//Taio6P19i3Etdl/t2/fRu/evTFs2DC8+eab1W4r9f4jYMKECbhw4UK1548AQMeOHdGxY0fN9506dUKrVq2watUqzJ8/v75j1lqfPn00/x0aGorw8HD4+Phg48aNeOONNyRMpnvfffcd+vTpAy8vryrXMbT9ZyhMrshMmTKl2sYMAP7+/jW6L09PzwpnXpddzeLp6VnlNo+f4FRSUoLMzMwqt6krbZ7z6tWr0ahRI7z88su1frzw8HAApUcEGuIPYV32aXh4OEpKSnDjxg0EBgZWuN3T0xNFRUXIysoqd1QmLS2t3vbX42r7/O7cuYMePXqgU6dO+Oabb2r9eA29/6ri6uoKc3PzCleIVffae3p61mp9fTBx4kTNSf+1/b9yS0tLtGvXDteuXaundLrl5OSEli1bVpnXEPcfANy8eRN79+6t9VFMQ9t/ZfshLS0NjRs31ixPS0tD27ZtK91Gm5/jWtPJmTZG7kkn+6alpWmWrVq1Sjg6OorCwsJK76vsZN+TJ09qlu3evVuvTvZVq9XCz89PTJkyRavtDx8+LACI2NhYHSfTvXXr1gkzMzORmZlZ6e1lJ/tu2rRJsywuLk5vT/ZNTk4WLVq0ECNGjBAlJSVa3Yc+7b8OHTqIiRMnar5XqVSiSZMm1Z7s279//3LLOnbsqJcni6rVajFhwgTh5eUlrly5otV9lJSUiMDAQPHBBx/oOF39yM3NFc7OzuLf//53pbcb0v57VGRkpPD09BTFxcW12k7f9x+qONl36dKlmmXZ2dk1Otm3Nj/Htc6pk3sxUjdv3hRnzpwRUVFRwt7eXpw5c0acOXNG5ObmCiFK/xEGBweLF198UZw9e1b8/vvvws3NTcycOVNzH8ePHxeBgYEiOTlZs6x3796iXbt24vjx4+Lw4cOiRYsW4tVXX23w51eVvXv3CgDi8uXLFW5LTk4WgYGB4vjx40IIIa5duybmzZsnTp48KRITE8X27duFv7+/6Nq1a0PHfqIjR46I5cuXi7Nnz4qEhASxbt064ebmJl577TXNOo8/PyGEGDdunGjWrJnYv3+/OHnypOjYsaPo2LGjFE+hWsnJyaJ58+aiZ8+eIjk5WaSkpGi+Hl3HkPbf+vXrhVwuF2vWrBGXLl0Sb731lnByctJcKfivf/1LzJgxQ7P+X3/9JSwsLMTSpUvF5cuXRWRkpLC0tBTnz5+X6ilU6Z133hEKhUIcPHiw3L4qKCjQrPP484uKihK7d+8WCQkJ4tSpU2LEiBHC2tpaXLx4UYqn8ERTpkwRBw8eFImJieKvv/4SERERwtXVVaSnpwshDHv/lVGpVKJZs2Zi+vTpFW4zxP2Xm5ur+VsHQHz22WfizJkz4ubNm0IIIRYuXCicnJzE9u3bxblz58SAAQOEn5+fePDggeY+nn/+ebFixQrN90/6Oa4rFplqjBo1SgCo8HXgwAHNOjdu3BB9+vQRNjY2wtXVVUyZMqVcKz9w4IAAIBITEzXL7t27J1599VVhb28vHB0dxejRozXlSB+8+uqrolOnTpXelpiYWO41uHXrlujatatwcXERcrlcNG/eXEybNk1kZ2c3YOKaOXXqlAgPDxcKhUJYW1uLVq1aiQULFpQ7evb48xNCiAcPHojx48cLZ2dnYWtrKwYNGlSuHOiL1atXV/rv9dEDr4a4/1asWCGaNWsmrKysRIcOHcSxY8c0t3Xr1k2MGjWq3PobN24ULVu2FFZWVqJNmzbi119/beDENVPVvlq9erVmncef36RJkzSvhYeHh+jbt684ffp0w4evoeHDh4vGjRsLKysr0aRJEzF8+HBx7do1ze2GvP/K7N69WwAQ8fHxFW4zxP1X9jfr8a+y56FWq8Xs2bOFh4eHkMvlomfPnhWeu4+Pj4iMjCy3rLqf47qSCSGEboZURERERA2L7yNDREREBotFhoiIiAwWiwwREREZLBYZIiIiMlgsMkRERGSwWGSIiIjIYLHIEBERkcFikSEiyXTv3h2TJk2SOgYRGTC+IR4RSSYzMxOWlpZwcHBosMecO3cutm3bhrNnzzbYYxJR/TG5T78mIv3h4uIidQQiMnAcLRGRZB4dLfn6+mLBggUYM2YMHBwc0KxZM3zzzTeadW/cuAGZTIb169ejU6dOsLa2RnBwMP744w/NOmvWrIGTk1O5x9i2bRtkMpnm9qioKMTGxkImk0Emk2HNmjX1/TSJqB6xyBCR3li2bBnat2+PM2fOYPz48XjnnXcQHx9fbp1p06ZhypQpOHPmDDp27IiXXnoJ9+7dq9H9Dx8+HFOmTEGbNm2QkpKClJQUDB8+vD6eChE1EBYZItIbffv2xfjx49G8eXNMnz4drq6uOHDgQLl1Jk6ciCFDhqBVq1b46quvoFAo8N1339Xo/m1sbGBvbw8LCwt4enrC09MTNjY29fFUiKiBsMgQkd4IDQ3V/LdMJoOnpyfS09PLrdOxY0fNf1tYWKB9+/a4fPlyg2UkIv3CIkNEesPS0rLc9zKZDGq1usbbm5mZ4fELMYuLi3WSjYj0E4sMERmUY8eOaf67pKQEp06dQqtWrQAAbm5uyM3NRX5+vmadxy+ztrKygkqlapCsRFT/WGSIyKCsXLkSW7duRVxcHCZMmID79+9jzJgxAIDw8HDY2tpi1qxZSEhIwE8//VThqiRfX18kJibi7NmzyMjIgFKplOBZEJGusMgQkUFZuHAhFi5ciLCwMBw+fBg7duyAq6srgNL3pVm3bh127dqFkJAQ/Pzzz5g7d2657YcMGYLevXujR48ecHNzw88//yzBsyAiXeE7+xKRQbhx4wb8/Pxw5swZtG3bVuo4RKQneESGiIiIDBaLDBERERksjpaIiIjIYPGIDBERERksFhkiIiIyWCwyREREZLBYZIiIiMhgscgQERGRwWKRISIiIoPFIkNEREQGi0WGiIiIDBaLDBERERms/wdNlWHG1RNoewAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, reLu(x))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.title(\"ReLU activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b927d56140>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b925b1aa70>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, softmax(x))\n",
    "# How do I test my implementation of the softmax function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.input = x # store the input to use it in the backward pass\n",
    "        return np.maximum(0, x)  # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        self.input[self.input <= 0] = 0 # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return self.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('gradient_values'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        \n",
    "        sigmoid_derivative = self.output * (1 - self.output) # calculate the derivative of Sigmoid: f(x) * (1 - f(x)) where f(x) is the Sigmoid function\n",
    "        return sigmoid_derivative  # multiply the gradient of the loss function by the derivative of Sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - Implement softmax layer\n",
    "Implement softmax with both forward and backward pass. Present the \n",
    "softmax in the report along with any numerical issues when calculating the \n",
    "softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'x', with the\n",
    "                         same shape as 'x'.\n",
    "        '''        \n",
    "        #e_x = np.exp(x - np.max(x, axis=-1, keepdims=True)) # shift input 'x' for numerical stability (prevention of overflow/underflow).\n",
    "        e_x = np.exp(x)\n",
    "        #self.output = e_x / np.sum(e_x, axis=-1, keepdims=True) # apply the softmax function: f(xi) = exp(xi) / sum(exp(x)) for x=[x1,...,xK]\n",
    "        self.output = e_x / np.sum(e_x)\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        # Gradient values not used -> Remove!!\n",
    "        softmax_jacobian = self.output * (np.eye(self.output.shape[0]) - self.output.T)\n",
    "        #print(softmax_jacobian)\n",
    "        print(softmax_jacobian.shape)\n",
    "        return softmax_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    weights = 0\n",
    "    new_weights = 0\n",
    "    bias = 0\n",
    "    activation = 0\n",
    "    layer_input = 0\n",
    "    softmax = False\n",
    "    \n",
    "    def __init__(self, input_units, output_units, activation):\n",
    "        # Weight initialisation crucial for performance\n",
    "        self.weights = 2*np.random.rand(output_units, input_units)-1\n",
    "        self.new_weights = 2*np.random.rand(output_units, input_units)-1\n",
    "        self.layer_input = 0\n",
    "        self.bias = 0\n",
    "        self.softmax = False\n",
    "        '''\n",
    "        Set activation function for the layer\n",
    "        '''   \n",
    "        if activation == 'relu':\n",
    "            print(\"ReLU\")\n",
    "            self.activation = ReLu()\n",
    "        elif activation == 'sigmoid':\n",
    "            print(\"Sigmoid\")\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'softmax':\n",
    "            print(\"Softmax\")\n",
    "            self.softmax = True\n",
    "            self.activation = Softmax()\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        #print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "        #print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Weights combined with input and bias\n",
    "        '''\n",
    "        z = np.dot(self.weights, x) + self.bias\n",
    "        '''\n",
    "        Pass z through activation function\n",
    "        '''\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "        \n",
    "    '''\n",
    "    Idea is to have backward pass for activation functions just return the derivative of the activation,\n",
    "    and backward_pass for layer perform any other calculation (dot product of activation function with loss for example)\n",
    "    '''   \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "         #print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "        #print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        derivative_final = x * activation_derivative\n",
    "        #print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "        #print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "        #print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        Check whether - or +, different sources say different expressions\n",
    "        '''\n",
    "        self.new_weights = (self.weights + learning_rate*np.dot(derivative_final, self.layer_input.T))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(self.weights.T, derivative_final)\n",
    "        #print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        #print(\"Old_weights\")\n",
    "        #print(self.weights)\n",
    "        #print(\"New_weights\")\n",
    "        #print(self.new_weights)\n",
    "        self.weights = self.new_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass of layer\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, input_units, output_units, activation):\n",
    "        super().__init__(input_units, output_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        #print (\"Shape of weights {}\".format(self.weights.shape))         \n",
    "        #print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = x\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "    \n",
    "    # No weights in input layer\n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print(\"Last backwards pass layer\")\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"No weights in input layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, input_units, output_units, activation):\n",
    "        super().__init__(input_units, output_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        #print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "        #print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(self.weights, x) + self.bias\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "    \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "        #print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            derivative_final = x * activation_derivative\n",
    "        print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "        print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "        print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = (self.weights + learning_rate*np.dot(derivative_final, self.layer_input.T))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(self.weights.T, derivative_final)\n",
    "        #print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def mse_loss(self, output, target):\n",
    "        loss = 1/len(output)*np.sum((output-target)**2)\n",
    "        return loss\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        #print(\"Old_weights\")\n",
    "        #print(self.weights)\n",
    "        #print(\"New_weights\")\n",
    "        #print(self.new_weights)\n",
    "        self.weights = self.new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08468093],\n",
       "       [-0.97573851],\n",
       "       [-0.3422069 ],\n",
       "       [ 0.05399495],\n",
       "       [-0.82073047]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY\n",
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "prediction = softmax.forward_pass(x)\n",
    "loss = np.sum((prediction - y) ** 2)\n",
    "loss_derivative = (prediction -y)\n",
    "prediction, loss, np.sum(prediction)\n",
    "loss_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_derivative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient_softmax = softmax.backward_pass(loss_derivative.T, learning_rate)\n",
    "#gradient_softmax.shape, gradient_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - Implement dropout \n",
    "Present dropout in the report. Implement inverted dropout. Forward and \n",
    "backward pass should be implemented.\n",
    "Note: Since the test performance is critical, it is also preferable to leaving \n",
    "the forward pass unchanged at test time. Therefore, in most \n",
    "implementations inverted dropout is employed to overcome the \n",
    "undesirable property of the original dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of \n",
    "hidden layers, units, activation functions can be changed. In addition, you \n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used \n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots \n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "    A class representing the Fully Parametrizable Neural Network.\n",
    "    '''\n",
    "    layer_list = []\n",
    "    X = 0\n",
    "    Y = 0\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 8\n",
    "    epochs = 100   \n",
    "    \n",
    "    def __init__(self, X, Y, learning_rate, dropout_rate = 0.5, batch_size = 4, epochs = 10):\n",
    "        self.layer_list = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def addLayer(self, input_units, output_units, activation, mode = \"input\"):\n",
    "        if mode == \"input\":\n",
    "            print(\"Added input\")\n",
    "            layer = InputLayer(input_units, output_units, activation)\n",
    "        elif mode == \"output\":\n",
    "            print(\"Added output\")\n",
    "            layer = OutputLayer(input_units, output_units, activation)\n",
    "        else:\n",
    "            print(\"Added hidden\")\n",
    "            layer = Layer(input_units, output_units, activation)\n",
    "        self.layer_list.append(layer)\n",
    "        \n",
    "    def loss(self, output, target, mode = \"mse\"):\n",
    "        if mode == \"mse\":\n",
    "            loss = 1/len(output)*np.sum((output-target)**2)\n",
    "            return loss\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            input_data = self.X\n",
    "            print(input_data.shape)\n",
    "            # Forward pass\n",
    "            print(\"Forward pass epoch {}\".format(i))\n",
    "            for index, layer in enumerate(self.layer_list):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                output_data = layer.forward_pass(input_data)\n",
    "                input_data = output_data\n",
    "                \n",
    "            # Calculate loss \n",
    "            output_data = np.around(output_data, 6)\n",
    "            print(\"Model output: {}\".format (output_data))\n",
    "            loss_cost = self.loss(output_data, self.Y, mode = \"mse\")\n",
    "            loss_cost = np.around(loss_cost, 6)\n",
    "            print(\"Loss: {}\".format(loss_cost))\n",
    "            \n",
    "            # Backward pass  \n",
    "            input_derivative = (self.Y - output_data)\n",
    "            print(\"Backward pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                output_derivative = layer.backward_pass(input_derivative, self.learning_rate)\n",
    "                input_derivative = output_derivative\n",
    "                \n",
    "            # Update pass. Supposedly update weights after backward pass completed\n",
    "            # Weights barely updating??\n",
    "            print(\"Update pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                layer.update_weights(self.learning_rate)\n",
    "                                         \n",
    "    def predict(self, X):\n",
    "        input_data = X\n",
    "        for index, layer in enumerate(self.layer_list):\n",
    "            output_data = layer.forward_pass(input_data)\n",
    "            input_data = output_data\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY DATASET\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "dataset = load_digits()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Sigmoid\n",
      "(1797, 64)\n",
      "Forward pass epoch 0\n",
      "Model output: [[5.00000e-01 0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 9.74002e-01 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 5.02000e-04 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  9.61217e-01 1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 9.90409e-01 5.00000e-01 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 0.00000e+00 5.00000e-01 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 7.77100e-03 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00]\n",
      " [5.00000e-01 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  7.51800e-03 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 5.00000e-01 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 5.00000e-01 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [5.00000e-01 0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 9.99827e-01 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 4.09296e-01 5.00000e-01 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 0.00000e+00 5.00000e-01 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  9.99999e-01 0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 9.72691e-01 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00]\n",
      " [5.00000e-01 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 2.00000e-06 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  9.21198e-01 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 4.84000e-04 5.00000e-01 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 5.00000e-01 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 9.96447e-01 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00]\n",
      " [5.00000e-01 0.00000e+00 9.99998e-01 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.97600e-03 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  9.70386e-01 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 5.00000e-01 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00 5.00000e-01 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 4.61000e-04 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [5.00000e-01 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 5.00000e-01 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 5.00000e-01 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00]\n",
      " [5.00000e-01 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 3.00000e-06 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 5.00000e-01 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 5.00000e-01 9.99998e-01 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [5.00000e-01 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 5.00000e-01 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 5.00000e-01 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00]\n",
      " [5.00000e-01 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      "  3.50000e-05 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 1.00000e+00 5.00000e-01 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 1.00000e+00 5.00000e-01 1.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [5.00000e-01 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00\n",
      "  7.64006e-01 1.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 9.99995e-01 5.00000e-01 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 5.00000e-01 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 3.79000e-04 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aless\\AppData\\Local\\Temp\\ipykernel_22796\\1113617650.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,64) (1797,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aless\\Desktop\\Uni\\Math and Programming for AI\\Programming_And_Mathematics_For_AI\\main.ipynb Cell 27\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39maddLayer(\u001b[39m128\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhidden\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39maddLayer(\u001b[39m32\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32mc:\\Users\\aless\\Desktop\\Uni\\Math and Programming for AI\\Programming_And_Mathematics_For_AI\\main.ipynb Cell 27\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m output_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maround(output_data, \u001b[39m6\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel output: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat (output_data))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m loss_cost \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(output_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mY, mode \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmse\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m loss_cost \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maround(loss_cost, \u001b[39m6\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(loss_cost))\n",
      "\u001b[1;32mc:\\Users\\aless\\Desktop\\Uni\\Math and Programming for AI\\Programming_And_Mathematics_For_AI\\main.ipynb Cell 27\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, output, target, mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         loss \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(output)\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msum((output\u001b[39m-\u001b[39;49mtarget)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X40sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m loss\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,64) (1797,) "
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.1, dropout_rate = 0, batch_size = 1, epochs = 100)\n",
    "model.addLayer(X.shape[0], X.shape[0], 'relu', 'input')\n",
    "model.addLayer(1797, 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 128, 'relu', 'hidden')\n",
    "model.addLayer(128, 32, 'relu', 'hidden')\n",
    "model.addLayer(32, 10, 'sigmoid', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Sigmoid\n",
      "(5, 1)\n",
      "Forward pass epoch 0\n",
      "Model output: [[0.225218]\n",
      " [0.004199]\n",
      " [0.033276]\n",
      " [0.995126]\n",
      " [0.85924 ]]\n",
      "Loss: 0.597397\n",
      "Backward pass epoch 0\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 0\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 1\n",
      "Model output: [[0.049977]\n",
      " [0.016798]\n",
      " [0.866947]\n",
      " [0.985991]\n",
      " [0.578904]]\n",
      "Loss: 0.427277\n",
      "Backward pass epoch 1\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 1\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 2\n",
      "Model output: [[0.090911]\n",
      " [0.026269]\n",
      " [0.613804]\n",
      " [0.990556]\n",
      " [0.884478]]\n",
      "Loss: 0.420022\n",
      "Backward pass epoch 2\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 2\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 3\n",
      "Model output: [[0.03272 ]\n",
      " [0.059182]\n",
      " [0.97321 ]\n",
      " [0.982731]\n",
      " [0.582098]]\n",
      "Loss: 0.405466\n",
      "Backward pass epoch 3\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 3\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 4\n",
      "Model output: [[0.144353]\n",
      " [0.109798]\n",
      " [0.867293]\n",
      " [0.961378]\n",
      " [0.776132]]\n",
      "Loss: 0.361055\n",
      "Backward pass epoch 4\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 4\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 5\n",
      "Model output: [[0.209713]\n",
      " [0.161366]\n",
      " [0.821772]\n",
      " [0.935862]\n",
      " [0.772246]]\n",
      "Loss: 0.341352\n",
      "Backward pass epoch 5\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 5\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 6\n",
      "Model output: [[0.25069 ]\n",
      " [0.218158]\n",
      " [0.815395]\n",
      " [0.900871]\n",
      " [0.746798]]\n",
      "Loss: 0.316776\n",
      "Backward pass epoch 6\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 6\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 7\n",
      "Model output: [[0.282921]\n",
      " [0.265058]\n",
      " [0.810948]\n",
      " [0.858015]\n",
      " [0.72593 ]]\n",
      "Loss: 0.293446\n",
      "Backward pass epoch 7\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 7\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 8\n",
      "Model output: [[0.310575]\n",
      " [0.304091]\n",
      " [0.808914]\n",
      " [0.813474]\n",
      " [0.710861]]\n",
      "Loss: 0.27252\n",
      "Backward pass epoch 8\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 8\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 9\n",
      "Model output: [[0.334446]\n",
      " [0.336495]\n",
      " [0.808584]\n",
      " [0.77179 ]\n",
      " [0.702193]]\n",
      "Loss: 0.254616\n",
      "Backward pass epoch 9\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 9\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 10\n",
      "Model output: [[0.355306]\n",
      " [0.365328]\n",
      " [0.809796]\n",
      " [0.734846]\n",
      " [0.698694]]\n",
      "Loss: 0.239202\n",
      "Backward pass epoch 10\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 10\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 11\n",
      "Model output: [[0.372104]\n",
      " [0.401031]\n",
      " [0.812754]\n",
      " [0.705402]\n",
      " [0.693942]]\n",
      "Loss: 0.22471\n",
      "Backward pass epoch 11\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 11\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 12\n",
      "Model output: [[0.387676]\n",
      " [0.435701]\n",
      " [0.817223]\n",
      " [0.679111]\n",
      " [0.69465 ]]\n",
      "Loss: 0.211313\n",
      "Backward pass epoch 12\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 12\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 13\n",
      "Model output: [[0.402625]\n",
      " [0.471027]\n",
      " [0.82325 ]\n",
      " [0.653781]\n",
      " [0.699832]]\n",
      "Loss: 0.198138\n",
      "Backward pass epoch 13\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 13\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 14\n",
      "Model output: [[0.417569]\n",
      " [0.509066]\n",
      " [0.830863]\n",
      " [0.627068]\n",
      " [0.709336]]\n",
      "Loss: 0.184337\n",
      "Backward pass epoch 14\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 14\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 15\n",
      "Model output: [[0.433644]\n",
      " [0.553296]\n",
      " [0.836967]\n",
      " [0.601661]\n",
      " [0.73139 ]]\n",
      "Loss: 0.169664\n",
      "Backward pass epoch 15\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 15\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 16\n",
      "Model output: [[0.441278]\n",
      " [0.598061]\n",
      " [0.846056]\n",
      " [0.57257 ]\n",
      " [0.754856]]\n",
      "Loss: 0.153582\n",
      "Backward pass epoch 16\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 16\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 17\n",
      "Model output: [[0.436067]\n",
      " [0.65855 ]\n",
      " [0.868928]\n",
      " [0.534478]\n",
      " [0.790394]]\n",
      "Loss: 0.130705\n",
      "Backward pass epoch 17\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 17\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 18\n",
      "Model output: [[0.422456]\n",
      " [0.70586 ]\n",
      " [0.907083]\n",
      " [0.527382]\n",
      " [0.877717]]\n",
      "Loss: 0.113341\n",
      "Backward pass epoch 18\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 18\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 19\n",
      "Model output: [[0.308631]\n",
      " [0.829267]\n",
      " [0.961415]\n",
      " [0.531439]\n",
      " [0.962358]]\n",
      "Loss: 0.081947\n",
      "Backward pass epoch 19\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 19\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 20\n",
      "Model output: [[0.231959]\n",
      " [0.952233]\n",
      " [0.992037]\n",
      " [0.286646]\n",
      " [0.996093]]\n",
      "Loss: 0.027666\n",
      "Backward pass epoch 20\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 20\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 21\n",
      "Model output: [[0.050758]\n",
      " [0.995339]\n",
      " [0.999835]\n",
      " [0.068506]\n",
      " [0.999968]]\n",
      "Loss: 0.001458\n",
      "Backward pass epoch 21\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 21\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 22\n",
      "Model output: [[0.022297]\n",
      " [0.999103]\n",
      " [0.999981]\n",
      " [0.033221]\n",
      " [0.999999]]\n",
      "Loss: 0.00032\n",
      "Backward pass epoch 22\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 22\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 23\n",
      "Model output: [[0.01548 ]\n",
      " [0.999626]\n",
      " [0.999993]\n",
      " [0.022452]\n",
      " [1.      ]]\n",
      "Loss: 0.000149\n",
      "Backward pass epoch 23\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 23\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 24\n",
      "Model output: [[0.012118]\n",
      " [0.999786]\n",
      " [0.999997]\n",
      " [0.017461]\n",
      " [1.      ]]\n",
      "Loss: 9e-05\n",
      "Backward pass epoch 24\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 24\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 25\n",
      "Model output: [[0.010082]\n",
      " [0.999859]\n",
      " [0.999998]\n",
      " [0.014482]\n",
      " [1.      ]]\n",
      "Loss: 6.2e-05\n",
      "Backward pass epoch 25\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 25\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 26\n",
      "Model output: [[0.008702]\n",
      " [0.999899]\n",
      " [0.999999]\n",
      " [0.012478]\n",
      " [1.      ]]\n",
      "Loss: 4.6e-05\n",
      "Backward pass epoch 26\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 26\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 27\n",
      "Model output: [[0.007697]\n",
      " [0.999923]\n",
      " [0.999999]\n",
      " [0.011025]\n",
      " [1.      ]]\n",
      "Loss: 3.6e-05\n",
      "Backward pass epoch 27\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 27\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 28\n",
      "Model output: [[0.006928]\n",
      " [0.999939]\n",
      " [0.999999]\n",
      " [0.009917]\n",
      " [1.      ]]\n",
      "Loss: 2.9e-05\n",
      "Backward pass epoch 28\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 28\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 29\n",
      "Model output: [[0.00632 ]\n",
      " [0.99995 ]\n",
      " [0.999999]\n",
      " [0.009042]\n",
      " [1.      ]]\n",
      "Loss: 2.4e-05\n",
      "Backward pass epoch 29\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 29\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 30\n",
      "Model output: [[0.005825]\n",
      " [0.999958]\n",
      " [1.      ]\n",
      " [0.00833 ]\n",
      " [1.      ]]\n",
      "Loss: 2.1e-05\n",
      "Backward pass epoch 30\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 30\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 31\n",
      "Model output: [[0.005412]\n",
      " [0.999964]\n",
      " [1.      ]\n",
      " [0.007739]\n",
      " [1.      ]]\n",
      "Loss: 1.8e-05\n",
      "Backward pass epoch 31\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 31\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 32\n",
      "Model output: [[0.005064]\n",
      " [0.999969]\n",
      " [1.      ]\n",
      " [0.007239]\n",
      " [1.      ]]\n",
      "Loss: 1.6e-05\n",
      "Backward pass epoch 32\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 32\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 33\n",
      "Model output: [[0.004764]\n",
      " [0.999973]\n",
      " [1.      ]\n",
      " [0.00681 ]\n",
      " [1.      ]]\n",
      "Loss: 1.4e-05\n",
      "Backward pass epoch 33\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 33\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 34\n",
      "Model output: [[0.004504]\n",
      " [0.999976]\n",
      " [1.      ]\n",
      " [0.006437]\n",
      " [1.      ]]\n",
      "Loss: 1.2e-05\n",
      "Backward pass epoch 34\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 34\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 35\n",
      "Model output: [[0.004275]\n",
      " [0.999979]\n",
      " [1.      ]\n",
      " [0.006109]\n",
      " [1.      ]]\n",
      "Loss: 1.1e-05\n",
      "Backward pass epoch 35\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 35\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 36\n",
      "Model output: [[0.004072]\n",
      " [0.999981]\n",
      " [1.      ]\n",
      " [0.005819]\n",
      " [1.      ]]\n",
      "Loss: 1e-05\n",
      "Backward pass epoch 36\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 36\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 37\n",
      "Model output: [[0.003891]\n",
      " [0.999983]\n",
      " [1.      ]\n",
      " [0.00556 ]\n",
      " [1.      ]]\n",
      "Loss: 9e-06\n",
      "Backward pass epoch 37\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 37\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 38\n",
      "Model output: [[0.003728]\n",
      " [0.999984]\n",
      " [1.      ]\n",
      " [0.005327]\n",
      " [1.      ]]\n",
      "Loss: 8e-06\n",
      "Backward pass epoch 38\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 38\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 39\n",
      "Model output: [[0.00358 ]\n",
      " [0.999986]\n",
      " [1.      ]\n",
      " [0.005117]\n",
      " [1.      ]]\n",
      "Loss: 8e-06\n",
      "Backward pass epoch 39\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 39\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 40\n",
      "Model output: [[0.003446]\n",
      " [0.999987]\n",
      " [1.      ]\n",
      " [0.004925]\n",
      " [1.      ]]\n",
      "Loss: 7e-06\n",
      "Backward pass epoch 40\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 40\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 41\n",
      "Model output: [[0.003324]\n",
      " [0.999988]\n",
      " [1.      ]\n",
      " [0.00475 ]\n",
      " [1.      ]]\n",
      "Loss: 7e-06\n",
      "Backward pass epoch 41\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 41\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 42\n",
      "Model output: [[0.003211]\n",
      " [0.999989]\n",
      " [1.      ]\n",
      " [0.004589]\n",
      " [1.      ]]\n",
      "Loss: 6e-06\n",
      "Backward pass epoch 42\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 42\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 43\n",
      "Model output: [[0.003107]\n",
      " [0.999989]\n",
      " [1.      ]\n",
      " [0.004441]\n",
      " [1.      ]]\n",
      "Loss: 6e-06\n",
      "Backward pass epoch 43\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 43\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 44\n",
      "Model output: [[0.003011]\n",
      " [0.99999 ]\n",
      " [1.      ]\n",
      " [0.004304]\n",
      " [1.      ]]\n",
      "Loss: 6e-06\n",
      "Backward pass epoch 44\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 44\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 45\n",
      "Model output: [[0.002922]\n",
      " [0.999991]\n",
      " [1.      ]\n",
      " [0.004177]\n",
      " [1.      ]]\n",
      "Loss: 5e-06\n",
      "Backward pass epoch 45\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 45\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 46\n",
      "Model output: [[0.002839]\n",
      " [0.999991]\n",
      " [1.      ]\n",
      " [0.004058]\n",
      " [1.      ]]\n",
      "Loss: 5e-06\n",
      "Backward pass epoch 46\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 46\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 47\n",
      "Model output: [[0.002761]\n",
      " [0.999992]\n",
      " [1.      ]\n",
      " [0.003948]\n",
      " [1.      ]]\n",
      "Loss: 5e-06\n",
      "Backward pass epoch 47\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 47\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 48\n",
      "Model output: [[0.002689]\n",
      " [0.999992]\n",
      " [1.      ]\n",
      " [0.003844]\n",
      " [1.      ]]\n",
      "Loss: 4e-06\n",
      "Backward pass epoch 48\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 48\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 49\n",
      "Model output: [[0.002621]\n",
      " [0.999993]\n",
      " [1.      ]\n",
      " [0.003747]\n",
      " [1.      ]]\n",
      "Loss: 4e-06\n",
      "Backward pass epoch 49\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 49\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 50\n",
      "Model output: [[0.002557]\n",
      " [0.999993]\n",
      " [1.      ]\n",
      " [0.003655]\n",
      " [1.      ]]\n",
      "Loss: 4e-06\n",
      "Backward pass epoch 50\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 50\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 51\n",
      "Model output: [[0.002496]\n",
      " [0.999993]\n",
      " [1.      ]\n",
      " [0.003569]\n",
      " [1.      ]]\n",
      "Loss: 4e-06\n",
      "Backward pass epoch 51\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 51\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 52\n",
      "Model output: [[0.002439]\n",
      " [0.999994]\n",
      " [1.      ]\n",
      " [0.003488]\n",
      " [1.      ]]\n",
      "Loss: 4e-06\n",
      "Backward pass epoch 52\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 52\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 53\n",
      "Model output: [[0.002385]\n",
      " [0.999994]\n",
      " [1.      ]\n",
      " [0.003411]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 53\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 53\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 54\n",
      "Model output: [[0.002334]\n",
      " [0.999994]\n",
      " [1.      ]\n",
      " [0.003338]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 54\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 54\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 55\n",
      "Model output: [[0.002285]\n",
      " [0.999994]\n",
      " [1.      ]\n",
      " [0.003269]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 55\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 55\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 56\n",
      "Model output: [[0.002239]\n",
      " [0.999995]\n",
      " [1.      ]\n",
      " [0.003203]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 56\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 56\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 57\n",
      "Model output: [[0.002195]\n",
      " [0.999995]\n",
      " [1.      ]\n",
      " [0.00314 ]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 57\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 57\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 58\n",
      "Model output: [[0.002154]\n",
      " [0.999995]\n",
      " [1.      ]\n",
      " [0.00308 ]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 58\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 58\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 59\n",
      "Model output: [[0.002113]\n",
      " [0.999995]\n",
      " [1.      ]\n",
      " [0.003023]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 59\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 59\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 60\n",
      "Model output: [[0.002075]\n",
      " [0.999995]\n",
      " [1.      ]\n",
      " [0.002969]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 60\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 60\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 61\n",
      "Model output: [[0.002039]\n",
      " [0.999996]\n",
      " [1.      ]\n",
      " [0.002917]\n",
      " [1.      ]]\n",
      "Loss: 3e-06\n",
      "Backward pass epoch 61\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 61\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 62\n",
      "Model output: [[0.002004]\n",
      " [0.999996]\n",
      " [1.      ]\n",
      " [0.002867]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 62\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 62\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 63\n",
      "Model output: [[0.00197 ]\n",
      " [0.999996]\n",
      " [1.      ]\n",
      " [0.002819]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 63\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 63\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 64\n",
      "Model output: [[0.001938]\n",
      " [0.999996]\n",
      " [1.      ]\n",
      " [0.002773]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 64\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 64\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 65\n",
      "Model output: [[0.001907]\n",
      " [0.999996]\n",
      " [1.      ]\n",
      " [0.002728]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 65\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 65\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 66\n",
      "Model output: [[0.001877]\n",
      " [0.999996]\n",
      " [1.      ]\n",
      " [0.002686]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 66\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 66\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 67\n",
      "Model output: [[0.001848]\n",
      " [0.999996]\n",
      " [1.      ]\n",
      " [0.002645]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 67\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 67\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 68\n",
      "Model output: [[0.001821]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002606]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 68\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 68\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 69\n",
      "Model output: [[0.001794]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002568]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 69\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 69\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 70\n",
      "Model output: [[0.001768]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002531]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 70\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 70\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 71\n",
      "Model output: [[0.001744]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002496]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 71\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 71\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 72\n",
      "Model output: [[0.00172 ]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002461]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 72\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 72\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 73\n",
      "Model output: [[0.001696]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002428]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 73\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 73\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 74\n",
      "Model output: [[0.001674]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002396]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 74\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 74\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 75\n",
      "Model output: [[0.001652]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002365]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 75\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 75\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 76\n",
      "Model output: [[0.001631]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002335]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 76\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 76\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 77\n",
      "Model output: [[0.001611]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002306]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 77\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 77\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 78\n",
      "Model output: [[0.001591]\n",
      " [0.999997]\n",
      " [1.      ]\n",
      " [0.002278]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 78\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 78\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 79\n",
      "Model output: [[0.001572]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002251]\n",
      " [1.      ]]\n",
      "Loss: 2e-06\n",
      "Backward pass epoch 79\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 79\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 80\n",
      "Model output: [[0.001553]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002224]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 80\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 80\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 81\n",
      "Model output: [[0.001535]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002198]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 81\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 81\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 82\n",
      "Model output: [[0.001518]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002173]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 82\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 82\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 83\n",
      "Model output: [[0.001501]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002149]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 83\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 83\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 84\n",
      "Model output: [[0.001484]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002125]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 84\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 84\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 85\n",
      "Model output: [[0.001468]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002102]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 85\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 85\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 86\n",
      "Model output: [[0.001452]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.00208 ]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 86\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 86\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 87\n",
      "Model output: [[0.001437]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002058]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 87\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 87\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 88\n",
      "Model output: [[0.001422]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002037]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 88\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 88\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 89\n",
      "Model output: [[0.001407]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.002016]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 89\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 89\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 90\n",
      "Model output: [[0.001393]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001996]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 90\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 90\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 91\n",
      "Model output: [[0.001379]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001976]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 91\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 91\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 92\n",
      "Model output: [[0.001366]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001957]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 92\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 92\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 93\n",
      "Model output: [[0.001352]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001938]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 93\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 93\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 94\n",
      "Model output: [[0.00134 ]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001919]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 94\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 94\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 95\n",
      "Model output: [[0.001327]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001901]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 95\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 95\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 96\n",
      "Model output: [[0.001315]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001884]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 96\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 96\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 97\n",
      "Model output: [[0.001303]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001867]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 97\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 97\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 98\n",
      "Model output: [[0.001291]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.00185 ]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 98\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 98\n",
      "No weights in input layer\n",
      "(5, 1)\n",
      "Forward pass epoch 99\n",
      "Model output: [[0.001279]\n",
      " [0.999998]\n",
      " [1.      ]\n",
      " [0.001834]\n",
      " [1.      ]]\n",
      "Loss: 1e-06\n",
      "Backward pass epoch 99\n",
      "%Shape of output derivative_final(5, 1)\n",
      "%Shape of weights (5, 10)\n",
      "%Shape of layer input(10, 1)\n",
      "Update pass epoch 99\n",
      "No weights in input layer\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "model = NeuralNetwork(x, y, learning_rate = 0.1, dropout_rate = 0, batch_size = 1, epochs = 100)\n",
    "model.addLayer(5, 5, 'relu', 'input')\n",
    "model.addLayer(5, 10, 'relu', 'hidden')\n",
    "model.addLayer(10, 20, 'relu', 'hidden')\n",
    "model.addLayer(20, 10, 'relu', 'hidden')\n",
    "model.addLayer(10, 5, 'sigmoid', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e - Implement optimizer\n",
    "Implement any two optimizers of your choice. Briefly present the optimizers \n",
    "in the report. The optimizers can be flavours of gradient descent. For \n",
    "instance: Stochastic gradient descent (SGD) and SGD with momentum. \n",
    "SGD and mini-batch gradient descent, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f - Evaluate different neural network architectures/parameters, present and discuss your results.\n",
    "Be creative in the analysis and discussion. Evaluate different\n",
    "hyperparameters. For instance: different network architectures, activation \n",
    "functions, comparison of optimizers, L1/L2 performance comparison with \n",
    "dropout, etc. Support your results with plots/graph and discussion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
