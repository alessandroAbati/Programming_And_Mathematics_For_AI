{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Mathematics for AI - coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The task is about classification on the MNIST dataset. \n",
    "You can use other APIâ€™s/libraries for loading the dataset, but not for the neural network \n",
    "implementation. The point of this task is to develop a multi-layer neural network for \n",
    "classification using numpy. The task requires following sub-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Implement sigmoid and ReLU layers\n",
    "For this sub-task, you should implement forward and backward pass for \n",
    "sigmoid and ReLU. You should consider presenting these activation\n",
    "functions in the report with any pros cons if they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLu(x):\n",
    "    '''\n",
    "    Implementation of reLu function.\n",
    "    '''\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Implementation of Sigmoid function.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Implementation of Softmax function\n",
    "    '''\n",
    "    normalization = np.sum(np.exp(x))\n",
    "    return [np.exp(el)/normalization for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ReLU activation function')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, reLu(x))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.title(\"ReLU activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2657c1750>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2659e4710>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, softmax(x))\n",
    "# How do I test my implementation of the softmax function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.input = x # store the input to use it in the backward pass\n",
    "        return np.maximum(0, x)  # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return np.where(self.input > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "* Advatages:\n",
    "    - No saturation of neurons (at least for positive values)\n",
    "    - Converge fast\n",
    "    - Computationally efficent (very simple to calculate, both the reLu and its derivative)\n",
    "\n",
    "* Disadvantages:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('gradient_values'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        \n",
    "        sigmoid_derivative = np.multiply(self.output, (1 - self.output)) # calculate the derivative of Sigmoid: f(x) * (1 - f(x)) where f(x) is the Sigmoid function\n",
    "        return sigmoid_derivative  # multiply the gradient of the loss function by the derivative of Sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note - __Sigmoid Problem__:\n",
    "\n",
    "Vanishing gradient and saturation of neurons:\n",
    "the sigmoid function usually have the output very close to zero or one and in this region the derivative of the sigmoid is very small, meaning that the (local) gradient will be small and the network will now learn efficently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - Implement softmax layer\n",
    "Implement softmax with both forward and backward pass. Present the \n",
    "softmax in the report along with any numerical issues when calculating the \n",
    "softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'x', with the\n",
    "                         same shape as 'x'.\n",
    "        '''        \n",
    "        x = np.asarray(x)\n",
    "        print (\"Shape of inputs {}\".format(x.shape))\n",
    "        print(np.max(x))\n",
    "        reg = x - np.max(x)\n",
    "        print(\"Reg:\")\n",
    "        print(reg[0])\n",
    "        e_x = np.clip(np.exp(reg), 0.000001, 1-0.000001)\n",
    "\n",
    "        print(\"Exp:\")\n",
    "        print(e_x[0])\n",
    "        print(\"Max exp\")\n",
    "        print(np.max(e_x))\n",
    "        exp_sum = np.sum(e_x, axis=0, keepdims = True)\n",
    "        exp_sum = np.clip(exp_sum, 0.000001, 1-0.000001)\n",
    "        print(exp_sum[0])\n",
    "        print(\"Max sum\")\n",
    "        print(np.max(exp_sum))\n",
    "        \n",
    "        return e_x / exp_sum\n",
    "#         e_x = np.exp(x - np.max(x, axis=-1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "#         self.output = e_x / np.sum(e_x) # apply the softmax function: f(xi) = exp(xi) / sum(exp(x)) for x=[x1,...,xK]\n",
    "#         return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        # Gradient values not used -> Remove!!\n",
    "        softmax_jacobian = self.output * (np.eye(self.output.shape[0]) - self.output.T)\n",
    "        #print(softmax_jacobian)\n",
    "        print(softmax_jacobian.shape)\n",
    "        return softmax_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    weights = 0\n",
    "    new_weights = 0\n",
    "    bias = 0\n",
    "    activation = 0\n",
    "    layer_input = 0\n",
    "    softmax = False\n",
    "    \n",
    "    def __init__(self, output_units, input_units, activation):\n",
    "        # Weight initialisation crucial for performance\n",
    "        #self.weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        #self.new_weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        self.weights = np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.new_weights = np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.layer_input = 0\n",
    "        self.bias = 0\n",
    "        self.softmax = False\n",
    "        '''\n",
    "        Set activation function for the layer\n",
    "        '''   \n",
    "        if activation == 'relu':\n",
    "            print(\"ReLU\")\n",
    "            self.activation = ReLu()\n",
    "        elif activation == 'sigmoid':\n",
    "            print(\"Sigmoid\")\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'softmax':\n",
    "            print(\"Softmax\")\n",
    "            self.softmax = True\n",
    "            self.activation = Softmax()\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Weights combined with input and bias\n",
    "        '''\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        '''\n",
    "        Pass z through activation function\n",
    "        '''\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        print(\"Output of hidden layer\")\n",
    "        print(output)\n",
    "        return output\n",
    "        \n",
    "    '''\n",
    "    Idea is to have backward pass for activation functions just return the derivative of the activation,\n",
    "    and backward_pass for layer perform any other calculation (dot product of activation function with loss for example)\n",
    "    '''   \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            derivative_final = np.multiply(x, activation_derivative)\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = (self.weights + learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "#         print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        #print(\"Old_weights\")\n",
    "        #print(self.weights)\n",
    "        #print(\"New_weights\")\n",
    "        #print(self.new_weights)\n",
    "        self.weights = self.new_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass of layer\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation):\n",
    "        super().__init__(output_units, input_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        output = x\n",
    "        return output\n",
    "    \n",
    "    # No weights in input layer\n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print(\"Last backwards pass layer\")\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"End of Backwards pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation):\n",
    "        super().__init__(output_units, input_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        print(\"Weights and biases\")\n",
    "        print(z[0])\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "    \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        \n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            activation_derivative = self.activation.backward_pass(x)\n",
    "            derivative_final = np.multiply(x, activation_derivative)\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = (self.weights + learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "#         print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def mse_loss(self, output, target):\n",
    "        loss = 1/len(output)*np.sum((output-target)**2)\n",
    "        return loss\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"Old_weights\")\n",
    "        print(self.weights)\n",
    "        print(\"New_weights\")\n",
    "        print(self.new_weights)\n",
    "        self.weights = self.new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of inputs (5, 1)\n",
      "2.3\n",
      "Reg:\n",
      "[-2.05]\n",
      "Exp:\n",
      "[0.1287349]\n",
      "Max exp\n",
      "0.999999\n",
      "[0.999999]\n",
      "Max sum\n",
      "0.999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.12873503],\n",
       "       [-0.9631168 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.08208508],\n",
       "       [-0.72746793]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY\n",
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "prediction = softmax.forward_pass(x)\n",
    "loss = np.sum((prediction - y) ** 2)\n",
    "loss_derivative = (prediction -y)\n",
    "prediction, loss, np.sum(prediction)\n",
    "loss_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_derivative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient_softmax = softmax.backward_pass(loss_derivative.T, learning_rate)\n",
    "#gradient_softmax.shape, gradient_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - Implement dropout \n",
    "Present dropout in the report. Implement inverted dropout. Forward and \n",
    "backward pass should be implemented.\n",
    "Note: Since the test performance is critical, it is also preferable to leaving \n",
    "the forward pass unchanged at test time. Therefore, in most \n",
    "implementations inverted dropout is employed to overcome the \n",
    "undesirable property of the original dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of \n",
    "hidden layers, units, activation functions can be changed. In addition, you \n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used \n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots \n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "    A class representing the Fully Parametrizable Neural Network.\n",
    "    '''\n",
    "    layer_list = []\n",
    "    X = 0\n",
    "    Y = 0\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 8\n",
    "    epochs = 100   \n",
    "    loss_history = []\n",
    "    \n",
    "    def __init__(self, X, Y, learning_rate, dropout_rate = 0.5, batch_size = 4, epochs = 10):\n",
    "        self.layer_list = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def addLayer(self, input_units, output_units, activation, mode = \"input\"):\n",
    "        if mode == \"input\":\n",
    "            print(\"Added input\")\n",
    "            layer = InputLayer(input_units, output_units, activation)\n",
    "        elif mode == \"output\":\n",
    "            print(\"Added output\")\n",
    "            layer = OutputLayer(input_units, output_units, activation)\n",
    "        else:\n",
    "            print(\"Added hidden\")\n",
    "            layer = Layer(input_units, output_units, activation)\n",
    "        self.layer_list.append(layer)\n",
    "        \n",
    "    def loss(self, output, target, mode = \"mse\"):\n",
    "        if mode == \"mse\":\n",
    "            loss = 1/len(output)*np.sum((np.sum(output-target))**2)\n",
    "            return loss\n",
    "        if mode == \"cross_entropy\":\n",
    "            output = np.clip(output, 0.000001, 1-0.000001)\n",
    "            loss = -np.sum(np.sum(np.array(target) * np.log(np.array(output) + 0.00001)))/ target.shape[0]\n",
    "            #loss = -np.sum(target * np.log(output))\n",
    "            print(\"Cross Loss: {}\".format(loss))\n",
    "            print(loss.shape)\n",
    "            return loss\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            input_data = self.X\n",
    "            print(input_data.shape)\n",
    "            # Forward pass\n",
    "            print(\"Forward pass epoch {}\".format(i))\n",
    "            for index, layer in enumerate(self.layer_list):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                output_data = layer.forward_pass(input_data)\n",
    "                input_data = output_data\n",
    "                \n",
    "            # Calculate loss \n",
    "            #output_data = np.around(output_data, 6)\n",
    "            print(output_data[0])\n",
    "            print(\"Sums to 1: \")\n",
    "            print(np.sum(output_data[0]))\n",
    "            print(\"At least one output is close to 1: \")\n",
    "            print(np.max(output_data))\n",
    "            # For softmax, not exactly 0 nor 1\n",
    "            print(\"Model output shape: {}\".format (output_data.shape))\n",
    "            print(\"Model target shape: {}\".format (self.Y.shape))\n",
    "            loss_cost = self.loss(output_data, self.Y, mode = \"cross_entropy\")\n",
    "            loss_cost = np.around(loss_cost, 6)\n",
    "            self.loss_history.append(loss_cost)\n",
    "            #print(\"Loss: {}\".format(loss_cost))\n",
    "            \n",
    "            # Backward pass  \n",
    "            # MSE derivative\n",
    "#             input_derivative = (self.Y - output_data)\n",
    "            input_derivative = (output_data - self.Y)\n",
    "            print(\"Backward pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                output_derivative = layer.backward_pass(input_derivative, self.learning_rate)\n",
    "                input_derivative = output_derivative\n",
    "                \n",
    "            # Update pass. Supposedly update weights after backward pass completed\n",
    "            # Weights barely updating??\n",
    "            print(\"Update pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                layer.update_weights(self.learning_rate)\n",
    "                                         \n",
    "    def predict(self, X):\n",
    "        input_data = X\n",
    "        for index, layer in enumerate(self.layer_list):\n",
    "            output_data = layer.forward_pass(input_data)\n",
    "            input_data = output_data\n",
    "        return output_data\n",
    "    \n",
    "    def show_loss(self):\n",
    "        plt.plot(self.loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY DATASET\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "dataset = load_digits()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[:100]\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y[:100]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Softmax\n",
      "(100, 64)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[ 0.          0.          4.95847684 ...  0.          8.46260092\n",
      "  16.80784476]\n",
      " [ 0.          9.57484255  0.         ...  0.          6.35516198\n",
      "  22.66158724]\n",
      " [ 0.         14.29309849  5.35087776 ...  0.          7.8372723\n",
      "  24.98501545]\n",
      " ...\n",
      " [ 0.          3.20647485  3.78495399 ...  0.          4.49441583\n",
      "  18.19766653]\n",
      " [ 0.          6.29435699  0.         ...  0.          5.57535559\n",
      "  30.64632927]\n",
      " [ 0.          3.62289184  0.         ...  0.          7.21898602\n",
      "  18.12598528]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[ 2.29676765  1.28889638 12.09488052 -2.87679441  5.94814989 11.25202746\n",
      "  0.61786112  8.89909564 -8.26090818  4.1540977 ]\n",
      "Shape of inputs (100, 10)\n",
      "18.264439582648436\n",
      "Reg:\n",
      "[-15.96767193 -16.97554321  -6.16955907 -21.14123399 -12.3162897\n",
      "  -7.01241212 -17.64657846  -9.36534394 -26.52534777 -14.11034188]\n",
      "Exp:\n",
      "[1.00000000e-06 1.00000000e-06 2.09215830e-03 1.00000000e-06\n",
      " 4.47819858e-06 9.00633527e-04 1.00000000e-06 8.56412123e-05\n",
      " 1.00000000e-06 1.00000000e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[4.20159147e-04 1.00000000e-04 9.99999000e-01 1.00000000e-04\n",
      " 6.92503813e-03 9.99999000e-01 1.00000000e-04 3.46936194e-01\n",
      " 1.00000000e-04 1.25164521e-02]\n",
      "Max sum\n",
      "0.999999\n",
      "[2.38005053e-03 1.00000000e-02 2.09216039e-03 1.00000000e-02\n",
      " 6.46667714e-04 9.00634427e-04 1.00000000e-02 2.46850037e-04\n",
      " 1.00000000e-02 7.98948448e-05]\n",
      "Sums to 1: \n",
      "0.046346257947107006\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5704.412425022355\n",
      "()\n",
      "Backward pass epoch 0\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[ 0.14110153 -0.01697665  0.06316088 ...  0.16224989 -0.08681267\n",
      "   0.01284147]\n",
      " [-0.04365889 -0.09420325  0.01498464 ... -0.11527566 -0.04796516\n",
      "   0.13944703]\n",
      " [-0.05650736  0.00891176  0.01662856 ...  0.05601014 -0.04960591\n",
      "  -0.01182776]\n",
      " ...\n",
      " [-0.00163523 -0.05984997 -0.13286308 ... -0.07216865 -0.00423439\n",
      "  -0.11686404]\n",
      " [ 0.01687853 -0.05450219  0.03537209 ... -0.12758942  0.01037073\n",
      "   0.03771842]\n",
      " [ 0.01096882  0.11043392  0.08190575 ... -0.00135032 -0.20394762\n",
      "  -0.01998661]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.30541293e+00 -1.69624074e+00 -4.33387326e+00 ... -2.79534727e+00\n",
      "  -5.04045765e-01 -3.74329865e-01]\n",
      " ...\n",
      " [ 4.63340442e-02 -4.98699341e-02 -7.58939703e-01 ... -7.19692224e-02\n",
      "   5.74564319e-03 -8.52634526e-02]\n",
      " [-7.32903072e+00 -5.77462954e+00 -3.17208697e+00 ... -5.92654577e+00\n",
      "  -3.65340133e+00 -5.81607183e+00]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[  0.           0.         131.62802354 ... 120.61628747   0.\n",
      "    0.        ]\n",
      " [  0.           0.          49.18618399 ... 181.7521607   68.49693304\n",
      "    0.        ]\n",
      " [  0.           0.         106.31783573 ... 223.01321013  56.45731118\n",
      "    0.        ]\n",
      " ...\n",
      " [  0.           0.          88.37871621 ... 177.0804806    0.\n",
      "    0.        ]\n",
      " [  0.           0.          30.76455502 ... 174.7874377  105.97884473\n",
      "    0.        ]\n",
      " [  0.           0.          81.74667556 ... 171.63046207  36.79671221\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-41295.81275273 -53789.9429035  -35411.1772569  -58947.15113609\n",
      "  -30046.85885749 -25280.94500897 -44671.09070906 -37653.60656238\n",
      "  -34504.98554236 -34721.57493134]]\n",
      "Shape of inputs (100, 10)\n",
      "-19489.361566859498\n",
      "Reg:\n",
      "[-21806.45118587 -34300.58133664 -15921.81569005 -39457.78956923\n",
      " -10557.49729063  -5791.58344211 -25181.7291422  -18164.24499552\n",
      " -15015.6239755  -15232.21336448]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02\n",
      " 1.000001e-06 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 1\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.30541293e+00 -1.69624074e+00 -4.33387326e+00 ... -2.79534727e+00\n",
      "  -5.04045765e-01 -3.74329865e-01]\n",
      " ...\n",
      " [ 4.63340442e-02 -4.98699341e-02 -7.58939703e-01 ... -7.19692224e-02\n",
      "   5.74564319e-03 -8.52634526e-02]\n",
      " [-7.32903072e+00 -5.77462954e+00 -3.17208697e+00 ... -5.92654577e+00\n",
      "  -3.65340133e+00 -5.81607183e+00]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.66793578e+02 -4.64833666e+01 -7.64228656e+01 ... -1.95538750e+01\n",
      "  -5.55805050e+01 -7.30706999e+01]\n",
      " ...\n",
      " [-1.52242671e+02 -1.98644556e+02 -1.67625905e+02 ... -1.56473379e+02\n",
      "  -1.15307197e+02 -9.95513087e+01]\n",
      " [-3.09144775e+00 -8.24017183e+01 -4.86885966e+01 ... -1.12538979e+02\n",
      "  -4.10306134e+01 -1.16073908e+01]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[     0.              0.          35500.83443763 ...   2440.35533485\n",
      "   70222.73722068      0.        ]\n",
      " [     0.              0.          42324.17764165 ...   3652.09962153\n",
      "   97146.788985        0.        ]\n",
      " [     0.              0.          46068.64837578 ...   3957.68301745\n",
      "   95687.41863121      0.        ]\n",
      " ...\n",
      " [     0.              0.          39239.96355522 ...   3214.5678134\n",
      "   79249.306272        0.        ]\n",
      " [     0.              0.          42050.56059917 ...   3361.03910314\n",
      "  107846.88203134      0.        ]\n",
      " [     0.              0.          42654.11500184 ...   3554.76275475\n",
      "   90575.62709977      0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.02614884e+09 -1.13694794e+09 -7.93012800e+08 -1.05347543e+09\n",
      "  -7.16749690e+08 -8.12644212e+08 -1.07831825e+09 -8.49842531e+08\n",
      "  -7.07739530e+08 -7.67016577e+08]]\n",
      "Shape of inputs (100, 10)\n",
      "-672836980.6960335\n",
      "Reg:\n",
      "[-3.53311863e+08 -4.64110961e+08 -1.20175819e+08 -3.80638452e+08\n",
      " -4.39127095e+07 -1.39807232e+08 -4.05481265e+08 -1.77005551e+08\n",
      " -3.49025495e+07 -9.41795963e+07]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 2\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.66793578e+02 -4.64833666e+01 -7.64228656e+01 ... -1.95538750e+01\n",
      "  -5.55805050e+01 -7.30706999e+01]\n",
      " ...\n",
      " [-1.52242671e+02 -1.98644556e+02 -1.67625905e+02 ... -1.56473379e+02\n",
      "  -1.15307197e+02 -9.95513087e+01]\n",
      " [-3.09144775e+00 -8.24017183e+01 -4.86885966e+01 ... -1.12538979e+02\n",
      "  -4.10306134e+01 -1.16073908e+01]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.27184807e+04 -4.34351293e+04 -3.39838327e+04 ... -3.66242983e+04\n",
      "  -2.96343569e+04 -2.86311503e+04]\n",
      " ...\n",
      " [-3.16314238e+03 -3.93404698e+03 -3.11619460e+03 ... -3.08355385e+03\n",
      "  -2.48452234e+03 -2.32593578e+03]\n",
      " [-8.16358566e+04 -1.00584693e+05 -7.15899630e+04 ... -8.16340408e+04\n",
      "  -6.51205374e+04 -6.72529509e+04]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[      0.               0.         1636294.6656792  ... 3066417.14400972\n",
      "   963862.74829407       0.        ]\n",
      " [      0.               0.         1910401.72994689 ... 4028047.76298082\n",
      "  1358682.73025995       0.        ]\n",
      " [      0.               0.         1998447.72885223 ... 4050899.232855\n",
      "  1342047.98710836       0.        ]\n",
      " ...\n",
      " [      0.               0.         1759356.13075193 ... 3531599.55542516\n",
      "  1114516.91618881       0.        ]\n",
      " [      0.               0.         1908577.79702089 ... 4049222.01703501\n",
      "  1473474.28984435       0.        ]\n",
      " [      0.               0.         1942367.92938036 ... 3953029.13061391\n",
      "  1276217.23012066       0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.31819907e+13 -2.58245257e+13 -1.88323441e+13 -2.51567113e+13\n",
      "  -1.56626205e+13 -1.87370423e+13 -2.35057952e+13 -2.06316528e+13\n",
      "  -1.71534025e+13 -1.76000126e+13]]\n",
      "Shape of inputs (100, 10)\n",
      "-14625949605345.506\n",
      "Reg:\n",
      "[-8.55604108e+12 -1.11985761e+13 -4.20639453e+12 -1.05307617e+13\n",
      " -1.03667092e+12 -4.11109274e+12 -8.87984555e+12 -6.00570321e+12\n",
      " -2.52745291e+12 -2.97406304e+12]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 3\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.27184807e+04 -4.34351293e+04 -3.39838327e+04 ... -3.66242983e+04\n",
      "  -2.96343569e+04 -2.86311503e+04]\n",
      " ...\n",
      " [-3.16314238e+03 -3.93404698e+03 -3.11619460e+03 ... -3.08355385e+03\n",
      "  -2.48452234e+03 -2.32593578e+03]\n",
      " [-8.16358566e+04 -1.00584693e+05 -7.15899630e+04 ... -8.16340408e+04\n",
      "  -6.51205374e+04 -6.72529509e+04]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.00110407e+06 -1.95623650e+06 -1.50558987e+06 ... -1.58798244e+06\n",
      "  -1.32989476e+06 -1.39935497e+06]\n",
      " ...\n",
      " [-3.65759442e+06 -4.10247562e+06 -2.99849500e+06 ... -3.28983532e+06\n",
      "  -2.64439784e+06 -2.73054967e+06]\n",
      " [-1.20516221e+06 -1.50876244e+06 -1.07348765e+06 ... -1.24525768e+06\n",
      "  -9.51885657e+05 -9.68687835e+05]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 7.61069588e+08 ... 6.62732168e+07\n",
      "  1.65870367e+09 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.75689691e+08 ... 8.64338541e+07\n",
      "  2.14674786e+09 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.80627439e+08 ... 8.66862326e+07\n",
      "  2.14468697e+09 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 8.58712564e+08 ... 7.57481276e+07\n",
      "  1.86981508e+09 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.92815647e+08 ... 8.73515040e+07\n",
      "  2.21124416e+09 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.60354495e+08 ... 8.48509835e+07\n",
      "  2.09751658e+09 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-5.34464531e+17 -5.89752805e+17 -4.29223614e+17 -5.67930050e+17\n",
      "  -3.71850673e+17 -4.31960725e+17 -5.41499288e+17 -4.73632233e+17\n",
      "  -3.83274310e+17 -4.00742213e+17]]\n",
      "Shape of inputs (100, 10)\n",
      "-3.470298225637604e+17\n",
      "Reg:\n",
      "[-1.87434708e+17 -2.42722983e+17 -8.21937915e+16 -2.20900227e+17\n",
      " -2.48208507e+16 -8.49309024e+16 -1.94469465e+17 -1.26602410e+17\n",
      " -3.62444877e+16 -5.37123905e+16]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 4\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.00110407e+06 -1.95623650e+06 -1.50558987e+06 ... -1.58798244e+06\n",
      "  -1.32989476e+06 -1.39935497e+06]\n",
      " ...\n",
      " [-3.65759442e+06 -4.10247562e+06 -2.99849500e+06 ... -3.28983532e+06\n",
      "  -2.64439784e+06 -2.73054967e+06]\n",
      " [-1.20516221e+06 -1.50876244e+06 -1.07348765e+06 ... -1.24525768e+06\n",
      "  -9.51885657e+05 -9.68687835e+05]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-9.05430836e+08 -9.93478324e+08 -7.26723494e+08 ... -8.02592485e+08\n",
      "  -6.47969052e+08 -6.74459689e+08]\n",
      " ...\n",
      " [-8.24802338e+07 -9.20057128e+07 -6.71083999e+07 ... -7.38814116e+07\n",
      "  -5.95452347e+07 -6.17634835e+07]\n",
      " [-1.96394189e+09 -2.18826362e+09 -1.58962982e+09 ... -1.76387740e+09\n",
      "  -1.42069443e+09 -1.48708023e+09]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.60871512e+10 ... 6.96618167e+10\n",
      "  2.62872715e+10 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.61186215e+10 ... 8.98369894e+10\n",
      "  3.40853972e+10 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.63024920e+10 ... 8.99155428e+10\n",
      "  3.40418041e+10 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 4.06272307e+10 ... 7.88114463e+10\n",
      "  2.97233584e+10 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.69605557e+10 ... 9.15932073e+10\n",
      "  3.50165788e+10 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.54184878e+10 ... 8.81897134e+10\n",
      "  3.33170207e+10 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.22198815e+22 -1.34964487e+22 -9.83312498e+21 -1.30498057e+22\n",
      "  -8.48771329e+21 -9.89648458e+21 -1.23360202e+22 -1.08728451e+22\n",
      "  -8.78344742e+21 -9.17888279e+21]]\n",
      "Shape of inputs (100, 10)\n",
      "-7.913088236038403e+21\n",
      "Reg:\n",
      "[-4.30679324e+21 -5.58336044e+21 -1.92003675e+21 -5.13671750e+21\n",
      " -5.74625054e+20 -1.98339634e+21 -4.42293196e+21 -2.95975683e+21\n",
      " -8.70359180e+20 -1.26579455e+21]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 5\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-9.05430836e+08 -9.93478324e+08 -7.26723494e+08 ... -8.02592485e+08\n",
      "  -6.47969052e+08 -6.74459689e+08]\n",
      " ...\n",
      " [-8.24802338e+07 -9.20057128e+07 -6.71083999e+07 ... -7.38814116e+07\n",
      "  -5.95452347e+07 -6.17634835e+07]\n",
      " [-1.96394189e+09 -2.18826362e+09 -1.58962982e+09 ... -1.76387740e+09\n",
      "  -1.42069443e+09 -1.48708023e+09]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.37402145e+10 -4.78165717e+10 -3.49732722e+10 ... -3.85741021e+10\n",
      "  -3.12229827e+10 -3.26121168e+10]\n",
      " ...\n",
      " [-8.27239945e+10 -9.14458476e+10 -6.65920357e+10 ... -7.36482795e+10\n",
      "  -5.94430008e+10 -6.20554971e+10]\n",
      " [-3.30850803e+10 -3.69161491e+10 -2.67979850e+10 ... -2.97603564e+10\n",
      "  -2.39391248e+10 -2.50158867e+10]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.70896002e+13 ... 1.63605350e+12\n",
      "  3.73835649e+13 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.19961855e+13 ... 2.10863212e+12\n",
      "  4.81498659e+13 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.20195265e+13 ... 2.11035987e+12\n",
      "  4.81794601e+13 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.93012758e+13 ... 1.84976224e+12\n",
      "  4.22106244e+13 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.24509229e+13 ... 2.15101091e+12\n",
      "  4.92075647e+13 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.15970763e+13 ... 2.06993360e+12\n",
      "  4.72438127e+13 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.79746831e+26 -3.08802419e+26 -2.24904077e+26 -2.98191394e+26\n",
      "  -1.94480054e+26 -2.26424393e+26 -2.82521401e+26 -2.48792018e+26\n",
      "  -2.00888200e+26 -2.09893081e+26]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.8132124063474056e+26\n",
      "Reg:\n",
      "[-9.84255904e+25 -1.27481178e+26 -4.35828364e+25 -1.16870154e+26\n",
      " -1.31588136e+25 -4.51031526e+25 -1.01200160e+26 -6.74707773e+25\n",
      " -1.95669597e+25 -2.85718406e+25]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 6\n",
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.37402145e+10 -4.78165717e+10 -3.49732722e+10 ... -3.85741021e+10\n",
      "  -3.12229827e+10 -3.26121168e+10]\n",
      " ...\n",
      " [-8.27239945e+10 -9.14458476e+10 -6.65920357e+10 ... -7.36482795e+10\n",
      "  -5.94430008e+10 -6.20554971e+10]\n",
      " [-3.30850803e+10 -3.69161491e+10 -2.67979850e+10 ... -2.97603564e+10\n",
      "  -2.39391248e+10 -2.50158867e+10]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.03116679e+13 -2.24127414e+13 -1.63271978e+13 ... -1.80622475e+13\n",
      "  -1.45830745e+13 -1.52332679e+13]\n",
      " ...\n",
      " [-2.02332390e+12 -2.23564300e+12 -1.62801769e+12 ... -1.80083628e+12\n",
      "  -1.45366216e+12 -1.51803382e+12]\n",
      " [-4.43547147e+13 -4.90067779e+13 -3.56798342e+13 ... -3.94907057e+13\n",
      "  -3.18748865e+13 -3.33125578e+13]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 8.39633971e+14 ... 1.56665048e+15\n",
      "  6.66944611e+14 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.08039959e+15 ... 2.01729125e+15\n",
      "  8.59150301e+14 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.08155278e+15 ... 2.01893705e+15\n",
      "  8.59661964e+14 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 9.48088678e+14 ... 1.76958921e+15\n",
      "  7.53232573e+14 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.10281727e+15 ... 2.05954505e+15\n",
      "  8.77821778e+14 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.06085116e+15 ... 1.98021980e+15\n",
      "  8.43015830e+14 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-6.39861803e+30 -7.06421540e+30 -5.14472578e+30 -6.82368534e+30\n",
      "  -4.44779280e+30 -5.18000540e+30 -6.46015780e+30 -5.69229608e+30\n",
      "  -4.59565672e+30 -4.80191354e+30]]\n",
      "Shape of inputs (100, 10)\n",
      "-4.1465619255372235e+30\n",
      "Reg:\n",
      "[-2.25205611e+30 -2.91765347e+30 -9.98163856e+29 -2.67712341e+30\n",
      " -3.01230874e+29 -1.03344347e+30 -2.31359587e+30 -1.54573415e+30\n",
      " -4.49094791e+29 -6.55351613e+29]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 7\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.03116679e+13 -2.24127414e+13 -1.63271978e+13 ... -1.80622475e+13\n",
      "  -1.45830745e+13 -1.52332679e+13]\n",
      " ...\n",
      " [-2.02332390e+12 -2.23564300e+12 -1.62801769e+12 ... -1.80083628e+12\n",
      "  -1.45366216e+12 -1.51803382e+12]\n",
      " [-4.43547147e+13 -4.90067779e+13 -3.56798342e+13 ... -3.94907057e+13\n",
      "  -3.18748865e+13 -3.33125578e+13]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.01609125e+15 -1.12086293e+15 -8.16570782e+14 ... -9.03270076e+14\n",
      "  -7.29391460e+14 -7.62040457e+14]\n",
      " ...\n",
      " [-1.85990088e+15 -2.05352056e+15 -1.49549173e+15 ... -1.65464143e+15\n",
      "  -1.33582594e+15 -1.39563873e+15]\n",
      " [-8.35116934e+14 -9.22792284e+14 -6.71819554e+14 ... -7.43583607e+14\n",
      "  -6.00153884e+14 -6.27149352e+14]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.84791798e+17 ... 3.98385109e+16\n",
      "  8.39804297e+17 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.95398776e+17 ... 5.12955366e+16\n",
      "  1.08126042e+18 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.95814972e+17 ... 5.13374517e+16\n",
      "  1.08212829e+18 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 4.34575533e+17 ... 4.49967161e+16\n",
      "  9.48423113e+17 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.05822336e+17 ... 5.23724403e+16\n",
      "  1.10415302e+18 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.86301819e+17 ... 5.03527243e+16\n",
      "  1.06133682e+18 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.46344147e+35 -1.61560093e+35 -1.17660531e+35 -1.56042435e+35\n",
      "  -1.01732019e+35 -1.18466566e+35 -1.47759731e+35 -1.30183619e+35\n",
      "  -1.05102784e+35 -1.09815612e+35]]\n",
      "Shape of inputs (100, 10)\n",
      "-9.484296598486246e+34\n",
      "Reg:\n",
      "[-5.15011814e+34 -6.67171275e+34 -2.28175654e+34 -6.11994689e+34\n",
      " -6.88905348e+33 -2.36235996e+34 -5.29167655e+34 -3.53406534e+34\n",
      " -1.02598180e+34 -1.49726459e+34]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 8\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.01609125e+15 -1.12086293e+15 -8.16570782e+14 ... -9.03270076e+14\n",
      "  -7.29391460e+14 -7.62040457e+14]\n",
      " ...\n",
      " [-1.85990088e+15 -2.05352056e+15 -1.49549173e+15 ... -1.65464143e+15\n",
      "  -1.33582594e+15 -1.39563873e+15]\n",
      " [-8.35116934e+14 -9.22792284e+14 -6.71819554e+14 ... -7.43583607e+14\n",
      "  -6.00153884e+14 -6.27149352e+14]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.57327213e+17 -5.04862413e+17 -3.67684918e+17 ... -4.06818603e+17\n",
      "  -3.28441595e+17 -3.43163915e+17]\n",
      " ...\n",
      " [-4.91034919e+16 -5.42134144e+16 -3.94815337e+16 ... -4.36835994e+16\n",
      "  -3.52668981e+16 -3.68468654e+16]\n",
      " [-9.96696455e+17 -1.10042075e+18 -8.01382027e+17 ... -8.86719713e+17\n",
      "  -7.15864401e+17 -7.47987665e+17]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.95893650e+19 ... 3.52099104e+19\n",
      "  1.66395104e+19 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.52197090e+19 ... 4.53323108e+19\n",
      "  2.14238483e+19 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.52409765e+19 ... 4.53696038e+19\n",
      "  2.14410274e+19 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 2.21234141e+19 ... 3.97654077e+19\n",
      "  1.87919607e+19 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.57505378e+19 ... 4.62875917e+19\n",
      "  2.18770129e+19 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.47566954e+19 ... 4.44988964e+19\n",
      "  2.10291659e+19 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-3.34620515e+39 -3.69418225e+39 -2.69036816e+39 -3.56811607e+39\n",
      "  -2.32611276e+39 -2.70882828e+39 -3.37849037e+39 -2.97676328e+39\n",
      "  -2.40324473e+39 -2.51102653e+39]]\n",
      "Shape of inputs (100, 10)\n",
      "-2.1685829357919083e+39\n",
      "Reg:\n",
      "[-1.17762221e+39 -1.52559931e+39 -5.21785222e+38 -1.39953313e+39\n",
      " -1.57529823e+38 -5.40245341e+38 -1.20990743e+39 -8.08180341e+38\n",
      " -2.34661794e+38 -3.42443598e+38]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 9\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.57327213e+17 -5.04862413e+17 -3.67684918e+17 ... -4.06818603e+17\n",
      "  -3.28441595e+17 -3.43163915e+17]\n",
      " ...\n",
      " [-4.91034919e+16 -5.42134144e+16 -3.94815337e+16 ... -4.36835994e+16\n",
      "  -3.52668981e+16 -3.68468654e+16]\n",
      " [-9.96696455e+17 -1.10042075e+18 -8.01382027e+17 ... -8.86719713e+17\n",
      "  -7.15864401e+17 -7.47987665e+17]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.36876419e+19 -2.61491969e+19 -1.90442475e+19 ... -2.10710806e+19\n",
      "  -1.70117062e+19 -1.77744178e+19]\n",
      " ...\n",
      " [-4.18029498e+19 -4.61503562e+19 -3.36099359e+19 ... -3.71876826e+19\n",
      "  -3.00228720e+19 -3.13690864e+19]\n",
      " [-2.07283391e+19 -2.28856138e+19 -1.66664306e+19 ... -1.84411735e+19\n",
      "  -1.48878589e+19 -1.55557939e+19]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 8.66692174e+21 ... 9.63728155e+20\n",
      "  1.88639879e+22 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.11584129e+22 ... 1.24078331e+21\n",
      "  2.42869460e+22 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.11676182e+22 ... 1.24180439e+21\n",
      "  2.43069009e+22 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 9.78814591e+21 ... 1.08841176e+21\n",
      "  2.13042994e+22 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.13936399e+22 ... 1.26693529e+21\n",
      "  2.47992515e+22 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.09532822e+22 ... 1.21797158e+21\n",
      "  2.38403207e+22 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-7.64977385e+43 -8.44525394e+43 -6.15044446e+43 -8.15698268e+43\n",
      "  -5.31775829e+43 -6.19263368e+43 -7.72362402e+43 -6.80516098e+43\n",
      "  -5.49404663e+43 -5.74042538e+43]]\n",
      "Shape of inputs (100, 10)\n",
      "-4.957632505839157e+43\n",
      "Reg:\n",
      "[-2.69214134e+43 -3.48762144e+43 -1.19281196e+43 -3.19935018e+43\n",
      " -3.60125782e+42 -1.23500117e+43 -2.76599151e+43 -1.84752848e+43\n",
      " -5.36414120e+42 -7.82792874e+42]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 10\n",
      "Update pass epoch 10\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.36876419e+19 -2.61491969e+19 -1.90442475e+19 ... -2.10710806e+19\n",
      "  -1.70117062e+19 -1.77744178e+19]\n",
      " ...\n",
      " [-4.18029498e+19 -4.61503562e+19 -3.36099359e+19 ... -3.71876826e+19\n",
      "  -3.00228720e+19 -3.13690864e+19]\n",
      " [-2.07283391e+19 -2.28856138e+19 -1.66664306e+19 ... -1.84411735e+19\n",
      "  -1.48878589e+19 -1.55557939e+19]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.03013814e+22 -1.13725671e+22 -8.28233452e+21 ... -9.16398621e+21\n",
      "  -7.39841147e+21 -7.73018191e+21]\n",
      " ...\n",
      " [-1.18464362e+21 -1.30784040e+21 -9.52461931e+20 ... -1.05385144e+21\n",
      "  -8.50810198e+20 -8.88961820e+20]\n",
      " [-2.23905672e+22 -2.47190973e+22 -1.80021711e+22 ... -1.99185961e+22\n",
      "  -1.60809427e+22 -1.68021439e+22]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 4.56558150e+23 ... 7.91415084e+23\n",
      "  4.10833240e+23 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.87804584e+23 ... 1.01892679e+24\n",
      "  5.28938646e+23 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.88289677e+23 ... 1.01976592e+24\n",
      "  5.29373243e+23 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 5.15621562e+23 ... 8.93798794e+23\n",
      "  4.63980696e+23 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.00196321e+23 ... 1.04041005e+24\n",
      "  5.40095100e+23 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.76998808e+23 ... 1.00019325e+24\n",
      "  5.19211918e+23 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.74847281e+48 -1.93029508e+48 -1.40577932e+48 -1.86441075e+48\n",
      "  -1.21545401e+48 -1.41542376e+48 -1.76534876e+48 -1.55542697e+48\n",
      "  -1.25575015e+48 -1.31206497e+48]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.1331413766178233e+48\n",
      "Reg:\n",
      "[-6.15331435e+47 -7.97153705e+47 -2.72637940e+47 -7.31269371e+47\n",
      " -8.23126349e+46 -2.82282383e+47 -6.32207386e+47 -4.22285591e+47\n",
      " -1.22608774e+47 -1.78923593e+47]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 11\n",
      "Update pass epoch 11\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.03013814e+22 -1.13725671e+22 -8.28233452e+21 ... -9.16398621e+21\n",
      "  -7.39841147e+21 -7.73018191e+21]\n",
      " ...\n",
      " [-1.18464362e+21 -1.30784040e+21 -9.52461931e+20 ... -1.05385144e+21\n",
      "  -8.50810198e+20 -8.88961820e+20]\n",
      " [-2.23905672e+22 -2.47190973e+22 -1.80021711e+22 ... -1.99185961e+22\n",
      "  -1.60809427e+22 -1.68021439e+22]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.51712089e+23 -6.09080786e+23 -4.43577353e+23 ... -4.90795911e+23\n",
      "  -3.96237156e+23 -4.14006047e+23]\n",
      " ...\n",
      " [-9.39685609e+23 -1.03740316e+24 -7.55511306e+23 ... -8.35936535e+23\n",
      "  -6.74880534e+23 -7.05145430e+23]\n",
      " [-5.09576899e+23 -5.62570979e+23 -4.09703420e+23 ... -4.53318344e+23\n",
      "  -3.65978917e+23 -3.82392147e+23]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.95244212e+26 ... 2.31918043e+25\n",
      "  4.23794402e+26 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.51371707e+26 ... 2.98588500e+25\n",
      "  5.45624159e+26 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.51578773e+26 ... 2.98834409e+25\n",
      "  5.46073448e+26 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 2.20502342e+26 ... 2.61920704e+25\n",
      "  4.78619132e+26 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.56671839e+26 ... 3.04884106e+25\n",
      "  5.57129274e+26 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.46750117e+26 ... 2.93098770e+25\n",
      "  5.35592283e+26 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-3.99566351e+52 -4.41116786e+52 -3.21252920e+52 -4.26060385e+52\n",
      "  -2.77759358e+52 -3.23456823e+52 -4.03423102e+52 -3.55450779e+52\n",
      "  -2.86967769e+52 -2.99836907e+52]]\n",
      "Shape of inputs (100, 10)\n",
      "-2.5894904534925465e+52\n",
      "Reg:\n",
      "[-1.40617306e+52 -1.82167740e+52 -6.23038749e+51 -1.67111339e+52\n",
      " -1.88103125e+51 -6.45077776e+51 -1.44474056e+52 -9.65017332e+51\n",
      " -2.80187238e+51 -4.08878613e+51]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 12\n",
      "Update pass epoch 12\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.51712089e+23 -6.09080786e+23 -4.43577353e+23 ... -4.90795911e+23\n",
      "  -3.96237156e+23 -4.14006047e+23]\n",
      " ...\n",
      " [-9.39685609e+23 -1.03740316e+24 -7.55511306e+23 ... -8.35936535e+23\n",
      "  -6.74880534e+23 -7.05145430e+23]\n",
      " [-5.09576899e+23 -5.62570979e+23 -4.09703420e+23 ... -4.53318344e+23\n",
      "  -3.65978917e+23 -3.82392147e+23]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.32082370e+26 -2.56216286e+26 -1.86595117e+26 ... -2.06458431e+26\n",
      "  -1.66681076e+26 -1.74155910e+26]\n",
      " ...\n",
      " [-2.84417252e+25 -3.13993635e+25 -2.28672673e+25 ... -2.53015214e+25\n",
      "  -2.04267955e+25 -2.13428346e+25]\n",
      " [-5.03066674e+26 -5.55380381e+26 -4.04467746e+26 ... -4.47524132e+26\n",
      "  -3.61301703e+26 -3.77504491e+26]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.06274986e+28 ... 1.77916487e+28\n",
      "  1.00593906e+28 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.36826191e+28 ... 2.29062772e+28\n",
      "  1.29512018e+28 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.36938903e+28 ... 2.29251433e+28\n",
      "  1.29618665e+28 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.20023435e+28 ... 2.00932971e+28\n",
      "  1.13607384e+28 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.39711159e+28 ... 2.33892610e+28\n",
      "  1.32242909e+28 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.34310577e+28 ... 2.24851298e+28\n",
      "  1.27130808e+28 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-9.12937291e+56 -1.00787272e+57 -7.34005237e+56 -9.73471761e+56\n",
      "  -6.34630161e+56 -7.39040826e+56 -9.21749109e+56 -8.12141292e+56\n",
      "  -6.55669856e+56 -6.85073582e+56]]\n",
      "Shape of inputs (100, 10)\n",
      "-5.916519618837838e+56\n",
      "Reg:\n",
      "[-3.21285329e+56 -4.16220759e+56 -1.42353275e+56 -3.81819799e+56\n",
      " -4.29781989e+55 -1.47388865e+56 -3.30097147e+56 -2.20489330e+56\n",
      " -6.40178937e+55 -9.34216199e+55]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update pass epoch 13\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.32082370e+26 -2.56216286e+26 -1.86595117e+26 ... -2.06458431e+26\n",
      "  -1.66681076e+26 -1.74155910e+26]\n",
      " ...\n",
      " [-2.84417252e+25 -3.13993635e+25 -2.28672673e+25 ... -2.53015214e+25\n",
      "  -2.04267955e+25 -2.13428346e+25]\n",
      " [-5.03066674e+26 -5.55380381e+26 -4.04467746e+26 ... -4.47524132e+26\n",
      "  -3.61301703e+26 -3.77504491e+26]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.28347183e+28 -1.41693811e+28 -1.03191621e+28 ... -1.14176515e+28\n",
      "  -9.21786762e+27 -9.63124448e+27]\n",
      " ...\n",
      " [-2.11266946e+28 -2.33236389e+28 -1.69859474e+28 ... -1.87941286e+28\n",
      "  -1.51731524e+28 -1.58535964e+28]\n",
      " [-1.24320075e+28 -1.37248070e+28 -9.99538694e+27 ... -1.10594151e+28\n",
      "  -8.92864821e+27 -9.32905818e+27]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 4.39905683e+30 ... 5.55594437e+29\n",
      "  9.52251795e+30 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.66366887e+30 ... 7.15313129e+29\n",
      "  1.22599894e+31 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.66833368e+30 ... 7.15902277e+29\n",
      "  1.22700868e+31 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 4.96814829e+30 ... 6.27469885e+29\n",
      "  1.07544142e+31 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.78308883e+30 ... 7.30395680e+29\n",
      "  1.25184961e+31 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.55953851e+30 ... 7.02161608e+29\n",
      "  1.20345806e+31 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.08553787e+61 -2.30241079e+61 -1.67678077e+61 -2.22382420e+61\n",
      "  -1.44976581e+61 -1.68828417e+61 -2.10566792e+61 -1.85527678e+61\n",
      "  -1.49782936e+61 -1.56499996e+61]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.3515852985135275e+61\n",
      "Reg:\n",
      "[-7.33952573e+60 -9.50825490e+60 -3.25195473e+60 -8.72238897e+60\n",
      " -9.81805121e+59 -3.36698868e+60 -7.54082618e+60 -5.03691483e+60\n",
      " -1.46244060e+60 -2.13414660e+60]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 14\n",
      "Update pass epoch 14\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.28347183e+28 -1.41693811e+28 -1.03191621e+28 ... -1.14176515e+28\n",
      "  -9.21786762e+27 -9.63124448e+27]\n",
      " ...\n",
      " [-2.11266946e+28 -2.33236389e+28 -1.69859474e+28 ... -1.87941286e+28\n",
      "  -1.51731524e+28 -1.58535964e+28]\n",
      " [-1.24320075e+28 -1.37248070e+28 -9.99538694e+27 ... -1.10594151e+28\n",
      "  -8.92864821e+27 -9.32905818e+27]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.22946267e+30 -5.77326894e+30 -4.20450881e+30 ... -4.65208549e+30\n",
      "  -3.75579015e+30 -3.92421963e+30]\n",
      " ...\n",
      " [-6.79979171e+29 -7.50689530e+29 -5.46705982e+29 ... -6.04903710e+29\n",
      "  -4.88359763e+29 -5.10260390e+29]\n",
      " [-1.13047234e+31 -1.24802907e+31 -9.08904308e+30 ... -1.00565867e+31\n",
      "  -8.11903144e+30 -8.48313209e+30]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 2.47089839e+32 ... 4.00038886e+32\n",
      "  2.44598622e+32 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.18121606e+32 ... 5.15039454e+32\n",
      "  3.14914242e+32 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.18383623e+32 ... 5.15463654e+32\n",
      "  3.15173609e+32 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 2.79055034e+32 ... 4.51790593e+32\n",
      "  2.76241528e+32 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.24829286e+32 ... 5.25899217e+32\n",
      "  3.21554329e+32 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.12272726e+32 ... 5.05570097e+32\n",
      "  3.09124316e+32 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-4.76346508e+65 -5.25881293e+65 -3.82984496e+65 -5.07931762e+65\n",
      "  -3.31133223e+65 -3.85611928e+65 -4.80944295e+65 -4.23753816e+65\n",
      "  -3.42111166e+65 -3.57453245e+65]]\n",
      "Shape of inputs (100, 10)\n",
      "-3.0870833825455386e+65\n",
      "Reg:\n",
      "[-1.67638169e+65 -2.17172955e+65 -7.42761578e+64 -1.99223424e+65\n",
      " -2.24248843e+64 -7.69035895e+64 -1.72235957e+65 -1.15045477e+65\n",
      " -3.34028275e+64 -4.87449064e+64]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 15\n",
      "Update pass epoch 15\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.22946267e+30 -5.77326894e+30 -4.20450881e+30 ... -4.65208549e+30\n",
      "  -3.75579015e+30 -3.92421963e+30]\n",
      " ...\n",
      " [-6.79979171e+29 -7.50689530e+29 -5.46705982e+29 ... -6.04903710e+29\n",
      "  -4.88359763e+29 -5.10260390e+29]\n",
      " [-1.13047234e+31 -1.24802907e+31 -9.08904308e+30 ... -1.00565867e+31\n",
      "  -8.11903144e+30 -8.48313209e+30]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.98241308e+32 -3.29255104e+32 -2.39787199e+32 ... -2.65312929e+32\n",
      "  -2.14196340e+32 -2.23802037e+32]\n",
      " ...\n",
      " [-4.75066671e+32 -5.24468369e+32 -3.81955503e+32 ... -4.22615283e+32\n",
      "  -3.41191989e+32 -3.56492846e+32]\n",
      " [-3.01362348e+32 -3.32700726e+32 -2.42296539e+32 ... -2.68089404e+32\n",
      "  -2.16437880e+32 -2.26144107e+32]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 9.91306555e+34 ... 1.32577207e+34\n",
      "  2.14004883e+35 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.27628089e+35 ... 1.70689637e+34\n",
      "  2.75525609e+35 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.27733207e+35 ... 1.70830221e+34\n",
      "  2.75752539e+35 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.11954860e+35 ... 1.49728281e+34\n",
      "  2.41689984e+35 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.30319166e+35 ... 1.74288680e+34\n",
      "  2.81335155e+35 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.25281558e+35 ... 1.67551390e+34\n",
      "  2.70459879e+35 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.08782316e+70 -1.20094477e+70 -8.74614166e+69 -1.15995377e+70\n",
      "  -7.56202435e+69 -8.80614379e+69 -1.09832304e+70 -9.67718258e+69\n",
      "  -7.81272544e+69 -8.16308947e+69]]\n",
      "Shape of inputs (100, 10)\n",
      "-7.049911678549882e+69\n",
      "Reg:\n",
      "[-3.82831991e+69 -4.95953605e+69 -1.69622998e+69 -4.54962606e+69\n",
      " -5.12112670e+68 -1.75623211e+69 -3.93331873e+69 -2.62727090e+69\n",
      " -7.62813765e+68 -1.11317779e+69]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 16\n",
      "Update pass epoch 16\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.98241308e+32 -3.29255104e+32 -2.39787199e+32 ... -2.65312929e+32\n",
      "  -2.14196340e+32 -2.23802037e+32]\n",
      " ...\n",
      " [-4.75066671e+32 -5.24468369e+32 -3.81955503e+32 ... -4.22615283e+32\n",
      "  -3.41191989e+32 -3.56492846e+32]\n",
      " [-3.01362348e+32 -3.32700726e+32 -2.42296539e+32 ... -2.68089404e+32\n",
      "  -2.16437880e+32 -2.26144107e+32]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.17852473e+35 -1.30107830e+35 -9.47538587e+34 ... -1.04840560e+35\n",
      "  -8.46414238e+34 -8.84371938e+34]\n",
      " ...\n",
      " [-1.61967539e+34 -1.78810378e+34 -1.30222549e+34 ... -1.44084950e+34\n",
      "  -1.16324782e+34 -1.21541401e+34]\n",
      " [-2.54079362e+35 -2.80500815e+35 -2.04280823e+35 ... -2.26026847e+35\n",
      "  -1.82479320e+35 -1.90662661e+35]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 5.73855593e+36 ... 8.99626237e+36\n",
      "  5.91244602e+36 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.38823849e+36 ... 1.15824491e+37\n",
      "  7.61211738e+36 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.39432364e+36 ... 1.15919887e+37\n",
      "  7.61838691e+36 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 6.48093387e+36 ... 1.01600790e+37\n",
      "  6.67731952e+36 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.54402177e+36 ... 1.18266686e+37\n",
      "  7.77262130e+36 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.25240061e+36 ... 1.13694977e+37\n",
      "  7.47216330e+36 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.48385662e+74 -2.74215033e+74 -1.99703065e+74 -2.64855445e+74\n",
      "  -1.72665788e+74 -2.01073110e+74 -2.50783129e+74 -2.20961779e+74\n",
      "  -1.78390115e+74 -1.86390074e+74]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.6097257774655876e+74\n",
      "Reg:\n",
      "[-8.74130845e+73 -1.13242455e+74 -3.87304873e+73 -1.03882868e+74\n",
      " -1.16932099e+73 -4.01005325e+73 -8.98105512e+73 -5.99892017e+73\n",
      " -1.74175374e+73 -2.54174959e+73]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update pass epoch 17\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.17852473e+35 -1.30107830e+35 -9.47538587e+34 ... -1.04840560e+35\n",
      "  -8.46414238e+34 -8.84371938e+34]\n",
      " ...\n",
      " [-1.61967539e+34 -1.78810378e+34 -1.30222549e+34 ... -1.44084950e+34\n",
      "  -1.16324782e+34 -1.21541401e+34]\n",
      " [-2.54079362e+35 -2.80500815e+35 -2.04280823e+35 ... -2.26026847e+35\n",
      "  -1.82479320e+35 -1.90662661e+35]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-6.92292732e+36 -7.64283541e+36 -5.56606122e+36 ... -6.15857743e+36\n",
      "  -4.97203336e+36 -5.19500569e+36]\n",
      " ...\n",
      " [-1.06844275e+37 -1.17954901e+37 -8.59032239e+36 ... -9.50477610e+36\n",
      "  -7.67353571e+36 -8.01765772e+36]\n",
      " [-7.26536200e+36 -8.02087959e+36 -5.84138010e+36 ... -6.46320447e+36\n",
      "  -5.21796933e+36 -5.45197075e+36]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 2.23420325e+39 ... 3.15259624e+38\n",
      "  4.81028251e+39 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.87647741e+39 ... 4.05888401e+38\n",
      "  6.19311110e+39 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.87884655e+39 ... 4.06222701e+38\n",
      "  6.19821190e+39 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 2.52323471e+39 ... 3.56043715e+38\n",
      "  5.43257279e+39 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.93712883e+39 ... 4.14446684e+38\n",
      "  6.32369478e+39 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.82359138e+39 ... 3.98425861e+38\n",
      "  6.07924645e+39 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-5.67061353e+78 -6.26029482e+78 -4.55919594e+78 -6.04661661e+78\n",
      "  -3.94193829e+78 -4.59047390e+78 -5.72534740e+78 -5.04452972e+78\n",
      "  -4.07262397e+78 -4.25526202e+78]]\n",
      "Shape of inputs (100, 10)\n",
      "-3.674983772458634e+78\n",
      "Reg:\n",
      "[-1.99562976e+78 -2.58531105e+78 -8.84212169e+77 -2.37163284e+78\n",
      " -2.66954516e+77 -9.15490129e+77 -2.05036363e+78 -1.36954595e+78\n",
      " -3.97640194e+77 -5.80278243e+77]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 18\n",
      "Update pass epoch 18\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-6.92292732e+36 -7.64283541e+36 -5.56606122e+36 ... -6.15857743e+36\n",
      "  -4.97203336e+36 -5.19500569e+36]\n",
      " ...\n",
      " [-1.06844275e+37 -1.17954901e+37 -8.59032239e+36 ... -9.50477610e+36\n",
      "  -7.67353571e+36 -8.01765772e+36]\n",
      " [-7.26536200e+36 -8.02087959e+36 -5.84138010e+36 ... -6.46320447e+36\n",
      "  -5.21796933e+36 -5.45197075e+36]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.65635608e+39 -2.93258783e+39 -2.13572091e+39 ... -2.36307185e+39\n",
      "  -1.90778994e+39 -1.99334535e+39]\n",
      " ...\n",
      " [-3.84535508e+38 -4.24522961e+38 -3.09168085e+38 ... -3.42079528e+38\n",
      "  -2.76172678e+38 -2.88557725e+38]\n",
      " [-5.71154582e+39 -6.30548362e+39 -4.59210567e+39 ... -5.08094274e+39\n",
      "  -4.10202146e+39 -4.28597785e+39]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.33139383e+41 ... 2.02346401e+41\n",
      "  1.42190538e+41 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.71413423e+41 ... 2.60515622e+41\n",
      "  1.83066545e+41 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.71554604e+41 ... 2.60730189e+41\n",
      "  1.83217324e+41 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.50363183e+41 ... 2.28523283e+41\n",
      "  1.60585256e+41 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.75027729e+41 ... 2.66008675e+41\n",
      "  1.86926560e+41 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.68261869e+41 ... 2.55725861e+41\n",
      "  1.79700740e+41 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.29440795e+83 -1.42901210e+83 -1.04070916e+83 -1.38023664e+83\n",
      "  -8.99810261e+82 -1.04784885e+83 -1.30690182e+83 -1.15149434e+83\n",
      "  -9.29641351e+82 -9.71331398e+82]]\n",
      "Shape of inputs (100, 10)\n",
      "-8.388736369708901e+82\n",
      "Reg:\n",
      "[-4.55534310e+82 -5.90138465e+82 -2.01835525e+82 -5.41363008e+82\n",
      " -6.09366243e+81 -2.08975218e+82 -4.68028187e+82 -3.12620699e+82\n",
      " -9.07677141e+81 -1.32457761e+82]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 19\n",
      "Update pass epoch 19\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.65635608e+39 -2.93258783e+39 -2.13572091e+39 ... -2.36307185e+39\n",
      "  -1.90778994e+39 -1.99334535e+39]\n",
      " ...\n",
      " [-3.84535508e+38 -4.24522961e+38 -3.09168085e+38 ... -3.42079528e+38\n",
      "  -2.76172678e+38 -2.88557725e+38]\n",
      " [-5.71154582e+39 -6.30548362e+39 -4.59210567e+39 ... -5.08094274e+39\n",
      "  -4.10202146e+39 -4.28597785e+39]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.60539886e+41 -1.77234264e+41 -1.29074710e+41 ... -1.42814922e+41\n",
      "  -1.15299444e+41 -1.20470082e+41]\n",
      " ...\n",
      " [-2.40337307e+41 -2.65329737e+41 -1.93232155e+41 ... -2.13802031e+41\n",
      "  -1.72609802e+41 -1.80350540e+41]\n",
      " [-1.74328401e+41 -1.92456633e+41 -1.40160731e+41 ... -1.55081068e+41\n",
      "  -1.25202330e+41 -1.30817066e+41]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 20\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 5.03620030e+43 ... 7.47350319e+42\n",
      "  1.08141437e+44 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.48397425e+43 ... 9.62193707e+42\n",
      "  1.39229231e+44 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.48931462e+43 ... 9.62986194e+42\n",
      "  1.39343904e+44 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 5.68771681e+43 ... 8.44032550e+42\n",
      "  1.22131336e+44 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.62069087e+43 ... 9.82481861e+42\n",
      "  1.42164923e+44 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.36476189e+43 ... 9.44503108e+42\n",
      "  1.36669405e+44 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.95428287e+87 -3.26149572e+87 -2.37525523e+87 -3.15017340e+87\n",
      "  -2.05367562e+87 -2.39155046e+87 -2.98279818e+87 -2.62810500e+87\n",
      "  -2.12176040e+87 -2.21691138e+87]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.914597344452861e+87\n",
      "Reg:\n",
      "[-1.03968553e+87 -1.34689837e+87 -4.60657890e+86 -1.23557605e+87\n",
      " -1.39078276e+86 -4.76953118e+86 -1.06820084e+87 -7.13507652e+86\n",
      " -2.07163054e+86 -3.02314038e+86]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 20\n",
      "Update pass epoch 20\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.60539886e+41 -1.77234264e+41 -1.29074710e+41 ... -1.42814922e+41\n",
      "  -1.15299444e+41 -1.20470082e+41]\n",
      " ...\n",
      " [-2.40337307e+41 -2.65329737e+41 -1.93232155e+41 ... -2.13802031e+41\n",
      "  -1.72609802e+41 -1.80350540e+41]\n",
      " [-1.74328401e+41 -1.92456633e+41 -1.40160731e+41 ... -1.55081068e+41\n",
      "  -1.25202330e+41 -1.30817066e+41]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.98823938e+43 -6.61095026e+43 -4.81456840e+43 ... -5.32708699e+43\n",
      "  -4.30074225e+43 -4.49361034e+43]\n",
      " ...\n",
      " [-9.10280186e+42 -1.00493929e+43 -7.31868908e+42 ... -8.09777537e+42\n",
      "  -6.53761517e+42 -6.83079649e+42]\n",
      " [-1.28414008e+44 -1.41767649e+44 -1.03245376e+44 ... -1.14236013e+44\n",
      "  -9.22266989e+43 -9.63626330e+43]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 21\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.08600022e+45 ... 4.55199594e+45\n",
      "  3.40450578e+45 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.97314340e+45 ... 5.86057399e+45\n",
      "  4.38321086e+45 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.97641578e+45 ... 5.86540091e+45\n",
      "  4.38682099e+45 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 3.48522582e+45 ... 5.14087254e+45\n",
      "  3.84493539e+45 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.05691836e+45 ... 5.98414602e+45\n",
      "  4.47563223e+45 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.90009440e+45 ... 5.75282327e+45\n",
      "  4.30262249e+45 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-6.74178451e+91 -7.44285577e+91 -5.42042169e+91 -7.18881405e+91\n",
      "  -4.68656492e+91 -5.45760801e+91 -6.80685752e+91 -5.99743434e+91\n",
      "  -4.84193694e+91 -5.05907507e+91]]\n",
      "Shape of inputs (100, 10)\n",
      "-4.369183072929496e+91\n",
      "Reg:\n",
      "[-2.37260143e+91 -3.07367270e+91 -1.05123861e+91 -2.81963097e+91\n",
      " -3.17381851e+90 -1.08842494e+91 -2.43767445e+91 -1.62825127e+91\n",
      " -4.72753872e+90 -6.89891993e+90]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update pass epoch 21\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.98823938e+43 -6.61095026e+43 -4.81456840e+43 ... -5.32708699e+43\n",
      "  -4.30074225e+43 -4.49361034e+43]\n",
      " ...\n",
      " [-9.10280186e+42 -1.00493929e+43 -7.31868908e+42 ... -8.09777537e+42\n",
      "  -6.53761517e+42 -6.83079649e+42]\n",
      " [-1.28414008e+44 -1.41767649e+44 -1.03245376e+44 ... -1.14236013e+44\n",
      "  -9.22266989e+43 -9.63626330e+43]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.71942021e+45 -4.10619890e+45 -2.99042871e+45 ... -3.30876469e+45\n",
      "  -2.67128059e+45 -2.79107498e+45]\n",
      " ...\n",
      " [-5.40709376e+45 -5.96937190e+45 -4.34732499e+45 ... -4.81010477e+45\n",
      "  -3.88336456e+45 -4.05751521e+45]\n",
      " [-4.16565211e+45 -4.59883400e+45 -3.34920094e+45 ... -3.70572880e+45\n",
      "  -2.99176350e+45 -3.12593004e+45]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 22\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.13539827e+48 ... 1.76676282e+47\n",
      "  2.43157659e+48 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.46179515e+48 ... 2.27466025e+47\n",
      "  3.13059034e+48 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.46299912e+48 ... 2.27653372e+47\n",
      "  3.13316878e+48 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.28228098e+48 ... 1.99532306e+47\n",
      "  2.74614159e+48 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.49261756e+48 ... 2.32262217e+47\n",
      "  3.19659982e+48 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.43491903e+48 ... 2.23283904e+47\n",
      "  3.07303227e+48 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.53830181e+96 -1.69826824e+96 -1.23680080e+96 -1.64030245e+96\n",
      "  -1.06935357e+96 -1.24528577e+96 -1.55314980e+96 -1.36846025e+96\n",
      "  -1.10480547e+96 -1.15435080e+96]]\n",
      "Shape of inputs (100, 10)\n",
      "-9.969351931189763e+95\n",
      "Reg:\n",
      "[-5.41366619e+95 -7.01333048e+95 -2.39865612e+95 -6.43367261e+95\n",
      " -7.24183746e+94 -2.48350574e+95 -5.56214608e+95 -3.71525058e+95\n",
      " -1.07870273e+95 -1.57415607e+95]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 22\n",
      "Update pass epoch 22\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.71942021e+45 -4.10619890e+45 -2.99042871e+45 ... -3.30876469e+45\n",
      "  -2.67128059e+45 -2.79107498e+45]\n",
      " ...\n",
      " [-5.40709376e+45 -5.96937190e+45 -4.34732499e+45 ... -4.81010477e+45\n",
      "  -3.88336456e+45 -4.05751521e+45]\n",
      " [-4.16565211e+45 -4.59883400e+45 -3.34920094e+45 ... -3.70572880e+45\n",
      "  -2.99176350e+45 -3.12593004e+45]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.35013310e+48 -1.49053206e+48 -1.08551241e+48 ... -1.20106696e+48\n",
      "  -9.69663052e+47 -1.01314788e+48]\n",
      " ...\n",
      " [-2.14918917e+47 -2.37268115e+47 -1.72795669e+47 ... -1.91190047e+47\n",
      "  -1.54354362e+47 -1.61276430e+47]\n",
      " [-2.88765427e+48 -3.18793847e+48 -2.32168557e+48 ... -2.56883275e+48\n",
      "  -2.07390786e+48 -2.16691288e+48]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 23\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 7.14656719e+49 ... 1.02419059e+50\n",
      "  8.11996200e+49 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.20101564e+49 ... 1.31861821e+50\n",
      "  1.04542356e+50 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.20859384e+49 ... 1.31970426e+50\n",
      "  1.04628460e+50 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 8.07109487e+49 ... 1.15668673e+50\n",
      "  9.17041454e+49 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.39502192e+49 ... 1.34642168e+50\n",
      "  1.06746664e+50 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.03184859e+49 ... 1.29437450e+50\n",
      "  1.02620273e+50 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-3.50957121e+100 -3.87452792e+100 -2.82170928e+100 -3.74228140e+100\n",
      "  -2.43968541e+100 -2.84106736e+100 -3.54344627e+100 -3.12208479e+100\n",
      "  -2.52056744e+100 -2.63360304e+100]]\n",
      "Shape of inputs (100, 10)\n",
      "-2.2744659215345544e+100\n",
      "Reg:\n",
      "[-1.23510529e+100 -1.60006200e+100 -5.47243355e+099 -1.46781548e+100\n",
      " -1.65219491e+099 -5.66601441e+099 -1.26898035e+100 -8.47618871e+099\n",
      " -2.46101514e+099 -3.59137121e+099]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 23\n",
      "Update pass epoch 23\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.35013310e+48 -1.49053206e+48 -1.08551241e+48 ... -1.20106696e+48\n",
      "  -9.69663052e+47 -1.01314788e+48]\n",
      " ...\n",
      " [-2.14918917e+47 -2.37268115e+47 -1.72795669e+47 ... -1.91190047e+47\n",
      "  -1.54354362e+47 -1.61276430e+47]\n",
      " [-2.88765427e+48 -3.18793847e+48 -2.32168557e+48 ... -2.56883275e+48\n",
      "  -2.07390786e+48 -2.16691288e+48]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-8.60978034e+49 -9.50510258e+49 -6.92229780e+49 ... -7.65918760e+49\n",
      "  -6.18352804e+49 -6.46083022e+49]\n",
      " ...\n",
      " [-1.21668708e+50 -1.34320912e+50 -9.78221273e+49 ... -1.08235451e+50\n",
      "  -8.73822369e+49 -9.13009197e+49]\n",
      " [-9.91783410e+49 -1.09491795e+50 -7.97397825e+49 ... -8.82282113e+49\n",
      "  -7.12296978e+49 -7.44240151e+49]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 24\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 2.56010443e+52 ... 4.16630682e+51\n",
      "  5.46836654e+52 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.29606652e+52 ... 5.36400949e+51\n",
      "  7.04037683e+52 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.29878125e+52 ... 5.36842743e+51\n",
      "  7.04617547e+52 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 2.89129664e+52 ... 4.70528811e+51\n",
      "  6.17579097e+52 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.36556511e+52 ... 5.47711130e+51\n",
      "  7.18882537e+52 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.23546605e+52 ... 5.26538846e+51\n",
      "  6.91093462e+52 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-8.00597509e+104 -8.83850824e+104 -6.43683597e+104 -8.53682970e+104\n",
      "  -5.56536953e+104 -6.48099531e+104 -8.08325032e+104 -7.12204757e+104\n",
      "  -5.74987624e+104 -6.00773118e+104]]\n",
      "Shape of inputs (100, 10)\n",
      "-5.188473588589688e+104\n",
      "Reg:\n",
      "[-2.81750150e+104 -3.65003465e+104 -1.24836238e+104 -3.34835611e+104\n",
      " -3.76895937e+103 -1.29252172e+104 -2.89477673e+104 -1.93357398e+104\n",
      " -5.61402655e+103 -8.19257588e+103]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 24\n",
      "Update pass epoch 24\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-8.60978034e+49 -9.50510258e+49 -6.92229780e+49 ... -7.65918760e+49\n",
      "  -6.18352804e+49 -6.46083022e+49]\n",
      " ...\n",
      " [-1.21668708e+50 -1.34320912e+50 -9.78221273e+49 ... -1.08235451e+50\n",
      "  -8.73822369e+49 -9.13009197e+49]\n",
      " [-9.91783410e+49 -1.09491795e+50 -7.97397825e+49 ... -8.82282113e+49\n",
      "  -7.12296978e+49 -7.44240151e+49]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.04451331e+52 -3.36110913e+52 -2.44780087e+52 ... -2.70837323e+52\n",
      "  -2.18656373e+52 -2.28462084e+52]\n",
      " ...\n",
      " [-5.06228967e+51 -5.58871199e+51 -4.07010113e+51 ... -4.50336998e+51\n",
      "  -3.63572692e+51 -3.79877219e+51]\n",
      " [-6.49458820e+52 -7.16995377e+52 -5.22167487e+52 ... -5.77753060e+52\n",
      "  -4.66440102e+52 -4.87357749e+52]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 25\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.65361878e+54 ... 2.30479195e+54\n",
      "  1.93004043e+54 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.12899031e+54 ... 2.96735848e+54\n",
      "  2.48487585e+54 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.13074380e+54 ... 2.96980248e+54\n",
      "  2.48692246e+54 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.86754196e+54 ... 2.60295524e+54\n",
      "  2.17972336e+54 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.17388073e+54 ... 3.02992616e+54\n",
      "  2.53727023e+54 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.08984734e+54 ... 2.91280154e+54\n",
      "  2.43918968e+54 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.82609704e+109 -2.01599100e+109 -1.46818932e+109 -1.94718061e+109\n",
      "  -1.26941499e+109 -1.47826170e+109 -1.84372289e+109 -1.62448045e+109\n",
      "  -1.31149946e+109 -1.37031405e+109]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.1834481321373277e+109\n",
      "Reg:\n",
      "[-6.42648909e+108 -8.32542869e+108 -2.84741187e+108 -7.63732476e+108\n",
      " -8.59668620e+107 -2.94813569e+108 -6.60274753e+108 -4.41032315e+108\n",
      " -1.28051326e+108 -1.86865915e+108]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 25\n",
      "Update pass epoch 25\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.04451331e+52 -3.36110913e+52 -2.44780087e+52 ... -2.70837323e+52\n",
      "  -2.18656373e+52 -2.28462084e+52]\n",
      " ...\n",
      " [-5.06228967e+51 -5.58871199e+51 -4.07010113e+51 ... -4.50336998e+51\n",
      "  -3.63572692e+51 -3.79877219e+51]\n",
      " [-6.49458820e+52 -7.16995377e+52 -5.22167487e+52 ... -5.77753060e+52\n",
      "  -4.66440102e+52 -4.87357749e+52]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.99139136e+54 -2.19847410e+54 -1.60108661e+54 ... -1.77152487e+54\n",
      "  -1.43021352e+54 -1.49435188e+54]\n",
      " ...\n",
      " [-2.73820315e+54 -3.02294609e+54 -2.20152628e+54 ... -2.43588231e+54\n",
      "  -1.96657235e+54 -2.05476388e+54]\n",
      " [-2.35368712e+54 -2.59844463e+54 -1.89237385e+54 ... -2.09382011e+54\n",
      "  -1.69041366e+54 -1.76622077e+54]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 26\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 5.77338651e+56 ... 9.80272966e+55\n",
      "  1.22998748e+57 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.43308195e+56 ... 1.26207543e+56\n",
      "  1.58357624e+57 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.43920403e+56 ... 1.26311491e+56\n",
      "  1.58488052e+57 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 6.52027037e+56 ... 1.10708763e+56\n",
      "  1.38910688e+57 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.58981080e+56 ... 1.28868669e+56\n",
      "  1.61696644e+57 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.29641958e+56 ... 1.23887130e+56\n",
      "  1.55446110e+57 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-4.16470855e+113 -4.59779232e+113 -3.34844231e+113 -4.44085913e+113\n",
      "  -2.89510544e+113 -3.37141401e+113 -4.20490712e+113 -3.70488942e+113\n",
      "  -2.99108584e+113 -3.12522199e+113]]\n",
      "Shape of inputs (100, 10)\n",
      "-2.699044157440035e+113\n",
      "Reg:\n",
      "[-1.46566439e+113 -1.89874816e+113 -6.49398158e+112 -1.74181497e+113\n",
      " -1.96061281e+112 -6.72369849e+112 -1.50586297e+113 -1.00584526e+113\n",
      " -2.92041682e+112 -4.26177828e+112]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 26\n",
      "Update pass epoch 26\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.99139136e+54 -2.19847410e+54 -1.60108661e+54 ... -1.77152487e+54\n",
      "  -1.43021352e+54 -1.49435188e+54]\n",
      " ...\n",
      " [-2.73820315e+54 -3.02294609e+54 -2.20152628e+54 ... -2.43588231e+54\n",
      "  -1.96657235e+54 -2.05476388e+54]\n",
      " [-2.35368712e+54 -2.59844463e+54 -1.89237385e+54 ... -2.09382011e+54\n",
      "  -1.69041366e+54 -1.76622077e+54]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-6.86629265e+56 -7.58031139e+56 -5.52052673e+56 ... -6.10819573e+56\n",
      "  -4.93135846e+56 -5.15250672e+56]\n",
      " ...\n",
      " [-1.18984014e+56 -1.31357040e+56 -9.56636231e+55 ... -1.05847171e+56\n",
      "  -8.54540952e+55 -8.92863099e+55]\n",
      " [-1.46093612e+57 -1.61285737e+57 -1.17459848e+57 ... -1.29963638e+57\n",
      "  -1.04924157e+57 -1.09629512e+57]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 27\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.82324277e+58 ... 5.18745318e+58\n",
      "  4.57357034e+58 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.92232362e+58 ... 6.67870833e+58\n",
      "  5.88835046e+58 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.92637777e+58 ... 6.68420909e+58\n",
      "  5.89320026e+58 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 4.31784299e+58 ... 5.85853678e+58\n",
      "  5.16523796e+58 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.02611234e+58 ... 6.81953098e+58\n",
      "  6.01250817e+58 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.83182328e+58 ... 6.55591564e+58\n",
      "  5.78008905e+58 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-9.49725616e+117 -1.04848661e+118 -7.63583190e+117 -1.01269936e+118\n",
      "  -6.60203653e+117 -7.68821685e+117 -9.58892552e+117 -8.44867856e+117\n",
      "  -6.82091150e+117 -7.12679733e+117]]\n",
      "Shape of inputs (100, 10)\n",
      "-6.15493580301188e+117\n",
      "Reg:\n",
      "[-3.34232035e+117 -4.32993029e+117 -1.48089610e+117 -3.97205778e+117\n",
      " -4.47100724e+116 -1.53328105e+117 -3.43398972e+117 -2.29374276e+117\n",
      " -6.65975695e+116 -9.71861526e+116]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 27\n",
      "Update pass epoch 27\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-6.86629265e+56 -7.58031139e+56 -5.52052673e+56 ... -6.10819573e+56\n",
      "  -4.93135846e+56 -5.15250672e+56]\n",
      " ...\n",
      " [-1.18984014e+56 -1.31357040e+56 -9.56636231e+55 ... -1.05847171e+56\n",
      "  -8.54540952e+55 -8.92863099e+55]\n",
      " [-1.46093612e+57 -1.61285737e+57 -1.17459848e+57 ... -1.29963638e+57\n",
      "  -1.04924157e+57 -1.09629512e+57]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.60246088e+58 -5.08106607e+58 -3.70039694e+58 ... -4.09431018e+58\n",
      "  -3.30547874e+58 -3.45371393e+58]\n",
      " ...\n",
      " [-6.16344725e+58 -6.80437781e+58 -4.95543622e+58 ... -5.48295042e+58\n",
      "  -4.42657621e+58 -4.62508736e+58]\n",
      " [-5.56966861e+58 -6.14885274e+58 -4.47803582e+58 ... -4.95472997e+58\n",
      "  -4.00012551e+58 -4.17951234e+58]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 28\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.30216603e+61 ... 2.30173549e+60\n",
      "  2.76704813e+61 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.67650422e+61 ... 2.96342336e+60\n",
      "  3.56250104e+61 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.67788503e+61 ... 2.96586412e+60\n",
      "  3.56543521e+61 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.47062293e+61 ... 2.59950337e+60\n",
      "  3.12501196e+61 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.71185383e+61 ... 3.02590807e+60\n",
      "  3.63761749e+61 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.64568052e+61 ... 2.90893877e+60\n",
      "  3.49700199e+61 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.16553913e+122 -2.39073132e+122 -1.74110211e+122 -2.30913018e+122\n",
      "  -1.50537883e+122 -1.75304679e+122 -2.18644133e+122 -1.92644525e+122\n",
      "  -1.55528612e+122 -1.62503340e+122]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.4034321148593915e+122\n",
      "Reg:\n",
      "[-7.62107010e+121 -9.87299204e+121 -3.37669996e+121 -9.05698066e+121\n",
      " -1.01946720e+121 -3.49614673e+121 -7.83009215e+121 -5.23013132e+121\n",
      " -1.51854009e+121 -2.21601284e+121]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 28\n",
      "Update pass epoch 28\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.60246088e+58 -5.08106607e+58 -3.70039694e+58 ... -4.09431018e+58\n",
      "  -3.30547874e+58 -3.45371393e+58]\n",
      " ...\n",
      " [-6.16344725e+58 -6.80437781e+58 -4.95543622e+58 ... -5.48295042e+58\n",
      "  -4.42657621e+58 -4.62508736e+58]\n",
      " [-5.56966861e+58 -6.14885274e+58 -4.47803582e+58 ... -4.95472997e+58\n",
      "  -4.00012551e+58 -4.17951234e+58]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.54877793e+61 -1.70983376e+61 -1.24522365e+61 ... -1.37777972e+61\n",
      "  -1.11232940e+61 -1.16221214e+61]\n",
      " ...\n",
      " [-2.79115082e+60 -3.08139974e+60 -2.24409642e+60 ... -2.48298411e+60\n",
      "  -2.00459927e+60 -2.09449613e+60]\n",
      " [-3.28687768e+61 -3.62867673e+61 -2.64266279e+61 ... -2.92397852e+61\n",
      "  -2.36062937e+61 -2.46649250e+61]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 29\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 8.83297981e+62 ... 1.16774395e+63\n",
      "  1.08083548e+63 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.13722271e+63 ... 1.50343935e+63\n",
      "  1.39154700e+63 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.13815936e+63 ... 1.50467762e+63\n",
      "  1.39269311e+63 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 9.97567310e+62 ... 1.31881111e+63\n",
      "  1.22065958e+63 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.16120141e+63 ... 1.53513984e+63\n",
      "  1.42088820e+63 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.11631409e+63 ... 1.47579757e+63\n",
      "  1.36596244e+63 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-4.93730288e+126 -5.45072794e+126 -3.96961125e+126 -5.26468211e+126\n",
      "  -3.43217593e+126 -3.99684441e+126 -4.98495869e+126 -4.39218278e+126\n",
      "  -3.54596163e+126 -3.70498135e+126]]\n",
      "Shape of inputs (100, 10)\n",
      "-3.19974335260857e+126\n",
      "Reg:\n",
      "[-1.73755953e+126 -2.25098459e+126 -7.69867893e+125 -2.06493876e+126\n",
      " -2.32432574e+125 -7.97101059e+125 -1.78521533e+126 -1.19243943e+126\n",
      " -3.46218282e+125 -5.05238000e+125]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 29\n",
      "Update pass epoch 29\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.54877793e+61 -1.70983376e+61 -1.24522365e+61 ... -1.37777972e+61\n",
      "  -1.11232940e+61 -1.16221214e+61]\n",
      " ...\n",
      " [-2.79115082e+60 -3.08139974e+60 -2.24409642e+60 ... -2.48298411e+60\n",
      "  -2.00459927e+60 -2.09449613e+60]\n",
      " [-3.28687768e+61 -3.62867673e+61 -2.64266279e+61 ... -2.92397852e+61\n",
      "  -2.36062937e+61 -2.46649250e+61]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.06294797e+63 -1.17348284e+63 -8.54614413e+62 ... -9.45589499e+62\n",
      "  -7.63407229e+62 -7.97642456e+62]\n",
      " ...\n",
      " [-1.38756200e+63 -1.53185315e+63 -1.11560539e+63 ... -1.23436339e+63\n",
      "  -9.96544416e+62 -1.04123475e+63]\n",
      " [-1.31457909e+63 -1.45128082e+63 -1.05692684e+63 ... -1.16943841e+63\n",
      "  -9.44128228e+62 -9.86467943e+62]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 30\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 2.93740705e+65 ... 5.39454325e+64\n",
      "  6.22594389e+65 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.78183364e+65 ... 6.94533129e+64\n",
      "  8.01573756e+65 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.78494846e+65 ... 6.95105165e+64\n",
      "  8.02233953e+65 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 3.31740965e+65 ... 6.09241740e+64\n",
      "  7.03137359e+65 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.86157478e+65 ... 7.09177577e+64\n",
      "  8.18475189e+65 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.71230200e+65 ... 6.81763656e+64\n",
      "  7.86836267e+65 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.12556559e+131 -1.24261200e+131 -9.04959230e+130 -1.20019880e+131\n",
      "  -7.82439158e+130 -9.11167622e+130 -1.13642976e+131 -1.00129360e+131\n",
      "  -8.08379086e+130 -8.44631089e+130]]\n",
      "Shape of inputs (100, 10)\n",
      "-7.294510974240573e+130\n",
      "Reg:\n",
      "[-3.96114489e+130 -5.13160901e+130 -1.75508132e+130 -4.70747706e+130\n",
      " -5.29880610e+129 -1.81716525e+130 -4.06978667e+130 -2.71842506e+130\n",
      " -7.89279883e+129 -1.15179992e+130]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 30\n",
      "Update pass epoch 30\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.06294797e+63 -1.17348284e+63 -8.54614413e+62 ... -9.45589499e+62\n",
      "  -7.63407229e+62 -7.97642456e+62]\n",
      " ...\n",
      " [-1.38756200e+63 -1.53185315e+63 -1.11560539e+63 ... -1.23436339e+63\n",
      "  -9.96544416e+62 -1.04123475e+63]\n",
      " [-1.31457909e+63 -1.45128082e+63 -1.05692684e+63 ... -1.16943841e+63\n",
      "  -9.44128228e+62 -9.86467943e+62]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.49395787e+65 -3.85729097e+65 -2.80915609e+65 ... -3.10819530e+65\n",
      "  -2.50935397e+65 -2.62188670e+65]\n",
      " ...\n",
      " [-6.53588310e+64 -7.21554289e+64 -5.25487613e+64 ... -5.81426620e+64\n",
      "  -4.69405894e+64 -4.90456543e+64]\n",
      " [-7.39619035e+65 -8.16531260e+65 -5.94656660e+65 ... -6.57958823e+65\n",
      "  -5.31192999e+65 -5.55014509e+65]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 31\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 2.03929543e+67 ... 2.62912646e+67\n",
      "  2.54798845e+67 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.62553876e+67 ... 3.38493056e+67\n",
      "  3.28046752e+67 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.62770122e+67 ... 3.38771847e+67\n",
      "  3.28316940e+67 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 2.30311232e+67 ... 2.96924782e+67\n",
      "  2.87761326e+67 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.68089906e+67 ... 3.45630287e+67\n",
      "  3.34963720e+67 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.57726641e+67 ... 3.32269626e+67\n",
      "  3.22015385e+67 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.56572755e+135 -2.83253493e+135 -2.06285520e+135 -2.73585402e+135\n",
      "  -1.78357061e+135 -2.07700724e+135 -2.59049245e+135 -2.28244948e+135\n",
      "  -1.84270070e+135 -1.92533716e+135]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.6627842913952415e+135\n",
      "Reg:\n",
      "[-9.02943257e+134 -1.16975064e+135 -4.00070911e+134 -1.07306973e+135\n",
      " -1.20786322e+134 -4.14222946e+134 -9.27708159e+134 -6.19665184e+134\n",
      " -1.79916405e+134 -2.62552873e+134]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 31\n",
      "Update pass epoch 31\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.49395787e+65 -3.85729097e+65 -2.80915609e+65 ... -3.10819530e+65\n",
      "  -2.50935397e+65 -2.62188670e+65]\n",
      " ...\n",
      " [-6.53588310e+64 -7.21554289e+64 -5.25487613e+64 ... -5.81426620e+64\n",
      "  -4.69405894e+64 -4.90456543e+64]\n",
      " [-7.39619035e+65 -8.16531260e+65 -5.94656660e+65 ... -6.57958823e+65\n",
      "  -5.31192999e+65 -5.55014509e+65]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.45324101e+67 -2.70835103e+67 -1.97241558e+67 ... -2.18238241e+67\n",
      "  -1.76191308e+67 -1.84092660e+67]\n",
      " ...\n",
      " [-3.12428929e+67 -3.44918093e+67 -2.51194108e+67 ... -2.77934127e+67\n",
      "  -2.24385869e+67 -2.34448521e+67]\n",
      " [-3.09549769e+67 -3.41739532e+67 -2.48879251e+67 ... -2.75372850e+67\n",
      "  -2.22318061e+67 -2.32287982e+67]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 32\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 6.62709507e+69 ... 1.26215713e+69\n",
      "  1.40108879e+70 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.53220906e+69 ... 1.62499381e+69\n",
      "  1.80386464e+70 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.53923641e+69 ... 1.62633220e+69\n",
      "  1.80535035e+70 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 7.48442036e+69 ... 1.42543821e+69\n",
      "  1.58234299e+70 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.71211335e+69 ... 1.65925732e+69\n",
      "  1.84189969e+70 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.37533848e+69 ... 1.59511718e+69\n",
      "  1.77069934e+70 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-5.84803957e+139 -6.45617122e+139 -4.70184719e+139 -6.23580730e+139\n",
      "  -4.06527635e+139 -4.73410379e+139 -5.90448599e+139 -5.20236643e+139\n",
      "  -4.20005102e+139 -4.38840357e+139]]\n",
      "Shape of inputs (100, 10)\n",
      "-3.7899691829906204e+139\n",
      "Reg:\n",
      "[-2.05807039e+139 -2.66620203e+139 -9.11878006e+138 -2.44583812e+139\n",
      " -2.75307171e+138 -9.44134612e+138 -2.11451681e+139 -1.41239724e+139\n",
      " -4.10081833e+138 -5.98434387e+138]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 32\n",
      "Update pass epoch 32\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.45324101e+67 -2.70835103e+67 -1.97241558e+67 ... -2.18238241e+67\n",
      "  -1.76191308e+67 -1.84092660e+67]\n",
      " ...\n",
      " [-3.12428929e+67 -3.44918093e+67 -2.51194108e+67 ... -2.77934127e+67\n",
      "  -2.24385869e+67 -2.34448521e+67]\n",
      " [-3.09549769e+67 -3.41739532e+67 -2.48879251e+67 ... -2.75372850e+67\n",
      "  -2.22318061e+67 -2.32287982e+67]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-7.88328267e+69 -8.70305716e+69 -6.33819077e+69 ... -7.01290143e+69\n",
      "  -5.66175878e+69 -5.91566206e+69]\n",
      " ...\n",
      " [-1.52797375e+69 -1.68686617e+69 -1.22849700e+69 ... -1.35927249e+69\n",
      "  -1.09738787e+69 -1.14660056e+69]\n",
      " [-1.66457866e+70 -1.83767649e+70 -1.33832790e+70 ... -1.48079506e+70\n",
      "  -1.19549726e+70 -1.24910970e+70]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 33\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 4.70508835e+71 ... 5.92031978e+71\n",
      "  5.99336523e+71 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.05767642e+71 ... 7.62225463e+71\n",
      "  7.71629871e+71 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.06266568e+71 ... 7.62853252e+71\n",
      "  7.72265405e+71 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 5.31377002e+71 ... 6.68621190e+71\n",
      "  6.76870700e+71 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.18540441e+71 ... 7.78297224e+71\n",
      "  7.87899927e+71 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.94630183e+71 ... 7.48211419e+71\n",
      "  7.57442920e+71 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.33281967e+144 -1.47141822e+144 -1.07159234e+144 -1.42119534e+144\n",
      "  -9.26512246e+143 -1.07894390e+144 -1.34568430e+144 -1.18566508e+144\n",
      "  -9.57228577e+143 -1.00015578e+144]]\n",
      "Shape of inputs (100, 10)\n",
      "-8.637673193386317e+143\n",
      "Reg:\n",
      "[-4.69052348e+143 -6.07650900e+143 -2.07825020e+143 -5.57428024e+143\n",
      " -6.27449264e+142 -2.15176584e+143 -4.81916983e+143 -3.21897758e+143\n",
      " -9.34612576e+142 -1.36388462e+143]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update pass epoch 33\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-7.88328267e+69 -8.70305716e+69 -6.33819077e+69 ... -7.01290143e+69\n",
      "  -5.66175878e+69 -5.91566206e+69]\n",
      " ...\n",
      " [-1.52797375e+69 -1.68686617e+69 -1.22849700e+69 ... -1.35927249e+69\n",
      "  -1.09738787e+69 -1.14660056e+69]\n",
      " [-1.66457866e+70 -1.83767649e+70 -1.33832790e+70 ... -1.48079506e+70\n",
      "  -1.19549726e+70 -1.24910970e+70]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.65836865e+71 -6.24677661e+71 -4.54935101e+71 ... -5.03363678e+71\n",
      "  -4.06382971e+71 -4.24607338e+71]\n",
      " ...\n",
      " [-7.03589950e+71 -7.76755548e+71 -5.65689132e+71 ... -6.25907655e+71\n",
      "  -5.05316978e+71 -5.27978070e+71]\n",
      " [-7.27369868e+71 -8.03008315e+71 -5.84808281e+71 ... -6.47062068e+71\n",
      "  -5.22395670e+71 -5.45822662e+71]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 34\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.49534986e+74 ... 2.94843877e+73\n",
      "  3.15353428e+74 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.92522326e+74 ... 3.79603669e+73\n",
      "  4.06009171e+74 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.92680893e+74 ... 3.79916320e+73\n",
      "  4.06343571e+74 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.68879831e+74 ... 3.32986851e+73\n",
      "  3.56149654e+74 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.96581720e+74 ... 3.87607730e+73\n",
      "  4.14570001e+74 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.88982670e+74 ... 3.72624392e+73\n",
      "  3.98544411e+74 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-3.03735146e+148 -3.35320252e+148 -2.44204271e+148 -3.23875004e+148\n",
      "  -2.11142091e+148 -2.45879613e+148 -3.06666857e+148 -2.70200211e+148\n",
      "  -2.18142010e+148 -2.27924654e+148]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.9684320325980706e+148\n",
      "Reg:\n",
      "[-1.06891943e+148 -1.38477049e+148 -4.73610679e+147 -1.27031801e+148\n",
      " -1.42988882e+147 -4.90364096e+147 -1.09823653e+148 -7.33570075e+147\n",
      " -2.12988069e+147 -3.10814511e+147]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 34\n",
      "Update pass epoch 34\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-5.65836865e+71 -6.24677661e+71 -4.54935101e+71 ... -5.03363678e+71\n",
      "  -4.06382971e+71 -4.24607338e+71]\n",
      " ...\n",
      " [-7.03589950e+71 -7.76755548e+71 -5.65689132e+71 ... -6.25907655e+71\n",
      "  -5.05316978e+71 -5.27978070e+71]\n",
      " [-7.27369868e+71 -8.03008315e+71 -5.84808281e+71 ... -6.47062068e+71\n",
      "  -5.22395670e+71 -5.45822662e+71]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.77892116e+74 -1.96390934e+74 -1.43025972e+74 ... -1.58251318e+74\n",
      "  -1.27761783e+74 -1.33491298e+74]\n",
      " ...\n",
      " [-3.56676937e+73 -3.93767406e+73 -2.86769683e+73 ... -3.17296780e+73\n",
      "  -2.56164705e+73 -2.67652488e+73]\n",
      " [-3.74689688e+74 -4.13653284e+74 -3.01252006e+74 ... -3.33320770e+74\n",
      "  -2.69101429e+74 -2.81169363e+74]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 35\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.08489073e+76 ... 1.33336208e+76\n",
      "  1.40691427e+76 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.39676803e+76 ... 1.71666830e+76\n",
      "  1.81136480e+76 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.39791844e+76 ... 1.71808219e+76\n",
      "  1.81285668e+76 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.22523944e+76 ... 1.50585470e+76\n",
      "  1.58892210e+76 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.42621932e+76 ... 1.75286478e+76\n",
      "  1.84955799e+76 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.37108748e+76 ... 1.68510616e+76\n",
      "  1.77806160e+76 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-6.92121697e+152 -7.64094723e+152 -5.56468610e+152 -7.38014419e+152\n",
      "  -4.81129776e+152 -5.60286214e+152 -6.98802190e+152 -6.15705594e+152\n",
      "  -4.97080500e+152 -5.19372225e+152]]\n",
      "Shape of inputs (100, 10)\n",
      "-4.485468794959938e+152\n",
      "Reg:\n",
      "[-2.43574818e+152 -3.15547843e+152 -1.07921731e+152 -2.89467540e+152\n",
      " -3.25828962e+151 -1.11739334e+152 -2.50255311e+152 -1.67158714e+152\n",
      " -4.85336207e+151 -7.08253455e+151]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 35\n",
      "Update pass epoch 35\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.77892116e+74 -1.96390934e+74 -1.43025972e+74 ... -1.58251318e+74\n",
      "  -1.27761783e+74 -1.33491298e+74]\n",
      " ...\n",
      " [-3.56676937e+73 -3.93767406e+73 -2.86769683e+73 ... -3.17296780e+73\n",
      "  -2.56164705e+73 -2.67652488e+73]\n",
      " [-3.74689688e+74 -4.13653284e+74 -3.01252006e+74 ... -3.33320770e+74\n",
      "  -2.69101429e+74 -2.81169363e+74]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.30430845e+76 -1.43994215e+76 -1.04866921e+76 ... -1.16030174e+76\n",
      "  -9.36751874e+75 -9.78760794e+75]\n",
      " ...\n",
      " [-1.58473611e+76 -1.74953120e+76 -1.27413417e+76 ... -1.40976781e+76\n",
      "  -1.13815450e+76 -1.18919538e+76]\n",
      " [-1.70586029e+76 -1.88325096e+76 -1.37151849e+76 ... -1.51751885e+76\n",
      "  -1.22514565e+76 -1.28008768e+76]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 36\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.37459930e+78 ... 6.87771711e+77\n",
      "  7.09905196e+78 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.34470706e+78 ... 8.85487829e+77\n",
      "  9.13984104e+78 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.34828547e+78 ... 8.86217139e+77\n",
      "  9.14736885e+78 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 3.81116001e+78 ... 7.76746454e+77\n",
      "  8.01743275e+78 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.43631656e+78 ... 9.04158615e+77\n",
      "  9.33255744e+78 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.26482660e+78 ... 8.69207521e+77\n",
      "  8.97179872e+78 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.57701125e+157 -1.74100303e+157 -1.26792335e+157 -1.68157861e+157\n",
      "  -1.09626251e+157 -1.27662182e+157 -1.59223287e+157 -1.40289584e+157\n",
      "  -1.13260651e+157 -1.18339859e+157]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.0220218184861505e+157\n",
      "Reg:\n",
      "[-5.54989432e+156 -7.18981216e+156 -2.45901529e+156 -6.59556793e+156\n",
      " -7.42406923e+155 -2.54600005e+156 -5.70211052e+156 -3.80874020e+156\n",
      " -1.10584694e+156 -1.61376774e+156]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 36\n",
      "Update pass epoch 36\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.30430845e+76 -1.43994215e+76 -1.04866921e+76 ... -1.16030174e+76\n",
      "  -9.36751874e+75 -9.78760794e+75]\n",
      " ...\n",
      " [-1.58473611e+76 -1.74953120e+76 -1.27413417e+76 ... -1.40976781e+76\n",
      "  -1.13815450e+76 -1.18919538e+76]\n",
      " [-1.70586029e+76 -1.88325096e+76 -1.37151849e+76 ... -1.51751885e+76\n",
      "  -1.22514565e+76 -1.28008768e+76]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.01481654e+78 -4.43231319e+78 -3.22792854e+78 ... -3.57154675e+78\n",
      "  -2.88343368e+78 -3.01274213e+78]\n",
      " ...\n",
      " [-8.31442438e+77 -9.17903285e+77 -6.68483043e+77 ... -7.39644144e+77\n",
      "  -5.97140394e+77 -6.23919335e+77]\n",
      " [-8.43547963e+78 -9.31267651e+78 -6.78215933e+78 ... -7.50413116e+78\n",
      "  -6.05834559e+78 -6.33003393e+78]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 37\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 2.50005432e+80 ... 3.00344488e+80\n",
      "  3.29659060e+80 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.21875360e+80 ... 3.86685559e+80\n",
      "  4.24427293e+80 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.22140465e+80 ... 3.87004044e+80\n",
      "  4.24776862e+80 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 2.82347805e+80 ... 3.39199058e+80\n",
      "  3.72305958e+80 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.28662202e+80 ... 3.94838945e+80\n",
      "  4.33376474e+80 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.15957458e+80 ... 3.79576077e+80\n",
      "  4.16623902e+80 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-3.59296627e+161 -3.96659515e+161 -2.88875924e+161 -3.83120617e+161\n",
      "  -2.49765766e+161 -2.90857732e+161 -3.62764628e+161 -3.19627233e+161\n",
      "  -2.58046161e+161 -2.69618319e+161]]\n",
      "Shape of inputs (100, 10)\n",
      "-2.328512190605957e+161\n",
      "Reg:\n",
      "[-1.26445408e+161 -1.63808296e+161 -5.60247050e+160 -1.50269398e+161\n",
      " -1.69145466e+160 -5.80065126e+160 -1.29913409e+161 -8.67760143e+160\n",
      " -2.51949423e+160 -3.67671002e+160]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 37\n",
      "Update pass epoch 37\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.01481654e+78 -4.43231319e+78 -3.22792854e+78 ... -3.57154675e+78\n",
      "  -2.88343368e+78 -3.01274213e+78]\n",
      " ...\n",
      " [-8.31442438e+77 -9.17903285e+77 -6.68483043e+77 ... -7.39644144e+77\n",
      "  -5.97140394e+77 -6.23919335e+77]\n",
      " [-8.43547963e+78 -9.31267651e+78 -6.78215933e+78 ... -7.50413116e+78\n",
      "  -6.05834559e+78 -6.33003393e+78]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.00484119e+80 -3.31731154e+80 -2.41590432e+80 ... -2.67308125e+80\n",
      "  -2.15807129e+80 -2.25485064e+80]\n",
      " ...\n",
      " [-3.56995387e+80 -3.94118972e+80 -2.87025718e+80 ... -3.17580070e+80\n",
      "  -2.56393415e+80 -2.67891455e+80]\n",
      " [-3.99362152e+80 -4.40891413e+80 -3.21088766e+80 ... -3.55269185e+80\n",
      "  -2.86821146e+80 -2.99683727e+80]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 38\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 7.61659090e+82 ... 1.60220352e+82\n",
      "  1.59835592e+83 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.80615869e+82 ... 2.06279452e+82\n",
      "  2.05784084e+83 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.81423529e+82 ... 2.06449349e+82\n",
      "  2.05953573e+83 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 8.60192398e+82 ... 1.80947527e+82\n",
      "  1.80512992e+83 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.00129246e+83 ... 2.10628919e+82\n",
      "  2.10123105e+83 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.62586566e+82 ... 2.02486861e+82\n",
      "  2.02000601e+83 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-8.18537496e+165 -9.03656371e+165 -6.58107418e+165 -8.72812509e+165\n",
      "  -5.69007970e+165 -6.62622306e+165 -8.26438179e+165 -7.28164017e+165\n",
      "  -5.87872089e+165 -6.14235390e+165]]\n",
      "Shape of inputs (100, 10)\n",
      "-5.3047381868638185e+165\n",
      "Reg:\n",
      "[-2.88063677e+165 -3.73182553e+165 -1.27633599e+165 -3.42338690e+165\n",
      " -3.85341515e+164 -1.32148487e+165 -2.95964361e+165 -1.97690198e+165\n",
      " -5.73982705e+164 -8.37615715e+164]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 38\n",
      "Update pass epoch 38\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.00484119e+80 -3.31731154e+80 -2.41590432e+80 ... -2.67308125e+80\n",
      "  -2.15807129e+80 -2.25485064e+80]\n",
      " ...\n",
      " [-3.56995387e+80 -3.94118972e+80 -2.87025718e+80 ... -3.17580070e+80\n",
      "  -2.56393415e+80 -2.67891455e+80]\n",
      " [-3.99362152e+80 -4.40891413e+80 -3.21088766e+80 ... -3.55269185e+80\n",
      "  -2.86821146e+80 -2.99683727e+80]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-9.06219373e+82 -1.00045620e+83 -7.28603997e+82 ... -8.06165071e+82\n",
      "  -6.50845048e+82 -6.80032390e+82]\n",
      " ...\n",
      " [-1.93567490e+82 -2.13696375e+82 -1.55629035e+82 ... -1.72195998e+82\n",
      "  -1.39019807e+82 -1.45254192e+82]\n",
      " [-1.89940630e+83 -2.09692361e+83 -1.52713026e+83 ... -1.68969574e+83\n",
      "  -1.36415003e+83 -1.42532575e+83]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 39\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 5.75800048e+84 ... 6.76642449e+84\n",
      "  7.71134843e+84 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.41327283e+84 ... 8.71159199e+84\n",
      "  9.92815649e+84 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.41937860e+84 ... 8.71876709e+84\n",
      "  9.93633358e+84 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 6.50289389e+84 ... 7.64177437e+84\n",
      "  8.70893998e+84 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.56958400e+84 ... 8.89527862e+84\n",
      "  1.01374948e+85 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.27697467e+84 ... 8.55142333e+84\n",
      "  9.74562045e+84 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.86462772e+170 -2.05852845e+170 -1.49916814e+170 -1.98826616e+170\n",
      "  -1.29619968e+170 -1.50945305e+170 -1.88262547e+170 -1.65875702e+170\n",
      "  -1.33917212e+170 -1.39922770e+170]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.2084189105997864e+170\n",
      "Reg:\n",
      "[-6.56208814e+169 -8.50109540e+169 -2.90749231e+169 -7.79847246e+169\n",
      " -8.77807644e+168 -3.01034141e+169 -6.74206563e+169 -4.50338105e+169\n",
      " -1.30753212e+169 -1.90808789e+169]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 39\n",
      "Update pass epoch 39\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-9.06219373e+82 -1.00045620e+83 -7.28603997e+82 ... -8.06165071e+82\n",
      "  -6.50845048e+82 -6.80032390e+82]\n",
      " ...\n",
      " [-1.93567490e+82 -2.13696375e+82 -1.55629035e+82 ... -1.72195998e+82\n",
      "  -1.39019807e+82 -1.45254192e+82]\n",
      " [-1.89940630e+83 -2.09692361e+83 -1.52713026e+83 ... -1.68969574e+83\n",
      "  -1.36415003e+83 -1.42532575e+83]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-6.91875512e+84 -7.63822937e+84 -5.56270677e+84 ... -6.15486590e+84\n",
      "  -4.96903691e+84 -5.19187486e+84]\n",
      " ...\n",
      " [-8.04333100e+84 -8.87974875e+84 -6.46687027e+84 ... -7.15527907e+84\n",
      "  -5.77670519e+84 -6.03576327e+84]\n",
      " [-9.33445430e+84 -1.03051346e+85 -7.50493856e+84 ... -8.30385141e+84\n",
      "  -6.70398751e+84 -7.00462985e+84]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 40\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.71932229e+87 ... 3.72781926e+86\n",
      "  3.59928631e+87 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.21358183e+87 ... 4.79946839e+86\n",
      "  4.63398562e+87 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.21540499e+87 ... 4.80342136e+86\n",
      "  4.63780229e+87 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.94174531e+87 ... 4.21007487e+86\n",
      "  4.06491403e+87 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.26025589e+87 ... 4.90066667e+86\n",
      "  4.73169465e+87 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.17288359e+87 ... 4.71122683e+86\n",
      "  4.54878658e+87 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-4.24731831e+174 -4.68899259e+174 -3.41486089e+174 -4.52894652e+174\n",
      "  -2.95253178e+174 -3.43828824e+174 -4.28831425e+174 -3.77837836e+174\n",
      "  -3.05041602e+174 -3.18721284e+174]]\n",
      "Shape of inputs (100, 10)\n",
      "-2.7525814920221667e+174\n",
      "Reg:\n",
      "[-1.49473682e+174 -1.93641109e+174 -6.62279402e+173 -1.77636503e+174\n",
      " -1.99950287e+173 -6.85706752e+173 -1.53573276e+174 -1.02579687e+174\n",
      " -2.97834523e+173 -4.34631349e+173]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 40\n",
      "Update pass epoch 40\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-6.91875512e+84 -7.63822937e+84 -5.56270677e+84 ... -6.15486590e+84\n",
      "  -4.96903691e+84 -5.19187486e+84]\n",
      " ...\n",
      " [-8.04333100e+84 -8.87974875e+84 -6.46687027e+84 ... -7.15527907e+84\n",
      "  -5.77670519e+84 -6.03576327e+84]\n",
      " [-9.33445430e+84 -1.03051346e+85 -7.50493856e+84 ... -8.30385141e+84\n",
      "  -6.70398751e+84 -7.00462985e+84]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.04577958e+87 -2.25851810e+87 -1.64481496e+87 ... -1.81990817e+87\n",
      "  -1.46927504e+87 -1.53516512e+87]\n",
      " ...\n",
      " [-4.50107317e+86 -4.96913515e+86 -3.61888081e+86 ... -4.00411653e+86\n",
      "  -3.23266228e+86 -3.37763199e+86]\n",
      " [-4.27755332e+87 -4.72237171e+87 -3.43916997e+87 ... -3.80527517e+87\n",
      "  -3.07213075e+87 -3.20990137e+87]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 41\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 1.32545611e+89 ... 1.52463602e+89\n",
      "  1.80103873e+89 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.70648957e+89 ... 1.96292843e+89\n",
      "  2.31878957e+89 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.70789508e+89 ... 1.96454514e+89\n",
      "  2.32069939e+89 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.49692596e+89 ... 1.72187312e+89\n",
      "  2.03403313e+89 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.74247143e+89 ... 2.00431738e+89\n",
      "  2.36768197e+89 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.67511457e+89 ... 1.92683862e+89\n",
      "  2.27615702e+89 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-9.67403278e+178 -1.06800255e+179 -7.77796101e+178 -1.03154918e+179\n",
      "  -6.72492315e+178 -7.83132102e+178 -9.76740842e+178 -8.60593754e+178\n",
      "  -6.94787213e+178 -7.25945155e+178]]\n",
      "Shape of inputs (100, 10)\n",
      "-6.269500338330745e+178\n",
      "Reg:\n",
      "[-3.40453244e+178 -4.41052519e+178 -1.50846067e+178 -4.04599145e+178\n",
      " -4.55422807e+177 -1.56182069e+178 -3.49790808e+178 -2.33643720e+178\n",
      " -6.78371794e+177 -9.89951214e+177]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 41\n",
      "Update pass epoch 41\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-2.04577958e+87 -2.25851810e+87 -1.64481496e+87 ... -1.81990817e+87\n",
      "  -1.46927504e+87 -1.53516512e+87]\n",
      " ...\n",
      " [-4.50107317e+86 -4.96913515e+86 -3.61888081e+86 ... -4.00411653e+86\n",
      "  -3.23266228e+86 -3.37763199e+86]\n",
      " [-4.27755332e+87 -4.72237171e+87 -3.43916997e+87 ... -3.80527517e+87\n",
      "  -3.07213075e+87 -3.20990137e+87]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.59225184e+89 -1.75782847e+89 -1.28017684e+89 ... -1.41645373e+89\n",
      "  -1.14355227e+89 -1.19483522e+89]\n",
      " ...\n",
      " [-1.81249290e+89 -2.00097218e+89 -1.45725154e+89 ... -1.61237832e+89\n",
      "  -1.30172899e+89 -1.36010542e+89]\n",
      " [-2.17853991e+89 -2.40508404e+89 -1.75155479e+89 ... -1.93801063e+89\n",
      "  -1.56462326e+89 -1.63478926e+89]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 42\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.88160579e+91 ... 8.66351344e+90\n",
      "  8.10640801e+91 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.99746447e+91 ... 1.11540437e+91\n",
      "  1.04367852e+92 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.00158051e+91 ... 1.11632304e+91\n",
      "  1.04453812e+92 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 4.38375625e+91 ... 9.78428342e+90\n",
      "  9.15510711e+91 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.10283756e+91 ... 1.13892302e+91\n",
      "  1.06568481e+92 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.90558262e+91 ... 1.09489689e+91\n",
      "  1.02448977e+92 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.20328814e+183 -2.43240581e+183 -1.77145247e+183 -2.34938223e+183\n",
      "  -1.53162014e+183 -1.78360536e+183 -2.22455470e+183 -1.96002645e+183\n",
      "  -1.58239739e+183 -1.65336048e+183]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.4278963118130052e+183\n",
      "Reg:\n",
      "[-7.75391825e+182 -1.00450950e+183 -3.43556155e+182 -9.21485916e+182\n",
      " -1.03723824e+182 -3.55709048e+182 -7.96658391e+182 -5.32130136e+182\n",
      " -1.54501081e+182 -2.25464169e+182]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 42\n",
      "Update pass epoch 42\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.59225184e+89 -1.75782847e+89 -1.28017684e+89 ... -1.41645373e+89\n",
      "  -1.14355227e+89 -1.19483522e+89]\n",
      " ...\n",
      " [-1.81249290e+89 -2.00097218e+89 -1.45725154e+89 ... -1.61237832e+89\n",
      "  -1.30172899e+89 -1.36010542e+89]\n",
      " [-2.17853991e+89 -2.40508404e+89 -1.75155479e+89 ... -1.93801063e+89\n",
      "  -1.56462326e+89 -1.63478926e+89]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.61893036e+91 -5.09924819e+91 -3.71363847e+91 ... -4.10896129e+91\n",
      "  -3.31730709e+91 -3.46607273e+91]\n",
      " ...\n",
      " [-1.04548892e+91 -1.15420824e+91 -8.40577271e+90 ... -9.30058081e+90\n",
      "  -7.50868176e+90 -7.84541086e+90]\n",
      " [-9.63478105e+91 -1.06366921e+92 -7.74640247e+91 ... -8.57101954e+91\n",
      "  -6.91968162e+91 -7.22999682e+91]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 43\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 3.04959465e+93 ... 3.43589450e+93\n",
      "  4.20045096e+93 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.92627219e+93 ... 4.42362300e+93\n",
      "  5.40796916e+93 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.92950597e+93 ... 4.42726641e+93\n",
      "  5.41242330e+93 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 3.44411059e+93 ... 3.88038477e+93\n",
      "  4.74384936e+93 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.00905887e+93 ... 4.51689647e+93\n",
      "  5.52199787e+93 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.85408496e+93 ... 4.34229163e+93\n",
      "  5.30853989e+93 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-5.01772582e+187 -5.53951399e+187 -4.03427161e+187 -5.35043768e+187\n",
      "  -3.48808210e+187 -4.06194838e+187 -5.06615789e+187 -4.46372635e+187\n",
      "  -3.60372124e+187 -3.76533121e+187]]\n",
      "Shape of inputs (100, 10)\n",
      "-3.2518634657320192e+187\n",
      "Reg:\n",
      "[-1.76586236e+187 -2.28765052e+187 -7.82408149e+186 -2.09857422e+187\n",
      " -2.36218631e+186 -8.10084912e+186 -1.81429442e+187 -1.21186289e+187\n",
      " -3.51857777e+186 -5.13467742e+186]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 43\n",
      "Update pass epoch 43\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-4.61893036e+91 -5.09924819e+91 -3.71363847e+91 ... -4.10896129e+91\n",
      "  -3.31730709e+91 -3.46607273e+91]\n",
      " ...\n",
      " [-1.04548892e+91 -1.15420824e+91 -8.40577271e+90 ... -9.30058081e+90\n",
      "  -7.50868176e+90 -7.84541086e+90]\n",
      " [-9.63478105e+91 -1.06366921e+92 -7.74640247e+91 ... -8.57101954e+91\n",
      "  -6.91968162e+91 -7.22999682e+91]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.66255552e+93 -4.04342092e+93 -2.94470928e+93 ... -3.25817834e+93\n",
      "  -2.63044048e+93 -2.74840338e+93]\n",
      " ...\n",
      " [-4.08491534e+93 -4.50970150e+93 -3.28428826e+93 ... -3.63390606e+93\n",
      "  -2.93377851e+93 -3.06534469e+93]\n",
      " [-5.07745865e+93 -5.60545837e+93 -4.08229704e+93 ... -4.51686417e+93\n",
      "  -3.64662124e+93 -3.81015507e+93]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 44\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 8.76440118e+95 ... 2.01126712e+95\n",
      "  1.82603490e+96 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.12839340e+96 ... 2.58945305e+95\n",
      "  2.35097149e+96 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.12932277e+96 ... 2.59158579e+95\n",
      "  2.35290781e+96 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 9.89822267e+95 ... 2.27145807e+95\n",
      "  2.06226298e+96 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.15218592e+96 ... 2.64405247e+95\n",
      "  2.40054245e+96 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.10764710e+96 ... 2.54184415e+95\n",
      "  2.30774725e+96 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.14265549e+192 -1.26147906e+192 -9.18699576e+191 -1.21842189e+192\n",
      "  -7.94319236e+191 -9.25002233e+191 -1.15368462e+192 -1.01649663e+192\n",
      "  -8.20653019e+191 -8.57455451e+191]]\n",
      "Shape of inputs (100, 10)\n",
      "-7.405266362909833e+191\n",
      "Reg:\n",
      "[-4.02128849e+191 -5.20952422e+191 -1.78172940e+191 -4.77895251e+191\n",
      " -5.37925993e+190 -1.84475597e+191 -4.13157982e+191 -2.75969996e+191\n",
      " -8.01263826e+190 -1.16928815e+191]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 44\n",
      "Update pass epoch 44\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-3.66255552e+93 -4.04342092e+93 -2.94470928e+93 ... -3.25817834e+93\n",
      "  -2.63044048e+93 -2.74840338e+93]\n",
      " ...\n",
      " [-4.08491534e+93 -4.50970150e+93 -3.28428826e+93 ... -3.63390606e+93\n",
      "  -2.93377851e+93 -3.06534469e+93]\n",
      " [-5.07745865e+93 -5.60545837e+93 -4.08229704e+93 ... -4.51686417e+93\n",
      "  -3.64662124e+93 -3.81015507e+93]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.04299033e+96 -1.15144983e+96 -8.38568397e+95 ... -9.27835360e+95\n",
      "  -7.49073696e+95 -7.82666131e+95]\n",
      " ...\n",
      " [-2.42591317e+95 -2.67818139e+95 -1.95044388e+95 ... -2.15807179e+95\n",
      "  -1.74228627e+95 -1.82041962e+95]\n",
      " [-2.17048359e+96 -2.39618995e+96 -1.74507748e+96 ... -1.93084380e+96\n",
      "  -1.55883723e+96 -1.62874375e+96]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 45\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 7.01314632e+97 ... 7.74425240e+97\n",
      "  9.78353687e+97 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.02923980e+97 ... 9.97051949e+97\n",
      "  1.25960441e+98 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.03667652e+97 ... 9.97873147e+97\n",
      "  1.26064186e+98 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 7.92041378e+97 ... 8.74610063e+97\n",
      "  1.10492006e+98 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.21962413e+97 ... 1.01807510e+98\n",
      "  1.28616356e+98 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.86323096e+97 ... 9.78720457e+97\n",
      "  1.23644571e+98 0.00000000e+00]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-2.60193997e+196 -2.87251304e+196 -2.09197013e+196 -2.77446759e+196\n",
      "  -1.80874375e+196 -2.10632191e+196 -2.62705440e+196 -2.31466374e+196\n",
      "  -1.86870839e+196 -1.95251118e+196]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.6862526624304138e+196\n",
      "Reg:\n",
      "[-9.15687308e+195 -1.18626038e+196 -4.05717472e+195 -1.08821493e+196\n",
      " -1.22491089e+195 -4.20069248e+195 -9.40801739e+195 -6.28411076e+195\n",
      " -1.82455727e+195 -2.66258518e+195]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 45\n",
      "Update pass epoch 45\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-1.04299033e+96 -1.15144983e+96 -8.38568397e+95 ... -9.27835360e+95\n",
      "  -7.49073696e+95 -7.82666131e+95]\n",
      " ...\n",
      " [-2.42591317e+95 -2.67818139e+95 -1.95044388e+95 ... -2.15807179e+95\n",
      "  -1.74228627e+95 -1.82041962e+95]\n",
      " [-2.17048359e+96 -2.39618995e+96 -1.74507748e+96 ... -1.93084380e+96\n",
      "  -1.55883723e+96 -1.62874375e+96]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-8.42084872e+97 -9.29652415e+97 -6.77039603e+97 ... -7.49111563e+97\n",
      "  -6.04783770e+97 -6.31905481e+97]\n",
      " ...\n",
      " [-9.20779203e+97 -1.01653009e+98 -7.40310159e+97 ... -8.19117373e+97\n",
      "  -6.61301891e+97 -6.90958173e+97]\n",
      " [-1.18188697e+98 -1.30479018e+98 -9.50241846e+97 ... -1.05139663e+98\n",
      "  -8.48828996e+97 -8.86894988e+97]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 46\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 0.00000000e+000 1.97919676e+100 ... 4.66458588e+099\n",
      "  4.11393677e+100 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.54816331e+100 ... 6.00553055e+099\n",
      "  5.29658443e+100 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.55026204e+100 ... 6.01047686e+099\n",
      "  5.30094684e+100 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 2.23523887e+100 ... 5.26802787e+099\n",
      "  4.64614311e+100 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.60189212e+100 ... 6.13215904e+099\n",
      "  5.40826456e+100 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.50131356e+100 ... 5.89511471e+099\n",
      "  5.19920305e+100 0.00000000e+000]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-5.92452617e+200 -6.54061157e+200 -4.76334272e+200 -6.31736551e+200\n",
      "  -4.11844616e+200 -4.79602121e+200 -5.98171085e+200 -5.27040825e+200\n",
      "  -4.25498354e+200 -4.44579956e+200]]\n",
      "Shape of inputs (100, 10)\n",
      "-3.83953824428219e+200\n",
      "Reg:\n",
      "[-2.08498792e+200 -2.70107333e+200 -9.23804472e+199 -2.47782727e+200\n",
      " -2.78907918e+199 -9.56482962e+199 -2.14217260e+200 -1.43087001e+200\n",
      " -4.15445300e+199 -6.06261319e+199]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 46\n",
      "Update pass epoch 46\n",
      "Old_weights\n",
      "[[-9.82181335e-01  7.74172872e-03 -6.39508772e-02 ...  1.63293916e-01\n",
      "  -6.20942925e-02 -1.61091839e-02]\n",
      " [-2.50069864e-01 -1.14706948e+01 -9.30479552e+00 ... -5.13515380e+00\n",
      "  -3.70388007e+00 -1.37794391e+00]\n",
      " [-8.42084872e+97 -9.29652415e+97 -6.77039603e+97 ... -7.49111563e+97\n",
      "  -6.04783770e+97 -6.31905481e+97]\n",
      " ...\n",
      " [-9.20779203e+97 -1.01653009e+98 -7.40310159e+97 ... -8.19117373e+97\n",
      "  -6.61301891e+97 -6.90958173e+97]\n",
      " [-1.18188697e+98 -1.30479018e+98 -9.50241846e+97 ... -1.05139663e+98\n",
      "  -8.48828996e+97 -8.86894988e+97]\n",
      " [-1.78691713e+01 -2.22517950e+01 -1.75301817e+01 ... -2.74210294e+01\n",
      "  -1.53347740e+01 -1.77000614e+01]]\n",
      "New_weights\n",
      "[[-9.82181335e-001  7.74172872e-003 -6.39508772e-002 ...  1.63293916e-001\n",
      "  -6.20942925e-002 -1.61091839e-002]\n",
      " [-2.50069864e-001 -1.14706948e+001 -9.30479552e+000 ... -5.13515380e+000\n",
      "  -3.70388007e+000 -1.37794391e+000]\n",
      " [-2.35545418e+100 -2.60039545e+100 -1.89379457e+100 ... -2.09539207e+100\n",
      "  -1.69168276e+100 -1.76754678e+100]\n",
      " ...\n",
      " [-5.62358382e+099 -6.20837454e+099 -4.52138387e+099 ... -5.00269249e+099\n",
      "  -4.03884732e+099 -4.21997064e+099]\n",
      " [-4.89033673e+100 -5.39887783e+100 -3.93185027e+100 ... -4.35040209e+100\n",
      "  -3.51223063e+100 -3.66973768e+100]\n",
      " [-1.78691713e+001 -2.22517950e+001 -1.75301817e+001 ... -2.74210294e+001\n",
      "  -1.53347740e+001 -1.77000614e+001]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 47\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 0.00000000e+000 1.61208475e+102 ... 1.74575996e+102\n",
      "  2.27596171e+102 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.07551634e+102 ... 2.24761963e+102\n",
      "  2.93024032e+102 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.07722579e+102 ... 2.24947083e+102\n",
      "  2.93265374e+102 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 1.82063480e+102 ... 1.97160314e+102\n",
      "  2.57039533e+102 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.11927925e+102 ... 2.29501139e+102\n",
      "  2.99202535e+102 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 2.03735653e+102 ... 2.20629559e+102\n",
      "  2.87636582e+102 0.00000000e+000]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-1.34891670e+205 -1.48918917e+205 -1.08453442e+205 -1.43835973e+205\n",
      "  -9.37702133e+204 -1.09197477e+205 -1.36193671e+205 -1.19998486e+205\n",
      "  -9.68789438e+204 -1.01223509e+205]]\n",
      "Shape of inputs (100, 10)\n",
      "-8.741994088677557e+204\n",
      "Reg:\n",
      "[-4.74717295e+204 -6.14989761e+204 -2.10335012e+204 -5.64160322e+204\n",
      " -6.35027239e+203 -2.17775364e+204 -4.87737302e+204 -3.25785455e+204\n",
      " -9.45900294e+203 -1.38035684e+204]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 47\n",
      "Update pass epoch 47\n",
      "Old_weights\n",
      "[[-9.82181335e-001  7.74172872e-003 -6.39508772e-002 ...  1.63293916e-001\n",
      "  -6.20942925e-002 -1.61091839e-002]\n",
      " [-2.50069864e-001 -1.14706948e+001 -9.30479552e+000 ... -5.13515380e+000\n",
      "  -3.70388007e+000 -1.37794391e+000]\n",
      " [-2.35545418e+100 -2.60039545e+100 -1.89379457e+100 ... -2.09539207e+100\n",
      "  -1.69168276e+100 -1.76754678e+100]\n",
      " ...\n",
      " [-5.62358382e+099 -6.20837454e+099 -4.52138387e+099 ... -5.00269249e+099\n",
      "  -4.03884732e+099 -4.21997064e+099]\n",
      " [-4.89033673e+100 -5.39887783e+100 -3.93185027e+100 ... -4.35040209e+100\n",
      "  -3.51223063e+100 -3.66973768e+100]\n",
      " [-1.78691713e+001 -2.22517950e+001 -1.75301817e+001 ... -2.74210294e+001\n",
      "  -1.53347740e+001 -1.77000614e+001]]\n",
      "New_weights\n",
      "[[-9.82181335e-001  7.74172872e-003 -6.39508772e-002 ...  1.63293916e-001\n",
      "  -6.20942925e-002 -1.61091839e-002]\n",
      " [-2.50069864e-001 -1.14706948e+001 -9.30479552e+000 ... -5.13515380e+000\n",
      "  -3.70388007e+000 -1.37794391e+000]\n",
      " [-1.93524757e+102 -2.13649198e+102 -1.55594678e+102 ... -1.72157983e+102\n",
      "  -1.38989116e+102 -1.45222125e+102]\n",
      " ...\n",
      " [-2.07583556e+102 -2.29169957e+102 -1.66898009e+102 ... -1.84664571e+102\n",
      "  -1.49086119e+102 -1.55771931e+102]\n",
      " [-2.74785585e+102 -3.03360257e+102 -2.20928709e+102 ... -2.44446927e+102\n",
      "  -1.97350490e+102 -2.06200732e+102]\n",
      " [-1.78691713e+001 -2.22517950e+001 -1.75301817e+001 ... -2.74210294e+001\n",
      "  -1.53347740e+001 -1.77000614e+001]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 48\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 0.00000000e+000 4.47003376e+104 ... 1.08081739e+104\n",
      "  9.26986538e+104 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 5.75504987e+104 ... 1.39152371e+104\n",
      "  1.19347057e+105 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 5.75978988e+104 ... 1.39266981e+104\n",
      "  1.19445355e+105 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 5.04830720e+104 ... 1.22063915e+104\n",
      "  1.04690771e+105 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 5.87639689e+104 ... 1.42086442e+104\n",
      "  1.21863527e+105 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 5.64923928e+104 ... 1.36593958e+104\n",
      "  1.17152779e+105 0.00000000e+000]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-3.07109007e+209 -3.39044958e+209 -2.46916869e+209 -3.27472577e+209\n",
      "  -2.13487438e+209 -2.48610821e+209 -3.10073283e+209 -2.73201569e+209\n",
      "  -2.20565111e+209 -2.30456420e+209]]\n",
      "Shape of inputs (100, 10)\n",
      "-1.9902971906826333e+209\n",
      "Reg:\n",
      "[-1.08079288e+209 -1.40015239e+209 -4.78871502e+208 -1.28442858e+209\n",
      " -1.44577189e+208 -4.95811014e+208 -1.11043564e+209 -7.41718503e+208\n",
      " -2.15353920e+208 -3.14267009e+208]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n",
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 48\n",
      "Update pass epoch 48\n",
      "Old_weights\n",
      "[[-9.82181335e-001  7.74172872e-003 -6.39508772e-002 ...  1.63293916e-001\n",
      "  -6.20942925e-002 -1.61091839e-002]\n",
      " [-2.50069864e-001 -1.14706948e+001 -9.30479552e+000 ... -5.13515380e+000\n",
      "  -3.70388007e+000 -1.37794391e+000]\n",
      " [-1.93524757e+102 -2.13649198e+102 -1.55594678e+102 ... -1.72157983e+102\n",
      "  -1.38989116e+102 -1.45222125e+102]\n",
      " ...\n",
      " [-2.07583556e+102 -2.29169957e+102 -1.66898009e+102 ... -1.84664571e+102\n",
      "  -1.49086119e+102 -1.55771931e+102]\n",
      " [-2.74785585e+102 -3.03360257e+102 -2.20928709e+102 ... -2.44446927e+102\n",
      "  -1.97350490e+102 -2.06200732e+102]\n",
      " [-1.78691713e+001 -2.22517950e+001 -1.75301817e+001 ... -2.74210294e+001\n",
      "  -1.53347740e+001 -1.77000614e+001]]\n",
      "New_weights\n",
      "[[-9.82181335e-001  7.74172872e-003 -6.39508772e-002 ...  1.63293916e-001\n",
      "  -6.20942925e-002 -1.61091839e-002]\n",
      " [-2.50069864e-001 -1.14706948e+001 -9.30479552e+000 ... -5.13515380e+000\n",
      "  -3.70388007e+000 -1.37794391e+000]\n",
      " [-5.32014847e+104 -5.87338526e+104 -4.27742063e+104 ... -4.73275898e+104\n",
      "  -3.82092062e+104 -3.99227096e+104]\n",
      " ...\n",
      " [-1.30244722e+104 -1.43788737e+104 -1.04717277e+104 ... -1.15864600e+104\n",
      "  -9.35415141e+103 -9.77364115e+103]\n",
      " [-1.10201618e+105 -1.21661371e+105 -8.86025413e+104 ... -9.80344252e+104\n",
      "  -7.91465947e+104 -8.26959476e+104]\n",
      " [-1.78691713e+001 -2.22517950e+001 -1.75301817e+001 ... -2.74210294e+001\n",
      "  -1.53347740e+001 -1.77000614e+001]]\n",
      "End of Backwards pass\n",
      "(100, 64)\n",
      "Forward pass epoch 49\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 0.00000000e+000 3.70404732e+106 ... 3.93599207e+106\n",
      "  5.28860133e+106 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 4.76886265e+106 ... 5.06748535e+106\n",
      "  6.80893389e+106 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 4.77279041e+106 ... 5.07165906e+106\n",
      "  6.81454190e+106 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 4.18322763e+106 ... 4.44517830e+106\n",
      "  5.97277013e+106 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 4.86941560e+106 ... 5.17433486e+106\n",
      "  6.95250238e+106 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 4.68118380e+106 ... 4.97431612e+106\n",
      "  6.68374691e+106 0.00000000e+000]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[[-6.99160060e+213 -7.71864998e+213 -5.62127482e+213 -7.45519477e+213\n",
      "  -4.86022508e+213 -5.65983908e+213 -7.05908489e+213 -6.21966862e+213\n",
      "  -5.02135439e+213 -5.24653854e+213]]\n",
      "Shape of inputs (100, 10)\n",
      "-4.531082677142372e+213\n",
      "Reg:\n",
      "[-2.46051792e+213 -3.18756730e+213 -1.09019215e+213 -2.92411209e+213\n",
      " -3.29142401e+212 -1.12875640e+213 -2.52800221e+213 -1.68858594e+213\n",
      " -4.90271715e+212 -7.15455866e+212]\n",
      "Exp:\n",
      "[1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      "Max exp\n",
      "0.999999\n",
      "[1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04 9.99999e-01 1.00000e-04\n",
      " 1.00000e-04 1.00000e-04 1.00000e-04 1.00000e-04]\n",
      "Max sum\n",
      "0.999999\n",
      "[1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000001e-06\n",
      " 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02 1.000000e-02]\n",
      "Sums to 1: \n",
      "0.09000100000100017\n",
      "At least one output is close to 1: \n",
      "1.0\n",
      "Model output shape: (100, 10)\n",
      "Model target shape: (100, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Loss: 5274.097512320904\n",
      "()\n",
      "Backward pass epoch 49\n",
      "Update pass epoch 49\n",
      "Old_weights\n",
      "[[-9.82181335e-001  7.74172872e-003 -6.39508772e-002 ...  1.63293916e-001\n",
      "  -6.20942925e-002 -1.61091839e-002]\n",
      " [-2.50069864e-001 -1.14706948e+001 -9.30479552e+000 ... -5.13515380e+000\n",
      "  -3.70388007e+000 -1.37794391e+000]\n",
      " [-5.32014847e+104 -5.87338526e+104 -4.27742063e+104 ... -4.73275898e+104\n",
      "  -3.82092062e+104 -3.99227096e+104]\n",
      " ...\n",
      " [-1.30244722e+104 -1.43788737e+104 -1.04717277e+104 ... -1.15864600e+104\n",
      "  -9.35415141e+103 -9.77364115e+103]\n",
      " [-1.10201618e+105 -1.21661371e+105 -8.86025413e+104 ... -9.80344252e+104\n",
      "  -7.91465947e+104 -8.26959476e+104]\n",
      " [-1.78691713e+001 -2.22517950e+001 -1.75301817e+001 ... -2.74210294e+001\n",
      "  -1.53347740e+001 -1.77000614e+001]]\n",
      "New_weights\n",
      "[[-9.82181335e-001  7.74172872e-003 -6.39508772e-002 ...  1.63293916e-001\n",
      "  -6.20942925e-002 -1.61091839e-002]\n",
      " [-2.50069864e-001 -1.14706948e+001 -9.30479552e+000 ... -5.13515380e+000\n",
      "  -3.70388007e+000 -1.37794391e+000]\n",
      " [-4.44565135e+106 -4.90795008e+106 -3.57432145e+106 ... -3.95481376e+106\n",
      "  -3.19285844e+106 -3.33604313e+106]\n",
      " ...\n",
      " [-4.68052635e+106 -5.16724949e+106 -3.76316189e+106 ... -4.16375656e+106\n",
      "  -3.36154522e+106 -3.51229472e+106]\n",
      " [-6.38169714e+106 -7.04532329e+106 -5.13091001e+106 ... -5.67710368e+106\n",
      "  -4.58332288e+106 -4.78886337e+106]\n",
      " [-1.78691713e+001 -2.22517950e+001 -1.75301817e+001 ... -2.74210294e+001\n",
      "  -1.53347740e+001 -1.77000614e+001]]\n",
      "End of Backwards pass\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.1, dropout_rate = 0, batch_size = 1, epochs = 50)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 128, 'relu', 'hidden')\n",
    "model.addLayer(128, 10, 'softmax', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e - Implement optimizer\n",
    "Implement any two optimizers of your choice. Briefly present the optimizers \n",
    "in the report. The optimizers can be flavours of gradient descent. For \n",
    "instance: Stochastic gradient descent (SGD) and SGD with momentum. \n",
    "SGD and mini-batch gradient descent, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f - Evaluate different neural network architectures/parameters, present and discuss your results.\n",
    "Be creative in the analysis and discussion. Evaluate different\n",
    "hyperparameters. For instance: different network architectures, activation \n",
    "functions, comparison of optimizers, L1/L2 performance comparison with \n",
    "dropout, etc. Support your results with plots/graph and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
