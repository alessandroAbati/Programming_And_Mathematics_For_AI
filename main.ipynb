{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Mathematics for AI - coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The task is about classification on the MNIST dataset. \n",
    "You can use other APIâ€™s/libraries for loading the dataset, but not for the neural network \n",
    "implementation. The point of this task is to develop a multi-layer neural network for \n",
    "classification using numpy. The task requires following sub-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Implement sigmoid and ReLU layers\n",
    "For this sub-task, you should implement forward and backward pass for \n",
    "sigmoid and ReLU. You should consider presenting these activation\n",
    "functions in the report with any pros cons if they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLu(x):\n",
    "    '''\n",
    "    Implementation of reLu function.\n",
    "    '''\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Implementation of Sigmoid function.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Implementation of Softmax function\n",
    "    '''\n",
    "    normalization = np.sum(np.exp(x))\n",
    "    return [np.exp(el)/normalization for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ReLU activation function')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, reLu(x))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.title(\"ReLU activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2657c1750>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2659e4710>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, softmax(x))\n",
    "# How do I test my implementation of the softmax function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.input = x # store the input to use it in the backward pass\n",
    "        return np.maximum(0, x)  # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return np.where(self.input > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "* Advatages:\n",
    "    - No saturation of neurons (at least for positive values)\n",
    "    - Converge fast\n",
    "    - Computationally efficent (very simple to calculate, both the reLu and its derivative)\n",
    "\n",
    "* Disadvantages:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('gradient_values'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        \n",
    "        sigmoid_derivative = np.multiply(self.output, (1 - self.output)) # calculate the derivative of Sigmoid: f(x) * (1 - f(x)) where f(x) is the Sigmoid function\n",
    "        return sigmoid_derivative  # multiply the gradient of the loss function by the derivative of Sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note - __Sigmoid Problem__:\n",
    "\n",
    "Vanishing gradient and saturation of neurons:\n",
    "the sigmoid function usually have the output very close to zero or one and in this region the derivative of the sigmoid is very small, meaning that the (local) gradient will be small and the network will now learn efficently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - Implement softmax layer\n",
    "Implement softmax with both forward and backward pass. Present the \n",
    "softmax in the report along with any numerical issues when calculating the \n",
    "softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'x', with the\n",
    "                         same shape as 'x'.\n",
    "        '''        \n",
    "        x = np.asarray(x)\n",
    "#         print (\"Shape of inputs {}\".format(x.shape))\n",
    "#         print(np.max(x))\n",
    "        reg = x - np.max(x)\n",
    "#         print(\"Reg:\")\n",
    "#         print(reg[0])\n",
    "#         e_x = np.exp(reg)\n",
    "        e_x = np.clip(np.exp(reg), 0.000001, 1-0.000001)\n",
    "\n",
    "#         print(\"Exp:\")\n",
    "#         print(e_x[0])\n",
    "#         print(\"Max exp\")\n",
    "#         print(np.max(e_x))\n",
    "        exp_sum = np.sum(e_x, axis=-1, keepdims = True)\n",
    "#         exp_sum = np.clip(exp_sum, 0.000001, 1-0.000001)\n",
    "#         print(exp_sum[0])\n",
    "#         print(\"Max sum\")\n",
    "#         print(np.max(exp_sum))\n",
    "        \n",
    "        return e_x / exp_sum\n",
    "#         e_x = np.exp(x - np.max(x, axis=-1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "#         self.output = e_x / np.sum(e_x) # apply the softmax function: f(xi) = exp(xi) / sum(exp(x)) for x=[x1,...,xK]\n",
    "#         return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        # Gradient values not used -> Remove!!\n",
    "        softmax_jacobian = self.output * (np.eye(self.output.shape[0]) - self.output.T)\n",
    "        #print(softmax_jacobian)\n",
    "        print(softmax_jacobian.shape)\n",
    "        return softmax_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    weights = 0\n",
    "    new_weights = 0\n",
    "    bias = 0\n",
    "    activation = 0\n",
    "    layer_input = 0\n",
    "    softmax = False\n",
    "    \n",
    "    def __init__(self, output_units, input_units, activation):\n",
    "        # Weight initialisation crucial for performance\n",
    "        #self.weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        #self.new_weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        self.weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.new_weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.layer_input = 0\n",
    "        self.bias = 0\n",
    "        self.softmax = False\n",
    "        '''\n",
    "        Set activation function for the layer\n",
    "        '''   \n",
    "        if activation == 'relu':\n",
    "            print(\"ReLU\")\n",
    "            self.activation = ReLu()\n",
    "        elif activation == 'sigmoid':\n",
    "            print(\"Sigmoid\")\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'softmax':\n",
    "            print(\"Softmax\")\n",
    "            self.softmax = True\n",
    "            self.activation = Softmax()\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Weights combined with input and bias\n",
    "        '''\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        '''\n",
    "        Pass z through activation function\n",
    "        '''\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        print(\"Output of hidden layer\")\n",
    "        print(output)\n",
    "        return output\n",
    "        \n",
    "    '''\n",
    "    Idea is to have backward pass for activation functions just return the derivative of the activation,\n",
    "    and backward_pass for layer perform any other calculation (dot product of activation function with loss for example)\n",
    "    '''   \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            derivative_final = np.multiply(x, activation_derivative)\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = (self.weights - (learning_rate*np.dot(self.layer_input.T, derivative_final)))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "#         print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        self.weights = self.new_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass of layer\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation):\n",
    "        super().__init__(output_units, input_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        return x\n",
    "    \n",
    "    # No weights in input layer\n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print(\"Last backwards pass layer\")\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"End of Backwards pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation):\n",
    "        super().__init__(output_units, input_units, activation)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        print(\"Weights and biases\")\n",
    "        print(z[0])\n",
    "        output = self.activation.forward_pass(z)\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output\n",
    "    \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            activation_derivative = self.activation.backward_pass(x)\n",
    "            derivative_final = np.multiply(x, activation_derivative)\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = (self.weights - (learning_rate*np.dot(self.layer_input.T, derivative_final)))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "        print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def mse_loss(self, output, target):\n",
    "        loss = 1/len(output)*np.sum((output-target)**2)\n",
    "        return loss\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"Old_weights\")\n",
    "        print(self.weights[:10])\n",
    "        print(\"New_weights\")\n",
    "        print(self.new_weights[:10])\n",
    "        self.weights = self.new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY\n",
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "prediction = softmax.forward_pass(x)\n",
    "loss = np.sum((prediction - y) ** 2)\n",
    "loss_derivative = (prediction -y)\n",
    "prediction, loss, np.sum(prediction)\n",
    "loss_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_derivative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient_softmax = softmax.backward_pass(loss_derivative.T, learning_rate)\n",
    "#gradient_softmax.shape, gradient_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - Implement dropout \n",
    "Present dropout in the report. Implement inverted dropout. Forward and \n",
    "backward pass should be implemented.\n",
    "Note: Since the test performance is critical, it is also preferable to leaving \n",
    "the forward pass unchanged at test time. Therefore, in most \n",
    "implementations inverted dropout is employed to overcome the \n",
    "undesirable property of the original dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of \n",
    "hidden layers, units, activation functions can be changed. In addition, you \n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used \n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots \n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "    A class representing the Fully Parametrizable Neural Network.\n",
    "    '''\n",
    "    layer_list = []\n",
    "    X = 0\n",
    "    Y = 0\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 8\n",
    "    epochs = 100   \n",
    "    loss_history = []\n",
    "    \n",
    "    def __init__(self, X, Y, learning_rate, dropout_rate = 0.5, batch_size = 4, epochs = 10):\n",
    "        self.layer_list = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def addLayer(self, input_units, output_units, activation, mode = \"input\"):\n",
    "        if mode == \"input\":\n",
    "            print(\"Added input\")\n",
    "            layer = InputLayer(input_units, output_units, activation)\n",
    "        elif mode == \"output\":\n",
    "            print(\"Added output\")\n",
    "            layer = OutputLayer(input_units, output_units, activation)\n",
    "        else:\n",
    "            print(\"Added hidden\")\n",
    "            layer = Layer(input_units, output_units, activation)\n",
    "        self.layer_list.append(layer)\n",
    "        \n",
    "    def loss(self, output, target, mode):\n",
    "        if mode == \"mse\":\n",
    "            loss = 1/len(output)*np.sum((np.sum(output-target))**2)\n",
    "            return loss\n",
    "        elif mode == \"cross_entropy\":\n",
    "            #output = np.clip(output, 0.000001, 1-0.000001)\n",
    "            loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n",
    "            #loss = -np.sum(target * np.log(output))\n",
    "            print(\"Cross Loss: {}\".format(loss))\n",
    "            print(loss.shape)\n",
    "            return loss\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            input_data = self.X\n",
    "            print(input_data.shape)\n",
    "            # Forward pass\n",
    "            print(\"Forward pass epoch {}\".format(i))\n",
    "            for index, layer in enumerate(self.layer_list):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                output_data = layer.forward_pass(input_data)\n",
    "                input_data = output_data\n",
    "                \n",
    "            # Calculate loss \n",
    "            #output_data = np.around(output_data, 6)\n",
    "            print(\"Output layer\")\n",
    "            print(output_data[:10])\n",
    "            print(\"Sums to 1: \")\n",
    "            print(np.sum(output_data[0]))\n",
    "            print(\"At least one output is closer to 1: \")\n",
    "            print(np.max(output_data))\n",
    "            # For softmax, not exactly 0 nor 1\n",
    "            print(\"Model output shape: {}\".format (output_data.shape))\n",
    "            print(\"Model target shape: {}\".format (self.Y.shape))\n",
    "            loss_cost = self.loss(output_data, self.Y, mode = \"cross_entropy\")\n",
    "#             loss_cost = np.around(loss_cost, 6)\n",
    "            self.loss_history.append(loss_cost)\n",
    "            #print(\"Loss: {}\".format(loss_cost))\n",
    "            \n",
    "            # Backward pass  \n",
    "            # MSE derivative\n",
    "#             input_derivative = (self.Y - output_data)\n",
    "            input_derivative = np.asarray(output_data - self.Y)\n",
    "            print(\"Backward pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                output_derivative = layer.backward_pass(input_derivative, self.learning_rate)\n",
    "                input_derivative = output_derivative\n",
    "                \n",
    "            # Update pass. Supposedly update weights after backward pass completed\n",
    "            # Weights barely updating??\n",
    "            print(\"Update pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                layer.update_weights(self.learning_rate)\n",
    "                                         \n",
    "    def predict(self, X):\n",
    "        input_data = X\n",
    "        for index, layer in enumerate(self.layer_list):\n",
    "            output_data = layer.forward_pass(input_data)\n",
    "            input_data = output_data\n",
    "        return output_data\n",
    "    \n",
    "    def show_loss(self):\n",
    "        plt.plot(self.loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY DATASET\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "dataset = load_digits()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Softmax\n",
      "(1797, 64)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00849362 0.27371169 0.         ... 0.         0.04276783 0.03351257]\n",
      " [0.         0.20979818 0.         ... 0.         0.03487145 0.        ]\n",
      " [0.0614601  0.20364379 0.         ... 0.         0.04432701 0.        ]\n",
      " ...\n",
      " [0.         0.28002499 0.         ... 0.         0.06838309 0.        ]\n",
      " [0.         0.21942404 0.         ... 0.         0.04254627 0.        ]\n",
      " [0.00509786 0.19083857 0.         ... 0.         0.06992196 0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[5.68096004e-04 0.00000000e+00 7.25233837e-04 ... 0.00000000e+00\n",
      "  7.94142098e-04 0.00000000e+00]\n",
      " [4.35413289e-04 1.96074364e-04 0.00000000e+00 ... 0.00000000e+00\n",
      "  8.04095501e-04 3.37515216e-05]\n",
      " [3.52494411e-04 5.03774278e-04 3.65411107e-04 ... 0.00000000e+00\n",
      "  4.31784893e-04 0.00000000e+00]\n",
      " ...\n",
      " [6.16586389e-04 5.93120150e-04 1.68072489e-04 ... 0.00000000e+00\n",
      "  1.02573650e-03 2.12782143e-04]\n",
      " [6.39145052e-04 3.20737958e-04 5.47876736e-04 ... 0.00000000e+00\n",
      "  1.22936807e-03 1.03556006e-04]\n",
      " [7.09478719e-04 8.11921909e-04 3.90564237e-04 ... 0.00000000e+00\n",
      "  1.00739054e-03 1.95406747e-04]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[-7.84166185e-07 -1.25136937e-08  4.64471527e-06 -1.14143162e-06\n",
      " -1.03177769e-06  2.39875578e-06  1.14952292e-05 -3.81473682e-06\n",
      "  2.43135972e-06  7.98952895e-07]\n",
      "Output layer\n",
      "[[0.09999977 0.09999985 0.10000031 0.09999974 0.09999975 0.10000009\n",
      "  0.100001   0.09999947 0.10000009 0.09999993]\n",
      " [0.09999984 0.09999978 0.10000055 0.09999958 0.09999988 0.09999975\n",
      "  0.10000121 0.09999984 0.09999982 0.09999974]\n",
      " [0.09999981 0.09999984 0.10000027 0.09999938 0.09999944 0.09999983\n",
      "  0.10000168 0.10000015 0.09999989 0.09999971]\n",
      " [0.09999982 0.09999994 0.10000013 0.0999997  0.09999949 0.10000019\n",
      "  0.1000008  0.09999972 0.10000005 0.10000017]\n",
      " [0.09999973 0.09999984 0.10000066 0.09999977 0.09999955 0.09999974\n",
      "  0.10000126 0.09999974 0.10000007 0.09999964]\n",
      " [0.09999962 0.09999996 0.1000004  0.09999976 0.09999959 0.09999984\n",
      "  0.1000009  0.09999961 0.10000038 0.09999995]\n",
      " [0.09999995 0.09999959 0.10000043 0.10000009 0.09999949 0.09999983\n",
      "  0.10000148 0.09999962 0.09999991 0.09999961]\n",
      " [0.10000007 0.10000003 0.10000013 0.09999954 0.09999965 0.09999996\n",
      "  0.10000076 0.09999992 0.09999983 0.10000012]\n",
      " [0.09999975 0.0999997  0.10000039 0.09999945 0.09999944 0.09999995\n",
      "  0.10000146 0.0999998  0.10000009 0.09999997]\n",
      " [0.09999978 0.09999959 0.10000024 0.09999969 0.09999958 0.09999999\n",
      "  0.10000127 0.09999962 0.10000011 0.10000014]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.1000019108580528\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.30258503143858\n",
      "()\n",
      "Backward pass epoch 0\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[-1.89074279e-04  6.03919864e-04 -3.31182639e-04 -1.11580974e-03\n",
      "  -5.33975569e-04  8.97241745e-04  2.64026402e-03 -5.30710217e-05\n",
      "  -2.01371556e-03  3.25273362e-04]\n",
      " [-4.59354431e-04 -1.08296566e-04 -1.11563347e-03  1.11289429e-03\n",
      "  -1.17704093e-03 -3.20036867e-04  6.71906405e-04  6.02271521e-04\n",
      "  -2.27172162e-03 -1.66688748e-03]\n",
      " [ 1.31868419e-03  9.81616302e-04  1.81703598e-03 -1.17381018e-03\n",
      "   1.50324009e-03  1.85468628e-03  1.09165142e-03  7.80055546e-04\n",
      "   7.71831870e-04  1.17739394e-03]\n",
      " [-7.36917988e-04  5.40849288e-05  2.11923143e-03 -6.19229278e-04\n",
      "  -2.14954599e-03 -1.49286991e-04  3.26627166e-04  5.22347944e-04\n",
      "  -1.45519886e-03  1.89944061e-03]\n",
      " [ 8.92666644e-04  1.47447039e-03 -1.25027210e-03  2.66376357e-05\n",
      "   2.27710582e-03  8.63141232e-04  3.21833606e-04 -7.41029322e-04\n",
      "   7.71473755e-04  6.52955644e-04]\n",
      " [ 1.13812949e-04  1.03489638e-03  1.44075540e-03 -1.23674963e-03\n",
      "  -1.71292508e-04 -1.51352782e-03 -1.99688544e-03 -8.66828581e-04\n",
      "   2.69219721e-03  3.95973093e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.79910894e-03  2.49341015e-03  8.47898474e-04 -5.80065787e-04\n",
      "   1.13566976e-03  2.56395996e-04 -1.23510370e-03 -1.43351383e-03\n",
      "   1.83682153e-04  1.06984421e-03]\n",
      " [ 4.05506489e-04 -8.02976808e-05  3.61308569e-04  1.04644937e-03\n",
      "  -5.24708071e-04  5.91994668e-05 -1.53169254e-03  2.72225268e-04\n",
      "   6.01736195e-04  8.90882621e-04]\n",
      " [-7.99949613e-04 -8.97718936e-04  1.68368727e-03  1.03762774e-03\n",
      "  -2.20057000e-03 -2.80140343e-03  1.91020285e-03 -3.74530005e-04\n",
      "   5.47704649e-04 -9.11414879e-04]]\n",
      "New_weights\n",
      "[[-4.15297786e-05  5.42763274e-04 -2.16961333e-04 -5.91111255e-04\n",
      "  -8.81053833e-04  8.19811368e-04  2.46890274e-03 -4.40852680e-04\n",
      "  -1.91079628e-03  4.80697963e-04]\n",
      " [-7.15323478e-04  5.88220945e-06 -7.51310803e-04  1.21773079e-03\n",
      "  -1.51704515e-03 -2.40879111e-04  1.03925654e-03  1.85976774e-04\n",
      "  -2.23687796e-03 -1.71930898e-03]\n",
      " [ 2.25029361e-03  7.26863745e-04  1.75356521e-03 -1.22370591e-03\n",
      "   1.20787150e-03  1.55136614e-03  8.58882755e-04  5.58886965e-04\n",
      "   7.52318657e-04  1.68604276e-03]\n",
      " [-7.62908661e-04  1.36827622e-04  2.09798282e-03 -6.57909424e-04\n",
      "  -2.16019624e-03 -1.86732354e-04  4.60231448e-04  4.83667851e-04\n",
      "  -1.47028102e-03  1.87087093e-03]\n",
      " [ 1.00552118e-03  1.38536789e-03 -5.94108043e-04  3.48994116e-04\n",
      "   2.22998514e-03  6.26303392e-04  8.02254436e-04 -1.20095134e-03\n",
      "   4.13053046e-04  2.72563484e-04]\n",
      " [ 1.18942080e-04  1.03341272e-03  1.43920717e-03 -1.23743355e-03\n",
      "  -1.66900529e-04 -1.51507604e-03 -1.99754924e-03 -8.68376798e-04\n",
      "   2.69064899e-03  3.95476265e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-9.29046825e-04  2.53008067e-03  1.56193678e-05 -6.33040719e-04\n",
      "   1.10520876e-03  1.00731007e-04 -1.79806995e-03 -1.34247921e-03\n",
      "   3.04171200e-04  1.58593419e-03]\n",
      " [ 4.03496130e-04 -8.17205437e-05  3.59298201e-04  1.04443901e-03\n",
      "  -5.20051339e-04  5.71891089e-05 -1.53210793e-03  2.70527067e-04\n",
      "   6.10131851e-04  8.89408125e-04]\n",
      " [-6.20879182e-04 -4.79881676e-04  1.30034705e-03  9.74617654e-04\n",
      "  -2.07435503e-03 -3.04642767e-03  1.64062254e-03 -9.99497798e-04\n",
      "   6.85344568e-04 -1.86254802e-04]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00915433 0.26941166 0.         ... 0.         0.05686706 0.        ]\n",
      " [0.         0.25302066 0.         ... 0.         0.04090263 0.        ]\n",
      " [0.05761731 0.2322927  0.         ... 0.         0.05990989 0.        ]\n",
      " ...\n",
      " [0.         0.31071571 0.         ... 0.         0.08676891 0.        ]\n",
      " [0.         0.2361896  0.         ... 0.         0.04960081 0.        ]\n",
      " [0.00542341 0.21147873 0.         ... 0.         0.08713258 0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[9.09311713e-04 0.00000000e+00 6.62400210e-04 ... 0.00000000e+00\n",
      "  1.23601619e-03 0.00000000e+00]\n",
      " [7.94139881e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  7.25447833e-04 0.00000000e+00]\n",
      " [1.00868079e-03 1.23185896e-04 1.80829944e-05 ... 0.00000000e+00\n",
      "  6.51115952e-04 0.00000000e+00]\n",
      " ...\n",
      " [1.32063454e-03 9.60288964e-05 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.17017810e-03 0.00000000e+00]\n",
      " [1.07731891e-03 0.00000000e+00 2.39184324e-04 ... 0.00000000e+00\n",
      "  1.44185877e-03 0.00000000e+00]\n",
      " [1.41855453e-03 3.69094073e-04 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.18134657e-03 0.00000000e+00]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 9.74592342e-06 -5.77953733e-06  1.03281146e-05 -2.72511889e-06\n",
      " -9.77897462e-06  9.57051709e-06  2.05446505e-05 -1.05240844e-05\n",
      "  2.60091003e-06  9.80263456e-06]\n",
      "Output layer\n",
      "[[0.10000064 0.09999908 0.10000069 0.09999939 0.09999868 0.10000062\n",
      "  0.10000172 0.09999861 0.09999992 0.10000064]\n",
      " [0.09999967 0.10000034 0.10000087 0.0999994  0.09999902 0.1000004\n",
      "  0.1000015  0.09999875 0.09999992 0.10000013]\n",
      " [0.09999983 0.10000006 0.10000102 0.09999915 0.0999983  0.10000016\n",
      "  0.10000253 0.09999866 0.10000017 0.10000012]\n",
      " [0.09999975 0.09999974 0.10000071 0.10000008 0.0999983  0.10000084\n",
      "  0.10000129 0.09999882 0.09999999 0.1000005 ]\n",
      " [0.1000001  0.0999999  0.10000051 0.09999903 0.09999984 0.09999977\n",
      "  0.10000171 0.09999901 0.10000018 0.09999994]\n",
      " [0.09999983 0.09999988 0.10000071 0.09999992 0.09999831 0.1000005\n",
      "  0.1000009  0.09999882 0.10000038 0.10000076]\n",
      " [0.10000026 0.09999941 0.10000062 0.09999926 0.09999861 0.10000041\n",
      "  0.10000365 0.09999779 0.10000001 0.1       ]\n",
      " [0.09999978 0.10000036 0.10000077 0.09999956 0.09999872 0.10000056\n",
      "  0.1000006  0.09999988 0.09999971 0.10000007]\n",
      " [0.10000016 0.09999932 0.10000105 0.09999944 0.09999794 0.10000055\n",
      "  0.10000207 0.09999878 0.10000014 0.10000056]\n",
      " [0.09999998 0.09999945 0.10000051 0.09999958 0.09999826 0.10000074\n",
      "  0.10000155 0.09999912 0.10000002 0.10000079]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.10000436879595553\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.3025786101844443\n",
      "()\n",
      "Backward pass epoch 1\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[-4.15297786e-05  5.42763274e-04 -2.16961333e-04 -5.91111255e-04\n",
      "  -8.81053833e-04  8.19811368e-04  2.46890274e-03 -4.40852680e-04\n",
      "  -1.91079628e-03  4.80697963e-04]\n",
      " [-7.15323478e-04  5.88220945e-06 -7.51310803e-04  1.21773079e-03\n",
      "  -1.51704515e-03 -2.40879111e-04  1.03925654e-03  1.85976774e-04\n",
      "  -2.23687796e-03 -1.71930898e-03]\n",
      " [ 2.25029361e-03  7.26863745e-04  1.75356521e-03 -1.22370591e-03\n",
      "   1.20787150e-03  1.55136614e-03  8.58882755e-04  5.58886965e-04\n",
      "   7.52318657e-04  1.68604276e-03]\n",
      " [-7.62908661e-04  1.36827622e-04  2.09798282e-03 -6.57909424e-04\n",
      "  -2.16019624e-03 -1.86732354e-04  4.60231448e-04  4.83667851e-04\n",
      "  -1.47028102e-03  1.87087093e-03]\n",
      " [ 1.00552118e-03  1.38536789e-03 -5.94108043e-04  3.48994116e-04\n",
      "   2.22998514e-03  6.26303392e-04  8.02254436e-04 -1.20095134e-03\n",
      "   4.13053046e-04  2.72563484e-04]\n",
      " [ 1.18942080e-04  1.03341272e-03  1.43920717e-03 -1.23743355e-03\n",
      "  -1.66900529e-04 -1.51507604e-03 -1.99754924e-03 -8.68376798e-04\n",
      "   2.69064899e-03  3.95476265e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-9.29046825e-04  2.53008067e-03  1.56193678e-05 -6.33040719e-04\n",
      "   1.10520876e-03  1.00731007e-04 -1.79806995e-03 -1.34247921e-03\n",
      "   3.04171200e-04  1.58593419e-03]\n",
      " [ 4.03496130e-04 -8.17205437e-05  3.59298201e-04  1.04443901e-03\n",
      "  -5.20051339e-04  5.71891089e-05 -1.53210793e-03  2.70527067e-04\n",
      "   6.10131851e-04  8.89408125e-04]\n",
      " [-6.20879182e-04 -4.79881676e-04  1.30034705e-03  9.74617654e-04\n",
      "  -2.07435503e-03 -3.04642767e-03  1.64062254e-03 -9.99497798e-04\n",
      "   6.85344568e-04 -1.86254802e-04]]\n",
      "New_weights\n",
      "[[ 2.71454133e-04  4.95594466e-04 -1.57368778e-04 -5.08467203e-04\n",
      "  -1.17052503e-03  8.25822746e-04  2.96388489e-03 -1.11248750e-03\n",
      "  -1.74233626e-03  3.64298718e-04]\n",
      " [-9.28102533e-04 -3.07421995e-05 -5.63308893e-04  1.27901173e-03\n",
      "  -1.64552280e-03 -1.39452677e-04  1.51215890e-03  2.20153841e-05\n",
      "  -2.34487299e-03 -1.89308309e-03]\n",
      " [ 3.07151321e-03  5.77118991e-04  1.68666682e-03 -1.33320481e-03\n",
      "   1.05400511e-03  1.39202881e-03  7.05246957e-04  4.15111718e-04\n",
      "   6.37942284e-04  1.91595636e-03]\n",
      " [-7.67352334e-04  1.56944466e-04  2.09983868e-03 -6.62353080e-04\n",
      "  -2.16063571e-03 -1.91176042e-04  4.63608883e-04  4.80862843e-04\n",
      "  -1.47461198e-03  1.86642725e-03]\n",
      " [ 1.26298969e-03  1.50161929e-03 -4.94320081e-04  2.45731710e-04\n",
      "   2.65342409e-03  2.87144664e-04  1.76745297e-03 -1.75969307e-03\n",
      "   7.47153193e-05 -2.50081283e-04]\n",
      " [ 1.29599907e-04  1.02590761e-03  1.41489273e-03 -1.25843718e-03\n",
      "  -2.45241541e-05 -1.53925597e-03 -2.01729604e-03 -8.89574143e-04\n",
      "   2.66651423e-03  3.84524061e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-9.48442575e-04  2.88215685e-03 -1.75652242e-04 -6.91854574e-04\n",
      "   1.17036471e-03 -2.22795526e-05 -1.99218770e-03 -1.36094479e-03\n",
      "   1.97523526e-04  1.88042484e-03]\n",
      " [ 4.03401300e-04 -8.18153738e-05  3.59203370e-04  1.04434419e-03\n",
      "  -5.20020979e-04  5.70942783e-05 -1.53220276e-03  2.70432238e-04\n",
      "   6.10860134e-04  8.89313294e-04]\n",
      " [-7.67064683e-04  2.25662496e-04  1.41340340e-03  9.92512334e-04\n",
      "  -2.30061028e-03 -3.67916307e-03  1.86835715e-03 -1.75138735e-03\n",
      "   1.03711208e-03  1.54813574e-04]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.0307048  0.28293556 0.         ... 0.         0.05247044 0.        ]\n",
      " [0.         0.2701086  0.         ... 0.         0.02159458 0.        ]\n",
      " [0.08033281 0.25103355 0.         ... 0.         0.05735377 0.        ]\n",
      " ...\n",
      " [0.         0.32848514 0.         ... 0.         0.07466855 0.        ]\n",
      " [0.         0.25845106 0.         ... 0.         0.03361597 0.        ]\n",
      " [0.03481273 0.23403704 0.         ... 0.         0.0763122  0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[8.07919964e-04 5.18057269e-04 1.74956901e-03 ... 1.25687364e-04\n",
      "  1.97146012e-03 0.00000000e+00]\n",
      " [8.02231732e-04 1.26355513e-03 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.09047770e-03 0.00000000e+00]\n",
      " [9.99655622e-04 1.52640835e-03 9.95215578e-04 ... 0.00000000e+00\n",
      "  1.13715873e-03 0.00000000e+00]\n",
      " ...\n",
      " [1.22238478e-03 1.72468427e-03 6.58680564e-04 ... 0.00000000e+00\n",
      "  2.06087809e-03 0.00000000e+00]\n",
      " [9.14080833e-04 9.67708243e-04 1.03015137e-03 ... 8.75259952e-05\n",
      "  2.34503760e-03 0.00000000e+00]\n",
      " [1.58575166e-03 2.02409211e-03 9.19038083e-04 ... 0.00000000e+00\n",
      "  2.31139591e-03 0.00000000e+00]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 3.26126685e-05 -1.03867596e-05  2.11235998e-05 -2.41971712e-05\n",
      "  1.14285162e-05 -3.97067085e-06  6.99710102e-05 -4.29074724e-05\n",
      " -4.51696218e-06 -1.37886663e-06]\n",
      "Output layer\n",
      "[[0.10000278 0.09999848 0.10000163 0.0999971  0.10000067 0.09999913\n",
      "  0.10000652 0.09999523 0.09999907 0.09999938]\n",
      " [0.09999908 0.10000225 0.10000217 0.09999705 0.10000144 0.09999894\n",
      "  0.10000571 0.09999664 0.09999904 0.09999769]\n",
      " [0.10000019 0.10000147 0.1000028  0.09999614 0.10000096 0.09999789\n",
      "  0.10000828 0.09999555 0.0999995  0.09999723]\n",
      " [0.09999976 0.10000061 0.10000245 0.10000004 0.09999749 0.10000065\n",
      "  0.1000048  0.09999612 0.0999992  0.09999888]\n",
      " [0.10000067 0.10000072 0.10000088 0.09999611 0.10000321 0.09999811\n",
      "  0.10000662 0.09999651 0.09999925 0.09999791]\n",
      " [0.10000058 0.10000081 0.10000219 0.0999989  0.09999895 0.0999995\n",
      "  0.10000385 0.09999593 0.09999985 0.09999944]\n",
      " [0.10000137 0.09999976 0.10000208 0.09999574 0.10000162 0.09999846\n",
      "  0.10001323 0.09999263 0.09999875 0.09999636]\n",
      " [0.09999902 0.10000108 0.10000172 0.09999863 0.09999971 0.09999979\n",
      "  0.10000173 0.10000003 0.09999925 0.09999904]\n",
      " [0.10000131 0.09999971 0.10000286 0.0999973  0.09999923 0.09999887\n",
      "  0.10000739 0.09999521 0.09999975 0.09999838]\n",
      " [0.10000085 0.09999987 0.10000167 0.0999978  0.09999964 0.09999946\n",
      "  0.10000515 0.0999966  0.09999948 0.09999949]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.10001630745248447\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.3025618321216137\n",
      "()\n",
      "Backward pass epoch 2\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[ 2.71454133e-04  4.95594466e-04 -1.57368778e-04 -5.08467203e-04\n",
      "  -1.17052503e-03  8.25822746e-04  2.96388489e-03 -1.11248750e-03\n",
      "  -1.74233626e-03  3.64298718e-04]\n",
      " [-9.28102533e-04 -3.07421995e-05 -5.63308893e-04  1.27901173e-03\n",
      "  -1.64552280e-03 -1.39452677e-04  1.51215890e-03  2.20153841e-05\n",
      "  -2.34487299e-03 -1.89308309e-03]\n",
      " [ 3.07151321e-03  5.77118991e-04  1.68666682e-03 -1.33320481e-03\n",
      "   1.05400511e-03  1.39202881e-03  7.05246957e-04  4.15111718e-04\n",
      "   6.37942284e-04  1.91595636e-03]\n",
      " [-7.67352334e-04  1.56944466e-04  2.09983868e-03 -6.62353080e-04\n",
      "  -2.16063571e-03 -1.91176042e-04  4.63608883e-04  4.80862843e-04\n",
      "  -1.47461198e-03  1.86642725e-03]\n",
      " [ 1.26298969e-03  1.50161929e-03 -4.94320081e-04  2.45731710e-04\n",
      "   2.65342409e-03  2.87144664e-04  1.76745297e-03 -1.75969307e-03\n",
      "   7.47153193e-05 -2.50081283e-04]\n",
      " [ 1.29599907e-04  1.02590761e-03  1.41489273e-03 -1.25843718e-03\n",
      "  -2.45241541e-05 -1.53925597e-03 -2.01729604e-03 -8.89574143e-04\n",
      "   2.66651423e-03  3.84524061e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-9.48442575e-04  2.88215685e-03 -1.75652242e-04 -6.91854574e-04\n",
      "   1.17036471e-03 -2.22795526e-05 -1.99218770e-03 -1.36094479e-03\n",
      "   1.97523526e-04  1.88042484e-03]\n",
      " [ 4.03401300e-04 -8.18153738e-05  3.59203370e-04  1.04434419e-03\n",
      "  -5.20020979e-04  5.70942783e-05 -1.53220276e-03  2.70432238e-04\n",
      "   6.10860134e-04  8.89313294e-04]\n",
      " [-7.67064683e-04  2.25662496e-04  1.41340340e-03  9.92512334e-04\n",
      "  -2.30061028e-03 -3.67916307e-03  1.86835715e-03 -1.75138735e-03\n",
      "   1.03711208e-03  1.54813574e-04]]\n",
      "New_weights\n",
      "[[ 7.79042123e-04  3.77428919e-04 -6.08779329e-05 -6.92933689e-04\n",
      "  -1.24319355e-03  7.68389043e-04  4.70333299e-03 -2.48760813e-03\n",
      "  -1.82905912e-03 -8.46504643e-05]\n",
      " [-1.45176502e-03  8.58926925e-05 -1.08318266e-06  1.41903934e-03\n",
      "  -2.08909493e-03  6.10956180e-05  3.28710507e-03 -1.01654323e-03\n",
      "  -2.35764204e-03 -2.66890347e-03]\n",
      " [ 5.33313790e-03 -7.73780235e-05  1.74734322e-03 -1.57708023e-03\n",
      "   4.55575929e-04  6.70377274e-04  3.24738880e-04 -1.11665981e-04\n",
      "   7.55354450e-04  2.60198202e-03]\n",
      " [-9.44354384e-04  8.29691697e-04  2.22062703e-03 -8.79936828e-04\n",
      "  -2.12838982e-03 -4.14276567e-04  6.76504441e-04  3.25466031e-04\n",
      "  -1.53338679e-03  1.65960816e-03]\n",
      " [ 2.04970267e-03  1.71135613e-03 -6.39413526e-04 -3.97288254e-04\n",
      "   3.71922873e-03 -1.93892902e-04  3.92384669e-03 -3.12972963e-03\n",
      "  -3.65412516e-04 -1.38941408e-03]\n",
      " [ 1.18106860e-04  1.00743815e-03  1.38951137e-03 -1.28347043e-03\n",
      "   1.61620219e-04 -1.56463661e-03 -2.04163564e-03 -9.14347610e-04\n",
      "   2.64113335e-03  3.78631398e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-6.19493850e-04  3.52713577e-03 -1.46451654e-03 -5.45855544e-04\n",
      "   1.44251485e-03 -1.90319512e-04 -2.72294301e-03 -1.50331339e-03\n",
      "   4.38644992e-04  2.57725473e-03]\n",
      " [ 3.95698862e-04 -7.03690672e-05  3.51500851e-04  1.03664198e-03\n",
      "  -4.90744779e-04  4.93919371e-05 -1.53907364e-03  2.67765497e-04\n",
      "   6.16786422e-04  8.83011617e-04]\n",
      " [-7.10814171e-04  9.30728545e-04  2.33978737e-03  1.42987815e-03\n",
      "  -3.48856932e-03 -4.71929264e-03  2.59022247e-03 -3.40148762e-03\n",
      "   1.59728286e-03  6.25900020e-04]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.0963266  0.3191704  0.         ... 0.         0.10078857 0.        ]\n",
      " [0.0641165  0.33871311 0.         ... 0.         0.05352631 0.        ]\n",
      " [0.16180891 0.32044706 0.         ... 0.         0.10776901 0.        ]\n",
      " ...\n",
      " [0.09704477 0.39913881 0.         ... 0.         0.12997069 0.        ]\n",
      " [0.07194743 0.31888891 0.         ... 0.         0.07995396 0.        ]\n",
      " [0.13357074 0.30404333 0.         ... 0.         0.13341886 0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00481911 0.0007572  0.00504528 ... 0.00302337 0.0059448  0.00023267]\n",
      " [0.0048891  0.00230411 0.00078908 ... 0.0026616  0.00344601 0.        ]\n",
      " [0.00565615 0.00256231 0.00326857 ... 0.0025572  0.00406955 0.        ]\n",
      " ...\n",
      " [0.00695057 0.0027953  0.00342483 ... 0.0037349  0.00625812 0.        ]\n",
      " [0.00537366 0.00118226 0.00381184 ... 0.00382864 0.00636156 0.000235  ]\n",
      " [0.00742519 0.00329677 0.00377591 ... 0.00393012 0.00706906 0.        ]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 2.27890014e-04 -1.21992873e-04  9.98471777e-05 -8.22209905e-06\n",
      " -1.49469025e-04  4.31469125e-05  4.25386402e-04 -2.93436031e-04\n",
      " -7.71034962e-06  4.85918050e-05]\n",
      "Output layer\n",
      "[[0.10002015 0.09998516 0.10000734 0.09999654 0.09998241 0.10000167\n",
      "  0.1000399  0.09996802 0.09999659 0.10000222]\n",
      " [0.10000443 0.09999769 0.1000103  0.09999785 0.09998217 0.10000264\n",
      "  0.10003625 0.09997313 0.0999982  0.09999734]\n",
      " [0.10001172 0.09999349 0.10001166 0.09999409 0.0999813  0.09999958\n",
      "  0.10004881 0.09996524 0.09999816 0.09999597]\n",
      " [0.10000643 0.09999282 0.10001191 0.10000678 0.09997323 0.10000588\n",
      "  0.10002691 0.09997474 0.09999844 0.10000287]\n",
      " [0.1000133  0.09999353 0.10000265 0.09998596 0.10000072 0.09999653\n",
      "  0.1000498  0.09997012 0.0999961  0.09999129]\n",
      " [0.10000978 0.09999135 0.10001205 0.10000646 0.09997148 0.10000473\n",
      "  0.10002714 0.09997216 0.09999889 0.10000596]\n",
      " [0.10002085 0.09998726 0.1000092  0.09998503 0.09998737 0.09999894\n",
      "  0.10008172 0.09994706 0.09999509 0.09998748]\n",
      " [0.09999763 0.09999899 0.1000083  0.10000489 0.09998311 0.10000495\n",
      "  0.10000527 0.09999514 0.0999983  0.1000034 ]\n",
      " [0.10001504 0.09998782 0.10001282 0.10000015 0.09997222 0.10000323\n",
      "  0.10004449 0.09996386 0.09999851 0.10000185]\n",
      " [0.10001225 0.09998888 0.10000927 0.10000169 0.09997595 0.1000041\n",
      "  0.10003268 0.09997264 0.09999769 0.10000485]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.10009559865919272\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.3024689994457783\n",
      "()\n",
      "Backward pass epoch 3\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[ 7.79042123e-04  3.77428919e-04 -6.08779329e-05 -6.92933689e-04\n",
      "  -1.24319355e-03  7.68389043e-04  4.70333299e-03 -2.48760813e-03\n",
      "  -1.82905912e-03 -8.46504643e-05]\n",
      " [-1.45176502e-03  8.58926925e-05 -1.08318266e-06  1.41903934e-03\n",
      "  -2.08909493e-03  6.10956180e-05  3.28710507e-03 -1.01654323e-03\n",
      "  -2.35764204e-03 -2.66890347e-03]\n",
      " [ 5.33313790e-03 -7.73780235e-05  1.74734322e-03 -1.57708023e-03\n",
      "   4.55575929e-04  6.70377274e-04  3.24738880e-04 -1.11665981e-04\n",
      "   7.55354450e-04  2.60198202e-03]\n",
      " [-9.44354384e-04  8.29691697e-04  2.22062703e-03 -8.79936828e-04\n",
      "  -2.12838982e-03 -4.14276567e-04  6.76504441e-04  3.25466031e-04\n",
      "  -1.53338679e-03  1.65960816e-03]\n",
      " [ 2.04970267e-03  1.71135613e-03 -6.39413526e-04 -3.97288254e-04\n",
      "   3.71922873e-03 -1.93892902e-04  3.92384669e-03 -3.12972963e-03\n",
      "  -3.65412516e-04 -1.38941408e-03]\n",
      " [ 1.18106860e-04  1.00743815e-03  1.38951137e-03 -1.28347043e-03\n",
      "   1.61620219e-04 -1.56463661e-03 -2.04163564e-03 -9.14347610e-04\n",
      "   2.64113335e-03  3.78631398e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-6.19493850e-04  3.52713577e-03 -1.46451654e-03 -5.45855544e-04\n",
      "   1.44251485e-03 -1.90319512e-04 -2.72294301e-03 -1.50331339e-03\n",
      "   4.38644992e-04  2.57725473e-03]\n",
      " [ 3.95698862e-04 -7.03690672e-05  3.51500851e-04  1.03664198e-03\n",
      "  -4.90744779e-04  4.93919371e-05 -1.53907364e-03  2.67765497e-04\n",
      "   6.16786422e-04  8.83011617e-04]\n",
      " [-7.10814171e-04  9.30728545e-04  2.33978737e-03  1.42987815e-03\n",
      "  -3.48856932e-03 -4.71929264e-03  2.59022247e-03 -3.40148762e-03\n",
      "   1.59728286e-03  6.25900020e-04]]\n",
      "New_weights\n",
      "[[ 2.58613742e-03  1.41294883e-04 -2.97420197e-05 -2.27168715e-03\n",
      "  -7.87867590e-04  4.42540846e-04  1.06191571e-02 -6.98619649e-03\n",
      "  -1.67034076e-03 -1.81342608e-03]\n",
      " [-2.24157138e-03  3.43210447e-04  9.43562332e-04  1.17815747e-03\n",
      "  -2.68151593e-03  3.14987774e-04  7.50900147e-03 -3.17103748e-03\n",
      "  -2.45290729e-03 -4.47378656e-03]\n",
      " [ 1.01076777e-02 -1.74608558e-03  2.10201697e-03 -2.10370853e-03\n",
      "  -4.90749820e-04 -9.66207745e-04  9.22216679e-04 -2.12518830e-03\n",
      "   1.01248106e-03  3.40993299e-03]\n",
      " [-1.04562386e-03  1.13299453e-03  2.58519780e-03 -9.71210803e-04\n",
      "  -2.22962682e-03 -5.15539891e-04  6.73306953e-04  2.24238390e-04\n",
      "  -1.60207091e-03  1.55988758e-03]\n",
      " [ 3.97110292e-03  1.92589467e-03 -2.27162802e-03 -3.36719903e-03\n",
      "   7.94746064e-03 -1.89546746e-03  1.09801208e-02 -6.24933672e-03\n",
      "  -1.36492712e-03 -4.38703742e-03]\n",
      " [ 1.18106860e-04  1.00743815e-03  1.38951137e-03 -1.28347043e-03\n",
      "   1.61620219e-04 -1.56463661e-03 -2.04163564e-03 -9.14347610e-04\n",
      "   2.64113335e-03  3.78631398e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.10854955e-03  4.62946557e-03 -1.96530075e-03 -4.47178567e-04\n",
      "   1.47975670e-03 -4.90370002e-04 -3.24789893e-03 -1.39449206e-03\n",
      "   2.12598898e-04  3.27107719e-03]\n",
      " [ 3.95698862e-04 -7.03690672e-05  3.51500851e-04  1.03664198e-03\n",
      "  -4.90744779e-04  4.93919371e-05 -1.53907364e-03  2.67765497e-04\n",
      "   6.16786422e-04  8.83011617e-04]\n",
      " [-5.28847052e-04  1.89043268e-03  4.61024486e-03  2.06861631e-03\n",
      "  -6.11146050e-03 -6.68898905e-03  5.86641109e-03 -7.57875060e-03\n",
      "   2.78920217e-03  8.76775755e-04]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.24422405 0.62214753 0.         ... 0.         0.13426317 0.        ]\n",
      " [0.1994273  0.55292044 0.         ... 0.         0.         0.        ]\n",
      " [0.32676989 0.58434717 0.         ... 0.         0.08254611 0.        ]\n",
      " ...\n",
      " [0.30382838 0.70733891 0.         ... 0.         0.09392643 0.        ]\n",
      " [0.21746708 0.66888324 0.         ... 0.         0.07272983 0.        ]\n",
      " [0.33772199 0.69132828 0.         ... 0.         0.12880005 0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.01957713 0.01049013 0.01043535 ... 0.00122677 0.01756072 0.00848446]\n",
      " [0.0125092  0.01200463 0.         ... 0.0008649  0.00253964 0.00714435]\n",
      " [0.01792668 0.01391427 0.00109675 ... 0.0001578  0.00745308 0.00824975]\n",
      " ...\n",
      " [0.02353104 0.01704417 0.0016025  ... 0.00052051 0.01243578 0.00943776]\n",
      " [0.01778232 0.01159009 0.00439565 ... 0.00215727 0.01385606 0.00977046]\n",
      " [0.02758944 0.01967647 0.0041582  ... 0.00203861 0.01779721 0.01122943]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 2.14086465e-03 -8.30011968e-05 -4.28838663e-04 -2.96563030e-03\n",
      "  3.16935845e-03 -1.26490752e-03  7.70332638e-03 -4.05526422e-03\n",
      " -4.65148001e-04 -2.66678262e-03]\n",
      "Output layer\n",
      "[[0.10020291 0.09998032 0.09994575 0.09969253 0.10030602 0.09986222\n",
      "  0.10076184 0.09958396 0.09994212 0.09972233]\n",
      " [0.1000462  0.10006372 0.0999645  0.09975441 0.10027708 0.09989116\n",
      "  0.10055581 0.09973648 0.09995556 0.09975508]\n",
      " [0.10011238 0.10004458 0.09995611 0.09968822 0.1003313  0.099858\n",
      "  0.10073733 0.09962808 0.0999467  0.09969729]\n",
      " [0.1000514  0.10003444 0.10001601 0.09984114 0.10014084 0.09992607\n",
      "  0.10048256 0.09973146 0.09997003 0.09980604]\n",
      " [0.10018599 0.1000065  0.09991125 0.09963793 0.10039066 0.09984666\n",
      "  0.10082552 0.0995765  0.09993634 0.09968264]\n",
      " [0.10007638 0.10004015 0.0999894  0.09978367 0.10021966 0.09989682\n",
      "  0.1005648  0.09969838 0.09996013 0.09977062]\n",
      " [0.10029454 0.0999933  0.09990788 0.09947676 0.1005173  0.09977827\n",
      "  0.10131742 0.09929563 0.09990957 0.09950933]\n",
      " [0.09996829 0.10004309 0.10000305 0.09994137 0.10008258 0.09996754\n",
      "  0.10011091 0.09996823 0.09998312 0.09993181]\n",
      " [0.10013428 0.10002878 0.09996788 0.09969208 0.10030869 0.09986046\n",
      "  0.10077725 0.09959119 0.09994677 0.09969262]\n",
      " [0.1001071  0.10002593 0.09996159 0.09974212 0.10027326 0.09988394\n",
      "  0.10062128 0.09968207 0.09995107 0.09975167]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.1015945318889899\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.3011077543820346\n",
      "()\n",
      "Backward pass epoch 4\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[ 2.58613742e-03  1.41294883e-04 -2.97420197e-05 -2.27168715e-03\n",
      "  -7.87867590e-04  4.42540846e-04  1.06191571e-02 -6.98619649e-03\n",
      "  -1.67034076e-03 -1.81342608e-03]\n",
      " [-2.24157138e-03  3.43210447e-04  9.43562332e-04  1.17815747e-03\n",
      "  -2.68151593e-03  3.14987774e-04  7.50900147e-03 -3.17103748e-03\n",
      "  -2.45290729e-03 -4.47378656e-03]\n",
      " [ 1.01076777e-02 -1.74608558e-03  2.10201697e-03 -2.10370853e-03\n",
      "  -4.90749820e-04 -9.66207745e-04  9.22216679e-04 -2.12518830e-03\n",
      "   1.01248106e-03  3.40993299e-03]\n",
      " [-1.04562386e-03  1.13299453e-03  2.58519780e-03 -9.71210803e-04\n",
      "  -2.22962682e-03 -5.15539891e-04  6.73306953e-04  2.24238390e-04\n",
      "  -1.60207091e-03  1.55988758e-03]\n",
      " [ 3.97110292e-03  1.92589467e-03 -2.27162802e-03 -3.36719903e-03\n",
      "   7.94746064e-03 -1.89546746e-03  1.09801208e-02 -6.24933672e-03\n",
      "  -1.36492712e-03 -4.38703742e-03]\n",
      " [ 1.18106860e-04  1.00743815e-03  1.38951137e-03 -1.28347043e-03\n",
      "   1.61620219e-04 -1.56463661e-03 -2.04163564e-03 -9.14347610e-04\n",
      "   2.64113335e-03  3.78631398e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.10854955e-03  4.62946557e-03 -1.96530075e-03 -4.47178567e-04\n",
      "   1.47975670e-03 -4.90370002e-04 -3.24789893e-03 -1.39449206e-03\n",
      "   2.12598898e-04  3.27107719e-03]\n",
      " [ 3.95698862e-04 -7.03690672e-05  3.51500851e-04  1.03664198e-03\n",
      "  -4.90744779e-04  4.93919371e-05 -1.53907364e-03  2.67765497e-04\n",
      "   6.16786422e-04  8.83011617e-04]\n",
      " [-5.28847052e-04  1.89043268e-03  4.61024486e-03  2.06861631e-03\n",
      "  -6.11146050e-03 -6.68898905e-03  5.86641109e-03 -7.57875060e-03\n",
      "   2.78920217e-03  8.76775755e-04]]\n",
      "New_weights\n",
      "[[ 1.81362621e-02 -4.63313070e-03 -2.51558234e-03 -1.49825999e-02\n",
      "   7.07069223e-03 -2.93961405e-03  4.71447403e-02 -3.13608737e-02\n",
      "  -4.05924169e-03 -1.16307820e-02]\n",
      " [ 1.23033738e-03 -5.36472459e-04  3.28342684e-03 -3.44661857e-03\n",
      "  -1.62095944e-03 -1.45442592e-04  2.81128499e-02 -1.70775338e-02\n",
      "  -2.87712826e-03 -1.16543582e-02]\n",
      " [ 2.45869676e-02 -6.06900268e-03 -1.02558316e-03 -5.80032804e-03\n",
      "  -3.36020600e-04 -4.09256776e-03  7.98381518e-03 -6.81123639e-03\n",
      "  -1.92452036e-03  3.61086162e-03]\n",
      " [-4.37719791e-05  1.16021461e-03  6.97197777e-03 -6.13632308e-04\n",
      "  -5.25840802e-03 -1.99864762e-03  8.81170973e-03 -7.54703853e-03\n",
      "  -1.36906167e-03 -3.01789013e-04]\n",
      " [ 2.59092606e-02 -1.28176835e-03 -1.01651795e-02 -2.63105838e-02\n",
      "   2.68547110e-02 -8.89959045e-03  6.40744830e-02 -3.95221011e-02\n",
      "  -3.77301749e-03 -2.15972307e-02]\n",
      " [ 8.72328053e-05  9.84122498e-04  1.35870774e-03 -1.31419905e-03\n",
      "   3.80400891e-04 -1.59542298e-03 -2.07268441e-03 -9.38422983e-04\n",
      "   2.61032243e-03  3.92294113e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [ 1.04713801e-03  5.11173711e-03 -3.61926903e-03  2.81713238e-04\n",
      "   3.61459024e-04 -1.30365600e-03  2.16196482e-03 -8.85090186e-03\n",
      "   1.17559283e-03  4.57333034e-03]\n",
      " [ 3.69720503e-04  6.15126005e-05  3.29753267e-04  1.01231611e-03\n",
      "  -5.09908616e-04  2.34350711e-05 -1.56512720e-03  3.06693190e-04\n",
      "   5.94129148e-04  8.78085622e-04]\n",
      " [ 4.92174662e-03  2.24632243e-04  1.34494657e-02  4.93558094e-03\n",
      "  -1.61899402e-02 -1.08360768e-02  2.04705136e-02 -2.44114937e-02\n",
      "   3.51189359e-03  1.11731365e-03]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.60102324 1.91596372 0.         ... 0.         1.48084093 0.        ]\n",
      " [0.383016   2.14210322 0.         ... 0.         1.239314   0.        ]\n",
      " [0.67983923 2.29884027 0.         ... 0.         1.54087632 0.        ]\n",
      " ...\n",
      " [0.79475153 2.69859858 0.         ... 0.         1.82453078 0.        ]\n",
      " [0.43043724 2.2548372  0.         ... 0.         1.55321773 0.        ]\n",
      " [0.80967469 2.65154288 0.         ... 0.         1.85477706 0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.4577668  0.21331297 0.40515829 ... 0.09761371 0.54822147 0.        ]\n",
      " [0.34416205 0.18553639 0.3425036  ... 0.11654158 0.47547637 0.02093431]\n",
      " [0.48319693 0.24735409 0.43159311 ... 0.12060723 0.5927243  0.        ]\n",
      " ...\n",
      " [0.64897883 0.32551636 0.54895778 ... 0.1452834  0.763878   0.        ]\n",
      " [0.38582434 0.18891523 0.39061253 ... 0.11805198 0.52561234 0.01822379]\n",
      " [0.62790339 0.31758349 0.53731483 ... 0.1450998  0.74650672 0.        ]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 0.29976106 -0.09866835 -0.03171437 -0.19897378  0.10865606 -0.07077033\n",
      "  0.64040004 -0.42734825 -0.03679389 -0.16108443]\n",
      "Output layer\n",
      "[[0.12908097 0.08666156 0.09266255 0.07839068 0.1066268  0.08911329\n",
      "  0.18146791 0.06238535 0.09219306 0.08141784]\n",
      " [0.11972506 0.09080181 0.09859391 0.088662   0.10090789 0.09392036\n",
      "  0.15034573 0.07227164 0.09563096 0.08914062]\n",
      " [0.12907729 0.08619105 0.09379475 0.07925115 0.10451494 0.08906388\n",
      "  0.18322934 0.06129723 0.09209193 0.08148845]\n",
      " [0.10921775 0.09502774 0.10197082 0.09803139 0.0970102  0.09809871\n",
      "  0.11940125 0.08601215 0.09834518 0.09688481]\n",
      " [0.14296655 0.07541637 0.08041784 0.05949684 0.11094013 0.07668832\n",
      "  0.26522289 0.04241504 0.0820828  0.06435321]\n",
      " [0.11278814 0.09339161 0.10158292 0.09602963 0.09721241 0.09708076\n",
      "  0.12761543 0.08159008 0.09756944 0.09513959]\n",
      " [0.15069229 0.06344675 0.06988776 0.04658963 0.10575261 0.06518675\n",
      "  0.34641177 0.02916575 0.07132562 0.05154108]\n",
      " [0.10214875 0.09793936 0.10266436 0.10236285 0.09591652 0.09985159\n",
      "  0.10394303 0.09514284 0.09957383 0.10045688]\n",
      " [0.12433351 0.08852178 0.09700138 0.0851799  0.10172163 0.09209208\n",
      "  0.16315998 0.06746178 0.09417527 0.0863527 ]\n",
      " [0.11953995 0.09096744 0.09844001 0.08913299 0.10107002 0.09428089\n",
      "  0.14719038 0.07366095 0.0957957  0.08992167]]\n",
      "Sums to 1: \n",
      "1.0\n",
      "At least one output is closer to 1: \n",
      "0.4169380900933369\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.1811671405039315\n",
      "()\n",
      "Backward pass epoch 5\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[ 1.81362621e-02 -4.63313070e-03 -2.51558234e-03 -1.49825999e-02\n",
      "   7.07069223e-03 -2.93961405e-03  4.71447403e-02 -3.13608737e-02\n",
      "  -4.05924169e-03 -1.16307820e-02]\n",
      " [ 1.23033738e-03 -5.36472459e-04  3.28342684e-03 -3.44661857e-03\n",
      "  -1.62095944e-03 -1.45442592e-04  2.81128499e-02 -1.70775338e-02\n",
      "  -2.87712826e-03 -1.16543582e-02]\n",
      " [ 2.45869676e-02 -6.06900268e-03 -1.02558316e-03 -5.80032804e-03\n",
      "  -3.36020600e-04 -4.09256776e-03  7.98381518e-03 -6.81123639e-03\n",
      "  -1.92452036e-03  3.61086162e-03]\n",
      " [-4.37719791e-05  1.16021461e-03  6.97197777e-03 -6.13632308e-04\n",
      "  -5.25840802e-03 -1.99864762e-03  8.81170973e-03 -7.54703853e-03\n",
      "  -1.36906167e-03 -3.01789013e-04]\n",
      " [ 2.59092606e-02 -1.28176835e-03 -1.01651795e-02 -2.63105838e-02\n",
      "   2.68547110e-02 -8.89959045e-03  6.40744830e-02 -3.95221011e-02\n",
      "  -3.77301749e-03 -2.15972307e-02]\n",
      " [ 8.72328053e-05  9.84122498e-04  1.35870774e-03 -1.31419905e-03\n",
      "   3.80400891e-04 -1.59542298e-03 -2.07268441e-03 -9.38422983e-04\n",
      "   2.61032243e-03  3.92294113e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [ 1.04713801e-03  5.11173711e-03 -3.61926903e-03  2.81713238e-04\n",
      "   3.61459024e-04 -1.30365600e-03  2.16196482e-03 -8.85090186e-03\n",
      "   1.17559283e-03  4.57333034e-03]\n",
      " [ 3.69720503e-04  6.15126005e-05  3.29753267e-04  1.01231611e-03\n",
      "  -5.09908616e-04  2.34350711e-05 -1.56512720e-03  3.06693190e-04\n",
      "   5.94129148e-04  8.78085622e-04]\n",
      " [ 4.92174662e-03  2.24632243e-04  1.34494657e-02  4.93558094e-03\n",
      "  -1.61899402e-02 -1.08360768e-02  2.04705136e-02 -2.44114937e-02\n",
      "   3.51189359e-03  1.11731365e-03]]\n",
      "New_weights\n",
      "[[ 1.21422034e-01  6.66975618e-02 -1.30834224e-01 -2.65644766e-01\n",
      "   5.16713310e-01 -5.04561241e-02  1.37559420e-01 -1.87201881e-01\n",
      "  -9.67093620e-03 -1.98354525e-01]\n",
      " [ 2.68648003e-02  4.67283881e-02 -3.99590984e-02 -1.14339193e-01\n",
      "   2.23027404e-01 -1.76014109e-02  6.76046742e-02 -9.45285641e-02\n",
      "   1.74171294e-03 -1.04270612e-01]\n",
      " [ 3.43105058e-02  6.31621725e-02 -5.60565126e-02 -7.80638978e-02\n",
      "   2.67261257e-01 -1.83207178e-02 -1.44854495e-01 -2.04481678e-02\n",
      "   2.00838953e-02 -5.69516542e-02]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 2.21740883e-01  2.13532364e-02 -2.45875840e-01 -3.56275154e-01\n",
      "   7.45336300e-01 -1.22009381e-01  3.82561042e-01 -2.60288051e-01\n",
      "  -7.68660385e-02 -3.04388014e-01]\n",
      " [ 8.72328053e-05  9.84122498e-04  1.35870774e-03 -1.31419905e-03\n",
      "   3.80400891e-04 -1.59542298e-03 -2.07268441e-03 -9.38422983e-04\n",
      "   2.61032243e-03  3.92294113e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.70903564e-02  1.00638136e-02 -5.69616870e-03  2.55623705e-02\n",
      "  -1.49813336e-02 -5.79633992e-03 -1.73961602e-02  1.63271858e-02\n",
      "  -5.62384560e-03  1.55699431e-02]\n",
      " [ 3.69720503e-04  6.15126005e-05  3.29753267e-04  1.01231611e-03\n",
      "  -5.09908616e-04  2.34350711e-05 -1.56512720e-03  3.06693190e-04\n",
      "   5.94129148e-04  8.78085622e-04]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.         0.         0.         ... 0.         0.         0.10339765]\n",
      " [0.         0.         0.         ... 0.         0.         0.08101968]\n",
      " [0.         0.         0.         ... 0.         0.         0.11369319]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.14528045]\n",
      " [0.         0.         0.         ... 0.         0.         0.08407336]\n",
      " [0.         0.         0.         ... 0.         0.         0.0937495 ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[ 0.          0.          0.         ...  1.94830517  0.\n",
      "   6.54658808]\n",
      " [ 0.          0.          0.         ...  4.67463642  0.\n",
      "   9.75943644]\n",
      " [ 0.          0.          0.         ...  3.83289517  0.\n",
      "   9.05013918]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  3.94255022  0.\n",
      "   9.99909983]\n",
      " [ 0.          0.          0.         ...  4.02755908  0.\n",
      "   9.81439591]\n",
      " [ 0.          0.          0.         ...  3.73644862  0.\n",
      "  10.07024656]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ -1.0301768    5.8652044  -23.08056708 -17.51999931  81.71972502\n",
      " -17.64183768  23.2992764  -11.59386685 -12.46217597 -27.36566772]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.9999910000719996\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.3089918450613465\n",
      "()\n",
      "Backward pass epoch 6\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[ 1.21422034e-01  6.66975618e-02 -1.30834224e-01 -2.65644766e-01\n",
      "   5.16713310e-01 -5.04561241e-02  1.37559420e-01 -1.87201881e-01\n",
      "  -9.67093620e-03 -1.98354525e-01]\n",
      " [ 2.68648003e-02  4.67283881e-02 -3.99590984e-02 -1.14339193e-01\n",
      "   2.23027404e-01 -1.76014109e-02  6.76046742e-02 -9.45285641e-02\n",
      "   1.74171294e-03 -1.04270612e-01]\n",
      " [ 3.43105058e-02  6.31621725e-02 -5.60565126e-02 -7.80638978e-02\n",
      "   2.67261257e-01 -1.83207178e-02 -1.44854495e-01 -2.04481678e-02\n",
      "   2.00838953e-02 -5.69516542e-02]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 2.21740883e-01  2.13532364e-02 -2.45875840e-01 -3.56275154e-01\n",
      "   7.45336300e-01 -1.22009381e-01  3.82561042e-01 -2.60288051e-01\n",
      "  -7.68660385e-02 -3.04388014e-01]\n",
      " [ 8.72328053e-05  9.84122498e-04  1.35870774e-03 -1.31419905e-03\n",
      "   3.80400891e-04 -1.59542298e-03 -2.07268441e-03 -9.38422983e-04\n",
      "   2.61032243e-03  3.92294113e-04]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.70903564e-02  1.00638136e-02 -5.69616870e-03  2.55623705e-02\n",
      "  -1.49813336e-02 -5.79633992e-03 -1.73961602e-02  1.63271858e-02\n",
      "  -5.62384560e-03  1.55699431e-02]\n",
      " [ 3.69720503e-04  6.15126005e-05  3.29753267e-04  1.01231611e-03\n",
      "  -5.09908616e-04  2.34350711e-05 -1.56512720e-03  3.06693190e-04\n",
      "   5.94129148e-04  8.78085622e-04]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "New_weights\n",
      "[[ 1.21422021e-01  6.66975492e-02 -1.30834236e-01 -2.65644779e-01\n",
      "   5.04128638e-01 -5.04561367e-02  1.50144193e-01 -1.87201893e-01\n",
      "  -9.67094878e-03 -1.98354537e-01]\n",
      " [ 2.68648003e-02  4.67283881e-02 -3.99590984e-02 -1.14339193e-01\n",
      "   2.23027404e-01 -1.76014109e-02  6.76046742e-02 -9.45285641e-02\n",
      "   1.74171294e-03 -1.04270612e-01]\n",
      " [ 3.43105058e-02  6.31621725e-02 -5.60565126e-02 -7.80638978e-02\n",
      "   2.67261257e-01 -1.83207178e-02 -1.44854495e-01 -2.04481678e-02\n",
      "   2.00838953e-02 -5.69516542e-02]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [-1.90300968e+00 -4.54688742e+00 -4.81411649e+00 -4.92451581e+00\n",
      "   1.63689094e+00 -4.69025003e+00  3.35934415e+01 -4.82852870e+00\n",
      "  -4.64510669e+00 -4.87262867e+00]\n",
      " [-4.60323777e-03 -4.85454352e-03 -4.47995828e-03 -7.15286507e-03\n",
      "   5.53213409e-03 -7.43408901e-03  3.83367151e-02 -6.77708900e-03\n",
      "  -3.22834359e-03 -5.44637191e-03]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.70903564e-02  1.00638136e-02 -5.69616870e-03  2.55623705e-02\n",
      "  -1.49813336e-02 -5.79633992e-03 -1.73961602e-02  1.63271858e-02\n",
      "  -5.62384560e-03  1.55699431e-02]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "  10.34714275]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   8.97373624]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "  10.14650148]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "  13.45028205]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "  10.36470317]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "  12.64883119]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[    0.          3150.7775171   2135.76499323 ... 21329.16101114\n",
      "   4293.39646206     0.        ]\n",
      " [    0.          3430.16131319  2328.4403175  ... 20388.88926734\n",
      "   4676.43686595     0.        ]\n",
      " [    0.          3632.57966906  2465.95074238 ... 22443.42193293\n",
      "   4952.98071774     0.        ]\n",
      " ...\n",
      " [    0.          4400.27297149  2978.07705447 ... 29817.94575238\n",
      "   5991.18292234     0.        ]\n",
      " [    0.          3685.32956057  2510.33536074 ... 21261.57281904\n",
      "   5033.24304386     0.        ]\n",
      " [    0.          4294.73974941  2920.73414761 ... 26528.88243168\n",
      "   5861.51184947     0.        ]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 1.91427886e+08 -1.64914505e+08 -1.92279430e+08 -2.20067103e+08\n",
      "  1.63834939e+08 -1.53021927e+08  9.44592714e+08 -2.40153089e+08\n",
      " -1.43369049e+08 -1.86024414e+08]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.9999910000719996\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.301303748479285\n",
      "()\n",
      "Backward pass epoch 7\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[ 1.21422021e-01  6.66975492e-02 -1.30834236e-01 -2.65644779e-01\n",
      "   5.04128638e-01 -5.04561367e-02  1.50144193e-01 -1.87201893e-01\n",
      "  -9.67094878e-03 -1.98354537e-01]\n",
      " [ 2.68648003e-02  4.67283881e-02 -3.99590984e-02 -1.14339193e-01\n",
      "   2.23027404e-01 -1.76014109e-02  6.76046742e-02 -9.45285641e-02\n",
      "   1.74171294e-03 -1.04270612e-01]\n",
      " [ 3.43105058e-02  6.31621725e-02 -5.60565126e-02 -7.80638978e-02\n",
      "   2.67261257e-01 -1.83207178e-02 -1.44854495e-01 -2.04481678e-02\n",
      "   2.00838953e-02 -5.69516542e-02]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [-1.90300968e+00 -4.54688742e+00 -4.81411649e+00 -4.92451581e+00\n",
      "   1.63689094e+00 -4.69025003e+00  3.35934415e+01 -4.82852870e+00\n",
      "  -4.64510669e+00 -4.87262867e+00]\n",
      " [-4.60323777e-03 -4.85454352e-03 -4.47995828e-03 -7.15286507e-03\n",
      "   5.53213409e-03 -7.43408901e-03  3.83367151e-02 -6.77708900e-03\n",
      "  -3.22834359e-03 -5.44637191e-03]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.70903564e-02  1.00638136e-02 -5.69616870e-03  2.55623705e-02\n",
      "  -1.49813336e-02 -5.79633992e-03 -1.73961602e-02  1.63271858e-02\n",
      "  -5.62384560e-03  1.55699431e-02]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "New_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 5.26718537e+02  1.67765984e+02 -6.57722603e+02 -9.10299588e+02\n",
      "   1.06112545e+03 -2.59791290e+02  1.55910188e+03 -8.72435227e+02\n",
      "   7.12593157e+01 -6.85727187e+02]\n",
      " [ 3.34913621e+02  1.06197181e+02 -4.06591545e+02 -5.59361549e+02\n",
      "   6.38821245e+02 -1.62687823e+02  1.00292567e+03 -5.82251885e+02\n",
      "   5.95647699e+01 -4.31519565e+02]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 4.46931955e+05  1.24660264e+05 -5.88963317e+05 -8.37250627e+05\n",
      "   1.02734533e+06 -2.23956784e+05  1.24011250e+06 -6.00432883e+05\n",
      "  -1.02895011e+04 -5.78156926e+05]\n",
      " [-4.60323777e-03 -4.85454352e-03 -4.47995828e-03 -7.15286507e-03\n",
      "   5.53213409e-03 -7.43408901e-03  3.83367151e-02 -6.77708900e-03\n",
      "  -3.22834359e-03 -5.44637191e-03]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.70903564e-02  1.00638136e-02 -5.69616870e-03  2.55623705e-02\n",
      "  -1.49813336e-02 -5.79633992e-03 -1.73961602e-02  1.63271858e-02\n",
      "  -5.62384560e-03  1.55699431e-02]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 2.49340406e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 5.70611321e+04]\n",
      " [0.00000000e+00 0.00000000e+00 3.33757029e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.46026774e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 8.69316970e+02]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 3.64588862e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.60439951e+04]\n",
      " [0.00000000e+00 0.00000000e+00 3.43874437e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.26448220e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 5.23998370e+04]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 1.13212330e+11 5.20994167e+10 ... 0.00000000e+00\n",
      "  1.09827678e+11 0.00000000e+00]\n",
      " [0.00000000e+00 4.90439260e-02 0.00000000e+00 ... 6.25342720e-01\n",
      "  1.07867580e-01 3.69151700e-02]\n",
      " [0.00000000e+00 1.56783048e+09 7.50692589e+08 ... 0.00000000e+00\n",
      "  1.55256233e+09 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 7.98767457e+10 3.68925467e+10 ... 0.00000000e+00\n",
      "  7.76318696e+10 0.00000000e+00]\n",
      " [0.00000000e+00 1.84987767e-01 2.09147388e-01 ... 6.55078996e-01\n",
      "  4.67994640e-01 2.41281784e-02]\n",
      " [0.00000000e+00 1.20650794e+11 5.57991899e+10 ... 0.00000000e+00\n",
      "  1.17340920e+11 0.00000000e+00]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 8.90430879e+19  2.56019293e+19 -1.17807791e+20 -1.66888291e+20\n",
      "  2.04572183e+20 -4.48229322e+19  2.48639162e+20 -1.21338958e+20\n",
      " -1.03554051e+18 -1.15962850e+20]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.9999910000719996\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.301303748479285\n",
      "()\n",
      "Backward pass epoch 8\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 5.26718537e+02  1.67765984e+02 -6.57722603e+02 -9.10299588e+02\n",
      "   1.06112545e+03 -2.59791290e+02  1.55910188e+03 -8.72435227e+02\n",
      "   7.12593157e+01 -6.85727187e+02]\n",
      " [ 3.34913621e+02  1.06197181e+02 -4.06591545e+02 -5.59361549e+02\n",
      "   6.38821245e+02 -1.62687823e+02  1.00292567e+03 -5.82251885e+02\n",
      "   5.95647699e+01 -4.31519565e+02]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 4.46931955e+05  1.24660264e+05 -5.88963317e+05 -8.37250627e+05\n",
      "   1.02734533e+06 -2.23956784e+05  1.24011250e+06 -6.00432883e+05\n",
      "  -1.02895011e+04 -5.78156926e+05]\n",
      " [-4.60323777e-03 -4.85454352e-03 -4.47995828e-03 -7.15286507e-03\n",
      "   5.53213409e-03 -7.43408901e-03  3.83367151e-02 -6.77708900e-03\n",
      "  -3.22834359e-03 -5.44637191e-03]\n",
      " [ 1.98911797e-04  3.36728580e-03 -2.69448826e-03 -4.04933553e-04\n",
      "  -4.35333783e-04 -1.87899555e-03  7.63299718e-04  9.49154277e-04\n",
      "   6.43408887e-04 -3.68530740e-04]\n",
      " [-1.70903564e-02  1.00638136e-02 -5.69616870e-03  2.55623705e-02\n",
      "  -1.49813336e-02 -5.79633992e-03 -1.73961602e-02  1.63271858e-02\n",
      "  -5.62384560e-03  1.55699431e-02]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "New_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 1.65491854e+11 -1.28668283e+11 -1.58470387e+11 -1.68166007e+11\n",
      "   2.59429478e+11 -1.35031204e+11  6.51434824e+11 -1.69614428e+11\n",
      "  -1.47708752e+11 -1.68697097e+11]\n",
      " [ 7.61796543e+10 -5.94475408e+10 -7.32402430e+10 -7.77284580e+10\n",
      "   1.19898967e+11 -6.24307825e+10  3.01413806e+11 -7.83982683e+10\n",
      "  -6.82725490e+10 -7.79745861e+10]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 1.62187878e+13 -1.25900820e+13 -1.55043251e+13 -1.64523687e+13\n",
      "   2.53817989e+13 -1.32089197e+13  6.37042452e+13 -1.65940490e+13\n",
      "  -1.44508224e+13 -1.65042650e+13]\n",
      " [-4.62799876e-02 -2.50113795e-02 -9.30531383e-03  2.11605033e-01\n",
      "  -3.57861543e-02 -2.63367863e-02 -4.03241508e-03 -2.53698321e-02\n",
      "  -1.98471983e-02 -1.97436150e-02]\n",
      " [ 1.31793449e+00  4.77364173e+00 -7.64681121e-01 -7.62391567e-01\n",
      "  -7.62421967e-01 -7.55982588e-01 -7.61223333e-01 -7.61037479e-01\n",
      "  -7.61343224e-01 -7.62355164e-01]\n",
      " [-4.85128131e+01  1.93034096e+02  3.85202955e+01 -4.69078180e+01\n",
      "  -4.85104371e+01 -4.38375172e+01 -2.35944677e+01 -4.04975096e+01\n",
      "   5.28762862e+01 -3.25691759e+01]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.14217270e+14]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.29768495e+14]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.33964330e+14]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.61282619e+14]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.38730084e+14]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.57099223e+14]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 3.76756363e+28 2.38497811e+28 ... 0.00000000e+00\n",
      "  4.97517189e+28 0.00000000e+00]\n",
      " [0.00000000e+00 4.28210995e+28 2.71070118e+28 ... 0.00000000e+00\n",
      "  5.65464470e+28 0.00000000e+00]\n",
      " [0.00000000e+00 4.42066586e+28 2.79841096e+28 ... 0.00000000e+00\n",
      "  5.83761145e+28 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 5.32138662e+28 3.36859371e+28 ... 0.00000000e+00\n",
      "  7.02703824e+28 0.00000000e+00]\n",
      " [0.00000000e+00 4.57731024e+28 2.89757152e+28 ... 0.00000000e+00\n",
      "  6.04446476e+28 0.00000000e+00]\n",
      " [0.00000000e+00 5.18384602e+28 3.28152645e+28 ... 0.00000000e+00\n",
      "  6.84541204e+28 0.00000000e+00]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 9.25238195e+45 -7.18540297e+45 -8.84902453e+45 -9.39024626e+45\n",
      "  1.44864653e+46 -7.53925121e+45  3.63638796e+46 -9.47111707e+45\n",
      " -8.24780999e+45 -9.41987477e+45]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.9999910000719996\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.3089918450613465\n",
      "()\n",
      "Backward pass epoch 9\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 1.65491854e+11 -1.28668283e+11 -1.58470387e+11 -1.68166007e+11\n",
      "   2.59429478e+11 -1.35031204e+11  6.51434824e+11 -1.69614428e+11\n",
      "  -1.47708752e+11 -1.68697097e+11]\n",
      " [ 7.61796543e+10 -5.94475408e+10 -7.32402430e+10 -7.77284580e+10\n",
      "   1.19898967e+11 -6.24307825e+10  3.01413806e+11 -7.83982683e+10\n",
      "  -6.82725490e+10 -7.79745861e+10]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 1.62187878e+13 -1.25900820e+13 -1.55043251e+13 -1.64523687e+13\n",
      "   2.53817989e+13 -1.32089197e+13  6.37042452e+13 -1.65940490e+13\n",
      "  -1.44508224e+13 -1.65042650e+13]\n",
      " [-4.62799876e-02 -2.50113795e-02 -9.30531383e-03  2.11605033e-01\n",
      "  -3.57861543e-02 -2.63367863e-02 -4.03241508e-03 -2.53698321e-02\n",
      "  -1.98471983e-02 -1.97436150e-02]\n",
      " [ 1.31793449e+00  4.77364173e+00 -7.64681121e-01 -7.62391567e-01\n",
      "  -7.62421967e-01 -7.55982588e-01 -7.61223333e-01 -7.61037479e-01\n",
      "  -7.61343224e-01 -7.62355164e-01]\n",
      " [-4.85128131e+01  1.93034096e+02  3.85202955e+01 -4.69078180e+01\n",
      "  -4.85104371e+01 -4.38375172e+01 -2.35944677e+01 -4.04975096e+01\n",
      "   5.28762862e+01 -3.25691759e+01]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "New_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 3.49378983e+27  2.82497500e+27 -6.31535171e+27 -7.15885427e+27\n",
      "   8.67453004e+27 -2.48022118e+27  1.21794676e+28 -7.58208555e+27\n",
      "   1.89189945e+27 -5.52814922e+27]\n",
      " [ 2.21167016e+27  1.78829270e+27 -3.99780261e+27 -4.53176507e+27\n",
      "   5.49123199e+27 -1.57005151e+27  7.70996116e+27 -4.79968347e+27\n",
      "   1.19762770e+27 -3.49948105e+27]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 2.93454211e+30  2.37277528e+30 -5.30444884e+30 -6.01292817e+30\n",
      "   7.28598983e+30 -2.08321618e+30  1.02298844e+31 -6.36840948e+30\n",
      "   1.58906206e+30 -4.64325103e+30]\n",
      " [-4.62799876e-02 -2.50113795e-02 -9.30531383e-03  2.11605033e-01\n",
      "  -3.57861543e-02 -2.63367863e-02 -4.03241508e-03 -2.53698321e-02\n",
      "  -1.98471983e-02 -1.97436150e-02]\n",
      " [ 3.66175398e+16  3.01060573e+16 -6.66863688e+16 -7.58219046e+16\n",
      "   9.17259481e+16 -2.59393410e+16  1.28997296e+17 -8.03888201e+16\n",
      "   2.00454887e+16 -5.86558950e+16]\n",
      " [-4.85128131e+01  1.93034096e+02  3.85202955e+01 -4.69078180e+01\n",
      "  -4.85104371e+01 -4.38375172e+01 -2.35944677e+01 -4.04975096e+01\n",
      "   5.28762862e+01 -3.25691759e+01]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.80861436e+29]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 2.40773566e+29]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 2.73447163e+29]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 6.88379484e+60 3.18301688e+60 ... 0.00000000e+00\n",
      "  6.69432347e+60 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 4.35180795e+60 2.01224448e+60 ... 0.00000000e+00\n",
      "  4.23202765e+60 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.94235957e+60 2.28531127e+60 ... 0.00000000e+00\n",
      "  4.80632477e+60 0.00000000e+00]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 3.56409614e+94  2.88181283e+94 -6.44242516e+94 -7.30289652e+94\n",
      "  8.84907111e+94 -2.53013318e+94  1.24245269e+95 -7.73464033e+94\n",
      "  1.92996739e+94 -5.63937923e+94]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.9999910000719996\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.301303748479285\n",
      "()\n",
      "Backward pass epoch 10\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 10\n",
      "Old_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 3.49378983e+27  2.82497500e+27 -6.31535171e+27 -7.15885427e+27\n",
      "   8.67453004e+27 -2.48022118e+27  1.21794676e+28 -7.58208555e+27\n",
      "   1.89189945e+27 -5.52814922e+27]\n",
      " [ 2.21167016e+27  1.78829270e+27 -3.99780261e+27 -4.53176507e+27\n",
      "   5.49123199e+27 -1.57005151e+27  7.70996116e+27 -4.79968347e+27\n",
      "   1.19762770e+27 -3.49948105e+27]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 2.93454211e+30  2.37277528e+30 -5.30444884e+30 -6.01292817e+30\n",
      "   7.28598983e+30 -2.08321618e+30  1.02298844e+31 -6.36840948e+30\n",
      "   1.58906206e+30 -4.64325103e+30]\n",
      " [-4.62799876e-02 -2.50113795e-02 -9.30531383e-03  2.11605033e-01\n",
      "  -3.57861543e-02 -2.63367863e-02 -4.03241508e-03 -2.53698321e-02\n",
      "  -1.98471983e-02 -1.97436150e-02]\n",
      " [ 3.66175398e+16  3.01060573e+16 -6.66863688e+16 -7.58219046e+16\n",
      "   9.17259481e+16 -2.59393410e+16  1.28997296e+17 -8.03888201e+16\n",
      "   2.00454887e+16 -5.86558950e+16]\n",
      " [-4.85128131e+01  1.93034096e+02  3.85202955e+01 -4.69078180e+01\n",
      "  -4.85104371e+01 -4.38375172e+01 -2.35944677e+01 -4.04975096e+01\n",
      "   5.28762862e+01 -3.25691759e+01]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "New_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 9.49242412e+60 -8.28396957e+60 -9.94738300e+60 -1.01198128e+61\n",
      "   2.05468574e+61 -8.50553014e+60  3.64095953e+61 -1.01353914e+61\n",
      "  -9.32079915e+60 -1.01359907e+61]\n",
      " [ 4.38922817e+60 -3.83044753e+60 -4.59959785e+60 -4.67932815e+60\n",
      "   9.50071806e+60 -3.93289554e+60  1.68355332e+61 -4.68653159e+60\n",
      "  -4.30987002e+60 -4.68680870e+60]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 9.28525205e+62 -8.10317201e+62 -9.73028145e+62 -9.89894798e+62\n",
      "   2.00984224e+63 -8.31989702e+62  3.56149562e+63 -9.91418660e+62\n",
      "  -9.11737279e+62 -9.91477282e+62]\n",
      " [-4.62799876e-02 -2.50113795e-02 -9.30531383e-03  2.11605033e-01\n",
      "  -3.57861543e-02 -2.63367863e-02 -4.03241508e-03 -2.53698321e-02\n",
      "  -1.98471983e-02 -1.97436150e-02]\n",
      " [ 1.46178757e+49 -1.27569139e+49 -1.53184905e+49 -1.55840241e+49\n",
      "   3.16411703e+49 -1.30981065e+49  5.60690222e+49 -1.56080144e+49\n",
      "  -1.43535815e+49 -1.56089373e+49]\n",
      " [-4.85128131e+01  1.93034096e+02  3.85202955e+01 -4.69078180e+01\n",
      "  -4.85104371e+01 -4.38375172e+01 -2.35944677e+01 -4.04975096e+01\n",
      "   5.28762862e+01 -3.25691759e+01]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 6.91530364e+63]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 7.99286915e+63]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 8.24188098e+63]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 9.90479715e+63]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 8.47043857e+63]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 9.66842255e+63]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 1.38255320e+128 8.75196761e+127 ... 0.00000000e+000\n",
      "  1.82569980e+128 0.00000000e+000]\n",
      " [0.00000000e+000 1.59798722e+128 1.01157282e+128 ... 0.00000000e+000\n",
      "  2.11018639e+128 0.00000000e+000]\n",
      " [0.00000000e+000 1.64777131e+128 1.04308761e+128 ... 0.00000000e+000\n",
      "  2.17592766e+128 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 1.98023250e+128 1.25354530e+128 ... 0.00000000e+000\n",
      "  2.61495187e+128 0.00000000e+000]\n",
      " [0.00000000e+000 1.69346605e+128 1.07201372e+128 ... 0.00000000e+000\n",
      "  2.23626884e+128 0.00000000e+000]\n",
      " [0.00000000e+000 1.93297492e+128 1.22362987e+128 ... 0.00000000e+000\n",
      "  2.55254694e+128 0.00000000e+000]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ 1.94483494e+195 -1.69724333e+195 -2.03804822e+195 -2.07337613e+195\n",
      "  4.20969878e+195 -1.74263729e+195  7.45970179e+195 -2.07656792e+195\n",
      " -1.90967193e+195 -2.07669071e+195]\n",
      "Output layer\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "0.9999999999999999\n",
      "At least one output is closer to 1: \n",
      "0.9999910000719996\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 2.3089918450613465\n",
      "()\n",
      "Backward pass epoch 11\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 11\n",
      "Old_weights\n",
      "[[-2.07482997e+01 -2.08030242e+01 -2.28891915e+00  1.50177615e+02\n",
      "  -2.03655931e+01 -2.06273027e+01 -2.07195775e+01 -1.76735928e+01\n",
      "  -2.00150701e+01 -6.93600583e+00]\n",
      " [ 9.49242412e+60 -8.28396957e+60 -9.94738300e+60 -1.01198128e+61\n",
      "   2.05468574e+61 -8.50553014e+60  3.64095953e+61 -1.01353914e+61\n",
      "  -9.32079915e+60 -1.01359907e+61]\n",
      " [ 4.38922817e+60 -3.83044753e+60 -4.59959785e+60 -4.67932815e+60\n",
      "   9.50071806e+60 -3.93289554e+60  1.68355332e+61 -4.68653159e+60\n",
      "  -4.30987002e+60 -4.68680870e+60]\n",
      " [-3.76530758e-02  2.88586360e-02  3.48069141e-02  2.32191254e-02\n",
      "  -3.30497798e-02  9.30130196e-03 -6.75516014e-02  9.46640291e-03\n",
      "   1.93492786e-02  1.30643510e-02]\n",
      " [ 9.28525205e+62 -8.10317201e+62 -9.73028145e+62 -9.89894798e+62\n",
      "   2.00984224e+63 -8.31989702e+62  3.56149562e+63 -9.91418660e+62\n",
      "  -9.11737279e+62 -9.91477282e+62]\n",
      " [-4.62799876e-02 -2.50113795e-02 -9.30531383e-03  2.11605033e-01\n",
      "  -3.57861543e-02 -2.63367863e-02 -4.03241508e-03 -2.53698321e-02\n",
      "  -1.98471983e-02 -1.97436150e-02]\n",
      " [ 1.46178757e+49 -1.27569139e+49 -1.53184905e+49 -1.55840241e+49\n",
      "   3.16411703e+49 -1.30981065e+49  5.60690222e+49 -1.56080144e+49\n",
      "  -1.43535815e+49 -1.56089373e+49]\n",
      " [-4.85128131e+01  1.93034096e+02  3.85202955e+01 -4.69078180e+01\n",
      "  -4.85104371e+01 -4.38375172e+01 -2.35944677e+01 -4.04975096e+01\n",
      "   5.28762862e+01 -3.25691759e+01]\n",
      " [-8.61613603e-03  1.17029913e-02  2.68916684e-03  1.80309177e-02\n",
      "  -3.22945835e-02 -6.64386632e-03  1.07769659e-02 -1.23699781e-02\n",
      "   1.68187505e-02  1.40638153e-03]\n",
      " [-4.06580459e-02  9.89175573e-02  2.87309424e-02 -2.76875871e-02\n",
      "   1.23127370e-01 -3.47474750e-03 -1.65941722e-01 -4.04827133e-02\n",
      "   5.82326130e-02 -3.35700314e-02]]\n",
      "New_weights\n",
      "[[-2.07482997e+001 -2.08030242e+001 -2.28891915e+000  1.50177615e+002\n",
      "  -2.03655931e+001 -2.06273027e+001 -2.07195775e+001 -1.76735928e+001\n",
      "  -2.00150701e+001 -6.93600583e+000]\n",
      " [ 1.07863701e+127  1.14416905e+127 -2.14438368e+127 -2.59783152e+127\n",
      "   3.01586079e+127 -9.25936892e+126  4.65703965e+127 -2.90200919e+127\n",
      "   7.78206160e+126 -2.10375138e+127]\n",
      " [ 6.82808894e+126  7.24292598e+126 -1.35745782e+127 -1.64450361e+127\n",
      "   1.90912841e+127 -5.86145234e+126  2.94804281e+127 -1.83705701e+127\n",
      "   4.92627344e+126 -1.33173638e+127]\n",
      " [-3.76530758e-002  2.88586360e-002  3.48069141e-002  2.32191254e-002\n",
      "  -3.30497798e-002  9.30130196e-003 -6.75516014e-002  9.46640291e-003\n",
      "   1.93492786e-002  1.30643510e-002]\n",
      " [ 9.05978463e+129  9.61020719e+129 -1.80112995e+130 -2.18199392e+130\n",
      "   2.53310881e+130 -7.77721208e+129  3.91158246e+130 -2.43748155e+130\n",
      "   6.53637888e+129 -1.76700171e+130]\n",
      " [-4.62799876e-002 -2.50113795e-002 -9.30531383e-003  2.11605033e-001\n",
      "  -3.57861543e-002 -2.63367863e-002 -4.03241508e-003 -2.53698321e-002\n",
      "  -1.98471983e-002 -1.97436150e-002]\n",
      " [ 1.14108227e+116  1.21040814e+116 -2.26852793e+116 -2.74822711e+116\n",
      "   3.19045724e+116 -9.79541918e+115  4.92664845e+116 -3.07001446e+116\n",
      "   8.23258648e+115 -2.22554332e+116]\n",
      " [-4.85128131e+001  1.93034096e+002  3.85202955e+001 -4.69078180e+001\n",
      "  -4.85104371e+001 -4.38375172e+001 -2.35944677e+001 -4.04975096e+001\n",
      "   5.28762862e+001 -3.25691759e+001]\n",
      " [-8.61613603e-003  1.17029913e-002  2.68916684e-003  1.80309177e-002\n",
      "  -3.22945835e-002 -6.64386632e-003  1.07769659e-002 -1.23699781e-002\n",
      "   1.68187505e-002  1.40638153e-003]\n",
      " [-4.06580459e-002  9.89175573e-002  2.87309424e-002 -2.76875871e-002\n",
      "   1.23127370e-001 -3.47474750e-003 -1.65941722e-001 -4.04827133e-002\n",
      "   5.82326130e-002 -3.35700314e-002]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 1.34839246e+129]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 8.81019544e+128]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 7.94891586e+128]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[0.00000000e+000 8.94007235e+259 4.13382471e+259 ... 0.00000000e+000\n",
      "  8.69400346e+259 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 5.84131006e+259 2.70097947e+259 ... 0.00000000e+000\n",
      "  5.68053232e+259 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 5.27026699e+259 2.43693329e+259 ... 0.00000000e+000\n",
      "  5.12520679e+259 0.00000000e+000]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[ inf  inf -inf -inf  inf -inf  inf -inf  inf -inf]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 12\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 12\n",
      "Old_weights\n",
      "[[-2.07482997e+001 -2.08030242e+001 -2.28891915e+000  1.50177615e+002\n",
      "  -2.03655931e+001 -2.06273027e+001 -2.07195775e+001 -1.76735928e+001\n",
      "  -2.00150701e+001 -6.93600583e+000]\n",
      " [ 1.07863701e+127  1.14416905e+127 -2.14438368e+127 -2.59783152e+127\n",
      "   3.01586079e+127 -9.25936892e+126  4.65703965e+127 -2.90200919e+127\n",
      "   7.78206160e+126 -2.10375138e+127]\n",
      " [ 6.82808894e+126  7.24292598e+126 -1.35745782e+127 -1.64450361e+127\n",
      "   1.90912841e+127 -5.86145234e+126  2.94804281e+127 -1.83705701e+127\n",
      "   4.92627344e+126 -1.33173638e+127]\n",
      " [-3.76530758e-002  2.88586360e-002  3.48069141e-002  2.32191254e-002\n",
      "  -3.30497798e-002  9.30130196e-003 -6.75516014e-002  9.46640291e-003\n",
      "   1.93492786e-002  1.30643510e-002]\n",
      " [ 9.05978463e+129  9.61020719e+129 -1.80112995e+130 -2.18199392e+130\n",
      "   2.53310881e+130 -7.77721208e+129  3.91158246e+130 -2.43748155e+130\n",
      "   6.53637888e+129 -1.76700171e+130]\n",
      " [-4.62799876e-002 -2.50113795e-002 -9.30531383e-003  2.11605033e-001\n",
      "  -3.57861543e-002 -2.63367863e-002 -4.03241508e-003 -2.53698321e-002\n",
      "  -1.98471983e-002 -1.97436150e-002]\n",
      " [ 1.14108227e+116  1.21040814e+116 -2.26852793e+116 -2.74822711e+116\n",
      "   3.19045724e+116 -9.79541918e+115  4.92664845e+116 -3.07001446e+116\n",
      "   8.23258648e+115 -2.22554332e+116]\n",
      " [-4.85128131e+001  1.93034096e+002  3.85202955e+001 -4.69078180e+001\n",
      "  -4.85104371e+001 -4.38375172e+001 -2.35944677e+001 -4.04975096e+001\n",
      "   5.28762862e+001 -3.25691759e+001]\n",
      " [-8.61613603e-003  1.17029913e-002  2.68916684e-003  1.80309177e-002\n",
      "  -3.22945835e-002 -6.64386632e-003  1.07769659e-002 -1.23699781e-002\n",
      "   1.68187505e-002  1.40638153e-003]\n",
      " [-4.06580459e-002  9.89175573e-002  2.87309424e-002 -2.76875871e-002\n",
      "   1.23127370e-001 -3.47474750e-003 -1.65941722e-001 -4.04827133e-002\n",
      "   5.82326130e-002 -3.35700314e-002]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 13\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 13\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 14\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 14\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 15\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 15\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 16\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 16\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 17\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 17\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 18\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 18\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n",
      "(1797, 64)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "Output layer\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "Sums to 1: \n",
      "nan\n",
      "At least one output is closer to 1: \n",
      "nan\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 19\n",
      "%Shape of output derivative_error(1797, 64)\n",
      "Update pass epoch 19\n",
      "Old_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "New_weights\n",
      "[[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]]\n",
      "End of Backwards pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\3879336325.py:23: RuntimeWarning: invalid value encountered in subtract\n",
      "  reg = x - np.max(x)\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.01, dropout_rate = 0, batch_size = 1, epochs = 20)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 10, 'softmax', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 1)\n"
     ]
    }
   ],
   "source": [
    "y.shape\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Sigmoid\n",
      "(569, 30)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[2.21613348 0.         0.         ... 3.72311489 0.         0.94676015]\n",
      " [3.7304495  0.         0.         ... 4.03361165 0.         0.65290222]\n",
      " [3.39051892 0.         0.         ... 3.43332559 0.         0.54207312]\n",
      " ...\n",
      " [2.51239161 0.         0.         ... 2.24068313 0.         0.26618449]\n",
      " [3.52647021 0.         0.         ... 3.62733276 0.         0.55609423]\n",
      " [0.46854619 0.         0.         ... 0.39847489 0.         0.03991069]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-0.06098279]\n",
      "Output layer\n",
      "[[0.48475902]\n",
      " [0.48628978]\n",
      " [0.48780721]\n",
      " [0.49560722]\n",
      " [0.48897652]\n",
      " [0.4944544 ]\n",
      " [0.48854531]\n",
      " [0.49326304]\n",
      " [0.4945327 ]\n",
      " [0.49472082]]\n",
      "Sums to 1: \n",
      "0.48475902439676466\n",
      "At least one output is closer to 1: \n",
      "0.4984540518173882\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.4400324460485686\n",
      "()\n",
      "Backward pass epoch 0\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[-0.00038111]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.00024587]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 1\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 2\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 3\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 4\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 5\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 6\n",
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 7\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 8\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 9\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 10\n",
      "Update pass epoch 10\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 11\n",
      "Update pass epoch 11\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 12\n",
      "Update pass epoch 12\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 13\n",
      "Update pass epoch 13\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 14\n",
      "Update pass epoch 14\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 15\n",
      "Update pass epoch 15\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 16\n",
      "Update pass epoch 16\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 17\n",
      "Update pass epoch 17\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 18\n",
      "Update pass epoch 18\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 19\n",
      "Update pass epoch 19\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 20\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 20\n",
      "Update pass epoch 20\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 21\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 21\n",
      "Update pass epoch 21\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 22\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 22\n",
      "Update pass epoch 22\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 23\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 23\n",
      "Update pass epoch 23\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 24\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 24\n",
      "Update pass epoch 24\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 25\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 25\n",
      "Update pass epoch 25\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 26\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 26\n",
      "Update pass epoch 26\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 27\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 27\n",
      "Update pass epoch 27\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 28\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 28\n",
      "Update pass epoch 28\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 29\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 29\n",
      "Update pass epoch 29\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 30\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 30\n",
      "Update pass epoch 30\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 31\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 31\n",
      "Update pass epoch 31\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 32\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 32\n",
      "Update pass epoch 32\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 33\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 33\n",
      "Update pass epoch 33\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 34\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 34\n",
      "Update pass epoch 34\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 35\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 35\n",
      "Update pass epoch 35\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 36\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 36\n",
      "Update pass epoch 36\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 37\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 37\n",
      "Update pass epoch 37\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 38\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 38\n",
      "Update pass epoch 38\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 39\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 39\n",
      "Update pass epoch 39\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 40\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 40\n",
      "Update pass epoch 40\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 41\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 41\n",
      "Update pass epoch 41\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 42\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 42\n",
      "Update pass epoch 42\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 43\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 43\n",
      "Update pass epoch 43\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 44\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 44\n",
      "Update pass epoch 44\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 45\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 45\n",
      "Update pass epoch 45\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 46\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 46\n",
      "Update pass epoch 46\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 47\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 47\n",
      "Update pass epoch 47\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 48\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 48\n",
      "Update pass epoch 48\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 49\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[108.62733697   0.           0.         ...  11.62842405   0.\n",
      "    0.        ]\n",
      " [112.6090909    0.           0.         ...  12.12222726   0.\n",
      "    0.        ]\n",
      " [ 99.32811521   0.           0.         ...  10.56054842   0.\n",
      "    0.        ]\n",
      " ...\n",
      " [ 66.59794096   0.           0.         ...   7.00161115   0.\n",
      "    0.        ]\n",
      " [105.37042468   0.           0.         ...  11.19334009   0.\n",
      "    0.        ]\n",
      " [ 15.28297087   0.           0.         ...   1.49904141   0.\n",
      "    0.        ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-1716.90550306]\n",
      "Output layer\n",
      "[[0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [5.52535631e-221]\n",
      " [0.00000000e+000]\n",
      " [1.16641115e-285]\n",
      " [0.00000000e+000]\n",
      " [0.00000000e+000]\n",
      " [1.09958278e-289]\n",
      " [6.96877149e-276]]\n",
      "Sums to 1: \n",
      "0.0\n",
      "At least one output is closer to 1: \n",
      "3.964697896710596e-74\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: nan\n",
      "()\n",
      "Backward pass epoch 49\n",
      "Update pass epoch 49\n",
      "Old_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "New_weights\n",
      "[[-0.06317535]\n",
      " [-0.000932  ]\n",
      " [-0.00115689]\n",
      " [ 0.00092105]\n",
      " [-0.09873505]\n",
      " [-0.00060072]\n",
      " [-0.00080082]\n",
      " [-0.00080518]\n",
      " [-0.00208977]\n",
      " [-0.00020037]]\n",
      "End of Backwards pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\3075896579.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\971627139.py:42: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_29916\\971627139.py:42: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.01, dropout_rate = 0, batch_size = 1, epochs = 50)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 1, 'sigmoid', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e - Implement optimizer\n",
    "Implement any two optimizers of your choice. Briefly present the optimizers \n",
    "in the report. The optimizers can be flavours of gradient descent. For \n",
    "instance: Stochastic gradient descent (SGD) and SGD with momentum. \n",
    "SGD and mini-batch gradient descent, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f - Evaluate different neural network architectures/parameters, present and discuss your results.\n",
    "Be creative in the analysis and discussion. Evaluate different\n",
    "hyperparameters. For instance: different network architectures, activation \n",
    "functions, comparison of optimizers, L1/L2 performance comparison with \n",
    "dropout, etc. Support your results with plots/graph and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
