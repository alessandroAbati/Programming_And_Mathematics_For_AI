{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Mathematics for AI - coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The task is about classification on the MNIST dataset. \n",
    "You can use other APIâ€™s/libraries for loading the dataset, but not for the neural network \n",
    "implementation. The point of this task is to develop a multi-layer neural network for \n",
    "classification using numpy. The task requires following sub-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Implement sigmoid and ReLU layers\n",
    "For this sub-task, you should implement forward and backward pass for \n",
    "sigmoid and ReLU. You should consider presenting these activation\n",
    "functions in the report with any pros cons if they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLu(x):\n",
    "    '''\n",
    "    Implementation of reLu function.\n",
    "    '''\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Implementation of Sigmoid function.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Implementation of Softmax function\n",
    "    '''\n",
    "    normalization = np.sum(np.exp(x))\n",
    "    return [np.exp(el)/normalization for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ReLU activation function')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKoUlEQVR4nO3deVxU9f4/8NewDfsAsokimwoqi5ZJam5JuZZ72vXeTLMytTKXXEoRLXHNbua3rNtVy0rFPbO8rpm55IorqIgKyiIiuwww8/n9gcxPZBGGgTPL6/l48HjEmXNmXjNH4NV5nzMjE0IIEBERERkgM6kDEBEREWmLRYaIiIgMFosMERERGSwWGSIiIjJYLDJERERksFhkiIiIyGCxyBAREZHBYpEhIiIig8UiQ0RERAaLRYaIdO7111+Hr6+vJI89d+5cyGQySR47Ly8PY8eOhaenJ2QyGSZNmiRJjieR8jUi0jUWGaJaWrNmDWQymebLwsICTZo0weuvv47bt29rdZ8HDx6ETCbDpk2bqlxHJpNh4sSJld62adMmyGQyHDx4UKvH18adO3cwd+5cnD17tsEes0xBQQHmzp3boM+3JhYsWIA1a9bgnXfewQ8//IB//etfkmXR19eISNcspA5AZKjmzZsHPz8/FBYW4tixY1izZg0OHz6MCxcuwNraWup49e7OnTuIioqCr68v2rZtW+62b7/9Fmq1ut4eu6CgAFFRUQCA7t27l7vt448/xowZM+rtsauzf/9+PPvss4iMjJTk8R+lr68Rka6xyBBpqU+fPmjfvj0AYOzYsXB1dcWiRYuwY8cOvPLKKxKnk5alpaVkj21hYQELC2l+taWnp6N169aSPHZtSPkaEekaR0tEOtKlSxcAQEJCQrnlcXFxGDp0KFxcXGBtbY327dtjx44dUkTEzZs3MX78eAQGBsLGxgaNGjXCsGHDcOPGjQrrZmVl4YMPPoCvry/kcjmaNm2K1157DRkZGTh48CCeeeYZAMDo0aM1Y7Y1a9YAKH+OTHFxMVxcXDB69OgKj5GTkwNra2tMnToVAFBUVIQ5c+bg6aefhkKhgJ2dHbp06YIDBw5otrlx4wbc3NwAAFFRUZrHnjt3LoDKz/8oKSnB/PnzERAQALlcDl9fX8yaNQtKpbLcer6+vujfvz8OHz6MDh06wNraGv7+/vj++++rfV3LRoOJiYn49ddfNZlu3LihGUU+/hqXbfPo6Kd79+4IDg7GpUuX0KNHD9ja2qJJkyZYvHhxhccsLCzE3Llz0bJlS1hbW6Nx48YYPHgwEhIS9PI1IqovLDJEOlL2h8rZ2Vmz7OLFi3j22Wdx+fJlzJgxA8uWLYOdnR0GDhyIrVu3NnjGEydO4MiRIxgxYgS++OILjBs3Dvv27UP37t1RUFCgWS8vLw9dunTBihUr8OKLL+Lf//43xo0bh7i4OCQnJ6NVq1aYN28eAOCtt97CDz/8gB9++AFdu3at8JiWlpYYNGgQtm3bhqKionK3bdu2DUqlEiNGjABQWmz+85//oHv37li0aBHmzp2Lu3fvolevXppzcdzc3PDVV18BAAYNGqR57MGDB1f5vMeOHYs5c+bgqaeewvLly9GtWzdER0drHvdR165dw9ChQ/HCCy9g2bJlcHZ2xuuvv46LFy9Wef+tWrXCDz/8AFdXV7Rt21aTqaxM1Mb9+/fRu3dvhIWFYdmyZQgKCsL06dPx22+/adZRqVTo378/oqKi8PTTT2PZsmV4//33kZ2djQsXLujla0RUbwQR1crq1asFALF3715x9+5dkZSUJDZt2iTc3NyEXC4XSUlJmnV79uwpQkJCRGFhoWaZWq0WnTp1Ei1atNAsO3DggAAgYmJiqnxcAGLChAmV3hYTEyMAiAMHDlSbvaCgoMKyo0ePCgDi+++/1yybM2eOACC2bNlSYX21Wi2EEOLEiRMCgFi9enWFdUaNGiV8fHw03+/evVsAEL/88ku59fr27Sv8/f0135eUlAilUllunfv37wsPDw8xZswYzbK7d+8KACIyMrLCY0dGRopHf7WdPXtWABBjx44tt97UqVMFALF//37NMh8fHwFAHDp0SLMsPT1dyOVyMWXKlAqP9TgfHx/Rr1+/csvK/r0kJiaWW162zx/dZ926dauwL5RKpfD09BRDhgzRLPvvf/8rAIjPPvusQoay/aOvrxGRrvGIDJGWIiIi4ObmBm9vbwwdOhR2dnbYsWMHmjZtCgDIzMzE/v378corryA3NxcZGRnIyMjAvXv30KtXL1y9elXrq5y0ZWNjo/nv4uJi3Lt3D82bN4eTkxNOnz6tuW3z5s0ICwvDoEGDKtyHNpftPv/883B1dcWGDRs0y+7fv489e/Zg+PDhmmXm5uawsrICAKjVamRmZqKkpATt27cvl682du3aBQCYPHlyueVTpkwBAPz666/llrdu3VozJgRKjwAFBgbi+vXrWj1+bdnb2+Of//yn5nsrKyt06NCh3ONv3rwZrq6uePfddytsr83+MbTXiOhRLDJEWlq5ciX27NmDTZs2oW/fvsjIyIBcLtfcfu3aNQghMHv2bLi5uZX7KruqJT09XaeZnvRH7MGDB5gzZw68vb0hl8vh6uoKNzc3ZGVlITs7W7NeQkICgoODdZbLwsICQ4YMwfbt2zXnXGzZsgXFxcXligwArF27FqGhobC2tkajRo3g5uaGX3/9tVy+2rh58ybMzMzQvHnzcss9PT3h5OSEmzdvllverFmzCvfh7OyM+/fva/X4tdW0adMK+/Hxx09ISEBgYKDOTtg1tNeI6FE8bZ1ISx06dNBctTRw4EA899xz+Mc//oH4+HjY29trLj+eOnUqevXqVel9PP6HozpyuRwPHjyo9Lay81uedNn3u+++i9WrV2PSpEno2LEjFAoFZDIZRowYUa+XSwPAiBEjsGrVKvz2228YOHAgNm7ciKCgIISFhWnWWbduHV5//XUMHDgQ06ZNg7u7O8zNzREdHV3hJOraqumRCnNz80qXCyF0+rgqlapBHr82pHqNiOqCRYZIB8r+2Pbo0QNffvklZsyYAX9/fwClJ7tGRETU+TF8fHwQHx9f6W1ly318fKq9j02bNmHUqFFYtmyZZllhYSGysrLKrRcQEIALFy5Ue1+1HWF07doVjRs3xoYNG/Dcc89h//79+Oijjyrk8/f3x5YtW8rd/+Pvy1Kbx/bx8YFarcbVq1fRqlUrzfK0tDRkZWU98TWrq7KTvx9/jR8/ylEbAQEBOH78OIqLi6u81N2QXiOiuuBoiUhHunfvjg4dOuDzzz9HYWEh3N3d0b17d6xatQopKSkV1r97926t7r9v3744duwYTp06VW55VlYWfvzxR7Rt2xaenp7V3oe5uXmF/2tesWJFhaMDQ4YMQWxsbKVXVpVtb2dnp3n8mjAzM8PQoUPxyy+/4IcffkBJSUmFsVLZ/+k/mvH48eM4evRoufVsbW1r/Nh9+/YFAHz++eflln/22WcAgH79+tUov7YCAgIAAIcOHdIsU6lU+Oabb7S+zyFDhiAjIwNffvllhdvKXjtDeo2I6oJHZIh0aNq0aRg2bBjWrFmDcePGYeXKlXjuuecQEhKCN998E/7+/khLS8PRo0eRnJyM2NjYcttv3rwZcXFxFe531KhRmDFjBmJiYtC1a1e8/fbbCAoKwp07d7BmzRqkpKRg9erVT8zXv39//PDDD1AoFGjdujWOHj2KvXv3olGjRhWex6ZNmzBs2DCMGTMGTz/9NDIzM7Fjxw58/fXXCAsLQ0BAAJycnPD111/DwcEBdnZ2CA8Ph5+fX5WPP3z4cKxYsQKRkZEICQkp93//Zfm2bNmCQYMGoV+/fkhMTMTXX3+N1q1bIy8vT7OejY0NWrdujQ0bNqBly5ZwcXFBcHBwpef1hIWFYdSoUfjmm2+QlZWFbt264e+//8batWsxcOBA9OjR44mvW120adMGzz77LGbOnInMzEy4uLhg/fr1KCkp0fo+X3vtNXz//feYPHky/v77b3Tp0gX5+fnYu3cvxo8fjwEDBhjUa0RUJ9JdMEVkmMoupz1x4kSF21QqlQgICBABAQGipKRECCFEQkKCeO2114Snp6ewtLQUTZo0Ef379xebNm3SbFd2KW5VX3/++acQQojk5GQxduxY0aRJE2FhYSFcXFxE//79xbFjx2qU/f79+2L06NHC1dVV2Nvbi169eom4uDjh4+MjRo0aVW7de/fuiYkTJ4omTZoIKysr0bRpUzFq1CiRkZGhWWf79u2idevWwsLCotyl2I9ffl1GrVYLb29vAUB88sknld6+YMEC4ePjI+RyuWjXrp3YuXNnpfd35MgR8fTTTwsrK6tylxk/fmmxEEIUFxeLqKgo4efnJywtLYW3t7eYOXNmucvihaj88mkhSi+L7tatW+Uvag22T0hIEBEREUIulwsPDw8xa9YssWfPnkovv27Tpk2F7St7/gUFBeKjjz7SPCdPT08xdOhQkZCQoFlHH18jIl2TCcGzs4iIiMgw8RwZIiIiMlgsMkRERGSwWGSIiIjIYLHIEBERkcFikSEiIiKDxSJDREREBsvo3xBPrVbjzp07cHBw0OpTYYmIiKjhCSGQm5sLLy8vmJlVfdzF6IvMnTt34O3tLXUMIiIi0kJSUhKaNm1a5e1GX2QcHBwAlL4Qjo6OEqchIiKimsjJyYG3t7fm73hVjL7IlI2THB0dWWSIiIgMzJNOC+HJvkRERGSwWGSIiIjIYLHIEBERkcFikSEiIiKDxSJDREREBotFhoiIiAwWiwwREREZLBYZIiIiMlgsMkRERGSwWGSIiIjIYElaZA4dOoSXXnoJXl5ekMlk2LZtW7nbhRCYM2cOGjduDBsbG0RERODq1avShCUiIiK9I2mRyc/PR1hYGFauXFnp7YsXL8YXX3yBr7/+GsePH4ednR169eqFwsLCBk5KRERE+kjSD43s06cP+vTpU+ltQgh8/vnn+PjjjzFgwAAAwPfffw8PDw9s27YNI0aMaMioRERE9JicwmLEpeSig5+LZBn09hyZxMREpKamIiIiQrNMoVAgPDwcR48erXI7pVKJnJyccl9ERESke5/svIRXVh3FVwcTJMugt0UmNTUVAODh4VFuuYeHh+a2ykRHR0OhUGi+vL296zUnERGRKToQl46NJ5MhkwHP+DpLlkNvi4y2Zs6ciezsbM1XUlKS1JGIiIiMSnZBMWZsOQcAeKOzH9r7crRUgaenJwAgLS2t3PK0tDTNbZWRy+VwdHQs90VERES6E7XzItJylPB3tcPUXoGSZtHbIuPn5wdPT0/s27dPsywnJwfHjx9Hx44dJUxGRERkuvZeSsOW07dhJgOWvhIGa0tzSfNIetVSXl4erl27pvk+MTERZ8+ehYuLC5o1a4ZJkybhk08+QYsWLeDn54fZs2fDy8sLAwcOlC40ERGRicoqKMLMrecBAG929cdTzaQ7N6aMpEXm5MmT6NGjh+b7yZMnAwBGjRqFNWvW4MMPP0R+fj7eeustZGVl4bnnnsPvv/8Oa2trqSITERGZrLk7LuJurhLN3e3xQURLqeMAAGRCCCF1iPqUk5MDhUKB7Oxsni9DRESkpd8vpGLculMwkwFbxndGW2+nen28mv791ttzZIiIiEg/ZOYX4eNtpSOlcd0C6r3E1AaLDBEREVUrcsdFZOQVoaWHPd6PaCF1nHJYZIiIiKhKu86n4JfYOzA3k2HZsLaQW0h7ldLjWGSIiIioUhl5Sny87QIAYHz3AIQ0VUicqCIWGSIiIqpACIHZ2y4gM78IQZ4OePd5/RoplWGRISIiogp2nkvBbxdSYWEmw9JhYbCy0M/KoJ+piIiISDJ3c5WYs710pDTx+eYIbqJ/I6UyLDJERESkIYTAx9vO435BMVo3dsSEHs2ljlQtFhkiIiLS2BF7B7svpsHSvHSkZGmu31VBv9MRERFRg0nPKcSc7RcBAO893wKtvfT/HfFZZIiIiAhCCMzaeh7ZD4oR0kSBcd0DpI5UIywyREREhK1nbmPv5XRYmZsZxEipjGGkJCIionqTml2IuTtKR0rvR7RAoKeDxIlqjkWGiIjIhAkhMHPLOeQUliCsqQJvd/WXOlKtsMgQERGZsJhTyTgQfxdWFqUjJQsDGSmVMay0REREpDMp2Q8w/5dLAIApL7RECw/DGSmVYZEhIiIyQUIITN98HrnKErRr5oSxXQxrpFSGRYaIiMgEbTiRhENX7kL+cKRkbiaTOpJWWGSIiIhMzO2sB/jk18sAgGm9AhHgZi9xIu2xyBAREZkQIQSmbzqHPGUJ2vs4Y3RnP6kj1QmLDBERkQn56e9bOHwtA9aWZlhiwCOlMiwyREREJiIpswCfPhwpfdgrCH6udhInqjsWGSIiIhOgVgt8uOkcCopU6ODrgtc7+UodSSdYZIiIiEzAuuM3cfT6PdhYmmPJsFCYGfhIqQyLDBERkZG7da8A0bviAAAz+wbBp5Hhj5TKsMgQEREZMbVaYOqmWDwoVuFZfxf8M9xH6kg6xSJDRERkxNYevYG/EzNha2WOJUPDjGakVIZFhoiIyEglZuRj0e+lI6VZfVvB28VW4kS6xyJDRERkhFRqgWkxsSgsVuO55q4YGd5M6kj1gkWGiIjICK3+KxEnb96HvdwCC4eEQCYzrpFSGRYZIiIiI5NwNw9LdscDAD7q1wpNnY1vpFSGRYaIiMiIqNQCU2NioSxRo0sLV4x4xlvqSPWKRYaIiMiI/OfP6zhzKwsOcgssGhJqtCOlMiwyRERERuJaei6W7bkCAJj9Umt4OdlInKj+scgQEREZgRKVGlNizqGoRI0egW4Y9nRTqSM1CBYZIiIiI/DNn9cRm5QFB2sLRA82/pFSGRYZIiIiAxefmovP91wFAMx9qQ08FdYSJ2o4LDJEREQGrFilxtSYWBSp1Iho5Y7BTzWROlKDYpEhIiIyYKv+SMD529lQ2FhiwSDjfeO7qrDIEBERGajLKTn4977SkVLUy23g7mg6I6UyLDJEREQGqFilxpSNsShWCbzY2gMD2npJHUkSLDJEREQGaOWBa7iUkgNnW0t8aoIjpTIsMkRERAbm4p1sfLn/GgBg3oBguDnIJU4kHRYZIiIiA1JUUjpSKlEL9An2RP/QxlJHkhSLDBERkQH5cv9VxKXmwsXOCvMHBpvsSKkMiwwREZGBOJ+cjZUHEwAA8wcEw9XedEdKZVhkiIiIDICyRIWpMbFQqQX6hzZGPxMfKZVhkSEiIjIAX+y7ivi0XLjaW2HegGCp4+gNFhkiIiI9F5uUha8ejpQ+GRgCFzsriRPpDxYZIiIiPVZYrMKUmFioBTCgrRd6B3tKHUmvsMgQERHpseV7r+Baeh7cHOSY+1IbqePoHRYZIiIiPXX61n18e+g6AGDBoBA4c6RUAYsMERGRHiosLr1KSS2Awe2a4IXWHlJH0kssMkRERHpo2f/icf1uPtwd5IjkSKlKLDJERER65uSNTPzncCIAYOGQEChsLSVOpL9YZIiIiPTIgyIVpm06ByGAYU83xfNBHClVR6+LjEqlwuzZs+Hn5wcbGxsEBARg/vz5EEJIHY2IiKheLNkdj8SMfHg6WuPj/q2ljqP3LKQOUJ1Fixbhq6++wtq1a9GmTRucPHkSo0ePhkKhwHvvvSd1PCIiIp06fv0eVh95ZKRkw5HSk+h1kTly5AgGDBiAfv36AQB8fX3x888/4++//5Y4GRERkW4VFJVoRkojnvFG90B3qSMZBL0eLXXq1An79u3DlStXAACxsbE4fPgw+vTpU+U2SqUSOTk55b6IiIj03aLf4nArswBeCmt81K+V1HEMhl4fkZkxYwZycnIQFBQEc3NzqFQqfPrppxg5cmSV20RHRyMqKqoBUxIREdXN0YR7WHv0JgBg0dBQOFhzpFRTen1EZuPGjfjxxx/x008/4fTp01i7di2WLl2KtWvXVrnNzJkzkZ2drflKSkpqwMRERES1k68swbRNsQCAf4Q3Q5cWbhInMix6fURm2rRpmDFjBkaMGAEACAkJwc2bNxEdHY1Ro0ZVuo1cLodcLm/ImERERFqL/u0yku8/QBMnG8zqy5FSben1EZmCggKYmZWPaG5uDrVaLVEiIiIi3fnrWgbWHbsFAFgyNBT2cr0+vqCX9PoVe+mll/Dpp5+iWbNmaNOmDc6cOYPPPvsMY8aMkToaERFRneQWFuPDTecAAK919EGn5q4SJzJMel1kVqxYgdmzZ2P8+PFIT0+Hl5cX3n77bcyZM0fqaERERHWyYFccbmc9gLeLDab3DpI6jsGSCSN/m9ycnBwoFApkZ2fD0dFR6jhEREQ4dOUuXvtv6XuirX/rWTzr30jiRPqnpn+/9focGSIiImOTU1iM6ZtLR0qvd/JliakjFhkiIqIG9MnOS0jJLoRvI1t82DtQ6jgGj0WGiIiogRyIT8fGk8mQyYAlw8Jga6XXp6oaBBYZIiKiBpBdUIwZD0dKYzr74RlfF4kTGQcWGSIiogYwb+clpOUo4e9qh6kvcqSkKywyRERE9WzvpTRsPp0Ms4cjJRsrc6kjGQ0WGSIionqUVVCEWVvPAwDe7OKPp32cJU5kXFhkiIiI6lHUL5eQnqtEgJsdPnihpdRxjA6LDBERUT3ZfTEVW8/chpkMWDosDNaWHCnpGosMERFRPcjML8JHD0dKb3cLQLtmHCnVBxYZIiKiehC54yIy8orQ0sMekyJaSB3HaLHIEBER6dhv51PwS+wdmJvJsHRYGOQWHCnVFxYZIiIiHbqXp8TH2y4AAN7pFoDQpk7SBjJyLDJEREQ6NGf7RdzLL0KQpwPe7dlc6jhGj0WGiIhIR3aeu4Nfz6fAgiOlBsMiQ0REpAN3c5WY/XCkNL5HcwQ3UUicyDSwyBAREdWREAIfbzuP+wXFaNXYERN7cKTUUFhkiIiI6mhH7B3svpgGCzMZlg0Lg5UF/7w2FL7SREREdZCeU4g52y8CAN7r2QKtvRwlTmRaWGSIiIi0JITArK0XkP2gGMFNHPFO9wCpI5kcFhkiIiItbTt7G3svp8HSvPQqJUtz/lltaHzFiYiItJCWU4jIhyOlSREtEeTJkZIUWGSIiIhqSQiBmVvOI6ewBKFNFXi7q7/UkUwWiwwREVEtbTqVjP1x6bAyN8OyYWGw4EhJMnzliYiIaiEl+wHm7bwEAPjghZZo4eEgcSLTxiJDRERUQ0IIzNh8HrmFJWjr7YQ3u/hJHcnkscgQERHV0MaTSfjjyl1YWZhhKUdKeoF7gIiIqAZuZz3A/J2XAQDTXgxEc3d7iRMRwCJDRET0RKUjpXPIU5bgaR9njHmOIyV9wSJDRET0BD//nYQ/r2ZAbmGGJUNDYW4mkzoSPcQiQ0REVI2kzAJ8+mvpVUof9g6CvxtHSvqERYaIiKgKarXA9M3nkF+kQgdfF4zu5Ct1JHoMiwwREVEVfjx+E0cS7sHG0hyLh4bCjCMlvcMiQ0REVIlb9woQ/VscAGB670D4utpJnIgqwyJDRET0GLVaYNqmWBQUqRDu54LXOvpKHYmqwCJDRET0mO+P3sDxxEzYWpljydAwjpT0GIsMERHRI25k5GPh76UjpZl9W6FZI1uJE1F1WGSIiIgeKhspFRar0SmgEUZ2aCZ1JHoCFhkiIqKHVh+5gRM37sPOyhyLhvAqJUPAIkNERATg+t08LH44UvqoX2t4u3CkZAhYZIiIyOSp1AJTY2KhLFGjSwtXvNrBW+pIVEMsMkREZPK+O3wdp29lwUFugUVDQiGTcaRkKFhkiIjIpF1Lz8PS/10BAHzcvxW8nGwkTkS1wSJDREQmq0SlxpSYWBSVqNGtpRteac+RkqFhkSEiIpP17Z+JiE3KgoO1BRYOCeFIyQCxyBARkUm6kpaL5XtKR0qRL7VBYwVHSoaIRYaIiExOiUqNqTGxKFKp8XyQO4Y81UTqSKQlFhkiIjI5qw5dx7nkbDhaWyB6MEdKhoxFhoiITEpcag4+31s6Uooa0AYejtYSJ6K6YJEhIiKTUaxSY8rGWBSrBF5o7YGBbTlSMnQsMkREZDL+70ACLt7JgZOtJT4dFMyRkhFgkSEiIpNw8U42Vuy/CgCIerkN3B04UjIGLDJERGT0ikrUmBpzDiVqgd5tPPFymJfUkUhHWGSIiMjofXngGi6n5MDFzgqfcKRkVFhkiIjIqF24nY2VB64BAOYPCIarvVziRKRLLDJERGS0lCUqTNkYC5VaoF9IY/QLbSx1JNIxvS8yt2/fxj//+U80atQINjY2CAkJwcmTJ6WORUREBmDFvmuIT8tFIzsrzBvQRuo4VA8spA5Qnfv376Nz587o0aMHfvvtN7i5ueHq1atwdnaWOhoREem52KQsfPVHAgDgk4HBaMSRklHS6yKzaNEieHt7Y/Xq1Zplfn5+EiYiIiJDUFiswtSY0pHSy2Fe6BPCkZKx0uvR0o4dO9C+fXsMGzYM7u7uaNeuHb799ttqt1EqlcjJySn3RUREpuXzvVdxNT0PrvZyRL3MkZIx0+sic/36dXz11Vdo0aIFdu/ejXfeeQfvvfce1q5dW+U20dHRUCgUmi9vb+8GTExERFI7c+s+vjlUOlJaMCgYznZWEiei+iQTQgipQ1TFysoK7du3x5EjRzTL3nvvPZw4cQJHjx6tdBulUgmlUqn5PicnB97e3sjOzoajo2O9ZyYiIukUFqvQ74s/kXA3H4PaNcHy4W2ljkRaysnJgUKheOLfb70+ItO4cWO0bt263LJWrVrh1q1bVW4jl8vh6OhY7ouIiEzDZ3uuIOFuPtwd5Ih8qfWTNyCDp9dFpnPnzoiPjy+37MqVK/Dx8ZEoERER6atTNzPx7Z/XAQDRg0PgZMuRkinQ6yLzwQcf4NixY1iwYAGuXbuGn376Cd988w0mTJggdTQiItIjD4pUmBpzDkIAQ55qip6tPKSORA1Er4vMM888g61bt+Lnn39GcHAw5s+fj88//xwjR46UOhoREemRpf+LR2JGPjwc5ZjDkZJJ0ev3kQGA/v37o3///lLHICIiPfV3Yib++1ciAGDhkFAobCwlTkQNSa+PyBAREVWnoKgE0zbFQghgeHtv9Ah0lzoSNTAWGSIiMliLf4/HzXsFaKywxkf9W0kdhyTAIkNERAbp2PV7WHPkBgBg0ZBQOFpzpGSKWGSIiMjg5CtLR0oA8GqHZuja0k3iRCQVFhkiIjI4C3+LQ1LmAzRxssFH/ThSMmUsMkREZFD+upaBH47dBAAsHhoKe7neX4BL9UirIjNv3jwUFBRUWP7gwQPMmzevzqGIiIgqk6cswYebzgEA/vlsM3Ru7ipxIpKaVh8aaW5ujpSUFLi7l7/M7d69e3B3d4dKpdJZwLqq6YdOERGR/pu19Tx+On4LTZ1tsHtSV9jxaIzRqtcPjRRCQCaTVVgeGxsLFxcXbe6SiIioWoeu3MVPx0s/NHjJ0DCWGAJQy3f2dXZ2hkwmg0wmQ8uWLcuVGZVKhby8PIwbN07nIYmIyLTlFBZjxubSkdLrnXzRMaCRxIlIX9SqyHz++ecQQmDMmDGIioqCQqHQ3GZlZQVfX1907NhR5yGJiMi0fbrzMu5kF8KnkS0+7B0odRzSI7UqMqNGjQIA+Pn5oVOnTrC05JsPERFR/ToYn44NJ5Mgk5WOlGytOFKi/0+rfw1+fn5ISUmp8vZmzZppHYiIiKhM9oNizNh8HgAwupMfOvjxPEwqT6si4+vrW+nJvmX06aolIiIyXPN3XkJqTiH8XO0wrRdHSlSRVkXmzJkz5b4vLi7GmTNn8Nlnn+HTTz/VSTAiIjJt+y6nYdOp5IcjpVDYWJlLHYn0kFZFJiwsrMKy9u3bw8vLC0uWLMHgwYPrHIyIiExXdkExZm4pHSmNfc4P7X05UqLK6fQjCgIDA3HixAld3iUREZmgqF8uIj1XCX83O0x5kSMlqppWR2RycnLKfS+EQEpKCubOnYsWLVroJBgREZmm/11MxZYzt2EmA5YOC4O1JUdKVDWtioyTk1OFk32FEPD29sb69et1EoyIiEzP/fwizNp6AQDwVtcAPNXMWeJEpO+0KjIHDhwo972ZmRnc3NzQvHlzWFjw+n4iItJO5I6LyMhTooW7PSZF8Ag/PZlWraNbt266zkFERCbu9wsp2BF7B+ZmMo6UqMa0PnwSHx+PFStW4PLlywCAVq1aYeLEiQgKCtJZOCIiMg338pT46OFIaVw3f4R5O0kbiAyGVlctbd68GcHBwTh16hTCwsIQFhaG06dPIyQkBJs3b9Z1RiIiMnJzdlzEvfwiBHo44L2eHClRzcmEEKK2GwUEBGDkyJGYN29eueWRkZFYt24dEhISdBawrnJycqBQKJCdnQ1HR0ep4xAR0WN2nruDiT+dgbmZDNvGd0ZIU8WTNyKjV9O/31odkUlJScFrr71WYfk///nPaj+DiYiI6FEZeUrM2X4RADChewBLDNWaVkWme/fu+PPPPyssP3z4MLp06VLnUEREZPyEEJi97QIy84sQ5OmAic9zpES1p9XJvi+//DKmT5+OU6dO4dlnnwUAHDt2DDExMYiKisKOHTvKrUtERPS4X86l4LcLqbAwk2HZK2GwstDpm82TidDqHBkzs5r9Y5PJZJJ/EjbPkSEi0j/puYV4cfkhZBUU44OIlnif7xlDj6np32+tjsio1WqtgxERkWkTQuCjrReQVVCMNl6OGN8jQOpIZMC0Oo73/fffQ6lUVlheVFSE77//vs6hiIjIeG0/ewd7LqXB0rz0je8szTlSIu1p9a9n9OjRyM7OrrA8NzcXo0ePrnMoIiIyTmk5hYjcUXqV0vs9W6BVY478qW60KjJCiAofGgkAycnJUCh46RwREVUkhMCsLeeR/aAYIU0UGNeNIyWqu1qdI9OuXTvIZDLIZDL07Nmz3AdEqlQqJCYmonfv3joPSUREhm/z6dvYF5cOK3MzLHslDBYcKZEO1KrIDBw4EABw9uxZ9OrVC/b29prbrKys4OvriyFDhug0IBERGb7U7EJE/VI6Upr0Qgu09HCQOBEZi1oVmcjISACAr68vhg8fDmtr63oJRURExkMIgRlbziG3sARh3k54q4u/1JHIiGh1+fWoUaN0nYOIiIxUzMlkHIy/CysLMywbFsqREumUVkXGzMys0pN9y0j9JnhERKQfbmc9wPydlwAAU19siebuHCmRbmlVZLZs2VKuyBQXF+PMmTNYu3YtoqKidBaOiIgMlxACMzafQ66yBE81c8Ibz3GkRLqnVZEpO+n3UUOHDkWbNm2wYcMGvPHGG3XNRUREBm79iST8eTUDcgszLBkWBnOzqo/kE2lLp4PKZ599Fvv27dPlXRIRkQFKvl+ATx6OlKb1CkSAm/0TtiDSjs6KzIMHD/DFF1+gSZMmurpLIiIyQGq1wIebziG/SIVnfJ0xurOf1JHIiGk1WnJ2di53jowQArm5ubC1tcW6det0Fo6IiAzPj3/fwpGEe7C2NMOSoRwpUf3SqsgsX768XJExMzODm5sbwsPD4ezsrLNwRERkWJIyCxC96zIAYHrvIPi62kmciIydVkXm9ddfR1ZWFr777jtcvlz6D7Z169bo2LGjTsMREZHhUKsFpm2KRUGRCh38XDCqo6/UkcgEaHWOzMmTJ9G8eXMsX74cmZmZyMzMxPLlyxEQEIDTp0/rOiMRERmAH47dxLHrmbC1MsfSoWEw40iJGoBWR2Q++OADvPTSS/j22281HxxZUlKCsWPHYtKkSTh06JBOQxIRkX67kZGPhb/FAQBm9AlCs0a2EiciU6FVkTl58mS5EgMAFhYW+PDDD9G+fXudhSMiIv1XdpXSg2IVOvo3wj/DfaSORCZEq9GSo6Mjbt26VWF5UlISHBz49tNERKZkzZEb+PtGJuyszLF4aChHStSgtCoyw4cPxxtvvIENGzYgKSkJSUlJWL9+PcaOHYtXX31V1xmJiEhPXb+bh8W7S0dKs/q1grcLR0rUsLQaLS1duhQymQyvvfYaSkpKAACWlpZ45513sHDhQp0GJCIi/aRSC0zbdA6FxWo819wV/+jQTOpIZIJkQgih7cYFBQVISEgAAAQEBMDWVv+aeE5ODhQKBbKzs+Ho6Ch1HCIio/Htoev4dNdl2MstsPuDrmjiZCN1JDIiNf37rdURmTK2trYICQmpy10QEZEBupaehyX/iwcAfNyvFUsMSUanHxpJRETGT6UWmBoTi6ISNbq2dMPwZ7yljkQmjEWGiIhq5ds/r+NsUhYcrC2waEhIuY+sIWpoLDJERFRjV9Ny8dn/rgAAZvdvjcYKjpRIWiwyRERUIyUqNabExKJIpUaPQDcMe7qp1JGIDKvILFy4EDKZDJMmTZI6ChGRyVl16DrOJWfD0doC0YNDOVIivWAwRebEiRNYtWoVQkNDpY5CRGRy4lJz8Pne0pHS3JfbwFNhLXEiolIGUWTy8vIwcuRIfPvtt3B2dpY6DhGRSSlWqTE1JhbFKoGIVh4Y1K6J1JGINAyiyEyYMAH9+vVDRESE1FGIiEzOVwcTcOF2DhQ2llgwKJgjJdIrdXpDvIawfv16nD59GidOnKjR+kqlEkqlUvN9Tk5OfUUjIjJ6l+7k4It9VwEA8wa0gbsjR0qkX/T6iExSUhLef/99/Pjjj7C2rtkPT3R0NBQKhebL25tv1EREpI2iktKRUolaoFcbD7wc5iV1JKIK6vRZS/Vt27ZtGDRoEMzNzTXLVCoVZDIZzMzMoFQqy90GVH5Extvbm5+1RERUS8v3XMG/912Fs60l/vdBN7g5yKWORCakQT5rqb717NkT58+fL7ds9OjRCAoKwvTp0yuUGACQy+WQy/nDRkRUFxduZ2PlgWsAgHkDglliSG/pdZFxcHBAcHBwuWV2dnZo1KhRheVERKQbj46U+oZ4on9oY6kjEVVJr8+RISKihrdi/1XEpeaikZ0V5g/gVUqk3/T6iExlDh48KHUEIiKjdS45C/93MAEA8MnAYDSy50iJ9BuPyBAREQBAWaLClI2xUKkF+oc2Rp8QjpRI/7HIEBERAODzvVdxNT0PrvZWmDeA5yGSYWCRISIinLl1H6v+KBsphcDFzkriREQ1wyJDRGTiCotVmBoTC7UABrb1Qu9gT6kjEdUYiwwRkYlbvucKEu7mw81Bjrkvt5E6DlGtsMgQEZmwUzcz8c2f1wEA0YNC4GTLkRIZFhYZIiITVViswrSYcxACGPxUE0S09pA6ElGtscgQEZmopbvjcT0jHx6OckT250iJDBOLDBGRCTpxIxPf/ZUIAFg4OBQKW0uJExFph0WGiMjEFBSVYFpMLIQAhj3dFD2C3KWORKQ1FhkiIhOz+Pd43LhXgMYKa3zcv7XUcYjqhEWGiMiEHLt+D2uO3AAALBwSCoUNR0pk2FhkiIhMRL6yBB9uOgcAeLWDN7q1dJM4EVHdscgQEZmIRb/H4VZmAZo42WBW31ZSxyHSCRYZIiITcORaBr4/ehMAsGhIKBysOVIi48AiQ0Rk5PKUJZj2cKQ0MrwZnmvhKnEiIt1hkSEiMnLRuy7jdtYDNHW2wUyOlMjIsMgQERmxP6/exY/HbwEAFg8Nhb3cQuJERLrFIkNEZKRyC4sx/eFI6bWOPugUwJESGR8WGSIiI/Xpr5dxJ7sQzVxsMb13kNRxiOoFiwwRkRE6GJ+O9SeSAABLhobCjiMlMlIsMkRERib7QTFmbD4PABjd2Rfh/o0kTkRUf1hkiIiMzCc7LyE1pxC+jWzxYS+OlMi4scgQERmR/XFpiDmVDJkMWDIsDDZW5lJHIqpXLDJEREYiu+D/j5Te6OyHZ3xdJE5EVP9YZIiIjETUzotIz1XC39UOU3sFSh2HqEGwyBARGYE9l9Kw5fRtmMmApa+EwdqSIyUyDSwyREQG7n5+EWZtLR0pvdnFH081c5Y4EVHDYZEhIjJwc3+5iLu5SgS42eGDF1pKHYeoQbHIEBEZsN8vpGL72TswkwHLXmnLkRKZHBYZIiIDlZlfhI+3lY6UxnULQFtvJ2kDEUmARYaIyEDN2X4BGXlFaOlhj/cjWkgdh0gSLDJERAbo13Mp2HkuBeZmMiwdFga5BUdKZJpYZIiIDExGnhKzt18AAIzvHoDQpk7SBiKSEIsMEZEBEUJg9rYLyMwvQpCnA959niMlMm0sMkREBmTnuRT8diEVFg9HSlYW/DVOpo0/AUREBiI9t1AzUprQozmCmygkTkQkPRYZIiIDIITAR1svIKugGK0bO2JCj+ZSRyLSCywyREQGYPvZO9hzKQ2W5hwpET2KPwlERHouPacQkTsuAgDee74FWns5SpyISH+wyBAR6TEhBGZtPY/sB8UIbuKIcd0DpI5EpFdYZIiI9NiW07ex93I6LM1lWDasLSzN+Wub6FH8iSAi0lOp2YWY+0vpSGlSREsEejpInIhI/7DIEBHpISEEZm45h9zCEoQ1VeDtrv5SRyLSSywyRER6KOZUMg7E34WVuRmWDguDBUdKRJXiTwYRkZ65k/UA83+5BACY/GJLtPDgSImoKiwyRER6RAiB6ZvPIVdZgnbNnPBmF46UiKrDIkNEpEfWn0jCn1czILcoHSmZm8mkjkSk11hkiIj0RPL9Anz662UAwLRegQhws5c4EZH+Y5EhItIDZSOlPGUJ2vs4Y3RnP6kjERkEFhkiIj3w4/Fb+OvaPVhbmmHx0FCOlIhqiEWGiEhiSZkFWLCrdKT0Ya8g+HOkRFRjLDJERBJSqwU+3HQOBUUqdPB1weudfKWORGRQWGSIiCS07vhNHL1+DzaW5lgyLBRmHCkR1QqLDBGRRG7ey0f0rjgAwIw+QfBpZCdxIiLDwyJDRCQBtVpgWsw5PChW4Vl/F/zrWR+pIxEZJL0uMtHR0XjmmWfg4OAAd3d3DBw4EPHx8VLHIiKqszVHbuDvG5mwtTLHkqFhHCkRaUmvi8wff/yBCRMm4NixY9izZw+Ki4vx4osvIj8/X+poRERaS8zIx+LdpSOlWX1bwdvFVuJERIbLQuoA1fn999/Lfb9mzRq4u7vj1KlT6Nq1q0SpiIi0p1ILTIuJRWGxGp2bN8LI8GZSRyIyaHp9ROZx2dnZAAAXFxeJkxARaWf1X4k4efM+7KzMsWhIKGQyjpSI6kKvj8g8Sq1WY9KkSejcuTOCg4OrXE+pVEKpVGq+z8nJaYh4RERPlHA3D0t2l57n93H/1mjqzJESUV0ZzBGZCRMm4MKFC1i/fn2160VHR0OhUGi+vL29GyghEVHVVGqBqTGxUJao0aWFK0Y8w99NRLpgEEVm4sSJ2LlzJw4cOICmTZtWu+7MmTORnZ2t+UpKSmqglEREVfvPn9dx5lYWHOQWHCkR6ZBej5aEEHj33XexdetWHDx4EH5+T/40WLlcDrlc3gDpiIhq5mpaLpbtuQIAmN2/NbycbCRORGQ89LrITJgwAT/99BO2b98OBwcHpKamAgAUCgVsbPiLgIj0X4lKjakxsSgqUaN7oBuGta/+qDIR1Y5ej5a++uorZGdno3v37mjcuLHma8OGDVJHIyKqkVWHriM2ORsO1hZYOJgjJSJd0+sjMkIIqSMQEWktPjUX/957FQAQ+VIbeCqsJU5EZHz0+ogMEZGhKi4bKanU6BnkjiFPNZE6EpFRYpEhIqoHXx9MwPnb2VDYWGLB4BCOlIjqCYsMEZGOXU7JwRf7S0dKUS+3gYcjR0pE9YVFhohIh4pVakzZGItilcCLrT0woK2X1JGIjBqLDBGRDq08cA2XUnLgZGuJTwYFc6REVM9YZIiIdOTC7Wx8uf8aAGDegGC4O3CkRFTfWGSIiHSgqKT0KqUStUCfYE+8FNpY6khEJoFFhohIB1bsv4q41Fy42Flh/kCOlIgaCosMEVEdnU/Oxv8dTAAAzB8QDFd7ft4bUUNhkSEiqgNliQpTYs5CpRboF9oY/ThSImpQLDJERHXw771XcSUtD672Vpg/IFjqOEQmh0WGiEhLZ5Oy8PUfpSOlTwaGwMXOSuJERKaHRYaISAuFxSpMjYmFWgAD2nqhd7Cn1JGITBKLDBGRFpbvvYJr6XlwtZdj7kttpI5DZLJYZIiIaunUzfv49tB1AMCCQcFw5kiJSDIsMkREtVBYrMK0hyOlwe2a4MU2HCkRSYlFhoioFpbujsf1jHy4O8gRyZESkeRYZIiIaujkjUx891ciAGDhkBAobC0lTkRELDJERDXwoKj0KiUhgKFPN8XzQR5SRyIisMgQEdXI4t1xuHGvAJ6O1pjdv7XUcYjoIRYZIqInOH79Hlb/dQPAw5GSDUdKRPqCRYaIqBoFRSWYtukcAGB4e290D3SXOBERPYpFhoioGot+i8OtzAJ4KazxUf9WUschosewyBARVeFIQgbWHr0JAFg0NBSO1hwpEekbFhkiokrkKUvw4cOR0j/Cm6FLCzeJExFRZVhkiIgqEb3rMpLvP0ATJxvM6suREpG+YpEhInrM4asZ+PH4LQDAkqGhsJdbSJyIiKrCIkNE9IjcwmJM31w6UvrXsz7o1NxV4kREVB0WGSKiRyzYdRm3sx7A28UGM/oESR2HiJ6ARYaI6KE/rtzFz38nAQCWDA2DHUdKRHqPRYaICEBOYTFmPBwpvd7JF8/6N5I4ERHVBIsMERGAT3ZeQkp2IXwa2eLD3oFSxyGiGmKRISKTdyAuHRtPJkMmKx0p2VpxpERkKFhkiMikZRcUY8aW0pHSmM5+6ODnInEiIqoNFhkiMmlROy8iLUcJf1c7TH2RIyUiQ8MiQ0Qma++lNGw5fbt0pDQsFDZW5lJHIqJaYpEhIpOUVVCEmVvPAwDe7OKPp304UiIyRCwyRGSS5u64iLu5SgS42WHyCy2ljkNEWmKRISKTs/tiKradvQMzGbB0WBisLTlSIjJULDJEZFIy84vw0cOR0ltdA9CumbPEiYioLlhkiMikRO64iIy8IrRwt8ekiBZSxyGiOmKRISKTset8Cn6JvQNzMxlHSkRGgkWGiExCRp4SH2+7AAB4p1sAwrydpA1ERDrBIkNEJmHO9gvIzC9CkKcD3u3ZXOo4RKQjLDJEZPR2nruDXedTNSMluQVHSkTGgkWGiIza3VwlZj8cKU3o0RzBTRQSJyIiXWKRISKjJYTAx9vO435BMVo1dsTEHhwpERkbFhkiMlo7Yu9g98U0WJjJsGxYGKws+CuPyNjwp5qIjFJ6TiHmbL8IAHj3+RZo7eUocSIiqg8sMkRkdIQQmLX1PLIfFKONlyPG9wiQOhIR1RMWGSIyOlvP3Mbey+mwNJdh2SthsDTnrzoiY8WfbiIyKqnZhZi7o3SkNCmiJYI8OVIiMmYsMkRkNIQQmLnlHHIKSxDaVIG3u/pLHYmI6hmLDBEZjU2nknEg/i6szM2wdFgYLDhSIjJ6/CknIqOQkv0A8365BAD44IWWaOnhIHEiImoILDJEZPCEEJi++TxylSVo6+2EN7v4SR2JiBoIiwwRGbwNJ5Jw6MpdWFlwpERkagzip33lypXw9fWFtbU1wsPD8ffff0sdiYj0xO2sB/jk18sAgKkvtkRzd3uJExFRQ9L7IrNhwwZMnjwZkZGROH36NMLCwtCrVy+kp6dLHY2IJCaEwPRN55CnLMFTzZzwxnO8SonI1MiEEELqENUJDw/HM888gy+//BIAoFar4e3tjXfffRczZsx44vY5OTlQKBTIzs6Go6Pu3k/ifn4R8otKdHZ/RFR728/ewZLd8ZBbmOG397vA341HY4iMRU3/fls0YKZaKyoqwqlTpzBz5kzNMjMzM0RERODo0aOVbqNUKqFUKjXf5+Tk1Eu2Jf+Lx0/Hb9XLfRNR7XzYO4glhshE6XWRycjIgEqlgoeHR7nlHh4eiIuLq3Sb6OhoREVF1Xs2SzMZ5PwkXSJJWZjJMPipphjdyVfqKEQkEb0uMtqYOXMmJk+erPk+JycH3t7eOn+cqAHBiBoQrPP7JSIioprT6yLj6uoKc3NzpKWllVuelpYGT0/PSreRy+WQy+UNEY+IiIgkptezESsrKzz99NPYt2+fZplarca+ffvQsWNHCZMRERGRPtDrIzIAMHnyZIwaNQrt27dHhw4d8PnnnyM/Px+jR4+WOhoRERFJTO+LzPDhw3H37l3MmTMHqampaNu2LX7//fcKJwATERGR6dH795Gpq/p6HxkiIiKqPzX9+63X58gQERERVYdFhoiIiAwWiwwREREZLBYZIiIiMlgsMkRERGSwWGSIiIjIYLHIEBERkcFikSEiIiKDxSJDREREBkvvP6KgrsreuDgnJ0fiJERERFRTZX+3n/QBBEZfZHJzcwEA3t7eEichIiKi2srNzYVCoajydqP/rCW1Wo07d+7AwcEBMplMZ/ebk5MDb29vJCUlGe1nOBn7czT25wcY/3Pk8zN8xv4c+fy0J4RAbm4uvLy8YGZW9ZkwRn9ExszMDE2bNq23+3d0dDTKf5yPMvbnaOzPDzD+58jnZ/iM/Tny+WmnuiMxZXiyLxERERksFhkiIiIyWCwyWpLL5YiMjIRcLpc6Sr0x9udo7M8PMP7nyOdn+Iz9OfL51T+jP9mXiIiIjBePyBAREZHBYpEhIiIig8UiQ0RERAaLRYaIiIgMFotMNT799FN06tQJtra2cHJyqnSdW7duoV+/frC1tYW7uzumTZuGkpKSau83MzMTI0eOhKOjI5ycnPDGG28gLy+vHp5B7Rw8eBAymazSrxMnTlS5Xffu3SusP27cuAZMXnO+vr4Vsi5cuLDabQoLCzFhwgQ0atQI9vb2GDJkCNLS0hoocc3duHEDb7zxBvz8/GBjY4OAgABERkaiqKio2u30ff+tXLkSvr6+sLa2Rnh4OP7+++9q14+JiUFQUBCsra0REhKCXbt2NVDS2omOjsYzzzwDBwcHuLu7Y+DAgYiPj692mzVr1lTYV9bW1g2UuPbmzp1bIW9QUFC12xjK/gMq/30ik8kwYcKEStc3hP136NAhvPTSS/Dy8oJMJsO2bdvK3S6EwJw5c9C4cWPY2NggIiICV69efeL91vbnuDZYZKpRVFSEYcOG4Z133qn0dpVKhX79+qGoqAhHjhzB2rVrsWbNGsyZM6fa+x05ciQuXryIPXv2YOfOnTh06BDeeuut+ngKtdKpUyekpKSU+xo7diz8/PzQvn37ard98803y223ePHiBkpde/PmzSuX9d133612/Q8++AC//PILYmJi8Mcff+DOnTsYPHhwA6Wtubi4OKjVaqxatQoXL17E8uXL8fXXX2PWrFlP3FZf99+GDRswefJkREZG4vTp0wgLC0OvXr2Qnp5e6fpHjhzBq6++ijfeeANnzpzBwIEDMXDgQFy4cKGBkz/ZH3/8gQkTJuDYsWPYs2cPiouL8eKLLyI/P7/a7RwdHcvtq5s3bzZQYu20adOmXN7Dhw9Xua4h7T8AOHHiRLnntmfPHgDAsGHDqtxG3/dffn4+wsLCsHLlykpvX7x4Mb744gt8/fXXOH78OOzs7NCrVy8UFhZWeZ+1/TmuNUFPtHr1aqFQKCos37VrlzAzMxOpqamaZV999ZVwdHQUSqWy0vu6dOmSACBOnDihWfbbb78JmUwmbt++rfPsdVFUVCTc3NzEvHnzql2vW7du4v3332+YUHXk4+Mjli9fXuP1s7KyhKWlpYiJidEsu3z5sgAgjh49Wg8JdWvx4sXCz8+v2nX0ef916NBBTJgwQfO9SqUSXl5eIjo6utL1X3nlFdGvX79yy8LDw8Xbb79drzl1IT09XQAQf/zxR5XrVPW7SF9FRkaKsLCwGq9vyPtPCCHef/99ERAQINRqdaW3G9r+AyC2bt2q+V6tVgtPT0+xZMkSzbKsrCwhl8vFzz//XOX91PbnuLZ4RKYOjh49ipCQEHh4eGiW9erVCzk5Obh48WKV2zg5OZU7whEREQEzMzMcP3683jPXxo4dO3Dv3j2MHj36iev++OOPcHV1RXBwMGbOnImCgoIGSKidhQsXolGjRmjXrh2WLFlS7Sjw1KlTKC4uRkREhGZZUFAQmjVrhqNHjzZE3DrJzs6Gi4vLE9fTx/1XVFSEU6dOlXvtzczMEBERUeVrf/To0XLrA6U/k4ayrwA8cX/l5eXBx8cH3t7eGDBgQJW/a/TF1atX4eXlBX9/f4wcORK3bt2qcl1D3n9FRUVYt24dxowZU+0HFBva/ntUYmIiUlNTy+0jhUKB8PDwKveRNj/HtWX0HxpZn1JTU8uVGACa71NTU6vcxt3dvdwyCwsLuLi4VLmNVL777jv06tXriR+6+Y9//AM+Pj7w8vLCuXPnMH36dMTHx2PLli0NlLTm3nvvPTz11FNwcXHBkSNHMHPmTKSkpOCzzz6rdP3U1FRYWVlVOEfKw8ND7/bX465du4YVK1Zg6dKl1a6nr/svIyMDKpWq0p+xuLi4Srep6mdS3/eVWq3GpEmT0LlzZwQHB1e5XmBgIP773/8iNDQU2dnZWLp0KTp16oSLFy/W64fjais8PBxr1qxBYGAgUlJSEBUVhS5duuDChQtwcHCosL6h7j8A2LZtG7KysvD6669XuY6h7b/Hle2H2uwjbX6Oa8vkisyMGTOwaNGiate5fPnyE09IMyTaPOfk5GTs3r0bGzdufOL9P3p+T0hICBo3boyePXsiISEBAQEB2gevodo8v8mTJ2uWhYaGwsrKCm+//Taio6P19i3Etdl/t2/fRu/evTFs2DC8+eab1W4r9f4jYMKECbhw4UK1548AQMeOHdGxY0fN9506dUKrVq2watUqzJ8/v75j1lqfPn00/x0aGorw8HD4+Phg48aNeOONNyRMpnvfffcd+vTpAy8vryrXMbT9ZyhMrshMmTKl2sYMAP7+/jW6L09PzwpnXpddzeLp6VnlNo+f4FRSUoLMzMwqt6krbZ7z6tWr0ahRI7z88su1frzw8HAApUcEGuIPYV32aXh4OEpKSnDjxg0EBgZWuN3T0xNFRUXIysoqd1QmLS2t3vbX42r7/O7cuYMePXqgU6dO+Oabb2r9eA29/6ri6uoKc3PzCleIVffae3p61mp9fTBx4kTNSf+1/b9yS0tLtGvXDteuXaundLrl5OSEli1bVpnXEPcfANy8eRN79+6t9VFMQ9t/ZfshLS0NjRs31ixPS0tD27ZtK91Gm5/jWtPJmTZG7kkn+6alpWmWrVq1Sjg6OorCwsJK76vsZN+TJ09qlu3evVuvTvZVq9XCz89PTJkyRavtDx8+LACI2NhYHSfTvXXr1gkzMzORmZlZ6e1lJ/tu2rRJsywuLk5vT/ZNTk4WLVq0ECNGjBAlJSVa3Yc+7b8OHTqIiRMnar5XqVSiSZMm1Z7s279//3LLOnbsqJcni6rVajFhwgTh5eUlrly5otV9lJSUiMDAQPHBBx/oOF39yM3NFc7OzuLf//53pbcb0v57VGRkpPD09BTFxcW12k7f9x+qONl36dKlmmXZ2dk1Otm3Nj/Htc6pk3sxUjdv3hRnzpwRUVFRwt7eXpw5c0acOXNG5ObmCiFK/xEGBweLF198UZw9e1b8/vvvws3NTcycOVNzH8ePHxeBgYEiOTlZs6x3796iXbt24vjx4+Lw4cOiRYsW4tVXX23w51eVvXv3CgDi8uXLFW5LTk4WgYGB4vjx40IIIa5duybmzZsnTp48KRITE8X27duFv7+/6Nq1a0PHfqIjR46I5cuXi7Nnz4qEhASxbt064ebmJl577TXNOo8/PyGEGDdunGjWrJnYv3+/OHnypOjYsaPo2LGjFE+hWsnJyaJ58+aiZ8+eIjk5WaSkpGi+Hl3HkPbf+vXrhVwuF2vWrBGXLl0Sb731lnByctJcKfivf/1LzJgxQ7P+X3/9JSwsLMTSpUvF5cuXRWRkpLC0tBTnz5+X6ilU6Z133hEKhUIcPHiw3L4qKCjQrPP484uKihK7d+8WCQkJ4tSpU2LEiBHC2tpaXLx4UYqn8ERTpkwRBw8eFImJieKvv/4SERERwtXVVaSnpwshDHv/lVGpVKJZs2Zi+vTpFW4zxP2Xm5ur+VsHQHz22WfizJkz4ubNm0IIIRYuXCicnJzE9u3bxblz58SAAQOEn5+fePDggeY+nn/+ebFixQrN90/6Oa4rFplqjBo1SgCo8HXgwAHNOjdu3BB9+vQRNjY2wtXVVUyZMqVcKz9w4IAAIBITEzXL7t27J1599VVhb28vHB0dxejRozXlSB+8+uqrolOnTpXelpiYWO41uHXrlujatatwcXERcrlcNG/eXEybNk1kZ2c3YOKaOXXqlAgPDxcKhUJYW1uLVq1aiQULFpQ7evb48xNCiAcPHojx48cLZ2dnYWtrKwYNGlSuHOiL1atXV/rv9dEDr4a4/1asWCGaNWsmrKysRIcOHcSxY8c0t3Xr1k2MGjWq3PobN24ULVu2FFZWVqJNmzbi119/beDENVPVvlq9erVmncef36RJkzSvhYeHh+jbt684ffp0w4evoeHDh4vGjRsLKysr0aRJEzF8+HBx7do1ze2GvP/K7N69WwAQ8fHxFW4zxP1X9jfr8a+y56FWq8Xs2bOFh4eHkMvlomfPnhWeu4+Pj4iMjCy3rLqf47qSCSGEboZURERERA2L7yNDREREBotFhoiIiAwWiwwREREZLBYZIiIiMlgsMkRERGSwWGSIiIjIYLHIEBERkcFikSEiyXTv3h2TJk2SOgYRGTC+IR4RSSYzMxOWlpZwcHBosMecO3cutm3bhrNnzzbYYxJR/TG5T78mIv3h4uIidQQiMnAcLRGRZB4dLfn6+mLBggUYM2YMHBwc0KxZM3zzzTeadW/cuAGZTIb169ejU6dOsLa2RnBwMP744w/NOmvWrIGTk1O5x9i2bRtkMpnm9qioKMTGxkImk0Emk2HNmjX1/TSJqB6xyBCR3li2bBnat2+PM2fOYPz48XjnnXcQHx9fbp1p06ZhypQpOHPmDDp27IiXXnoJ9+7dq9H9Dx8+HFOmTEGbNm2QkpKClJQUDB8+vD6eChE1EBYZItIbffv2xfjx49G8eXNMnz4drq6uOHDgQLl1Jk6ciCFDhqBVq1b46quvoFAo8N1339Xo/m1sbGBvbw8LCwt4enrC09MTNjY29fFUiKiBsMgQkd4IDQ3V/LdMJoOnpyfS09PLrdOxY0fNf1tYWKB9+/a4fPlyg2UkIv3CIkNEesPS0rLc9zKZDGq1usbbm5mZ4fELMYuLi3WSjYj0E4sMERmUY8eOaf67pKQEp06dQqtWrQAAbm5uyM3NRX5+vmadxy+ztrKygkqlapCsRFT/WGSIyKCsXLkSW7duRVxcHCZMmID79+9jzJgxAIDw8HDY2tpi1qxZSEhIwE8//VThqiRfX18kJibi7NmzyMjIgFKplOBZEJGusMgQkUFZuHAhFi5ciLCwMBw+fBg7duyAq6srgNL3pVm3bh127dqFkJAQ/Pzzz5g7d2657YcMGYLevXujR48ecHNzw88//yzBsyAiXeE7+xKRQbhx4wb8/Pxw5swZtG3bVuo4RKQneESGiIiIDBaLDBERERksjpaIiIjIYPGIDBERERksFhkiIiIyWCwyREREZLBYZIiIiMhgscgQERGRwWKRISIiIoPFIkNEREQGi0WGiIiIDBaLDBERERms/wdNlWHG1RNoewAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, reLu(x))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.title(\"ReLU activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dace515720>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dace008f10>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, softmax(x))\n",
    "# How do I test my implementation of the softmax function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.input = x # store the input to use it in the backward pass\n",
    "        return np.maximum(0, x)  # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return gradient_values * np.where(self.input > 0, 1.0, 0.0)\n",
    "        #return gradient_values * (self.input > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "* Advatages:\n",
    "    - No saturation of neurons (at least for positive values)\n",
    "    - Converge fast\n",
    "    - Computationally efficent (very simple to calculate, both the reLu and its derivative)\n",
    "\n",
    "* Disadvantages:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))  # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('gradient_values'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        \n",
    "        sigmoid_derivative = np.multiply(self.output, (1 - self.output)) # calculate the derivative of Sigmoid: f(x) * (1 - f(x)) where f(x) is the Sigmoid function\n",
    "        return sigmoid_derivative  # multiply the gradient of the loss function by the derivative of Sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note - __Sigmoid Problem__:\n",
    "\n",
    "Vanishing gradient and saturation of neurons:\n",
    "the sigmoid function usually have the output very close to zero or one and in this region the derivative of the sigmoid is very small, meaning that the (local) gradient will be small and the network will now learn efficently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - Implement softmax layer\n",
    "Implement softmax with both forward and backward pass. Present the \n",
    "softmax in the report along with any numerical issues when calculating the \n",
    "softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'x', with the\n",
    "                         same shape as 'x'.\n",
    "        '''        \n",
    "#         x = np.asarray(x)\n",
    "# #         print (\"Shape of inputs {}\".format(x.shape))\n",
    "# #         print(np.max(x))\n",
    "#         reg = x - np.max(x)\n",
    "# #         print(\"Reg:\")\n",
    "# #         print(reg[0])\n",
    "# #         e_x = np.exp(reg)\n",
    "#         e_x = np.clip(np.exp(reg), 0.000001, 1-0.000001)\n",
    "\n",
    "# #         print(\"Exp:\")\n",
    "# #         print(e_x[0])\n",
    "# #         print(\"Max exp\")\n",
    "# #         print(np.max(e_x))\n",
    "#         exp_sum = np.sum(e_x, axis=-1, keepdims = True)\n",
    "# #         exp_sum = np.clip(exp_sum, 0.000001, 1-0.000001)\n",
    "# #         print(exp_sum[0])\n",
    "# #         print(\"Max sum\")\n",
    "# #         print(np.max(exp_sum))\n",
    "        \n",
    "#         return e_x / exp_sum\n",
    "\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "        self.output = e_x / np.sum(e_x, axis=1, keepdims = True)\n",
    "        return self.output\n",
    "#         e_x = np.exp(x - np.max(x, axis=-1, keepdims = True)) # shift input 'x' for numerical stability (prevention of overflow).\n",
    "#         self.output = e_x / np.sum(e_x) # apply the softmax function: f(xi) = exp(xi) / sum(exp(x)) for x=[x1,...,xK]\n",
    "    \n",
    "    def backward_pass(self, gradient_values):\n",
    "        # Gradient values not used -> Remove!!\n",
    "        #softmax_jacobian = self.output * (np.eye(self.output.shape[0]) - self.output.T)\n",
    "        #print(softmax_jacobian)\n",
    "        #print(softmax_jacobian.shape)\n",
    "        #return softmax_jacobian\n",
    "        return gradient_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    weights = 0\n",
    "    new_weights = 0\n",
    "    bias = 0\n",
    "    activation = 0\n",
    "    layer_input = 0\n",
    "    softmax = False\n",
    "    \n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        # Weight initialisation crucial for performance\n",
    "        #self.weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        #self.new_weights = 2*np.random.normal(size=(output_units, input_units))-1\n",
    "        self.weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.new_weights = 0.01*np.random.normal(size=(output_units, input_units)) / np.sqrt(output_units)\n",
    "        self.layer_input = 0\n",
    "        self.bias = 0\n",
    "        self.softmax = False\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = []\n",
    "        '''\n",
    "        Set activation function for the layer\n",
    "        '''   \n",
    "        if activation == 'relu':\n",
    "            print(\"ReLU\")\n",
    "            self.activation = ReLu()\n",
    "        elif activation == 'sigmoid':\n",
    "            print(\"Sigmoid\")\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'softmax':\n",
    "            print(\"Softmax\")\n",
    "            self.softmax = True\n",
    "            self.activation = Softmax()\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Weights combined with input and bias\n",
    "        '''\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        '''\n",
    "        Pass z through activation function\n",
    "        '''\n",
    "        output = self.activation.forward_pass(z)\n",
    "        self.mask = 1\n",
    "        if (self.dropout_rate != 0):\n",
    "            self.mask = (np.random.rand(*output.shape) < self.dropout_rate) / self.dropout_rate\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        print(\"Output of hidden layer\")\n",
    "        print(output)\n",
    "        return output * self.mask\n",
    "        \n",
    "    '''\n",
    "    Idea is to have backward pass for activation functions just return the derivative of the activation,\n",
    "    and backward_pass for layer perform any other calculation (dot product of activation function with loss for example)\n",
    "    '''   \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            derivative_final = np.multiply(x, activation_derivative)*self.mask\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = -(learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "#         print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        self.weights -= self.new_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass of layer\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        super().__init__(output_units, input_units, activation, dropout_rate)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "        return x\n",
    "    \n",
    "    # No weights in input layer\n",
    "    def backward_pass(self, x, learning_rate):\n",
    "        #print(\"Last backwards pass layer\")\n",
    "        return 0\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"End of Backwards pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, output_units, input_units, activation, dropout_rate):\n",
    "        super().__init__(output_units, input_units, activation, dropout_rate)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        self.layer_input = x\n",
    "#         print (\"Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"Shape of inputs {}\".format(self.layer_input.shape))\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        print(\"Weights and biases\")\n",
    "        print(z[0])\n",
    "        output = self.activation.forward_pass(z)\n",
    "        self.mask = 1\n",
    "        if (self.dropout_rate != 0):\n",
    "            self.mask = (np.random.rand(*output.shape) < self.dropout_rate) / self.dropout_rate\n",
    "        #print (\"Shape of output {}\".format(output.shape))\n",
    "        return output*self.mask\n",
    "    \n",
    "    def backward_pass(self, x, learning_rate):\n",
    "#         print (\"%Shape of Error{}\".format(x.shape))\n",
    "        # x must be derivative of loss for output layer, derivative of previous layer*weights for other layers\n",
    "        '''\n",
    "        Calculate derivative of activation function\n",
    "        '''\n",
    "#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\n",
    "        '''\n",
    "        Derivative of error (input of method) dot product with derivative of activation\n",
    "        '''\n",
    "        activation_derivative = self.activation.backward_pass(x)\n",
    "        if self.softmax:\n",
    "            derivative_final = x\n",
    "        else:\n",
    "            \n",
    "            derivative_final = np.multiply(x, activation_derivative)*self.mask\n",
    "#             derivative_final = activation_derivative * x\n",
    "#         print (\"%Shape of output derivative_final{}\".format(derivative_final.shape))\n",
    "#         print (\"%Shape of weights {}\".format(self.weights.shape))\n",
    "#         print (\"%Shape of layer input{}\".format(self.layer_input.shape))\n",
    "        '''\n",
    "        Calculate new weights with learning rate and dot product of main derivative with input of the layer\n",
    "        Update weights after backpropagation is complete\n",
    "        '''\n",
    "        self.new_weights = -(learning_rate*np.dot(self.layer_input.T, derivative_final))\n",
    "#         print(\"Old_weights\")\n",
    "#         print(self.weights)\n",
    "#         print(\"New_weights\")\n",
    "#         print(self.new_weights)\n",
    "        '''\n",
    "        Calculate derivative of error for next layer (hidden layers)\n",
    "        '''\n",
    "        derivative_error = np.dot(derivative_final, self.weights.T)\n",
    "        print (\"%Shape of output derivative_error{}\".format(derivative_error.shape))\n",
    "        return derivative_error\n",
    "    \n",
    "    def mse_loss(self, output, target):\n",
    "        loss = 1/len(output)*np.sum((output-target)**2)\n",
    "        return loss\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        print(\"Old_weights\")\n",
    "        print(self.weights[:10])\n",
    "        print(\"New_weights\")\n",
    "        print(self.new_weights[:10])\n",
    "        self.weights -= self.new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY\n",
    "x = np.array([[0.25],\n",
    "              [-1], \n",
    "              [2.3], \n",
    "              [-0.2], \n",
    "              [1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0], [1]])\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "prediction = softmax.forward_pass(x)\n",
    "loss = np.sum((prediction - y) ** 2)\n",
    "loss_derivative = (prediction -y)\n",
    "prediction, loss, np.sum(prediction)\n",
    "loss_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_derivative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient_softmax = softmax.backward_pass(loss_derivative.T, learning_rate)\n",
    "#gradient_softmax.shape, gradient_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - Implement dropout \n",
    "Present dropout in the report. Implement inverted dropout. Forward and \n",
    "backward pass should be implemented.\n",
    "Note: Since the test performance is critical, it is also preferable to leaving \n",
    "the forward pass unchanged at test time. Therefore, in most \n",
    "implementations inverted dropout is employed to overcome the \n",
    "undesirable property of the original dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of \n",
    "hidden layers, units, activation functions can be changed. In addition, you \n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used \n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots \n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "    A class representing the Fully Parametrizable Neural Network.\n",
    "    '''\n",
    "    layer_list = []\n",
    "    X = 0\n",
    "    Y = 0\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 8\n",
    "    epochs = 100   \n",
    "    loss_history = []\n",
    "    \n",
    "    def __init__(self, X, Y, learning_rate, dropout_rate = 0, batch_size = 4, epochs = 10):\n",
    "        self.layer_list = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def addLayer(self, input_units, output_units, activation, mode = \"input\"):\n",
    "        if mode == \"input\":\n",
    "            print(\"Added input\")\n",
    "            layer = InputLayer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        elif mode == \"output\":\n",
    "            print(\"Added output\")\n",
    "            layer = OutputLayer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        else:\n",
    "            print(\"Added hidden\")\n",
    "            layer = Layer(input_units, output_units, activation, dropout_rate = self.dropout_rate)\n",
    "        self.layer_list.append(layer)\n",
    "        \n",
    "    def loss(self, output, target, mode):\n",
    "        if mode == \"mse\":\n",
    "            loss = 1/len(output)*np.sum((np.sum(output-target))**2)\n",
    "            return loss\n",
    "        elif mode == \"cross_entropy\":\n",
    "            output = np.clip(output, 0.000001, 1-0.000001)\n",
    "#             loss = -np.sum(np.array(target) * np.log(np.array(output)))/ target.shape[0]\n",
    "            loss = -np.sum(target * np.log(output))\n",
    "            print(\"Cross Loss: {}\".format(loss))\n",
    "            print(loss.shape)\n",
    "            return loss\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            input_data = self.X\n",
    "            print(input_data.shape)\n",
    "            # Forward pass\n",
    "            print(\"Forward pass epoch {}\".format(i))\n",
    "            for index, layer in enumerate(self.layer_list):\n",
    "                print (\"Layer {}\".format(index))\n",
    "                output_data = layer.forward_pass(input_data)\n",
    "                input_data = output_data\n",
    "                \n",
    "            # Calculate loss \n",
    "            #output_data = np.around(output_data, 6)\n",
    "            print(\"Output layer\")\n",
    "            print(output_data[:10])\n",
    "            print(\"Sums to 1: \")\n",
    "            print(np.sum(output_data[0]))\n",
    "            print(\"At least one output is closer to 1: \")\n",
    "            print(np.max(output_data))\n",
    "            # For softmax, not exactly 0 nor 1\n",
    "            print(\"Model output shape: {}\".format (output_data.shape))\n",
    "            print(\"Model target shape: {}\".format (self.Y.shape))\n",
    "            loss_cost = self.loss(output_data, self.Y, mode = \"cross_entropy\")\n",
    "#             loss_cost = np.around(loss_cost, 6)\n",
    "            self.loss_history.append(loss_cost)\n",
    "            #print(\"Loss: {}\".format(loss_cost))\n",
    "            \n",
    "            # Backward pass  \n",
    "            # MSE derivative\n",
    "#             input_derivative = (self.Y - output_data)\n",
    "            input_derivative = np.asarray(output_data - self.Y)\n",
    "            print(\"Backward pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                output_derivative = layer.backward_pass(input_derivative, self.learning_rate)\n",
    "                input_derivative = output_derivative\n",
    "                \n",
    "            # Update pass. Supposedly update weights after backward pass completed\n",
    "            # Weights barely updating??\n",
    "            print(\"Update pass epoch {}\".format(i))\n",
    "            for index, layer in reversed(list(enumerate(self.layer_list))):\n",
    "                #print (\"Layer {}\".format(index))\n",
    "                layer.update_weights(self.learning_rate)\n",
    "                                         \n",
    "    def predict(self, X):\n",
    "        input_data = X\n",
    "        for index, layer in enumerate(self.layer_list):\n",
    "            output_data = layer.forward_pass(input_data)\n",
    "            input_data = output_data\n",
    "        return output_data\n",
    "    \n",
    "    def show_loss(self):\n",
    "        plt.plot(self.loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY DATASET\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "dataset = load_digits()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape(-1, 1)).toarray()\n",
    "\n",
    "X /= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Softmax\n",
      "(1797, 64)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[0.         0.         0.         ... 0.         0.00457591 0.        ]\n",
      " [0.         0.00483046 0.00675183 ... 0.00593222 0.         0.        ]\n",
      " [0.         0.         0.00832449 ... 0.00103161 0.00143141 0.        ]\n",
      " ...\n",
      " [0.         0.00248704 0.006304   ... 0.00202744 0.00015871 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.0061765  0.        ]\n",
      " [0.         0.         0.00316327 ... 0.         0.00210999 0.        ]]\n",
      "Layer 2\n",
      "Output of hidden layer\n",
      "[[7.20815306e-05 1.04908579e-04 1.73082973e-05 ... 4.74485970e-05\n",
      "  0.00000000e+00 1.12793047e-04]\n",
      " [4.27411049e-05 2.18116300e-05 1.30886909e-05 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 1.41261888e-04 9.23100412e-05 ... 3.18295817e-04\n",
      "  2.82387536e-05 0.00000000e+00]\n",
      " [4.33086836e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  4.88120873e-05 1.41783378e-04]\n",
      " [1.97332318e-06 1.63990683e-04 1.09088358e-04 ... 1.58854409e-04\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Layer 3\n",
      "Weights and biases\n",
      "[-7.61520884e-07  2.26606777e-06  1.52244294e-06 -3.03935840e-07\n",
      " -4.50853496e-07 -7.35359183e-07  3.98466525e-06 -3.76248933e-07\n",
      "  2.46659342e-07 -4.56114753e-08]\n",
      "Output layer\n",
      "[[0.         0.         1.00000099 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.99999773 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.99999997 0.         0.         0.\n",
      "  0.         0.99999947 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.00000245\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.9999971  0.\n",
      "  1.00000021 0.         0.         0.        ]\n",
      " [0.99999933 1.00000106 0.         0.         1.00000125 0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Sums to 1: \n",
      "1.0000009878117775\n",
      "At least one output is closer to 1: \n",
      "1.0000103317146993\n",
      "Model output shape: (1797, 10)\n",
      "Model target shape: (1797, 10)\n",
      "Cross Loss: 22381.127373157375\n",
      "()\n",
      "Backward pass epoch 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1797,1797) (10,1797) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aless\\Desktop\\Uni\\Math and Programming for AI\\Programming_And_Mathematics_For_AI\\main.ipynb Cell 28\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39maddLayer(\u001b[39m128\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhidden\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39maddLayer(\u001b[39m256\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32mc:\\Users\\aless\\Desktop\\Uni\\Math and Programming for AI\\Programming_And_Mathematics_For_AI\\main.ipynb Cell 28\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBackward pass epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_list))):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     \u001b[39m#print (\"Layer {}\".format(index))\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     output_derivative \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackward_pass(input_derivative, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     input_derivative \u001b[39m=\u001b[39m output_derivative\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39m# Update pass. Supposedly update weights after backward pass completed\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m# Weights barely updating??\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\aless\\Desktop\\Uni\\Math and Programming for AI\\Programming_And_Mathematics_For_AI\\main.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#         print (\"%Shape of output activation_derivative{}\".format(activation_derivative.shape))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m        \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m        Derivative of error (input of method) dot product with derivative of activation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m        '''\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         activation_derivative \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation\u001b[39m.\u001b[39;49mbackward_pass(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             derivative_final \u001b[39m=\u001b[39m x\n",
      "\u001b[1;32mc:\\Users\\aless\\Desktop\\Uni\\Math and Programming for AI\\Programming_And_Mathematics_For_AI\\main.ipynb Cell 28\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_pass\u001b[39m(\u001b[39mself\u001b[39m, gradient_values):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# Gradient values not used -> Remove!!\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     softmax_jacobian \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m*\u001b[39m (np\u001b[39m.\u001b[39;49meye(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]) \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m#print(softmax_jacobian)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/Desktop/Uni/Math%20and%20Programming%20for%20AI/Programming_And_Mathematics_For_AI/main.ipynb#X36sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mprint\u001b[39m(softmax_jacobian\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1797,1797) (10,1797) "
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.01, dropout_rate = 0.1, batch_size = 32, epochs = 100)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 128, 'relu', 'hidden')\n",
    "model.addLayer(128, 256, 'relu', 'hidden')\n",
    "model.addLayer(256, 10, 'softmax', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 1)\n"
     ]
    }
   ],
   "source": [
    "y.shape\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added input\n",
      "ReLU\n",
      "Added hidden\n",
      "ReLU\n",
      "Added output\n",
      "Sigmoid\n",
      "(569, 30)\n",
      "Forward pass epoch 0\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.17308472e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.02930347e+00 0.00000000e+00]\n",
      " [3.79664366e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  4.64356185e+00 0.00000000e+00]\n",
      " [3.46806880e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  4.14199592e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.44437372e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.60176935e+00 3.65777978e-03]\n",
      " [3.63322866e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  4.28226433e+00 0.00000000e+00]\n",
      " [5.57300034e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.55594619e-01 2.28443093e-01]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[-0.03640695]\n",
      "Output layer\n",
      "[[0.49089927]\n",
      " [0.48955333]\n",
      " [0.49051526]\n",
      " [0.49682491]\n",
      " [0.49052759]\n",
      " [0.4960273 ]\n",
      " [0.49160788]\n",
      " [0.49518293]\n",
      " [0.49584525]\n",
      " [0.49608837]]\n",
      "Sums to 1: \n",
      "0.49089926811148\n",
      "At least one output is closer to 1: \n",
      "0.4988305347865708\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 249.90803123558575\n",
      "()\n",
      "Backward pass epoch 0\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 0\n",
      "Old_weights\n",
      "[[ 0.00018321]\n",
      " [-0.00045649]\n",
      " [-0.00166944]\n",
      " [ 0.00019412]\n",
      " [ 0.00040816]\n",
      " [-0.00030755]\n",
      " [ 0.00012958]\n",
      " [-0.0010831 ]\n",
      " [-0.00052247]\n",
      " [-0.00010711]]\n",
      "New_weights\n",
      "[[-0.13262678]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.18671206]\n",
      " [-0.14351982]\n",
      " [-0.23491118]\n",
      " [ 0.14145769]\n",
      " [-0.05448827]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 1\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18035117 0.         0.         ... 0.         5.1391675  0.        ]\n",
      " [3.80436007 0.         0.         ... 0.         4.76022901 0.        ]\n",
      " [3.47490898 0.         0.         ... 0.         4.24541513 0.        ]\n",
      " ...\n",
      " [2.44901694 0.         0.         ... 0.         2.67197191 0.01628553]\n",
      " [3.64049178 0.         0.         ... 0.         4.39207804 0.        ]\n",
      " [0.5583824  0.         0.         ... 0.         0.57195927 0.23138859]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.27747105]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993731]\n",
      " [1.        ]\n",
      " [0.99999736]\n",
      " [1.        ]\n",
      " [0.99999981]\n",
      " [0.99999746]\n",
      " [0.99999536]]\n",
      "Sums to 1: \n",
      "0.9999999999999987\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.38660226010151194\n",
      "()\n",
      "Backward pass epoch 1\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 1\n",
      "Old_weights\n",
      "[[ 1.32809988e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86404507e-01]\n",
      " [ 1.43649391e-01]\n",
      " [ 2.33828084e-01]\n",
      " [-1.41980160e-01]\n",
      " [ 5.43811547e-02]]\n",
      "New_weights\n",
      "[[ 2.19598141e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.52375069e-05]\n",
      " [ 6.49964638e-06]\n",
      " [ 1.04972651e-05]\n",
      " [ 1.74052379e-05]\n",
      " [ 2.73597456e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 2\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18082101 0.         0.         ... 0.         5.14187515 0.        ]\n",
      " [3.80485949 0.         0.         ... 0.         4.76310709 0.        ]\n",
      " [3.47535249 0.         0.         ... 0.         4.24797099 0.        ]\n",
      " ...\n",
      " [2.44931946 0.         0.         ... 0.         2.67371531 0.01649025]\n",
      " [3.64096341 0.         0.         ... 0.         4.39479596 0.        ]\n",
      " [0.55845444 0.         0.         ... 0.         0.57237443 0.23143734]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.29492736]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993765]\n",
      " [1.        ]\n",
      " [0.99999738]\n",
      " [1.        ]\n",
      " [0.99999981]\n",
      " [0.99999748]\n",
      " [0.99999539]]\n",
      "Sums to 1: \n",
      "0.9999999999999987\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3854211204049849\n",
      "()\n",
      "Backward pass epoch 2\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 2\n",
      "Old_weights\n",
      "[[ 1.32788029e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86389269e-01]\n",
      " [ 1.43642891e-01]\n",
      " [ 2.33817586e-01]\n",
      " [-1.41997566e-01]\n",
      " [ 5.43784187e-02]]\n",
      "New_weights\n",
      "[[ 2.18590941e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.51722886e-05]\n",
      " [ 6.47243718e-06]\n",
      " [ 1.04568743e-05]\n",
      " [ 1.73259096e-05]\n",
      " [ 2.72410545e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 3\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18128702 0.         0.         ... 0.         5.14456127 0.        ]\n",
      " [3.80535483 0.         0.         ... 0.         4.76596227 0.        ]\n",
      " [3.47579238 0.         0.         ... 0.         4.25050653 0.        ]\n",
      " ...\n",
      " [2.44961952 0.         0.         ... 0.         2.67544484 0.01669341]\n",
      " [3.64143118 0.         0.         ... 0.         4.39749226 0.        ]\n",
      " [0.55852589 0.         0.         ... 0.         0.5727863  0.23148572]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.31223022]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993799]\n",
      " [1.        ]\n",
      " [0.99999739]\n",
      " [1.        ]\n",
      " [0.99999982]\n",
      " [0.9999975 ]\n",
      " [0.99999542]]\n",
      "Sums to 1: \n",
      "0.9999999999999987\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.38425414592463203\n",
      "()\n",
      "Backward pass epoch 3\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 3\n",
      "Old_weights\n",
      "[[ 1.32766169e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86374097e-01]\n",
      " [ 1.43636419e-01]\n",
      " [ 2.33807129e-01]\n",
      " [-1.42014891e-01]\n",
      " [ 5.43756946e-02]]\n",
      "New_weights\n",
      "[[ 2.17597327e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.51079301e-05]\n",
      " [ 6.44558508e-06]\n",
      " [ 1.04169975e-05]\n",
      " [ 1.72476505e-05]\n",
      " [ 2.71239309e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 4\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18174926 0.         0.         ... 0.         5.14722622 0.        ]\n",
      " [3.80584616 0.         0.         ... 0.         4.76879496 0.        ]\n",
      " [3.4762287  0.         0.         ... 0.         4.25302209 0.        ]\n",
      " ...\n",
      " [2.44991714 0.         0.         ... 0.         2.67716074 0.01689505]\n",
      " [3.64189517 0.         0.         ... 0.         4.40016732 0.        ]\n",
      " [0.55859677 0.         0.         ... 0.         0.57319492 0.23153373]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.32938225]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993833]\n",
      " [1.        ]\n",
      " [0.99999741]\n",
      " [1.        ]\n",
      " [0.99999982]\n",
      " [0.99999751]\n",
      " [0.99999545]]\n",
      "Sums to 1: \n",
      "0.9999999999999987\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3831010494855581\n",
      "()\n",
      "Backward pass epoch 4\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 4\n",
      "Old_weights\n",
      "[[ 1.32744410e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86358989e-01]\n",
      " [ 1.43629973e-01]\n",
      " [ 2.33796712e-01]\n",
      " [-1.42032139e-01]\n",
      " [ 5.43729822e-02]]\n",
      "New_weights\n",
      "[[ 2.16617003e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.50444129e-05]\n",
      " [ 6.41908241e-06]\n",
      " [ 1.03776239e-05]\n",
      " [ 1.71704374e-05]\n",
      " [ 2.70083409e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 5\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18220778 0.         0.         ... 0.         5.14987034 0.        ]\n",
      " [3.80633354 0.         0.         ... 0.         4.7716055  0.        ]\n",
      " [3.47666152 0.         0.         ... 0.         4.25551798 0.        ]\n",
      " ...\n",
      " [2.45021237 0.         0.         ... 0.         2.67886324 0.01709517]\n",
      " [3.64235543 0.         0.         ... 0.         4.40282146 0.        ]\n",
      " [0.55866708 0.         0.         ... 0.         0.57360035 0.23158139]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.34638595]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993866]\n",
      " [1.        ]\n",
      " [0.99999743]\n",
      " [1.        ]\n",
      " [0.99999982]\n",
      " [0.99999753]\n",
      " [0.99999548]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.381961552093128\n",
      "()\n",
      "Backward pass epoch 5\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 5\n",
      "Old_weights\n",
      "[[ 1.32722748e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86343944e-01]\n",
      " [ 1.43623554e-01]\n",
      " [ 2.33786335e-01]\n",
      " [-1.42049310e-01]\n",
      " [ 5.43702813e-02]]\n",
      "New_weights\n",
      "[[ 2.15649682e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.49817191e-05]\n",
      " [ 6.39292178e-06]\n",
      " [ 1.03387431e-05]\n",
      " [ 1.70942477e-05]\n",
      " [ 2.68942520e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 6\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18266266 0.         0.         ... 0.         5.15249398 0.        ]\n",
      " [3.80681705 0.         0.         ... 0.         4.77439427 0.        ]\n",
      " [3.47709089 0.         0.         ... 0.         4.25799454 0.        ]\n",
      " ...\n",
      " [2.45050526 0.         0.         ... 0.         2.68055254 0.01729382]\n",
      " [3.64281203 0.         0.         ... 0.         4.40545505 0.        ]\n",
      " [0.55873682 0.         0.         ... 0.         0.57400264 0.2316287 ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.36324381]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993898]\n",
      " [1.        ]\n",
      " [0.99999745]\n",
      " [1.        ]\n",
      " [0.99999982]\n",
      " [0.99999755]\n",
      " [0.99999551]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3808353826338414\n",
      "()\n",
      "Backward pass epoch 6\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 6\n",
      "Old_weights\n",
      "[[ 1.32701183e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86328963e-01]\n",
      " [ 1.43617161e-01]\n",
      " [ 2.33775996e-01]\n",
      " [-1.42066404e-01]\n",
      " [ 5.43675919e-02]]\n",
      "New_weights\n",
      "[[ 2.14695086e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.49198313e-05]\n",
      " [ 6.36709598e-06]\n",
      " [ 1.03003448e-05]\n",
      " [ 1.70190594e-05]\n",
      " [ 2.67816324e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 7\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18311394 0.         0.         ... 0.         5.15509747 0.        ]\n",
      " [3.80729673 0.         0.         ... 0.         4.77716162 0.        ]\n",
      " [3.47751688 0.         0.         ... 0.         4.26045208 0.        ]\n",
      " ...\n",
      " [2.45079583 0.         0.         ... 0.         2.68222887 0.01749101]\n",
      " [3.64326502 0.         0.         ... 0.         4.40806841 0.        ]\n",
      " [0.55880602 0.         0.         ... 0.         0.57440183 0.23167565]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.37995823]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999393 ]\n",
      " [1.        ]\n",
      " [0.99999746]\n",
      " [1.        ]\n",
      " [0.99999982]\n",
      " [0.99999757]\n",
      " [0.99999554]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3797222809726736\n",
      "()\n",
      "Backward pass epoch 7\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 7\n",
      "Old_weights\n",
      "[[ 1.32679714e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86314043e-01]\n",
      " [ 1.43610794e-01]\n",
      " [ 2.33765696e-01]\n",
      " [-1.42083423e-01]\n",
      " [ 5.43649138e-02]]\n",
      "New_weights\n",
      "[[ 2.13752943e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.48587327e-05]\n",
      " [ 6.34159803e-06]\n",
      " [ 1.02624194e-05]\n",
      " [ 1.69448514e-05]\n",
      " [ 2.66704513e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 8\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18356169 0.         0.         ... 0.         5.15768113 0.        ]\n",
      " [3.80777266 0.         0.         ... 0.         4.77990789 0.        ]\n",
      " [3.47793952 0.         0.         ... 0.         4.2628909  0.        ]\n",
      " ...\n",
      " [2.45108412 0.         0.         ... 0.         2.68389243 0.01768676]\n",
      " [3.64371447 0.         0.         ... 0.         4.41066186 0.        ]\n",
      " [0.55887467 0.         0.         ... 0.         0.57479799 0.23172227]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.39653155]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993962]\n",
      " [1.        ]\n",
      " [0.99999748]\n",
      " [1.        ]\n",
      " [0.99999982]\n",
      " [0.99999758]\n",
      " [0.99999557]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.37862199175133826\n",
      "()\n",
      "Backward pass epoch 8\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 8\n",
      "Old_weights\n",
      "[[ 1.32658338e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86299184e-01]\n",
      " [ 1.43604452e-01]\n",
      " [ 2.33755433e-01]\n",
      " [-1.42100368e-01]\n",
      " [ 5.43622467e-02]]\n",
      "New_weights\n",
      "[[ 2.12822992e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.47984068e-05]\n",
      " [ 6.31642113e-06]\n",
      " [ 1.02249571e-05]\n",
      " [ 1.68716030e-05]\n",
      " [ 2.65606788e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 9\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18400596 0.         0.         ... 0.         5.16024527 0.        ]\n",
      " [3.8082449  0.         0.         ... 0.         4.78263342 0.        ]\n",
      " [3.47835889 0.         0.         ... 0.         4.26531129 0.        ]\n",
      " ...\n",
      " [2.45137018 0.         0.         ... 0.         2.68554343 0.0178811 ]\n",
      " [3.64416043 0.         0.         ... 0.         4.41323572 0.        ]\n",
      " [0.55894279 0.         0.         ... 0.         0.57519116 0.23176855]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.41296607]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99993993]\n",
      " [1.        ]\n",
      " [0.9999975 ]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.9999976 ]\n",
      " [0.9999956 ]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3775342614922083\n",
      "()\n",
      "Backward pass epoch 9\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 9\n",
      "Old_weights\n",
      "[[ 1.32637056e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86284386e-01]\n",
      " [ 1.43598136e-01]\n",
      " [ 2.33745208e-01]\n",
      " [-1.42117239e-01]\n",
      " [ 5.43595906e-02]]\n",
      "New_weights\n",
      "[[ 2.11904977e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.47388378e-05]\n",
      " [ 6.29155869e-06]\n",
      " [ 1.01879488e-05]\n",
      " [ 1.67992940e-05]\n",
      " [ 2.64522859e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 10\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18444681 0.         0.         ... 0.         5.16279022 0.        ]\n",
      " [3.80871349 0.         0.         ... 0.         4.78533854 0.        ]\n",
      " [3.47877503 0.         0.         ... 0.         4.26771356 0.        ]\n",
      " ...\n",
      " [2.45165403 0.         0.         ... 0.         2.68718206 0.01807406]\n",
      " [3.64460295 0.         0.         ... 0.         4.41579031 0.        ]\n",
      " [0.55901039 0.         0.         ... 0.         0.57558139 0.2318145 ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.429264]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994024]\n",
      " [1.        ]\n",
      " [0.99999751]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.99999761]\n",
      " [0.99999562]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3764588493426039\n",
      "()\n",
      "Backward pass epoch 10\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 10\n",
      "Old_weights\n",
      "[[ 1.32615865e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86269647e-01]\n",
      " [ 1.43591845e-01]\n",
      " [ 2.33735020e-01]\n",
      " [-1.42134039e-01]\n",
      " [ 5.43569454e-02]]\n",
      "New_weights\n",
      "[[ 2.10998651e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.46800102e-05]\n",
      " [ 6.26700431e-06]\n",
      " [ 1.01513852e-05]\n",
      " [ 1.67279051e-05]\n",
      " [ 2.63452443e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 11\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18488429 0.         0.         ... 0.         5.16531626 0.        ]\n",
      " [3.80917851 0.         0.         ... 0.         4.78802356 0.        ]\n",
      " [3.47918798 0.         0.         ... 0.         4.27009799 0.        ]\n",
      " ...\n",
      " [2.45193572 0.         0.         ... 0.         2.68880852 0.01826564]\n",
      " [3.64504209 0.         0.         ... 0.         4.41832593 0.        ]\n",
      " [0.55907747 0.         0.         ... 0.         0.57596872 0.23186013]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.44542755]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994055]\n",
      " [1.        ]\n",
      " [0.99999753]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.99999763]\n",
      " [0.99999565]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3753955236514834\n",
      "()\n",
      "Backward pass epoch 11\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 11\n",
      "Old_weights\n",
      "[[ 1.32594766e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86254967e-01]\n",
      " [ 1.43585578e-01]\n",
      " [ 2.33724869e-01]\n",
      " [-1.42150766e-01]\n",
      " [ 5.43543109e-02]]\n",
      "New_weights\n",
      "[[ 2.10103774e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.46219089e-05]\n",
      " [ 6.24275176e-06]\n",
      " [ 1.01152577e-05]\n",
      " [ 1.66574173e-05]\n",
      " [ 2.62395266e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 12\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18531846 0.         0.         ... 0.         5.16782369 0.        ]\n",
      " [3.80964    0.         0.         ... 0.         4.7906888  0.        ]\n",
      " [3.47959781 0.         0.         ... 0.         4.27246485 0.        ]\n",
      " ...\n",
      " [2.45221527 0.         0.         ... 0.         2.690423   0.01845588]\n",
      " [3.64547791 0.         0.         ... 0.         4.42084286 0.        ]\n",
      " [0.55914405 0.         0.         ... 0.         0.57635319 0.23190543]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.46145883]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994085]\n",
      " [1.        ]\n",
      " [0.99999755]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.99999765]\n",
      " [0.99999568]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3743440493368053\n",
      "()\n",
      "Backward pass epoch 12\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 12\n",
      "Old_weights\n",
      "[[ 1.32573755e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86240345e-01]\n",
      " [ 1.43579335e-01]\n",
      " [ 2.33714754e-01]\n",
      " [-1.42167424e-01]\n",
      " [ 5.43516869e-02]]\n",
      "New_weights\n",
      "[[ 2.09220110e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.45645194e-05]\n",
      " [ 6.21879500e-06]\n",
      " [ 1.00795577e-05]\n",
      " [ 1.65878122e-05]\n",
      " [ 2.61351063e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 13\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18574937 0.         0.         ... 0.         5.1703128  0.        ]\n",
      " [3.81009803 0.         0.         ... 0.         4.79333456 0.        ]\n",
      " [3.48000456 0.         0.         ... 0.         4.27481441 0.        ]\n",
      " ...\n",
      " [2.45249272 0.         0.         ... 0.         2.69202568 0.01864479]\n",
      " [3.64591045 0.         0.         ... 0.         4.4233414  0.        ]\n",
      " [0.55921012 0.         0.         ... 0.         0.57673486 0.23195042]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.47735992]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994114]\n",
      " [1.        ]\n",
      " [0.99999756]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.99999766]\n",
      " [0.9999957 ]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.37330420311720947\n",
      "()\n",
      "Backward pass epoch 13\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 13\n",
      "Old_weights\n",
      "[[ 1.32552833e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86225780e-01]\n",
      " [ 1.43573116e-01]\n",
      " [ 2.33704674e-01]\n",
      " [-1.42184012e-01]\n",
      " [ 5.43490734e-02]]\n",
      "New_weights\n",
      "[[ 2.08347434e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.45078275e-05]\n",
      " [ 6.19512813e-06]\n",
      " [ 1.00442768e-05]\n",
      " [ 1.65190720e-05]\n",
      " [ 2.60319573e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 14\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18617706 0.         0.         ... 0.         5.17278387 0.        ]\n",
      " [3.81055264 0.         0.         ... 0.         4.79596114 0.        ]\n",
      " [3.48040828 0.         0.         ... 0.         4.27714695 0.        ]\n",
      " ...\n",
      " [2.45276811 0.         0.         ... 0.         2.69361674 0.0188324 ]\n",
      " [3.64633976 0.         0.         ... 0.         4.42582183 0.        ]\n",
      " [0.5592757  0.         0.         ... 0.         0.57711376 0.23199509]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.49313286]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994144]\n",
      " [1.        ]\n",
      " [0.99999758]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.99999768]\n",
      " [0.99999573]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.37227576762484255\n",
      "()\n",
      "Backward pass epoch 14\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 14\n",
      "Old_weights\n",
      "[[ 1.32531998e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86211273e-01]\n",
      " [ 1.43566921e-01]\n",
      " [ 2.33694630e-01]\n",
      " [-1.42200531e-01]\n",
      " [ 5.43464702e-02]]\n",
      "New_weights\n",
      "[[ 2.07485525e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.44518194e-05]\n",
      " [ 6.17174544e-06]\n",
      " [ 1.00094070e-05]\n",
      " [ 1.64511794e-05]\n",
      " [ 2.59300544e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 15\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.1866016  0.         0.         ... 0.         5.17523717 0.        ]\n",
      " [3.81100389 0.         0.         ... 0.         4.79856884 0.        ]\n",
      " [3.48080901 0.         0.         ... 0.         4.27946271 0.        ]\n",
      " ...\n",
      " [2.45304145 0.         0.         ... 0.         2.69519637 0.01901872]\n",
      " [3.6467659  0.         0.         ... 0.         4.42828443 0.        ]\n",
      " [0.5593408  0.         0.         ... 0.         0.57748994 0.23203947]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.50877962]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994173]\n",
      " [1.        ]\n",
      " [0.99999759]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.99999769]\n",
      " [0.99999576]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3712585312041945\n",
      "()\n",
      "Backward pass epoch 15\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 15\n",
      "Old_weights\n",
      "[[ 1.32511250e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86196821e-01]\n",
      " [ 1.43560749e-01]\n",
      " [ 2.33684621e-01]\n",
      " [-1.42216982e-01]\n",
      " [ 5.43438772e-02]]\n",
      "New_weights\n",
      "[[ 2.06634168e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.43964815e-05]\n",
      " [ 6.14864136e-06]\n",
      " [ 9.97494038e-06]\n",
      " [ 1.63841173e-05]\n",
      " [ 2.58293733e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 16\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18702301 0.         0.         ... 0.         5.17767297 0.        ]\n",
      " [3.81145183 0.         0.         ... 0.         4.80115794 0.        ]\n",
      " [3.4812068  0.         0.         ... 0.         4.28176195 0.        ]\n",
      " ...\n",
      " [2.45331279 0.         0.         ... 0.         2.69676473 0.01920377]\n",
      " [3.64718891 0.         0.         ... 0.         4.43072946 0.        ]\n",
      " [0.55940541 0.         0.         ... 0.         0.57786343 0.23208353]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.52430215]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994201]\n",
      " [1.        ]\n",
      " [0.99999761]\n",
      " [1.        ]\n",
      " [0.99999983]\n",
      " [0.99999771]\n",
      " [0.99999578]]\n",
      "Sums to 1: \n",
      "0.9999999999999989\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3702522877192135\n",
      "()\n",
      "Backward pass epoch 16\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 16\n",
      "Old_weights\n",
      "[[ 1.32490587e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86182424e-01]\n",
      " [ 1.43554600e-01]\n",
      " [ 2.33674646e-01]\n",
      " [-1.42233366e-01]\n",
      " [ 5.43412943e-02]]\n",
      "New_weights\n",
      "[[ 2.05793153e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.43418009e-05]\n",
      " [ 6.12581048e-06]\n",
      " [ 9.94086928e-06]\n",
      " [ 1.63178694e-05]\n",
      " [ 2.57298899e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 17\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18744136 0.         0.         ... 0.         5.18009154 0.        ]\n",
      " [3.8118965  0.         0.         ... 0.         4.80372871 0.        ]\n",
      " [3.48160169 0.         0.         ... 0.         4.28404491 0.        ]\n",
      " ...\n",
      " [2.45358216 0.         0.         ... 0.         2.69832198 0.01938757]\n",
      " [3.64760884 0.         0.         ... 0.         4.43315718 0.        ]\n",
      " [0.55946956 0.         0.         ... 0.         0.57823428 0.23212731]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.53970233]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994229]\n",
      " [1.        ]\n",
      " [0.99999762]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999772]\n",
      " [0.99999581]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3692568363684265\n",
      "()\n",
      "Backward pass epoch 17\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 17\n",
      "Old_weights\n",
      "[[ 1.32470007e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86168083e-01]\n",
      " [ 1.43548475e-01]\n",
      " [ 2.33664705e-01]\n",
      " [-1.42249684e-01]\n",
      " [ 5.43387213e-02]]\n",
      "New_weights\n",
      "[[ 2.04962279e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.42877649e-05]\n",
      " [ 6.10324752e-06]\n",
      " [ 9.90718623e-06]\n",
      " [ 1.62524198e-05]\n",
      " [ 2.56315812e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 18\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18785668 0.         0.         ... 0.         5.18249312 0.        ]\n",
      " [3.81233796 0.         0.         ... 0.         4.80628143 0.        ]\n",
      " [3.48199373 0.         0.         ... 0.         4.28631185 0.        ]\n",
      " ...\n",
      " [2.45384957 0.         0.         ... 0.         2.69986831 0.01957015]\n",
      " [3.64802574 0.         0.         ... 0.         4.43556786 0.        ]\n",
      " [0.55953324 0.         0.         ... 0.         0.57860253 0.23217079]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.55498202]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994257]\n",
      " [1.        ]\n",
      " [0.99999764]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999774]\n",
      " [0.99999583]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3682719815075478\n",
      "()\n",
      "Backward pass epoch 18\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 18\n",
      "Old_weights\n",
      "[[ 1.32449511e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86153795e-01]\n",
      " [ 1.43542371e-01]\n",
      " [ 2.33654798e-01]\n",
      " [-1.42265936e-01]\n",
      " [ 5.43361581e-02]]\n",
      "New_weights\n",
      "[[ 2.04141346e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.42343611e-05]\n",
      " [ 6.08094737e-06]\n",
      " [ 9.87388397e-06]\n",
      " [ 1.61877528e-05]\n",
      " [ 2.55344246e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 19\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18826903 0.         0.         ... 0.         5.18487797 0.        ]\n",
      " [3.81277626 0.         0.         ... 0.         4.80881636 0.        ]\n",
      " [3.48238296 0.         0.         ... 0.         4.28856299 0.        ]\n",
      " ...\n",
      " [2.45411507 0.         0.         ... 0.         2.70140386 0.01975151]\n",
      " [3.64843965 0.         0.         ... 0.         4.43796174 0.        ]\n",
      " [0.55959647 0.         0.         ... 0.         0.57896822 0.23221398]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.57014302]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994285]\n",
      " [1.        ]\n",
      " [0.99999765]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999775]\n",
      " [0.99999586]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.36729753247931407\n",
      "()\n",
      "Backward pass epoch 19\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 19\n",
      "Old_weights\n",
      "[[ 1.32429097e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86139560e-01]\n",
      " [ 1.43536290e-01]\n",
      " [ 2.33644924e-01]\n",
      " [-1.42282124e-01]\n",
      " [ 5.43336047e-02]]\n",
      "New_weights\n",
      "[[ 2.03330164e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.41815774e-05]\n",
      " [ 6.05890503e-06]\n",
      " [ 9.84095541e-06]\n",
      " [ 1.61238534e-05]\n",
      " [ 2.54383980e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 20\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18867844 0.         0.         ... 0.         5.18724633 0.        ]\n",
      " [3.81321144 0.         0.         ... 0.         4.81133377 0.        ]\n",
      " [3.48276942 0.         0.         ... 0.         4.29079857 0.        ]\n",
      " ...\n",
      " [2.45437869 0.         0.         ... 0.         2.70292879 0.01993168]\n",
      " [3.64885061 0.         0.         ... 0.         4.44033907 0.        ]\n",
      " [0.55965925 0.         0.         ... 0.         0.57933137 0.23225688]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.5851871]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994312]\n",
      " [1.        ]\n",
      " [0.99999767]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999776]\n",
      " [0.99999588]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.36633330345013276\n",
      "()\n",
      "Backward pass epoch 20\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 20\n",
      "Old_weights\n",
      "[[ 1.32408764e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86125379e-01]\n",
      " [ 1.43530232e-01]\n",
      " [ 2.33635083e-01]\n",
      " [-1.42298248e-01]\n",
      " [ 5.43310609e-02]]\n",
      "New_weights\n",
      "[[ 2.02528545e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.41294021e-05]\n",
      " [ 6.03711563e-06]\n",
      " [ 9.80839366e-06]\n",
      " [ 1.60607067e-05]\n",
      " [ 2.53434802e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 21\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18908496 0.         0.         ... 0.         5.18959845 0.        ]\n",
      " [3.81364354 0.         0.         ... 0.         4.8138339  0.        ]\n",
      " [3.48315314 0.         0.         ... 0.         4.29301881 0.        ]\n",
      " ...\n",
      " [2.45464043 0.         0.         ... 0.         2.70444326 0.02011067]\n",
      " [3.64925867 0.         0.         ... 0.         4.4427001  0.        ]\n",
      " [0.55972159 0.         0.         ... 0.         0.57969204 0.23229951]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.600116]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994338]\n",
      " [1.        ]\n",
      " [0.99999768]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999778]\n",
      " [0.99999591]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.36537911325326866\n",
      "()\n",
      "Backward pass epoch 21\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 21\n",
      "Old_weights\n",
      "[[ 1.32388511e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86111249e-01]\n",
      " [ 1.43524194e-01]\n",
      " [ 2.33625274e-01]\n",
      " [-1.42314309e-01]\n",
      " [ 5.43285265e-02]]\n",
      "New_weights\n",
      "[[ 2.01736306e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.40778238e-05]\n",
      " [ 6.01557445e-06]\n",
      " [ 9.77619200e-06]\n",
      " [ 1.59982986e-05]\n",
      " [ 2.52496502e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 22\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.18948863 0.         0.         ... 0.         5.19193455 0.        ]\n",
      " [3.81407261 0.         0.         ... 0.         4.81631701 0.        ]\n",
      " [3.48353418 0.         0.         ... 0.         4.29522394 0.        ]\n",
      " ...\n",
      " [2.45490035 0.         0.         ... 0.         2.70594743 0.0202885 ]\n",
      " [3.64966387 0.         0.         ... 0.         4.44504504 0.        ]\n",
      " [0.55978348 0.         0.         ... 0.         0.58005025 0.23234186]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.6149314]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994365]\n",
      " [1.        ]\n",
      " [0.99999769]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999779]\n",
      " [0.99999593]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.36443427561730485\n",
      "()\n",
      "Backward pass epoch 22\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 22\n",
      "Old_weights\n",
      "[[ 1.32368337e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86097172e-01]\n",
      " [ 1.43518179e-01]\n",
      " [ 2.33615498e-01]\n",
      " [-1.42330307e-01]\n",
      " [ 5.43260016e-02]]\n",
      "New_weights\n",
      "[[ 2.00952235e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.40267719e-05]\n",
      " [ 5.99424767e-06]\n",
      " [ 9.74430296e-06]\n",
      " [ 1.59365354e-05]\n",
      " [ 2.51568048e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 23\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.1898895  0.         0.         ... 0.         5.19425486 0.        ]\n",
      " [3.8144987  0.         0.         ... 0.         4.81878334 0.        ]\n",
      " [3.48391257 0.         0.         ... 0.         4.29741416 0.        ]\n",
      " ...\n",
      " [2.45515845 0.         0.         ... 0.         2.70744142 0.02046518]\n",
      " [3.65006625 0.         0.         ... 0.         4.44737414 0.        ]\n",
      " [0.55984495 0.         0.         ... 0.         0.58040604 0.23238393]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.62964108]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994391]\n",
      " [1.        ]\n",
      " [0.99999771]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.9999978 ]\n",
      " [0.99999595]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.36349848488854136\n",
      "()\n",
      "Backward pass epoch 23\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 23\n",
      "Old_weights\n",
      "[[ 1.32348242e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86083145e-01]\n",
      " [ 1.43512185e-01]\n",
      " [ 2.33605754e-01]\n",
      " [-1.42346244e-01]\n",
      " [ 5.43234859e-02]]\n",
      "New_weights\n",
      "[[ 2.00176362e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.39762435e-05]\n",
      " [ 5.97313613e-06]\n",
      " [ 9.71272555e-06]\n",
      " [ 1.58754182e-05]\n",
      " [ 2.50649273e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 24\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19028759 0.         0.         ... 0.         5.1965596  0.        ]\n",
      " [3.81492184 0.         0.         ... 0.         4.82123311 0.        ]\n",
      " [3.48428834 0.         0.         ... 0.         4.29958967 0.        ]\n",
      " ...\n",
      " [2.45541478 0.         0.         ... 0.         2.70892538 0.02064074]\n",
      " [3.65046585 0.         0.         ... 0.         4.4496876  0.        ]\n",
      " [0.55990599 0.         0.         ... 0.         0.58075945 0.23242574]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.6442404]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994417]\n",
      " [1.        ]\n",
      " [0.99999772]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999782]\n",
      " [0.99999598]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3625722353955412\n",
      "()\n",
      "Backward pass epoch 24\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 24\n",
      "Old_weights\n",
      "[[ 1.32328224e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86069169e-01]\n",
      " [ 1.43506211e-01]\n",
      " [ 2.33596041e-01]\n",
      " [-1.42362119e-01]\n",
      " [ 5.43209794e-02]]\n",
      "New_weights\n",
      "[[ 1.99409385e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.39262815e-05]\n",
      " [ 5.95226021e-06]\n",
      " [ 9.68149032e-06]\n",
      " [ 1.58150013e-05]\n",
      " [ 2.49740813e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 25\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19068295 0.         0.         ... 0.         5.19884898 0.        ]\n",
      " [3.81534208 0.         0.         ... 0.         4.82366655 0.        ]\n",
      " [3.48466154 0.         0.         ... 0.         4.30175069 0.        ]\n",
      " ...\n",
      " [2.45566934 0.         0.         ... 0.         2.71039946 0.02081518]\n",
      " [3.65086271 0.         0.         ... 0.         4.45198565 0.        ]\n",
      " [0.55996662 0.         0.         ... 0.         0.5811105  0.23246729]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.65873094]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994442]\n",
      " [1.        ]\n",
      " [0.99999773]\n",
      " [1.        ]\n",
      " [0.99999984]\n",
      " [0.99999783]\n",
      " [0.999996  ]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3616553626975113\n",
      "()\n",
      "Backward pass epoch 25\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 25\n",
      "Old_weights\n",
      "[[ 1.32308284e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86055242e-01]\n",
      " [ 1.43500259e-01]\n",
      " [ 2.33586360e-01]\n",
      " [-1.42377934e-01]\n",
      " [ 5.43184820e-02]]\n",
      "New_weights\n",
      "[[ 1.98651137e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.38768756e-05]\n",
      " [ 5.93161564e-06]\n",
      " [ 9.65059117e-06]\n",
      " [ 1.57552717e-05]\n",
      " [ 2.48842480e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 26\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19107562 0.         0.         ... 0.         5.20112322 0.        ]\n",
      " [3.81575946 0.         0.         ... 0.         4.82608391 0.        ]\n",
      " [3.48503219 0.         0.         ... 0.         4.30389742 0.        ]\n",
      " ...\n",
      " [2.45592217 0.         0.         ... 0.         2.71186379 0.02098852]\n",
      " [3.65125686 0.         0.         ... 0.         4.45426849 0.        ]\n",
      " [0.56002683 0.         0.         ... 0.         0.58145923 0.23250857]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.67311425]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994468]\n",
      " [1.        ]\n",
      " [0.99999775]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999784]\n",
      " [0.99999602]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3607477063401099\n",
      "()\n",
      "Backward pass epoch 26\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 26\n",
      "Old_weights\n",
      "[[ 1.32288418e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86041365e-01]\n",
      " [ 1.43494328e-01]\n",
      " [ 2.33576709e-01]\n",
      " [-1.42393689e-01]\n",
      " [ 5.43159935e-02]]\n",
      "New_weights\n",
      "[[ 1.97901459e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.38280157e-05]\n",
      " [ 5.91119823e-06]\n",
      " [ 9.62002217e-06]\n",
      " [ 1.56962167e-05]\n",
      " [ 2.47954090e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 27\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19146563 0.         0.         ... 0.         5.20338253 0.        ]\n",
      " [3.81617402 0.         0.         ... 0.         4.82848539 0.        ]\n",
      " [3.48540033 0.         0.         ... 0.         4.30603005 0.        ]\n",
      " ...\n",
      " [2.45617329 0.         0.         ... 0.         2.7133185  0.02116078]\n",
      " [3.65164835 0.         0.         ... 0.         4.45653635 0.        ]\n",
      " [0.56008663 0.         0.         ... 0.         0.58180567 0.23254959]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.68739186]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994493]\n",
      " [1.        ]\n",
      " [0.99999776]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999786]\n",
      " [0.99999604]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3598491097312208\n",
      "()\n",
      "Backward pass epoch 27\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 27\n",
      "Old_weights\n",
      "[[ 1.32268628e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86027537e-01]\n",
      " [ 1.43488416e-01]\n",
      " [ 2.33567089e-01]\n",
      " [-1.42409385e-01]\n",
      " [ 5.43135140e-02]]\n",
      "New_weights\n",
      "[[ 1.97160194e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.37796919e-05]\n",
      " [ 5.89100390e-06]\n",
      " [ 9.58977749e-06]\n",
      " [ 1.56378240e-05]\n",
      " [ 2.47075463e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 28\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19185302 0.         0.         ... 0.         5.20562711 0.        ]\n",
      " [3.81658579 0.         0.         ... 0.         4.83087121 0.        ]\n",
      " [3.485766   0.         0.         ... 0.         4.30814878 0.        ]\n",
      " ...\n",
      " [2.45642272 0.         0.         ... 0.         2.71476374 0.02133198]\n",
      " [3.65203721 0.         0.         ... 0.         4.45878943 0.        ]\n",
      " [0.56014603 0.         0.         ... 0.         0.58214985 0.23259036]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.70156525]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994517]\n",
      " [1.        ]\n",
      " [0.99999777]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999787]\n",
      " [0.99999606]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3589594200214706\n",
      "()\n",
      "Backward pass epoch 28\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 28\n",
      "Old_weights\n",
      "[[ 1.32248912e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86013758e-01]\n",
      " [ 1.43482525e-01]\n",
      " [ 2.33557499e-01]\n",
      " [-1.42425023e-01]\n",
      " [ 5.43110432e-02]]\n",
      "New_weights\n",
      "[[ 1.96427189e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.37318948e-05]\n",
      " [ 5.87102868e-06]\n",
      " [ 9.55985150e-06]\n",
      " [ 1.55800816e-05]\n",
      " [ 2.46206426e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 29\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19223783 0.         0.         ... 0.         5.20785717 0.        ]\n",
      " [3.81699481 0.         0.         ... 0.         4.8332416  0.        ]\n",
      " [3.48612924 0.         0.         ... 0.         4.3102538  0.        ]\n",
      " ...\n",
      " [2.45667049 0.         0.         ... 0.         2.71619962 0.02150212]\n",
      " [3.65242348 0.         0.         ... 0.         4.46102794 0.        ]\n",
      " [0.56020504 0.         0.         ... 0.         0.58249181 0.23263088]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.71563587]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994541]\n",
      " [1.        ]\n",
      " [0.99999778]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999788]\n",
      " [0.99999609]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.35807848798920505\n",
      "()\n",
      "Backward pass epoch 29\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 29\n",
      "Old_weights\n",
      "[[ 1.32229270e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.86000026e-01]\n",
      " [ 1.43476654e-01]\n",
      " [ 2.33547939e-01]\n",
      " [-1.42440603e-01]\n",
      " [ 5.43085812e-02]]\n",
      "New_weights\n",
      "[[ 1.95702295e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.36846148e-05]\n",
      " [ 5.85126868e-06]\n",
      " [ 9.53023867e-06]\n",
      " [ 1.55229777e-05]\n",
      " [ 2.45346807e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 30\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.1926201  0.         0.         ... 0.         5.21007291 0.        ]\n",
      " [3.81740113 0.         0.         ... 0.         4.83559677 0.        ]\n",
      " [3.48649007 0.         0.         ... 0.         4.3123453  0.        ]\n",
      " ...\n",
      " [2.45691663 0.         0.         ... 0.         2.71762628 0.02167122]\n",
      " [3.65280719 0.         0.         ... 0.         4.46325206 0.        ]\n",
      " [0.56026366 0.         0.         ... 0.         0.58283157 0.23267115]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.72960516]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994566]\n",
      " [1.        ]\n",
      " [0.9999978 ]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999789]\n",
      " [0.99999611]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3572061679298344\n",
      "()\n",
      "Backward pass epoch 30\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 30\n",
      "Old_weights\n",
      "[[ 1.32209699e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85986341e-01]\n",
      " [ 1.43470803e-01]\n",
      " [ 2.33538409e-01]\n",
      " [-1.42456126e-01]\n",
      " [ 5.43061277e-02]]\n",
      "New_weights\n",
      "[[ 1.94985367e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.36378430e-05]\n",
      " [ 5.83172014e-06]\n",
      " [ 9.50093360e-06]\n",
      " [ 1.54665011e-05]\n",
      " [ 2.44496441e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 31\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19299985 0.         0.         ... 0.         5.21227452 0.        ]\n",
      " [3.81780478 0.         0.         ... 0.         4.83793691 0.        ]\n",
      " [3.48684853 0.         0.         ... 0.         4.31442346 0.        ]\n",
      " ...\n",
      " [2.45716114 0.         0.         ... 0.         2.71904384 0.02183929]\n",
      " [3.65318838 0.         0.         ... 0.         4.465462   0.        ]\n",
      " [0.56032189 0.         0.         ... 0.         0.58316916 0.23271118]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.74347452]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994589]\n",
      " [1.        ]\n",
      " [0.99999781]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.9999979 ]\n",
      " [0.99999613]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3563423175492587\n",
      "()\n",
      "Backward pass epoch 31\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 31\n",
      "Old_weights\n",
      "[[ 1.32190201e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85972703e-01]\n",
      " [ 1.43464971e-01]\n",
      " [ 2.33528908e-01]\n",
      " [-1.42471593e-01]\n",
      " [ 5.43036828e-02]]\n",
      "New_weights\n",
      "[[ 1.94276264e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.35915705e-05]\n",
      " [ 5.81237935e-06]\n",
      " [ 9.47193105e-06]\n",
      " [ 1.54106405e-05]\n",
      " [ 2.43655165e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 32\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19337713 0.         0.         ... 0.         5.21446218 0.        ]\n",
      " [3.8182058  0.         0.         ... 0.         4.84026223 0.        ]\n",
      " [3.48720465 0.         0.         ... 0.         4.31648847 0.        ]\n",
      " ...\n",
      " [2.45740406 0.         0.         ... 0.         2.72045243 0.02200635]\n",
      " [3.65356708 0.         0.         ... 0.         4.46765794 0.        ]\n",
      " [0.56037974 0.         0.         ... 0.         0.58350462 0.23275097]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.7572453]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994613]\n",
      " [1.        ]\n",
      " [0.99999782]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999792]\n",
      " [0.99999615]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3554867978612092\n",
      "()\n",
      "Backward pass epoch 32\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 32\n",
      "Old_weights\n",
      "[[ 1.32170773e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85959112e-01]\n",
      " [ 1.43459159e-01]\n",
      " [ 2.33519436e-01]\n",
      " [-1.42487003e-01]\n",
      " [ 5.43012462e-02]]\n",
      "New_weights\n",
      "[[ 1.93574848e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.35457884e-05]\n",
      " [ 5.79324273e-06]\n",
      " [ 9.44322587e-06]\n",
      " [ 1.53553851e-05]\n",
      " [ 2.42822821e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 33\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19375196 0.         0.         ... 0.         5.21663609 0.        ]\n",
      " [3.81860422 0.         0.         ... 0.         4.84257293 0.        ]\n",
      " [3.48755847 0.         0.         ... 0.         4.31854048 0.        ]\n",
      " ...\n",
      " [2.4576454  0.         0.         ... 0.         2.72185215 0.02217242]\n",
      " [3.65394333 0.         0.         ... 0.         4.46984007 0.        ]\n",
      " [0.56043722 0.         0.         ... 0.         0.58383797 0.23279051]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.77091886]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994636]\n",
      " [1.        ]\n",
      " [0.99999783]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999793]\n",
      " [0.99999617]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3546394730884259\n",
      "()\n",
      "Backward pass epoch 33\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 33\n",
      "Old_weights\n",
      "[[ 1.32151416e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85945566e-01]\n",
      " [ 1.43453366e-01]\n",
      " [ 2.33509993e-01]\n",
      " [-1.42502359e-01]\n",
      " [ 5.42988180e-02]]\n",
      "New_weights\n",
      "[[ 1.92880983e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.35004885e-05]\n",
      " [ 5.77430674e-06]\n",
      " [ 9.41481305e-06]\n",
      " [ 1.53007243e-05]\n",
      " [ 2.41999256e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 34\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19412438 0.         0.         ... 0.         5.21879643 0.        ]\n",
      " [3.81900007 0.         0.         ... 0.         4.8448692  0.        ]\n",
      " [3.48791001 0.         0.         ... 0.         4.32057969 0.        ]\n",
      " ...\n",
      " [2.45788519 0.         0.         ... 0.         2.72324314 0.0223375 ]\n",
      " [3.65431716 0.         0.         ... 0.         4.47200858 0.        ]\n",
      " [0.56049433 0.         0.         ... 0.         0.58416924 0.23282983]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.7844965]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994659]\n",
      " [1.        ]\n",
      " [0.99999784]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999794]\n",
      " [0.99999619]]\n",
      "Sums to 1: \n",
      "0.9999999999999991\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.35380021056735494\n",
      "()\n",
      "Backward pass epoch 34\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 34\n",
      "Old_weights\n",
      "[[ 1.32132128e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85932065e-01]\n",
      " [ 1.43447591e-01]\n",
      " [ 2.33500578e-01]\n",
      " [-1.42517660e-01]\n",
      " [ 5.42963980e-02]]\n",
      "New_weights\n",
      "[[ 1.92194539e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.34556624e-05]\n",
      " [ 5.75556797e-06]\n",
      " [ 9.38668771e-06]\n",
      " [ 1.52466477e-05]\n",
      " [ 2.41184317e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 35\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19449442 0.         0.         ... 0.         5.22094338 0.        ]\n",
      " [3.81939339 0.         0.         ... 0.         4.84715124 0.        ]\n",
      " [3.48825929 0.         0.         ... 0.         4.32260624 0.        ]\n",
      " ...\n",
      " [2.45812345 0.         0.         ... 0.         2.72462551 0.02250161]\n",
      " [3.6546886  0.         0.         ... 0.         4.47416365 0.        ]\n",
      " [0.56055107 0.         0.         ... 0.         0.58449845 0.23286891]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.79797952]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994682]\n",
      " [1.        ]\n",
      " [0.99999786]\n",
      " [1.        ]\n",
      " [0.99999985]\n",
      " [0.99999795]\n",
      " [0.99999621]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.352968880656378\n",
      "()\n",
      "Backward pass epoch 35\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 35\n",
      "Old_weights\n",
      "[[ 1.32112908e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85918610e-01]\n",
      " [ 1.43441836e-01]\n",
      " [ 2.33491192e-01]\n",
      " [-1.42532906e-01]\n",
      " [ 5.42939861e-02]]\n",
      "New_weights\n",
      "[[ 1.91515388e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.34113020e-05]\n",
      " [ 5.73702306e-06]\n",
      " [ 9.35884505e-06]\n",
      " [ 1.51931453e-05]\n",
      " [ 2.40377859e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 36\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19486211 0.         0.         ... 0.         5.2230771  0.        ]\n",
      " [3.81978422 0.         0.         ... 0.         4.84941922 0.        ]\n",
      " [3.48860637 0.         0.         ... 0.         4.32462032 0.        ]\n",
      " ...\n",
      " [2.4583602  0.         0.         ... 0.         2.72599936 0.02266475]\n",
      " [3.65505768 0.         0.         ... 0.         4.47630544 0.        ]\n",
      " [0.56060745 0.         0.         ... 0.         0.58482564 0.23290777]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.81136916]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994704]\n",
      " [1.        ]\n",
      " [0.99999787]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999796]\n",
      " [0.99999623]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3521453566472588\n",
      "()\n",
      "Backward pass epoch 36\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 36\n",
      "Old_weights\n",
      "[[ 1.32093757e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85905199e-01]\n",
      " [ 1.43436099e-01]\n",
      " [ 2.33481833e-01]\n",
      " [-1.42548099e-01]\n",
      " [ 5.42915824e-02]]\n",
      "New_weights\n",
      "[[ 1.90843403e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.33673995e-05]\n",
      " [ 5.71866875e-06]\n",
      " [ 9.33128040e-06]\n",
      " [ 1.51402072e-05]\n",
      " [ 2.39579737e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 37\n",
      "Layer 0\n",
      "Layer 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of hidden layer\n",
      "[[3.19522748 0.         0.         ... 0.         5.22519778 0.        ]\n",
      " [3.82017258 0.         0.         ... 0.         4.85167333 0.        ]\n",
      " [3.48895125 0.         0.         ... 0.         4.32662209 0.        ]\n",
      " ...\n",
      " [2.45859545 0.         0.         ... 0.         2.72736481 0.02282695]\n",
      " [3.65542443 0.         0.         ... 0.         4.47843414 0.        ]\n",
      " [0.56066348 0.         0.         ... 0.         0.58515083 0.23294639]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.82466668]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994726]\n",
      " [1.        ]\n",
      " [0.99999788]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999797]\n",
      " [0.99999625]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.35132951965662546\n",
      "()\n",
      "Backward pass epoch 37\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 37\n",
      "Old_weights\n",
      "[[ 1.32074672e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85891831e-01]\n",
      " [ 1.43430380e-01]\n",
      " [ 2.33472501e-01]\n",
      " [-1.42563240e-01]\n",
      " [ 5.42891866e-02]]\n",
      "New_weights\n",
      "[[ 1.90178462e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.33239471e-05]\n",
      " [ 5.70050183e-06]\n",
      " [ 9.30398921e-06]\n",
      " [ 1.50878237e-05]\n",
      " [ 2.38789811e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 38\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19559056 0.         0.         ... 0.         5.22730557 0.        ]\n",
      " [3.82055851 0.         0.         ... 0.         4.85391375 0.        ]\n",
      " [3.48929398 0.         0.         ... 0.         4.32861169 0.        ]\n",
      " ...\n",
      " [2.45882923 0.         0.         ... 0.         2.72872196 0.02298822]\n",
      " [3.65578889 0.         0.         ... 0.         4.48054991 0.        ]\n",
      " [0.56071915 0.         0.         ... 0.         0.58547404 0.2329848 ]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.83787328]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994748]\n",
      " [1.        ]\n",
      " [0.99999789]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999798]\n",
      " [0.99999627]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.35052124451051414\n",
      "()\n",
      "Backward pass epoch 38\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 38\n",
      "Old_weights\n",
      "[[ 1.32055654e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85878507e-01]\n",
      " [ 1.43424680e-01]\n",
      " [ 2.33463197e-01]\n",
      " [-1.42578327e-01]\n",
      " [ 5.42867987e-02]]\n",
      "New_weights\n",
      "[[ 1.89520447e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.32809375e-05]\n",
      " [ 5.68251919e-06]\n",
      " [ 9.27696701e-06]\n",
      " [ 1.50359856e-05]\n",
      " [ 2.38007945e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 39\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19595139 0.         0.         ... 0.         5.22940065 0.        ]\n",
      " [3.82094204 0.         0.         ... 0.         4.85614066 0.        ]\n",
      " [3.48963457 0.         0.         ... 0.         4.3305893  0.        ]\n",
      " ...\n",
      " [2.45906156 0.         0.         ... 0.         2.73007093 0.02314856]\n",
      " [3.65615108 0.         0.         ... 0.         4.48265291 0.        ]\n",
      " [0.56077448 0.         0.         ... 0.         0.5857953  0.23302299]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.85099015]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999477 ]\n",
      " [1.        ]\n",
      " [0.9999979 ]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.999998  ]\n",
      " [0.99999629]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3497204175494008\n",
      "()\n",
      "Backward pass epoch 39\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 39\n",
      "Old_weights\n",
      "[[ 1.32036702e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85865226e-01]\n",
      " [ 1.43418997e-01]\n",
      " [ 2.33453920e-01]\n",
      " [-1.42593363e-01]\n",
      " [ 5.42844186e-02]]\n",
      "New_weights\n",
      "[[ 1.88869241e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.32383631e-05]\n",
      " [ 5.66471778e-06]\n",
      " [ 9.25020945e-06]\n",
      " [ 1.49846835e-05]\n",
      " [ 2.37234003e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 40\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19630998 0.         0.         ... 0.         5.23148318 0.        ]\n",
      " [3.82132319 0.         0.         ... 0.         4.85835422 0.        ]\n",
      " [3.48997306 0.         0.         ... 0.         4.33255505 0.        ]\n",
      " ...\n",
      " [2.45929245 0.         0.         ... 0.         2.73141182 0.02330799]\n",
      " [3.65651103 0.         0.         ... 0.         4.48474332 0.        ]\n",
      " [0.56082947 0.         0.         ... 0.         0.58611465 0.23306096]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.86401846]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994792]\n",
      " [1.        ]\n",
      " [0.99999791]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999801]\n",
      " [0.99999631]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.34892692330069386\n",
      "()\n",
      "Backward pass epoch 40\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 40\n",
      "Old_weights\n",
      "[[ 1.32017815e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85851988e-01]\n",
      " [ 1.43413332e-01]\n",
      " [ 2.33444670e-01]\n",
      " [-1.42608348e-01]\n",
      " [ 5.42820462e-02]]\n",
      "New_weights\n",
      "[[ 1.88224729e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.31962169e-05]\n",
      " [ 5.64709462e-06]\n",
      " [ 9.22371227e-06]\n",
      " [ 1.49339086e-05]\n",
      " [ 2.36467857e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 41\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19666638 0.         0.         ... 0.         5.23355332 0.        ]\n",
      " [3.82170201 0.         0.         ... 0.         4.8605546  0.        ]\n",
      " [3.49030947 0.         0.         ... 0.         4.3345091  0.        ]\n",
      " ...\n",
      " [2.45952192 0.         0.         ... 0.         2.73274473 0.02346652]\n",
      " [3.65686877 0.         0.         ... 0.         4.48682128 0.        ]\n",
      " [0.56088412 0.         0.         ... 0.         0.58643209 0.23309871]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.87695934]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994813]\n",
      " [1.        ]\n",
      " [0.99999792]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999802]\n",
      " [0.99999633]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3481406423108061\n",
      "()\n",
      "Backward pass epoch 41\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 41\n",
      "Old_weights\n",
      "[[ 1.31998993e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85838792e-01]\n",
      " [ 1.43407685e-01]\n",
      " [ 2.33435447e-01]\n",
      " [-1.42623282e-01]\n",
      " [ 5.42796816e-02]]\n",
      "New_weights\n",
      "[[ 1.87586800e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.31544918e-05]\n",
      " [ 5.62964681e-06]\n",
      " [ 9.19747130e-06]\n",
      " [ 1.48836520e-05]\n",
      " [ 2.35709377e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 42\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.1970206  0.         0.         ... 0.         5.23561121 0.        ]\n",
      " [3.82207852 0.         0.         ... 0.         4.86274198 0.        ]\n",
      " [3.49064382 0.         0.         ... 0.         4.3364516  0.        ]\n",
      " ...\n",
      " [2.45975    0.         0.         ... 0.         2.73406976 0.02362416]\n",
      " [3.65722433 0.         0.         ... 0.         4.48888695 0.        ]\n",
      " [0.56093844 0.         0.         ... 0.         0.58674765 0.23313625]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.88981392]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994834]\n",
      " [1.        ]\n",
      " [0.99999793]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999803]\n",
      " [0.99999634]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3473614637853784\n",
      "()\n",
      "Backward pass epoch 42\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 42\n",
      "Old_weights\n",
      "[[ 1.31980234e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85825637e-01]\n",
      " [ 1.43402056e-01]\n",
      " [ 2.33426249e-01]\n",
      " [-1.42638166e-01]\n",
      " [ 5.42773245e-02]]\n",
      "New_weights\n",
      "[[ 1.86955346e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.31131810e-05]\n",
      " [ 5.61237149e-06]\n",
      " [ 9.17148246e-06]\n",
      " [ 1.48339053e-05]\n",
      " [ 2.34958438e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 43\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19737267 0.         0.         ... 0.         5.23765703 0.        ]\n",
      " [3.82245275 0.         0.         ... 0.         4.86491651 0.        ]\n",
      " [3.49097616 0.         0.         ... 0.         4.33838269 0.        ]\n",
      " ...\n",
      " [2.45997669 0.         0.         ... 0.         2.735387   0.02378092]\n",
      " [3.65757774 0.         0.         ... 0.         4.4909405  0.        ]\n",
      " [0.56099243 0.         0.         ... 0.         0.58706136 0.23317359]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.9025833]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994855]\n",
      " [1.        ]\n",
      " [0.99999794]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999804]\n",
      " [0.99999636]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3465892793252908\n",
      "()\n",
      "Backward pass epoch 43\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 43\n",
      "Old_weights\n",
      "[[ 1.31961539e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85812524e-01]\n",
      " [ 1.43396443e-01]\n",
      " [ 2.33417078e-01]\n",
      " [-1.42653000e-01]\n",
      " [ 5.42749749e-02]]\n",
      "New_weights\n",
      "[[ 1.86330261e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.30722777e-05]\n",
      " [ 5.59526588e-06]\n",
      " [ 9.14574179e-06]\n",
      " [ 1.47846601e-05]\n",
      " [ 2.34214920e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 44\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19772263 0.         0.         ... 0.         5.2396909  0.        ]\n",
      " [3.82282472 0.         0.         ... 0.         4.86707835 0.        ]\n",
      " [3.49130649 0.         0.         ... 0.         4.34030252 0.        ]\n",
      " ...\n",
      " [2.46020202 0.         0.         ... 0.         2.73669656 0.02393681]\n",
      " [3.65792902 0.         0.         ... 0.         4.49298206 0.        ]\n",
      " [0.56104609 0.         0.         ... 0.         0.58737324 0.23321071]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.91526856]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994875]\n",
      " [1.        ]\n",
      " [0.99999796]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999805]\n",
      " [0.99999638]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3458239828600304\n",
      "()\n",
      "Backward pass epoch 44\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 44\n",
      "Old_weights\n",
      "[[ 1.31942906e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85799452e-01]\n",
      " [ 1.43390848e-01]\n",
      " [ 2.33407932e-01]\n",
      " [-1.42667784e-01]\n",
      " [ 5.42726327e-02]]\n",
      "New_weights\n",
      "[[ 1.85711440e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.30317755e-05]\n",
      " [ 5.57832728e-06]\n",
      " [ 9.12024539e-06]\n",
      " [ 1.47359081e-05]\n",
      " [ 2.33478702e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 45\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19807049 0.         0.         ... 0.         5.24171299 0.        ]\n",
      " [3.82319447 0.         0.         ... 0.         4.86922766 0.        ]\n",
      " [3.49163484 0.         0.         ... 0.         4.34221121 0.        ]\n",
      " ...\n",
      " [2.460426   0.         0.         ... 0.         2.73799853 0.02409185]\n",
      " [3.6582782  0.         0.         ... 0.         4.4950118  0.        ]\n",
      " [0.56109943 0.         0.         ... 0.         0.58768332 0.23324764]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.92787075]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994896]\n",
      " [1.        ]\n",
      " [0.99999797]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999806]\n",
      " [0.9999964 ]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.34506547386701847\n",
      "()\n",
      "Backward pass epoch 45\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 45\n",
      "Old_weights\n",
      "[[ 1.31924335e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85786420e-01]\n",
      " [ 1.43385270e-01]\n",
      " [ 2.33398812e-01]\n",
      " [-1.42682520e-01]\n",
      " [ 5.42702980e-02]]\n",
      "New_weights\n",
      "[[ 1.85098782e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.29916679e-05]\n",
      " [ 5.56155301e-06]\n",
      " [ 9.09498944e-06]\n",
      " [ 1.46876415e-05]\n",
      " [ 2.32749668e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 46\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19841629 0.         0.         ... 0.         5.24372343 0.        ]\n",
      " [3.82356202 0.         0.         ... 0.         4.87136459 0.        ]\n",
      " [3.49196125 0.         0.         ... 0.         4.34410892 0.        ]\n",
      " ...\n",
      " [2.46064865 0.         0.         ... 0.         2.739293   0.02424604]\n",
      " [3.6586253  0.         0.         ... 0.         4.49702984 0.        ]\n",
      " [0.56115246 0.         0.         ... 0.         0.58799161 0.23328436]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.94039091]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994916]\n",
      " [1.        ]\n",
      " [0.99999798]\n",
      " [1.        ]\n",
      " [0.99999986]\n",
      " [0.99999807]\n",
      " [0.99999642]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3443136497200456\n",
      "()\n",
      "Backward pass epoch 46\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 46\n",
      "Old_weights\n",
      "[[ 1.31905825e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85773428e-01]\n",
      " [ 1.43379708e-01]\n",
      " [ 2.33389717e-01]\n",
      " [-1.42697208e-01]\n",
      " [ 5.42679705e-02]]\n",
      "New_weights\n",
      "[[ 1.84492188e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.29519487e-05]\n",
      " [ 5.54494048e-06]\n",
      " [ 9.06997022e-06]\n",
      " [ 1.46398524e-05]\n",
      " [ 2.32027704e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 47\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19876004 0.         0.         ... 0.         5.24572237 0.        ]\n",
      " [3.8239274  0.         0.         ... 0.         4.8734893  0.        ]\n",
      " [3.49228573 0.         0.         ... 0.         4.34599576 0.        ]\n",
      " ...\n",
      " [2.46086998 0.         0.         ... 0.         2.74058007 0.02439939]\n",
      " [3.65897035 0.         0.         ... 0.         4.49903633 0.        ]\n",
      " [0.56120517 0.         0.         ... 0.         0.58829813 0.23332088]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.95283007]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994936]\n",
      " [1.        ]\n",
      " [0.99999799]\n",
      " [1.        ]\n",
      " [0.99999987]\n",
      " [0.99999808]\n",
      " [0.99999643]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.3435684109317352\n",
      "()\n",
      "Backward pass epoch 47\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 47\n",
      "Old_weights\n",
      "[[ 1.31887375e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85760476e-01]\n",
      " [ 1.43374163e-01]\n",
      " [ 2.33380647e-01]\n",
      " [-1.42711848e-01]\n",
      " [ 5.42656502e-02]]\n",
      "New_weights\n",
      "[[ 1.83891561e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.29126117e-05]\n",
      " [ 5.52848715e-06]\n",
      " [ 9.04518408e-06]\n",
      " [ 1.45925331e-05]\n",
      " [ 2.31312697e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 48\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19910178 0.         0.         ... 0.         5.24770995 0.        ]\n",
      " [3.82429064 0.         0.         ... 0.         4.87560193 0.        ]\n",
      " [3.4926083  0.         0.         ... 0.         4.34787188 0.        ]\n",
      " ...\n",
      " [2.46109002 0.         0.         ... 0.         2.74185982 0.02455192]\n",
      " [3.65931338 0.         0.         ... 0.         4.50103142 0.        ]\n",
      " [0.56125757 0.         0.         ... 0.         0.58860292 0.23335721]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.96518922]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994956]\n",
      " [1.        ]\n",
      " [0.999998  ]\n",
      " [1.        ]\n",
      " [0.99999987]\n",
      " [0.99999809]\n",
      " [0.99999645]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.342829660932504\n",
      "()\n",
      "Backward pass epoch 48\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 48\n",
      "Old_weights\n",
      "[[ 1.31868986e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85747564e-01]\n",
      " [ 1.43368635e-01]\n",
      " [ 2.33371601e-01]\n",
      " [-1.42726440e-01]\n",
      " [ 5.42633370e-02]]\n",
      "New_weights\n",
      "[[ 1.83296805e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.28736510e-05]\n",
      " [ 5.51219053e-06]\n",
      " [ 9.02062746e-06]\n",
      " [ 1.45456762e-05]\n",
      " [ 2.30604540e-06]]\n",
      "End of Backwards pass\n",
      "(569, 30)\n",
      "Forward pass epoch 49\n",
      "Layer 0\n",
      "Layer 1\n",
      "Output of hidden layer\n",
      "[[3.19944153 0.         0.         ... 0.         5.2496863  0.        ]\n",
      " [3.82465176 0.         0.         ... 0.         4.87770262 0.        ]\n",
      " [3.49292899 0.         0.         ... 0.         4.34973741 0.        ]\n",
      " ...\n",
      " [2.46130877 0.         0.         ... 0.         2.74313234 0.02470363]\n",
      " [3.65965441 0.         0.         ... 0.         4.50301524 0.        ]\n",
      " [0.56130967 0.         0.         ... 0.         0.58890598 0.23339334]]\n",
      "Layer 2\n",
      "Weights and biases\n",
      "[34.97746934]\n",
      "Output layer\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99994975]\n",
      " [1.        ]\n",
      " [0.99999801]\n",
      " [1.        ]\n",
      " [0.99999987]\n",
      " [0.9999981 ]\n",
      " [0.99999647]]\n",
      "Sums to 1: \n",
      "0.9999999999999993\n",
      "At least one output is closer to 1: \n",
      "1.0\n",
      "Model output shape: (569, 1)\n",
      "Model target shape: (569, 1)\n",
      "Cross Loss: 0.34209730119925863\n",
      "()\n",
      "Backward pass epoch 49\n",
      "%Shape of output derivative_error(569, 64)\n",
      "Update pass epoch 49\n",
      "Old_weights\n",
      "[[ 1.31850657e-01]\n",
      " [-4.56492916e-04]\n",
      " [-1.66943513e-03]\n",
      " [ 1.94124801e-04]\n",
      " [ 4.08164485e-04]\n",
      " [ 1.85734690e-01]\n",
      " [ 1.43363123e-01]\n",
      " [ 2.33362581e-01]\n",
      " [-1.42740986e-01]\n",
      " [ 5.42610310e-02]]\n",
      "New_weights\n",
      "[[ 1.82707829e-05]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.28350607e-05]\n",
      " [ 5.49604819e-06]\n",
      " [ 8.99629687e-06]\n",
      " [ 1.44992745e-05]\n",
      " [ 2.29903125e-06]]\n",
      "End of Backwards pass\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X, y, learning_rate = 0.01, dropout_rate = 0, batch_size = 1, epochs = 50)\n",
    "model.addLayer(X.shape[1], X.shape[1], 'relu', 'input')\n",
    "model.addLayer(X.shape[1], 64, 'relu', 'hidden')\n",
    "model.addLayer(64, 1, 'sigmoid', 'output')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e - Implement optimizer\n",
    "Implement any two optimizers of your choice. Briefly present the optimizers \n",
    "in the report. The optimizers can be flavours of gradient descent. For \n",
    "instance: Stochastic gradient descent (SGD) and SGD with momentum. \n",
    "SGD and mini-batch gradient descent, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f - Evaluate different neural network architectures/parameters, present and discuss your results.\n",
    "Be creative in the analysis and discussion. Evaluate different\n",
    "hyperparameters. For instance: different network architectures, activation \n",
    "functions, comparison of optimizers, L1/L2 performance comparison with \n",
    "dropout, etc. Support your results with plots/graph and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
