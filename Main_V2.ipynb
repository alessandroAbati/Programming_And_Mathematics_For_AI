{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236dfa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ReLU layer class\n",
    "class ReLU:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data # store the input to use it in the backward pass\n",
    "        return np.maximum(0, input_data) # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return output_gradient * (self.input > 0)\n",
    "        #return output_gradient * np.where(self.input > 0, 1.0, 0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1d0cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid layer class\n",
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.output = 1 / (1 + np.exp(-input_data)) # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('output_gradient'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        return output_gradient * (self.output * (1 - self.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94c275e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax layer class\n",
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - input_data (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'input_data', with the\n",
    "                         same shape as 'input_data'.\n",
    "        ''' \n",
    "        exp_values = np.exp(input_data - np.max(input_data, axis=1, keepdims=True)) # Shift the input data to avoid numerical instability in exponential calculations\n",
    "        output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return output\n",
    "\n",
    "    def backward_pass(self, dvalues):\n",
    "        # The gradient of loss with respect to the input logits \n",
    "        # directly passed through in case of softmax + categorical cross-entropy\n",
    "        return dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb61882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:    \n",
    "    def __init__(self, probability):\n",
    "        self.probability = probability\n",
    "        \n",
    "    def forward_pass(self, input_data):\n",
    "        self.mask = np.random.binomial(1, 1-self.probability, size=input_data.shape) / (1-self.probability)\n",
    "        return input_data * self.mask\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        return output_gradient * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a283b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer class\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = 0.01 * np.random.normal(0, 1/np.sqrt(input_size), (input_size, output_size)) # Normal distribution initialisation\n",
    "        self.biases = np.full((1, output_size), 0.001) # Initialise biases with a small positive value\n",
    "        self.input = None\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data\n",
    "        return np.dot(input_data, self.weights) + self.biases\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate):\n",
    "        '''\n",
    "        Computes the backward pass of the Dense layer.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient: The gradient of the loss function with respect to the output of the layer.\n",
    "\n",
    "        - learning_rate: A hyperparameter that controls how much the weights and biases are updated during training.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: the gradient of the loss with respect to the layer's inputs (which will be passed back to the previous layer in the network).\n",
    "        ''' \n",
    "        weights_gradient = np.dot(self.input.T, output_gradient)\n",
    "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
    "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights += learning_rate * weights_gradient\n",
    "        self.biases += learning_rate * biases_gradient\n",
    "\n",
    "        return input_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cc0ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network wrapper class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = [] # placeholder for storing the layers of the network so we can propagate the infomation in a sequential order\n",
    "        self.loss_history = [] # placegolder to store the loss for plotting\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        '''\n",
    "        Add the layer to the network\n",
    "        '''\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network. \n",
    "        It sequentially passes the input data through each layer, transforming it according to each layer's operation.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def prediction(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network ignoring the dropout.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            if not isinstance(layer, Dropout):\n",
    "                input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate):\n",
    "        '''\n",
    "        Performs the backward pass (backpropagation) for training. \n",
    "        It propagates the gradient of the loss function backward through the network, updating weights in the process if the layer is a dense one.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient: The gradient of the loss function with respect to the network's output.\n",
    "\n",
    "        - learning_rate: The step size for weight updates.\n",
    "        '''\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Layer):\n",
    "                output_gradient = layer.backward_pass(output_gradient, learning_rate)\n",
    "            else:\n",
    "                output_gradient = layer.backward_pass(output_gradient)\n",
    "    \n",
    "    def compute_categorical_cross_entropy_loss(self, y_pred, y_true):\n",
    "        '''\n",
    "        Computes the categorical cross entropy loss\n",
    "        '''\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7) # Clip predictions to prevent log(0)\n",
    "\n",
    "        # Calculate the negative log of the probabilities of the correct class\n",
    "        # Multiply with the one-hot encoded true labels and sum across classes\n",
    "        loss = np.sum(y_true * -np.log(y_pred_clipped), axis=1)\n",
    "\n",
    "        # Average loss over all samples\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def compute_categorical_cross_entropy_gradient(self, y_pred, y_true):\n",
    "        '''\n",
    "        Calculates the gradient of the categorical cross entropy loss with respect to the network's output, assuming that the output layer is the softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - y_pred: Output of the softmax activation function.\n",
    "\n",
    "        - y_true: One-hot encoded label array.\n",
    "        '''\n",
    "        # Assuming y_true is one-hot encoded and y_pred is the output of softmax\n",
    "        y_pred_gradient = (y_pred - y_true) / len(y_pred)\n",
    "        return y_pred_gradient\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, learning_rate=0.001, batch_size=32, verbose = 1):\n",
    "        '''\n",
    "        Conducts the training process over a specified number of epochs.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: The input features of the training data.\n",
    "\n",
    "        - y_train: The target output (labels) of the training data.\n",
    "\n",
    "        - epochs: The number of times the entire training dataset is passed forward and backward through the neural network.\n",
    "\n",
    "        - learning_rate: The step size at each iteration while moving toward a minimum of the loss function.\n",
    "\n",
    "        - batch_size: The number of training examples used in one iteration.\n",
    "\n",
    "        - verbose: The mode of verbosity (0 = silent, 1 = update every 10 epochs, 2 = update every epoch).\n",
    "        '''\n",
    "        n_samples = len(X_train)\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X_train = X_train[indices]\n",
    "            y_train = y_train[indices]\n",
    "\n",
    "            for start_idx in range(0, n_samples, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, n_samples)\n",
    "                batch_x = X_train[start_idx:end_idx]\n",
    "                batch_y = y_train[start_idx:end_idx]\n",
    "\n",
    "                output = self.forward_pass(batch_x)\n",
    "                loss_gradient = self.compute_categorical_cross_entropy_gradient(batch_y, output)\n",
    "                self.backward_pass(loss_gradient, learning_rate)\n",
    "\n",
    "            output = self.forward_pass(X_train)\n",
    "            loss = self.compute_categorical_cross_entropy_loss(y_train, output)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            if verbose == 1:\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f\"Epoch {epoch}/{epochs} --- Loss: {loss}\")\n",
    "            elif verbose == 2:\n",
    "                print(f\"Epoch {epoch}/{epochs} --- Loss: {loss}\")\n",
    "            epoch += 1\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        output = self.prediction(X_test)\n",
    "\n",
    "        # Convert probabilities to class predictions\n",
    "        predictions = np.argmax(output, axis=1)\n",
    "        return predictions\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss history stored in self.loss_history over the epochs.\n",
    "        '''\n",
    "        plt.plot(self.loss_history)\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed3504a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(X):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = X.mean(axis=0)\n",
    "    stds = X.std(axis=0)\n",
    "\n",
    "    # Avoid division by zero in case of a constant feature\n",
    "    stds[stds == 0] = 1\n",
    "\n",
    "    # Standardize each feature\n",
    "    X_standardized = (X - means) / stds\n",
    "    return X_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32d43306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/200 --- Loss: 14.505399332952601\n",
      "Epoch 10/200 --- Loss: 6.639191571194193\n",
      "Epoch 20/200 --- Loss: 2.450448246155132\n",
      "Epoch 30/200 --- Loss: 1.4275895784051285\n",
      "Epoch 40/200 --- Loss: 1.1138967807235596\n",
      "Epoch 50/200 --- Loss: 0.8478670346046957\n",
      "Epoch 60/200 --- Loss: 0.7564949041647251\n",
      "Epoch 70/200 --- Loss: 0.6677058457768406\n",
      "Epoch 80/200 --- Loss: 0.5165143308708674\n",
      "Epoch 90/200 --- Loss: 0.5140322525567442\n",
      "Epoch 100/200 --- Loss: 0.4492882185684458\n",
      "Epoch 110/200 --- Loss: 0.3890707817950642\n",
      "Epoch 120/200 --- Loss: 0.35468647441103035\n",
      "Epoch 130/200 --- Loss: 0.34119704500746806\n",
      "Epoch 140/200 --- Loss: 0.30075267490161395\n",
      "Epoch 150/200 --- Loss: 0.27531559296325897\n",
      "Epoch 160/200 --- Loss: 0.2571090399327928\n",
      "Epoch 170/200 --- Loss: 0.28495044674389547\n",
      "Epoch 180/200 --- Loss: 0.2274065718587537\n",
      "Epoch 190/200 --- Loss: 0.22287512014477814\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNM0lEQVR4nO3deVxU9f4/8NeZFRiYYd9kd9/XINNMk1Sy0syy8qZ5u1lp2225Xb9dy7x1abm32638md1y6VZmWdrunpqJC66piYCAKJuAMKwDzHx+fwBTE6AsA2dmeD0fj3k8mHPODO/DEeblZzuSEEKAiIiIyAkp5C6AiIiIqL0YZIiIiMhpMcgQERGR02KQISIiIqfFIENEREROi0GGiIiInBaDDBERETktBhkiIiJyWgwyRERE5LQYZIiIHExmZiYkScI///lPuUshcngMMkROYPXq1ZAkCcnJyXKX4hIag0JLj5dfflnuEomolVRyF0BEJJe77roLN954Y5Ptw4cPl6EaImoPBhkickkVFRXQ6XSXPWbEiBH4wx/+0EUVEVFnYNcSkQs5cuQIEhISoNfr4enpiYkTJ2Lfvn02x9TW1uKFF15A79694ebmBj8/P4wdOxZbt261HpOXl4d58+YhLCwMWq0WISEhmDZtGjIzM69Yw44dO3DttddCp9PB29sb06ZNwy+//GLdv379ekiShF27djV57YoVKyBJEk6cOGHddvr0acycORO+vr5wc3PDqFGj8NVXX9m8rrHrbdeuXViwYAECAwMRFhbW2h/bZUVFReGmm27Cli1bMGzYMLi5uWHAgAH44osvmhx79uxZ3H777fD19YWHhweuvvpqfPvtt02Oq66uxpIlS9CnTx+4ubkhJCQEM2bMQHp6epNj3333XfTs2RNarRZXXXUVDh48aLO/I9eKyBWwRYbIRZw8eRLXXnst9Ho9/vKXv0CtVmPFihUYP348du3ahbi4OADAkiVLkJiYiD/96U+IjY2F0WhEcnIyDh8+jBtuuAEAcNttt+HkyZN45JFHEBUVhYKCAmzduhXnzp1DVFRUizVs27YNCQkJiImJwZIlS1BVVYW33noLY8aMweHDhxEVFYWpU6fC09MTn376Ka677jqb169btw4DBw7EoEGDrOc0ZswY9OjRA3/961+h0+nw6aefYvr06fj8889x66232rx+wYIFCAgIwHPPPYeKioor/swqKytRWFjYZLu3tzdUql//PKampmLWrFl48MEHMXfuXKxatQq33347Nm3aZP2Z5efn45prrkFlZSUeffRR+Pn5Yc2aNbjllluwfv16a61msxk33XQTtm/fjjvvvBOPPfYYysrKsHXrVpw4cQI9e/a0ft+PP/4YZWVleOCBByBJEl599VXMmDEDZ8+ehVqt7tC1InIZgogc3qpVqwQAcfDgwRaPmT59utBoNCI9Pd26LScnR3h5eYlx48ZZtw0dOlRMnTq1xfe5dOmSACBee+21Ntc5bNgwERgYKIqKiqzbjh07JhQKhZgzZ45121133SUCAwNFXV2ddVtubq5QKBRi6dKl1m0TJ04UgwcPFtXV1dZtFotFXHPNNaJ3797WbY0/n7Fjx9q8Z0syMjIEgBYfSUlJ1mMjIyMFAPH5559bt5WWloqQkBAxfPhw67bHH39cABA//vijdVtZWZmIjo4WUVFRwmw2CyGEWLlypQAgXn/99SZ1WSwWm/r8/PxEcXGxdf+XX34pAIivv/5aCNGxa0XkKti1ROQCzGYztmzZgunTpyMmJsa6PSQkBHfffTf27NkDo9EIoL614eTJk0hNTW32vdzd3aHRaLBz505cunSp1TXk5ubi6NGjuPfee+Hr62vdPmTIENxwww347rvvrNtmzZqFgoIC7Ny507pt/fr1sFgsmDVrFgCguLgYO3bswB133IGysjIUFhaisLAQRUVFmDx5MlJTU3HhwgWbGu6//34olcpW1zx//nxs3bq1yWPAgAE2x4WGhtq0/uj1esyZMwdHjhxBXl4eAOC7775DbGwsxo4daz3O09MT8+fPR2ZmJk6dOgUA+Pzzz+Hv749HHnmkST2SJNk8nzVrFnx8fKzPr732WgD1XVhA+68VkSthkCFyARcvXkRlZSX69u3bZF///v1hsViQnZ0NAFi6dClKSkrQp08fDB48GE8//TSOHz9uPV6r1eKVV17B999/j6CgIIwbNw6vvvqq9QO7JVlZWQDQYg2FhYXW7p4pU6bAYDBg3bp11mPWrVuHYcOGoU+fPgCAtLQ0CCGwePFiBAQE2Dyef/55AEBBQYHN94mOjr7iz+q3evfujfj4+CYPvV5vc1yvXr2ahIzGOhvHomRlZbV47o37ASA9PR19+/a16bpqSUREhM3zxlDTGFrae62IXAmDDFE3M27cOKSnp2PlypUYNGgQ3nvvPYwYMQLvvfee9ZjHH38cZ86cQWJiItzc3LB48WL0798fR44csUsNWq0W06dPx4YNG1BXV4cLFy7gp59+srbGAIDFYgEAPPXUU822mmzduhW9evWyeV93d3e71OcoWmpdEkJYv+7sa0Xk6BhkiFxAQEAAPDw8kJKS0mTf6dOnoVAoEB4ebt3m6+uLefPmYe3atcjOzsaQIUOwZMkSm9f17NkTTz75JLZs2YITJ06gpqYG//rXv1qsITIyEgBarMHf399mOvSsWbNQWFiI7du347PPPoMQwibINHaRqdXqZltN4uPj4eXl1bofUAc1tg791pkzZwDAOqA2MjKyxXNv3A/U/1xTUlJQW1trt/raeq2IXAmDDJELUCqVmDRpEr788kubabf5+fn4+OOPMXbsWGt3SVFRkc1rPT090atXL5hMJgD1M3mqq6ttjunZsye8vLysxzQnJCQEw4YNw5o1a1BSUmLdfuLECWzZsqXJwnPx8fHw9fXFunXrsG7dOsTGxtp0DQUGBmL8+PFYsWIFcnNzm3y/ixcvXv6HYkc5OTnYsGGD9bnRaMQHH3yAYcOGITg4GABw44034sCBA0hKSrIeV1FRgXfffRdRUVHWcTe33XYbCgsL8fbbbzf5Pr8PS1fS3mtF5Eo4/ZrIiaxcuRKbNm1qsv2xxx7Diy++iK1bt2Ls2LFYsGABVCoVVqxYAZPJhFdffdV67IABAzB+/HiMHDkSvr6+SE5Oxvr16/Hwww8DqG9pmDhxIu644w4MGDAAKpUKGzZsQH5+Pu68887L1vfaa68hISEBo0ePxn333Wedfm0wGJq0+KjVasyYMQOffPIJKioqmr2v0LJlyzB27FgMHjwY999/P2JiYpCfn4+kpCScP38ex44da8dP8VeHDx/Ghx9+2GR7z549MXr0aOvzPn364L777sPBgwcRFBSElStXIj8/H6tWrbIe89e//hVr165FQkICHn30Ufj6+mLNmjXIyMjA559/DoWi/v+Nc+bMwQcffIAnnngCBw4cwLXXXouKigps27YNCxYswLRp01pdf0euFZHLkHXOFBG1SuP04pYe2dnZQgghDh8+LCZPniw8PT2Fh4eHmDBhgti7d6/Ne7344osiNjZWeHt7C3d3d9GvXz/x0ksviZqaGiGEEIWFhWLhwoWiX79+QqfTCYPBIOLi4sSnn37aqlq3bdsmxowZI9zd3YVerxc333yzOHXqVLPHbt26VQAQkiRZz+H30tPTxZw5c0RwcLBQq9WiR48e4qabbhLr169v8vO53PT037rS9Ou5c+daj42MjBRTp04VmzdvFkOGDBFarVb069dPfPbZZ83WOnPmTOHt7S3c3NxEbGys+Oabb5ocV1lZKZ599lkRHR0t1Gq1CA4OFjNnzrROnW+sr7lp1QDE888/L4To+LUicgWSEG1syyQi6kaioqIwaNAgfPPNN3KXQkTN4BgZIiIicloMMkREROS0GGSIiIjIaXGMDBERETkttsgQERGR02KQISIiIqfl8gviWSwW5OTkwMvLq8lN34iIiMgxCSFQVlaG0NBQ64KSzXH5IJOTk2NzjxkiIiJyHtnZ2QgLC2txv8sHmcabymVnZ1vvNUNERESOzWg0Ijw8/Io3h3X5INPYnaTX6xlkiIiInMyVhoVwsC8RERE5LQYZIiIicloMMkREROS0GGSIiIjIaTHIEBERkdNikCEiIiKnxSBDRERETotBhoiIiJwWgwwRERE5LQYZIiIicloMMkREROS0GGSIiIjIabn8TSM7S1G5CVW1ZripldCqFHBTK6FSSFe8uRURERHZD4NMO72xLRX/25dls00hAf6eWvQO8sTgHt7407XR8PfUylQhERGR62PXUjtJEqBV2f74LAIoKDPhp7QivLMrHRP+uROrfsqA2SJkqpKIiMi1SUIIl/6UNRqNMBgMKC0thV6vt/v7CyFgqrPUP2rNyCmtxpm8MnywLxMnLhgBAI/H98bj8X3s/r2JiIhcVWs/v9ki00GSJMFNrYTBXY1AvRuGhXvjjqvC8eXCsfjLlL4AgJV7MlBhqpO5UiIiItfDINNJlAoJD4zriWh/HYzVdfg0OVvukoiIiFwOg0wnUiok3Dc2GgDw/p4M1JktMldERETkWhhkOtltI8Lgq9Pg/KUqbDqZJ3c5RERELoVBppO5a5S45+pIAMCHv5uuTURERB0ja5DZvXs3br75ZoSGhkKSJGzcuLHFYx988EFIkoQ33nijy+qzlxsGBAEA0grKZa6EiIjItcgaZCoqKjB06FAsW7bsssdt2LAB+/btQ2hoaBdVZl89vN0BAIXlNaiuNctcDRERkeuQdWXfhIQEJCQkXPaYCxcu4JFHHsHmzZsxderULqrMvrw91PDQKFFZY0ZuaTWi/XVyl0REROQSHHqMjMViwT333IOnn34aAwcOlLucdpMkCaENrTI5JVUyV0NEROQ6HPpeS6+88gpUKhUeffTRVr/GZDLBZDJZnxuNxs4orc1Cvd2RVlCOCwwyREREduOwLTKHDh3Cf/7zH6xevbpNd5ROTEyEwWCwPsLDwzuxytbr4e0GgC0yRERE9uSwQebHH39EQUEBIiIioFKpoFKpkJWVhSeffBJRUVEtvm7RokUoLS21PrKzHWNF3VADu5aIiIjszWG7lu655x7Ex8fbbJs8eTLuuecezJs3r8XXabVaaLXazi6vzX4dI1MtcyVERESuQ9YgU15ejrS0NOvzjIwMHD16FL6+voiIiICfn5/N8Wq1GsHBwejbt29Xl9phHOxLRERkf7IGmeTkZEyYMMH6/IknngAAzJ07F6tXr5apqs7RuJbMhZIqCCHaNO6HiIiImidrkBk/fjyEEK0+PjMzs/OK6WRBBi0kCTDVWVBUUQN/T8fr/iIiInI2DjvY19VoVUoENIQXdi8RERHZB4NMF+I4GSIiIvtikOlCPXwax8lw5hIREZE9MMh0oR5skSEiIrIrBpkuFGrg6r5ERET2xCDThThGhoiIyL4YZLpQqDfHyBAREdkTg0wXahwjU1huQnWtWeZqiIiInB+DTBfy9lBDpahf0fdSZY3M1RARETk/BpkuJEkSPDRKAECFiS0yREREHcUg08U8tfV3hagw1clcCRERkfNjkOliOgYZIiIiu2GQ6WLWIFPDriUiIqKOYpDpYjpt4xgZtsgQERF1FINMF9Np6ltkyhlkiIiIOoxBpotxsC8REZH9MMh0MY/GriWOkSEiIuowBpkuxllLRERE9sMg08U8NQwyRERE9sIg08U4/ZqIiMh+GGS6GKdfExER2Q+DTBdrbJHh9GsiIqKOY5DpYhzsS0REZD8MMl2scUG8So6RISIi6jAGmS7WOEaGXUtEREQdxyDTxbiyLxERkf0wyHSxxjEylTVmWCxC5mqIiIicG4NMF2scIwMAlbUcJ0NERNQRDDJdzE2tgEKq/5rdS0RERB3DINPFJEniWjJERER2wiAjA+sUbBO7loiIiDqCQUYGnIJNRERkHwwyMuAUbCIiIvtgkJHBr3fAZpAhIiLqCAYZGXhoGltkOEaGiIioIxhkZODZMEaGXUtEREQdI2uQ2b17N26++WaEhoZCkiRs3LjRuq+2thbPPPMMBg8eDJ1Oh9DQUMyZMwc5OTnyFWwnnH5NRERkH7IGmYqKCgwdOhTLli1rsq+yshKHDx/G4sWLcfjwYXzxxRdISUnBLbfcIkOl9uVpvU0BgwwREVFHqK58SOdJSEhAQkJCs/sMBgO2bt1qs+3tt99GbGwszp07h4iIiK4osVM0jpEp5xgZIiKiDnGqMTKlpaWQJAne3t5yl9IhOo6RISIisgtZW2Taorq6Gs888wzuuusu6PX6Fo8zmUwwmUzW50ajsSvKaxN2LREREdmHU7TI1NbW4o477oAQAsuXL7/ssYmJiTAYDNZHeHh4F1XZeh4c7EtERGQXDh9kGkNMVlYWtm7detnWGABYtGgRSktLrY/s7OwuqrT1fp1+zTEyREREHeHQXUuNISY1NRU//PAD/Pz8rvgarVYLrVbbBdW1n07DWxQQERHZg6xBpry8HGlpadbnGRkZOHr0KHx9fRESEoKZM2fi8OHD+Oabb2A2m5GXlwcA8PX1hUajkavsDuMtCoiIiOxD1iCTnJyMCRMmWJ8/8cQTAIC5c+diyZIl+OqrrwAAw4YNs3ndDz/8gPHjx3dVmXZnDTLsWiIiIuoQWYPM+PHjIYRocf/l9jkz6/TrmjoIISBJkswVEREROSeHH+zrihqnXwsBVNWyVYaIiKi9GGRk4K5WorERhlOwiYiI2o9BRgaSJP1m5hJbZIiIiNqLQUYmvE0BERFRxzHIyOTXmUsMMkRERO3FICMTa9cS15IhIiJqNwYZmTR2LZVzjAwREVG7McjIxHoHbHYtERERtRuDjEx0vAM2ERFRhzHIyMSD06+JiIg6jEFGJp6/uU0BERERtQ+DjEw4/ZqIiKjjGGRk8uvKvgwyRERE7cUgI5NfB/tyjAwREVF7McjIpHEdmUqOkSEiImo3BhmZeHKMDBERUYcxyMikcfo115EhIiJqPwYZmfzaIsMxMkRERO3FICMTHdeRISIi6jAGGZn8dh0ZIYTM1RARETknBhmZNAYZiwCqay0yV0NEROScGGRk4qFWWr9m9xIREVH7MMjIRKGQoNM0jJPhzCUiIqJ2YZCRkYeWU7CJiIg6gkFGRpyCTURE1DEMMjLiFGwiIqKOYZCREe+ATURE1DEMMjLS8X5LREREHcIgIyMdx8gQERF1CIOMjDy1nH5NRETUEQwyMrLeAZuDfYmIiNqFQUZGHCNDRETUMQwyMmrsWqrkGBkiIqJ2YZCRkY4r+xIREXUIg4yMrOvIcIwMERFRuzDIyIjTr4mIiDpG1iCze/du3HzzzQgNDYUkSdi4caPNfiEEnnvuOYSEhMDd3R3x8fFITU2Vp9hOoOP0ayIiog6RNchUVFRg6NChWLZsWbP7X331Vbz55pt45513sH//fuh0OkyePBnV1dVdXGnn4C0KiIiIOkYl5zdPSEhAQkJCs/uEEHjjjTfwt7/9DdOmTQMAfPDBBwgKCsLGjRtx5513dmWpnYKDfYmIiDrGYcfIZGRkIC8vD/Hx8dZtBoMBcXFxSEpKkrEy+/FsCDKVNWYIIWSuhoiIyPnI2iJzOXl5eQCAoKAgm+1BQUHWfc0xmUwwmUzW50ajsXMKtIPGMTJ1FgFTnQVuaqXMFRERETkXh22Raa/ExEQYDAbrIzw8XO6SWtR4iwKA42SIiIjaw2GDTHBwMAAgPz/fZnt+fr51X3MWLVqE0tJS6yM7O7tT6+wIpUKCe0MrTGUNp2ATERG1lcMGmejoaAQHB2P79u3WbUajEfv378fo0aNbfJ1Wq4Ver7d5ODIO+CUiImo/WcfIlJeXIy0tzfo8IyMDR48eha+vLyIiIvD444/jxRdfRO/evREdHY3FixcjNDQU06dPl69oO/PUKlFYzq4lIiKi9pA1yCQnJ2PChAnW50888QQAYO7cuVi9ejX+8pe/oKKiAvPnz0dJSQnGjh2LTZs2wc3NTa6S7a5xnAxbZIiIiNpO1iAzfvz4y047liQJS5cuxdKlS7uwqq712ynYRERE1DYOO0amu2icgs0WGSIiorZjkJGZh5a3KSAiImovBhmZeWrYtURERNReDDIy4/RrIiKi9mOQkZlnwxgZdi0RERG1HYOMzKwtMtUMMkRERG3FICMzg7saAFBaVStzJURERM6HQUZmjUHGWM0gQ0RE1FYMMjLTs0WGiIio3RhkZMauJSIiovZjkJEZgwwREVH7McjIrLFrqbrWAlMdF8UjIiJqCwYZmXlpVZCk+q+NVZyCTURE1BYMMjJTKCR4Nawlw+4lIiKitmGQcQAGD46TISIiag8GGQdgXUuGQYaIiKhNGGQcgN6Ni+IRERG1B4OMA+AUbCIiovZhkHEA1iBTySBDRETUFgwyDoAtMkRERO3DIOMA9LxxJBERUbswyDgA3jiSiIiofRhkHAC7loiIiNqHQcYB/BpkeIsCIiKitmCQcQBcEI+IiKh9GGQcgN6t/l5LDDJERERtwyDjABpbZMpMdTBbhMzVEBEROQ8GGQfQOGsJYKsMERFRWzDIOAC1UgGdRgmAM5eIiIjagkHGQXBRPCIiorZjkHEQXEuGiIio7RhkHARX9yUiImo7BhkHwRYZIiKitmOQcRAMMkRERG3HIOMg9G6Nq/vyNgVEREStxSDjINgiQ0RE1HYOHWTMZjMWL16M6OhouLu7o2fPnvj73/8OIVxv9VuDO29TQERE1FYquQu4nFdeeQXLly/HmjVrMHDgQCQnJ2PevHkwGAx49NFH5S7PrgwebJEhIiJqK4cOMnv37sW0adMwdepUAEBUVBTWrl2LAwcOyFyZ/VnHyHBBPCIiolZz6K6la665Btu3b8eZM2cAAMeOHcOePXuQkJDQ4mtMJhOMRqPNwxlwjAwREVHbOXSLzF//+lcYjUb069cPSqUSZrMZL730EmbPnt3iaxITE/HCCy90YZX24c2uJSIiojZz6BaZTz/9FB999BE+/vhjHD58GGvWrME///lPrFmzpsXXLFq0CKWlpdZHdnZ2F1bcfgZ3DYD6IGOxuN5gZiIios7g0C0yTz/9NP7617/izjvvBAAMHjwYWVlZSExMxNy5c5t9jVarhVar7coy7aKxa0kIoKy6zjr4l4iIiFrm0C0ylZWVUChsS1QqlbBYLDJV1Hk0KgU8NEoAQElVjczVEBEROYd2tchkZ2dDkiSEhYUBAA4cOICPP/4YAwYMwPz58+1W3M0334yXXnoJERERGDhwII4cOYLXX38df/zjH+32PRyJt7salTVmlFTWItJP7mqIiIgcX7taZO6++2788MMPAIC8vDzccMMNOHDgAJ599lksXbrUbsW99dZbmDlzJhYsWID+/fvjqaeewgMPPIC///3vdvsejsTgUT9OpoQDfomIiFqlXUHmxIkTiI2NBVA/IHfQoEHYu3cvPvroI6xevdpuxXl5eeGNN95AVlYWqqqqkJ6ejhdffBEajcZu38OReHMKNhERUZu0K8jU1tZaB9Ru27YNt9xyCwCgX79+yM3NtV913Yx1CnYlx8gQERG1RruCzMCBA/HOO+/gxx9/xNatWzFlyhQAQE5ODvz8OLijvRqDTEklW2SIiIhao11B5pVXXsGKFSswfvx43HXXXRg6dCgA4KuvvrJ2OVHb6Ru6ljhGhoiIqHXaNWtp/PjxKCwshNFohI+Pj3X7/Pnz4eHhYbfiuhvvhkXx2CJDRETUOu1qkamqqoLJZLKGmKysLLzxxhtISUlBYGCgXQvsTn69TQHHyBAREbVGu4LMtGnT8MEHHwAASkpKEBcXh3/961+YPn06li9fbtcCuxPOWiIiImqbdgWZw4cP49prrwUArF+/HkFBQcjKysIHH3yAN998064FdicGDvYlIiJqk3YFmcrKSnh5eQEAtmzZghkzZkChUODqq69GVlaWXQvsTqxjZNgiQ0RE1CrtCjK9evXCxo0bkZ2djc2bN2PSpEkAgIKCAuj1ersW2J0YrOvI1EII3gGbiIjoStoVZJ577jk89dRTiIqKQmxsLEaPHg2gvnVm+PDhdi2wO2kcI1NjtqCq1ixzNURERI6vXdOvZ86cibFjxyI3N9e6hgwATJw4EbfeeqvdiutuPDRKqJUSas0CJZW18NC06/IQERF1G+3+pAwODkZwcDDOnz8PAAgLC+NieB0kSRIM7hoUlptQWlWLUG93uUsiIiJyaO3qWrJYLFi6dCkMBgMiIyMRGRkJb29v/P3vf4fFYrF3jd0Kb1NARETUeu1qkXn22Wfx/vvv4+WXX8aYMWMAAHv27MGSJUtQXV2Nl156ya5Fdie/riXDRfGIiIiupF1BZs2aNXjvvfesd70GgCFDhqBHjx5YsGABg0wHsEWGiIio9drVtVRcXIx+/fo12d6vXz8UFxd3uKjujDeOJCIiar12BZmhQ4fi7bffbrL97bffxpAhQzpcVHfGG0cSERG1Xru6ll599VVMnToV27Zts64hk5SUhOzsbHz33Xd2LbC7+fXGkQwyREREV9KuFpnrrrsOZ86cwa233oqSkhKUlJRgxowZOHnyJP73v//Zu8ZuhXfAJiIiar12ryMTGhraZFDvsWPH8P777+Pdd9/tcGHdlcGdg32JiIhaq10tMtR5vD04RoaIiKi1GGQcjMGdY2SIiIhai0HGwXhbu5Y4RoaIiOhK2jRGZsaMGZfdX1JS0pFaCL8O9q2oMaPWbIFayaxJRETUkjYFGYPBcMX9c+bM6VBB3Z2XmxqSBAhR373k76mVuyQiIiKH1aYgs2rVqs6qgxooFRIM7mqUVNbiUkUNgwwREdFlsN/CAQU0hJeCMpPMlRARETk2BhkHFKR3AwDkG6tlroSIiMixMcg4oEAvtsgQERG1BoOMAwpkiwwREVGrMMg4ILbIEBERtQ6DjANqHCNTwBYZIiKiy2KQcUCBerbIEBERtQaDjAMK8vp1jIwQQuZqiIiIHBeDjANqbJGprrWgzFQnczVERESOi0HGAbmpldC71S+6zHEyRERELXP4IHPhwgX84Q9/gJ+fH9zd3TF48GAkJyfLXVanC7QO+OU4GSIiopa06V5LXe3SpUsYM2YMJkyYgO+//x4BAQFITU2Fj4+P3KV1uiC9FmkF5cgvY4sMERFRSxw6yLzyyisIDw+3uVlldHS0jBV1ncYBv2yRISIiaplDdy199dVXGDVqFG6//XYEBgZi+PDh+O9//3vZ15hMJhiNRpuHMwpoGPCbzyBDRETUIocOMmfPnsXy5cvRu3dvbN68GQ899BAeffRRrFmzpsXXJCYmwmAwWB/h4eFdWLH9WKdgs2uJiIioRZJw4IVKNBoNRo0ahb1791q3Pfroozh48CCSkpKafY3JZILJ9GsrhtFoRHh4OEpLS6HX6zu9Znv55ngOHv74CGKjfPHpg6PlLoeIiKhLGY1GGAyGK35+O3SLTEhICAYMGGCzrX///jh37lyLr9FqtdDr9TYPZ9R4mwK2yBAREbXMoYPMmDFjkJKSYrPtzJkziIyMlKmirmO9caTRxNV9iYiIWuDQQebPf/4z9u3bh3/84x9IS0vDxx9/jHfffRcLFy6Uu7ROF9gwRqaq1szVfYmIiFrg0EHmqquuwoYNG7B27VoMGjQIf//73/HGG29g9uzZcpfW6dw1SnhZV/flzCUiIqLmOPQ6MgBw00034aabbpK7DFkE6d1QVl2OAmM1egV6yl0OERGRw3HoFpnurnGcDAf8EhERNY9BxoGFGNwBABcuVclcCRERkWNikHFgMQE6AMDZwgqZKyEiInJMDDIOLMqvPshkMsgQERE1i0HGgUX71weZDAYZIiKiZjHIOLAofw8AwKXKWpRU1shcDRERkeNhkHFgHhoVghtuVcBWGSIioqYYZBwcu5eIiIhaxiDj4KIDGGSIiIhawiDj4GL8OQWbiIioJQwyDo5TsImIiFrGIOPgftu1JISQuRoiIiLHwiDj4MJ9PKBUSKisMaOgjHfBJiIi+i0GGQenUSkQ5lN/z6WzF9m9RERE9FsMMk6gcQp2ZhGDDBER0W8xyDgBriVDRETUPAYZJ9A4BTu9oFzmSoiIiBwLg4wT6BnoCQBIu8ggQ0RE9FsMMk6gT5AXAOBccSWqaswyV0NEROQ4GGScgJ9OAx8PNYQA0tkqQ0REZMUg4wQkSULvhlaZ1IIymashIiJyHAwyTqJ3wziZ1Hy2yBARETVikHESjeNkzjDIEBERWTHIOInGFpk0di0RERFZMcg4icYxMlnFlaiu5cwlIiIigEHGafh7auDNmUtEREQ2GGSchCRJ6BPYMHOJ42SIiIgAMMg4ld5BDTOXOE6GiIgIAIOMU2kc8MuZS0RERPUYZJxI4xTs1Hy2yBAREQEMMk6lf4geCgnILKpEVlGF3OUQERHJjkHGifjoNBjTyx8A8PWxHJmrISIikh+DjJO5ZWgoAODLozkQQshcDRERkbwYZJzM5EHB0KgUSC0ox+k8jpUhIqLujUHGyejd1Li+byCA+lYZIiKi7oxBxgndMqy+e+nrYzmwWNi9RERE3ZdTBZmXX34ZkiTh8ccfl7sUWV3fLxCeWhUulFThRE6p3OUQERHJxmmCzMGDB7FixQoMGTJE7lJk56ZWIi7aFwBwIKNY5mqIiIjk4xRBpry8HLNnz8Z///tf+Pj4yF2OQxgZVf9zOJR1SeZKiIiI5OMUQWbhwoWYOnUq4uPjr3isyWSC0Wi0ebiiq6LqW2QOZl7iNGwiIuq2HD7IfPLJJzh8+DASExNbdXxiYiIMBoP1ER4e3skVymNwDwM0SgUKy004V1wpdzlERESycOggk52djcceewwfffQR3NzcWvWaRYsWobS01PrIzs7u5Crl4aZWYlAPPQAgOZPdS0RE1D05dJA5dOgQCgoKMGLECKhUKqhUKuzatQtvvvkmVCoVzGZzk9dotVro9Xqbh6tq7F5K5jgZIiLqplRyF3A5EydOxM8//2yzbd68eejXrx+eeeYZKJVKmSpzDCMj6wf8Jmdy5hIREXVPDh1kvLy8MGjQIJttOp0Ofn5+TbZ3R41BJrWgHCWVNfD20MhcERERUddy6K4lujw/Ty1iAnQAgMPn2L1ERETdj0O3yDRn586dcpfgUGKjfHH2YgV2pVzE9f2C5C6HiIioS7FFxslNHhgMAPj25zzUmS0yV0NERNS1GGSc3Nje/vD2UKOw3IT9vF0BERF1MwwyTk6tVCBhUAgA4KujOTJXQ0RE1LUYZFzALUNDAQDfn8iFqa7p2jpERESuikHGBcRG+yLQSwtjdR1+PFModzlERERdhkHGBSgVEm4aUt8q8/Vxdi8REVH3wSDjIiYPrJ96/VNaIe+GTURE3QaDjIsYFuENrUqBwvIapF8sl7scIiKiLsEg4yK0KiVGRNTfsmDfWU7DJiKi7oFBxoVcHeMHANh3tkjmSoiIiLoGg4wLiYvxBVDfIsNxMkRE1B0wyLiQYeHe0KgUKCw34WxhhdzlEBERdToGGRfiplZiRIQ3AHYvERFR98Ag42LiouvHyezngF8iIuoGGGRcTOOA36SzRTBbOE6GiIhcG4OMixke4Q29mwoXy0zYfDJP7nKIiIg6FYOMi3FTK3HvmGgAwFs70jh7iYiIXBqDjAuad00UdBolfsk1YsfpArnLISIi6jQMMi7IR6fBH0ZHAmCrDBERuTYGGRf1p7Ex0KoUOJpdgqR0TsUmIiLXxCDjogK8tLhjVDgA4L09GTJXQ0RE1DkYZFzYH8dGQ5KAHacLkFZQJnc5REREdscg48Ki/XWI7x8EAHh/T6a8xRAREXUCBhkXd/+1MQCALw6fR1G5SeZqiIiI7ItBxsVdFeWDIWEGmOos+N++LLnLISIisisGGRcnSZK1VWb13kxUmOpkroiIiMh+GGS6gRsHhyDKzwMllbVYe+Cc3OUQERHZDYNMN6BUSHjgup4AgPd+zICpzixzRURERPbBINNNzBjRA0F6LfKM1dh45ILc5RAREdkFg0w3oVUp8aex9WNllv2Qjpo6i8wVERERdRyDTDcy++oIBHhpca64Eh/v5wwmIiJyfgwy3YiHRoXHJvYGALy5Iw1l1bUyV0RERNQxDDLdzKyrwhHjr0NxRQ3+u/us3OUQERF1CINMN6NWKvD05L4AgBW7z+KntEKZKyIiImo/BpluaMqgYEzsFwhTnQXzVh/EtlP5cpdERETULgwy3ZAkSfh/fxiByQODUFNnwYMfHsKx7BK5yyIiImozhw4yiYmJuOqqq+Dl5YXAwEBMnz4dKSkpcpflErQqJZbdPQLx/QNRZxF4Z1e63CURERG1mUMHmV27dmHhwoXYt28ftm7ditraWkyaNAkVFRVyl+YSVEoFnp7cDwCw+WQesosrZa6IiIiobVRyF3A5mzZtsnm+evVqBAYG4tChQxg3bpxMVbmWvsFeuLa3P35MLcTqvZlYfNMAuUsiIiJqNYdukfm90tJSAICvr2+Lx5hMJhiNRpsHXd59Y6MBAOsOZnNtGSIicipOE2QsFgsef/xxjBkzBoMGDWrxuMTERBgMBusjPDy8C6t0Ttf1CUCvQE+Um+rw3o8ZcpdDRETUak4TZBYuXIgTJ07gk08+uexxixYtQmlpqfWRnZ3dRRU6L0mS8FDD3bH/sz0VXxw+L3NFRERErePQY2QaPfzww/jmm2+we/duhIWFXfZYrVYLrVbbRZW5jhkjeuBkjhErf8rA0+uPQ++mRvyAILnLIiIiuiyHbpERQuDhhx/Ghg0bsGPHDkRHR8tdksuSJAl/m9ofM4b3gNki8OCHh7DhCFtmiIjIsTl0i8zChQvx8ccf48svv4SXlxfy8vIAAAaDAe7u7jJX53oUCgmvzByCOovAV8dy8Od1x3D2YgVmjgxDhK8HJEmSu0QiIiIbkhBCyF1ES1r64Fy1ahXuvffeVr2H0WiEwWBAaWkp9Hq9HatzXRaLQOL3v+C/vxn4G+nngedvHoDr+7G7iYiIOl9rP78dOsjYA4NM+32anI31yedxJPsSas31/0weGBeDpyb3hVrp0L2SRETk5BhkGjDIdFyFqQ6vbU7B6r2ZAICJ/QLxzj0jGWaIiKjTtPbzm59EdEU6rQpLbhmId/4wAlqVAttPF+Av64/DYnHpDExERE6AQYZabcqgEPy/2SOgVEjYcOQC/rjmIN778SxS8srkLo2IiLopBhlqk4n9g/DP24cAAHamXMSL3/6CKf/ZjW2n8mWujIiIuiMGGWqzW4eHYcOCa/Dn+D6IjfKFEMCf1x1FRiHvSk5ERF2Lg32pQ2rqLLj7v/uQnHUJMf469A7yRFpBOUZG+uDhCb0R4echd4lEROSEOGupAYNM5yswVuOmt/agoMxks12lkDBndBSendofSgUX0yMiotZr7ee3Q6/sS84hUO+G1fNi8b99mYjx90S4rzs+PpCN3WcuYuVPGSgsN+H1O4ZCxenaRERkZ2yRoU7z3c+5eOyTI6g1C0waEIT/u7E/ovx1cpdFREROgC0yJLsbB4dAo1RgwUeHseVUPracyseoSB/cMzoSNw4O4YJ6RETUYWyRoU53MLMYb+9Iw4+pF9G4hl4Pb3fcMiwUV8f4YXiEN/RuanmLJCIih8LBvg0YZBxHvrEanxzIxgdJmSiqqLHZF+ClxdAwA16YNgg9vHlncyKi7o5BpgGDjOOprjVj04k87EkrxL6zRTh/qcq6L9pfh3UPXI1ALzfrtlqzBQpJ4swnIqJuhEGmAYOM4zNW1yI1vwyPfXIU5y9VoU+QJ8b1DsDZwgpkFFbgXHElPDRKzI6LxB/HRCFQ73blNyUiIqfGINOAQcZ5ZBVV4I4VScg3mlo8RqmQMCBEj5GRPrh5aAhGRPhAkthSQ0TkahhkGjDIOJf0i+VYtiMNPjoNov11iPHXITpAhxMXjFixKx3JWZdsjh8SZsDtI8Mwuqc/lAoJXx/Lwek8I/4c3we9g7xkOgsiIuooBpkGDDKu5UJJFQ5lXcLOlAJ8czwXNXWWZo/z99Ri3QNXo2eAZxdXSERE9sAg04BBxnUVlZvw2aHz2H3mIpKzLsFsERjTyx8FxmqczitDkF6LO0aFI6+0GnUWATe1Er46NUZE+GBkpA+8PTRynwIREbWAQaYBg0z3UF1rhtkioNOqUFxRgzvfTcKZ/PIWj1dIwLRhPfDEDX0Q7ssbWxIRORoGmQYMMt3TxTIT3tmVjupaM4L1bnBTK1FVa8b5S5VIzrqEsxcrAABqpYS5o6Pw5xv6QKdVobKmDgcyinEo6xLOX6rCLcNCMaFvYIvfx2IRUHBaOBGR3THINGCQoeYcP1+C1zan4MfUQgBAqMENwyN8sON0AapqzTbH3j4yDDcMCEJmUQXyjSaUVtWioMyE9IJy5JZWIS7aD/eNjcb1/QIZaoiI7IRBpgGDDF3ODykFWLzxhM2ifD283REX4wuNUoF1ydlo7W+I3k2FIWHeCPNxR0WNGWqFhHljojE4zAAAyCutRrmpDuG+7tCqlJ1xOkRELoNBpgGDDF1JVY0ZHyRloqSqFlMGBmNImMG6Ns2BjGK8uuk0THUWRPnrEOrtBm93DXx1asQEeMLbXY31h89j7f5zMFbXNXlvhQTMGR2F85cqsf10AYQAJAmI8PXA1dF+6B/ihaPZJTh07hJCDe6I7x+E/iF61Fos8NdprSGIiKi7YZBpwCBDXaHWbEFKXhmOny/FxTITPN1UOHzuEr49nmtznE6jREWNuYV3aWp2XASev3kgzl+qxPt7MlBSWQutSoFwXw/MHBnGgcpE5LIYZBowyJCctp3Kx7KdaRgUasC8MVGI9tehsLwGJ3JKsTetEGfyyzGohx6x0X44e7EcO04XoMBogkop4VSuEUIAPQN0yCqqRJ3F9ldVkoDYKF/4eWrgplLC30uLIL0bYqN8L9uSw3tXEZEzYJBpwCBDzmr7L/l47JOjKDfVd1ld3y8Q1/UJQHWtGT+mFmJPWmGLrx0R4Y3bRoahh7c7fDw0EABKKmvw7fFcfPtzLoL1bnjzruEY1KNp4Ck31eGfm1NgEQLzx8UgzKf5Vp9j2SUoq67DmF5+vE0EEdkdg0wDBhlyZmkFZfhw3zlMGhiEa3r62+zLLKzAgYxiVNeZUVljxsUyE7KKKrHrTAFqzVf+tdYoFbg7LgLFFTXIM1YjNsoXQ8IM+Md3vyCzqBJA/fT0m4eEIszHHT46Da6K8kXvIE+8vuUMVuw+CwAYHuGNRyf2Rv9gPfw9NVApFfb/QRBRt8Mg04BBhrqbgrJqrN2fjUPnLqGwzISSyhpIkgS1UkJstC9uHhqK/yVlYcup/BbfI9Tghih/HfamFzXZp1UpYGq4NYRGpbC5TYRSIWFC3wDMvjoSIyN9IAHYd7YYHyRlIjW/HDNHhmHBhJ7w0KjadE6F5SYkZ17CoaxiZBZV4ob+QZg+vAc0ql9DkxACdRYBNYMUkUtgkGnAIEPUlBACnyWfR3JWMaL9PeHjocbOlIvYnXoR43oH4OXbBsPbQ4MDGcXYfeYiSqtqkVNShaSzRaisMcPbQ41XbhuC4RHeWLYjDZtP5uNiuQlmy5X/nIQY3DBjRA8MD/dBkN4NdRYLsooqsTv1Ik7lGOHnqUGw3h0CAuXVdTiTX2ZtIfqtUIMbxvUJgMFDjZySaiSlF+JSZS2mDArGrFHhyCyqwJ7UQnh7qHF9vyBc29sfOm19gMopqcLWU/noE+SFq2N8r9g1ll1cCY1KgSC9W/t+4ETUZgwyDRhkiFpPCHHZD3VTnRmnc8sQ5aeDwUNts89sETh7sRxrD2Tj88PnUVpVCwDw8VBj1lUR6BvsiX9tOWOzZk9rSRLQJ9ALI6N8EOCpxccHzuFimalN76FRKhAX44sALy2+PpZj7X7rFeiJ6/sFIsBTiyh/Ha7t7Q83df06P1lFFXh96xl8dSwH7mol3rxzOOIHBAG4/M/KbBFQSIAQQFFFDS6WmRDu6w4vN3Wzx1+OEAKmOou1ppaOOZVrRJiPBwzubf8eRI6IQaYBgwxR17NYBGot9V1OaoXCuuJxda0ZXx3NwcHMYhw7Xz9YWKmQ4KvT4Jqe/hgZ6QNjVS3yjNVQKiR4alXo4eOOERE+Nh/Q1bVmbDqRh+ziSlyqrIWXmwrX9PSDTqvCB0mZ2P5LAXoGemJ83wAUltVg++l8ZP2uVWdwDwPSL5aj8nfT4b20KsTF+OFsYbn1VhaNJAm486pwnMotw8/nS9A3WI+rY3xRZxY4W1iOnJJqFBirm51i76VVYc41kbh1eA/U1AlU1dahwmRGVa0ZWpUCHhoVLpaZkJJfhqyiCuSVViPfWI08YzWqay24trc/EmcMBgC8+M0vOJVrxB2jwjCmlz/e2JaKXWcuwuCuxpOT+uDu2AjrWCVTnRln8srRM1Bn7dI7lHUJ54orEOPviZ6BnvDUtq2rj6grMMg0YJAhIiEE0i9WYMfpfGQX199D66ooXxira/Ht8VykFZTjYpkJyZnFyCmttnntdX0C8Hh8b3yanI21B7Lb/L0lCfDUqFBmarpgYlt5alUwW0ST22j8XpSfB24fFQ4/nQZv7UjDhZIqeHuo8Ye4SBzNLmky4y3E4IZegZ6IjfLFuD4BGNTDAKVCQl5pNV7ddBr7zhZhbG9/zBsTjf4h9X9HC4zV+HBfFg5kFqOkshYVNXXw9dAgUO+GyQODMWN4D2uAramz4Pj5EpzKNSLQS4uYAE9E+nl0aIVrs0Vg88k86LQqjOvtD0mSIITA0ewSfH74PLaczMfE/oF44ZZBNmOpyHkwyDRgkCGi1rJYBJKzLuFo9iX0CvTEsHAf+Oo0AOrD0If7spB0tghjewUgNtoHv+SWITmzGB5aFWL8dYjw9UCg3g3e7mpYhIBFAN4eaiglCVt/ycfynelIzS+Du0YFnVYJd7US7holauosqDDVweChQb8gL8QE6BBscEOQ3g3BejfUmC1Y9MXPOJR1CQAQG+2LW4aGYu2BcziZY8SEvgF4dmp/JJ0txr+2pKCkstbmvFQKyWYdIrVSwtAwb2QWVaKwvGkXnValQEyAJzILK5qEJj+dBsEGN5zJL7vs7Lih4d4Y3ycABzOLcfjcJVTXWmz2KyQg3NcDMf46xAR4IsLXA2qlAmqlhEg/HWICdPgprRAf7TuH4soa3Dg4BDcPCYFWpURmUQVe2XQaJ3OMAOpnzl3XJwBfH8tB+u9a0cb08sPSaYOQXlCO4ooa9An2Qv9gPdw19SEqu7gSb+1IRXWtBU9N6osIP9vlBkx1ZkiQoFEpYKoz41DWJRzLLkVRuQkVNXUY3zcQkwYE2W0Jgst1WVosAmWmOqiVUpsHzDsjBpkGDDJE5ArMFoHPD5+Hu1qJm4aEWFsgiitq4OeptR5XbqrDdz/n4vND55FvrMadsRH4w9WR+OF0AdYfOo9QbzcsGN/Luip0aWUt0i6W4VSOEXvSCrE3rcim9WhkpA/uvSYKm07mYdOJPJsB3aMifXDHqHCEeLvBQ6NEUXkNTuUa8d/dZ5t0r/nqNBgaZkBRRQ3OXqywro/UEV5aFWotFpuQ5KZWYMrAYAyP8MGrm043282nkICYAE9E+Xlg95lC1JjrX69VKTBvTDR6+LijqqYOP6YWYv/ZYtSYLfD31Fi7An9vZKQPro7xRUpeOUx1ZgyP8MGAEC+cv1SFtIJyGKtrUV1rgbeHGqMifRGk1+JYdgkyiipxdYwvpg4OwZZT+XhzeypKq2oxaUAwxvXxR1WNGXnGavx8vhTHL5SisNxkvc1Jn0AvDOyhR6jBHUF6LYZH+GBgqB6SVN+SdjrPiIzCChRX1GBEhA9G9/SDUiEht6Qav+QZceJCKS6UVEEpSfDQKDF9eA8Mj/ABAJzJL0NZdR0G9dBfttWsuKIGv+QacSrHiBsGBCHKX9fRS2qDQaYBgwwRUeuZLQLnL1XiTH453NVKmwUPy6prca64EhcuVaGHjzsGhja/gnSBsRr/b2c6iitqcFWUD66O8UOvQE/r+wghcLHMhPSLFUi/WD8WKbe0CnUWgepaM85erMCFkioEemkxOy4SEX7u+OLwBezPKIZKUf/BO3lgMJ64oQ/MFoF3dp3FueJKTBoQhITBwdZB1SculOKhjw4hp6QavQM9EeClxem8siYDxcf28odFiGaXG/i9AC8t4qJ9Eertjpo6Cz45eK5Ja5NcAry0kAAUNDMQXqNUoM5iweUmFk7sF4jCchOOnS+tf41KgWFh3riubwBGRPhgf0YRtpzMR76xGpU1tqHu5RmDcWdshF3Ph0GmAYMMEZHzqaypg1al7PCtNIQQqDFbbFoWCsqqcTLHiNT8MgwKNeCaXv4QQuDr47nYcjIPdWYBhQIYGuaNif0D4eOhQb7RBLVSsglkAJBvrMb7ezJQVl2LvkFeUKsUSM68hNSCMoT7eKB3kBf8G24jkn2pEsmZl1BYbsLgMAPCfDzw/c+5SC0oh8FdjYcn9MLgMAO++zkXJ3OM8HZXw89Tg37BegwN90aknwe83FQorarFsexSnM41Ir+sGucvVeFARrF14LpCqp+NF+2vg6dWjb3phchtGPulUSkQ46/D4B4GRAfUt6Ck5pfjy6MXrCFHrZSgd1OjqKLmij/fKD8P9A/RY9ZV4RjfN7BD1+r3XCrILFu2DK+99hry8vIwdOhQvPXWW4iNjW3VaxlkiIjIUQkhkF1cBT9PjXWdo/Yw1Zlx5FwJlAoJA0P1NmNohBA4V1wJd7US/p5a6yDs30orKMOnyefh76nBjBFh8NNpkFlUiZ/SCrEzpQBHs0sxJMyAqYNDMLCHHjqNCr66jtV8JS4TZNatW4c5c+bgnXfeQVxcHN544w189tlnSElJQWDgldMfgwwREZHzae3nt8PPSXv99ddx//33Y968eRgwYADeeecdeHh4YOXKlXKXRkRERDJz6CBTU1ODQ4cOIT4+3rpNoVAgPj4eSUlJzb7GZDLBaDTaPIiIiMg1OXSQKSwshNlsRlBQkM32oKAg5OXlNfuaxMREGAwG6yM8PLwrSiUiIiIZOHSQaY9FixahtLTU+sjObvtKnEREROQcHHppQH9/fyiVSuTn59tsz8/PR3BwcLOv0Wq10Gq1ze4jIiIi1+LQLTIajQYjR47E9u3brdssFgu2b9+O0aNHy1gZEREROQKHbpEBgCeeeAJz587FqFGjEBsbizfeeAMVFRWYN2+e3KURERGRzBw+yMyaNQsXL17Ec889h7y8PAwbNgybNm1qMgCYiIiIuh+HXxCvo7ggHhERkfNxmQXxiIiIiFrCIENEREROi0GGiIiInBaDDBERETktBhkiIiJyWg4//bqjGidl8eaRREREzqPxc/tKk6tdPsiUlZUBAG8eSURE5ITKyspgMBha3O/y68hYLBbk5OTAy8sLkiTZ7X2NRiPCw8ORnZ3tsuvT8Bydn6ufH8BzdAWufn4Az7E9hBAoKytDaGgoFIqWR8K4fIuMQqFAWFhYp72/Xq932X+UjXiOzs/Vzw/gOboCVz8/gOfYVpdriWnEwb5ERETktBhkiIiIyGkxyLSTVqvF888/D61WK3cpnYbn6Pxc/fwAnqMrcPXzA3iOncnlB/sSERGR62KLDBERETktBhkiIiJyWgwyRERE5LQYZIiIiMhpMci007JlyxAVFQU3NzfExcXhwIEDcpfULomJibjqqqvg5eWFwMBATJ8+HSkpKTbHjB8/HpIk2TwefPBBmSpuuyVLljSpv1+/ftb91dXVWLhwIfz8/ODp6YnbbrsN+fn5MlbcdlFRUU3OUZIkLFy4EIDzXcPdu3fj5ptvRmhoKCRJwsaNG232CyHw3HPPISQkBO7u7oiPj0dqaqrNMcXFxZg9ezb0ej28vb1x3333oby8vAvP4vIud461tbV45plnMHjwYOh0OoSGhmLOnDnIycmxeY/mrvvLL7/cxWfSsitdx3vvvbdJ/VOmTLE5xpGv45XOr7nfSUmS8Nprr1mPceRr2JrPh9b8/Tx37hymTp0KDw8PBAYG4umnn0ZdXZ3d6mSQaYd169bhiSeewPPPP4/Dhw9j6NChmDx5MgoKCuQurc127dqFhQsXYt++fdi6dStqa2sxadIkVFRU2Bx3//33Izc31/p49dVXZaq4fQYOHGhT/549e6z7/vznP+Prr7/GZ599hl27diEnJwczZsyQsdq2O3jwoM35bd26FQBw++23W49xpmtYUVGBoUOHYtmyZc3uf/XVV/Hmm2/inXfewf79+6HT6TB58mRUV1dbj5k9ezZOnjyJrVu34ptvvsHu3bsxf/78rjqFK7rcOVZWVuLw4cNYvHgxDh8+jC+++AIpKSm45ZZbmhy7dOlSm+v6yCOPdEX5rXKl6wgAU6ZMsal/7dq1Nvsd+Tpe6fx+e165ublYuXIlJEnCbbfdZnOco17D1nw+XOnvp9lsxtSpU1FTU4O9e/dizZo1WL16NZ577jn7FSqozWJjY8XChQutz81mswgNDRWJiYkyVmUfBQUFAoDYtWuXddt1110nHnvsMfmK6qDnn39eDB06tNl9JSUlQq1Wi88++8y67ZdffhEARFJSUhdVaH+PPfaY6Nmzp7BYLEII576GAMSGDRuszy0WiwgODhavvfaadVtJSYnQarVi7dq1QgghTp06JQCIgwcPWo/5/vvvhSRJ4sKFC11We2v9/hybc+DAAQFAZGVlWbdFRkaKf//7351bnJ00d45z584V06ZNa/E1znQdW3MNp02bJq6//nqbbc50DX//+dCav5/fffedUCgUIi8vz3rM8uXLhV6vFyaTyS51sUWmjWpqanDo0CHEx8dbtykUCsTHxyMpKUnGyuyjtLQUAODr62uz/aOPPoK/vz8GDRqERYsWobKyUo7y2i01NRWhoaGIiYnB7Nmzce7cOQDAoUOHUFtba3M9+/Xrh4iICKe9njU1Nfjwww/xxz/+0eZGqc5+DRtlZGQgLy/P5poZDAbExcVZr1lSUhK8vb0xatQo6zHx8fFQKBTYv39/l9dsD6WlpZAkCd7e3jbbX375Zfj5+WH48OF47bXX7Npk3xV27tyJwMBA9O3bFw899BCKioqs+1zpOubn5+Pbb7/Ffffd12Sfs1zD338+tObvZ1JSEgYPHoygoCDrMZMnT4bRaMTJkyftUpfL3zTS3goLC2E2m20uCgAEBQXh9OnTMlVlHxaLBY8//jjGjBmDQYMGWbfffffdiIyMRGhoKI4fP45nnnkGKSkp+OKLL2SstvXi4uKwevVq9O3bF7m5uXjhhRdw7bXX4sSJE8jLy4NGo2ny4RAUFIS8vDx5Cu6gjRs3oqSkBPfee691m7Nfw99qvC7N/Q427svLy0NgYKDNfpVKBV9fX6e8rtXV1XjmmWdw11132dyM79FHH8WIESPg6+uLvXv3YtGiRcjNzcXrr78uY7WtN2XKFMyYMQPR0dFIT0/H//3f/yEhIQFJSUlQKpUudR3XrFkDLy+vJt3WznINm/t8aM3fz7y8vGZ/Vxv32QODDFktXLgQJ06csBk/AsCmP3rw4MEICQnBxIkTkZ6ejp49e3Z1mW2WkJBg/XrIkCGIi4tDZGQkPv30U7i7u8tYWed4//33kZCQgNDQUOs2Z7+G3VltbS3uuOMOCCGwfPlym31PPPGE9eshQ4ZAo9HggQceQGJiolMshX/nnXdavx48eDCGDBmCnj17YufOnZg4caKMldnfypUrMXv2bLi5udlsd5Zr2NLngyNg11Ib+fv7Q6lUNhmVnZ+fj+DgYJmq6riHH34Y33zzDX744QeEhYVd9ti4uDgAQFpaWleUZnfe3t7o06cP0tLSEBwcjJqaGpSUlNgc46zXMysrC9u2bcOf/vSnyx7nzNew8bpc7ncwODi4yeD7uro6FBcXO9V1bQwxWVlZ2Lp1q01rTHPi4uJQV1eHzMzMrinQzmJiYuDv72/9d+kq1/HHH39ESkrKFX8vAce8hi19PrTm72dwcHCzv6uN++yBQaaNNBoNRo4cie3bt1u3WSwWbN++HaNHj5axsvYRQuDhhx/Ghg0bsGPHDkRHR1/xNUePHgUAhISEdHJ1naO8vBzp6ekICQnByJEjoVarba5nSkoKzp0755TXc9WqVQgMDMTUqVMve5wzX8Po6GgEBwfbXDOj0Yj9+/dbr9no0aNRUlKCQ4cOWY/ZsWMHLBaLNcQ5usYQk5qaim3btsHPz++Krzl69CgUCkWT7hhncf78eRQVFVn/XbrCdQTqW0lHjhyJoUOHXvFYR7qGV/p8aM3fz9GjR+Pnn3+2CaSNoXzAgAF2K5Ta6JNPPhFarVasXr1anDp1SsyfP194e3vbjMp2Fg899JAwGAxi586dIjc31/qorKwUQgiRlpYmli5dKpKTk0VGRob48ssvRUxMjBg3bpzMlbfek08+KXbu3CkyMjLETz/9JOLj44W/v78oKCgQQgjx4IMPioiICLFjxw6RnJwsRo8eLUaPHi1z1W1nNptFRESEeOaZZ2y2O+M1LCsrE0eOHBFHjhwRAMTrr78ujhw5Yp2x8/LLLwtvb2/x5ZdfiuPHj4tp06aJ6OhoUVVVZX2PKVOmiOHDh4v9+/eLPXv2iN69e4u77rpLrlNq4nLnWFNTI2655RYRFhYmjh49avO72TjTY+/eveLf//63OHr0qEhPTxcffvihCAgIEHPmzJH5zH51uXMsKysTTz31lEhKShIZGRli27ZtYsSIEaJ3796iurra+h6OfB2v9O9UCCFKS0uFh4eHWL58eZPXO/o1vNLngxBX/vtZV1cnBg0aJCZNmiSOHj0qNm3aJAICAsSiRYvsVieDTDu99dZbIiIiQmg0GhEbGyv27dsnd0ntAqDZx6pVq4QQQpw7d06MGzdO+Pr6Cq1WK3r16iWefvppUVpaKm/hbTBr1iwREhIiNBqN6NGjh5g1a5ZIS0uz7q+qqhILFiwQPj4+wsPDQ9x6660iNzdXxorbZ/PmzQKASElJsdnujNfwhx9+aPbf5dy5c4UQ9VOwFy9eLIKCgoRWqxUTJ05sct5FRUXirrvuEp6enkKv14t58+aJsrIyGc6meZc7x4yMjBZ/N3/44QchhBCHDh0ScXFxwmAwCDc3N9G/f3/xj3/8wyYEyO1y51hZWSkmTZokAgIChFqtFpGRkeL+++9v8h9CR76OV/p3KoQQK1asEO7u7qKkpKTJ6x39Gl7p80GI1v39zMzMFAkJCcLd3V34+/uLJ598UtTW1tqtTqmhWCIiIiKnwzEyRERE5LQYZIiIiMhpMcgQERGR02KQISIiIqfFIENEREROi0GGiIiInBaDDBERETktBhki6nYkScLGjRvlLoOI7IBBhoi61L333gtJkpo8pkyZIndpROSEVHIXQETdz5QpU7Bq1SqbbVqtVqZqiMiZsUWGiLqcVqtFcHCwzcPHxwdAfbfP8uXLkZCQAHd3d8TExGD9+vU2r//5559x/fXXw93dHX5+fpg/fz7Ky8ttjlm5ciUGDhwIrVaLkJAQPPzwwzb7CwsLceutt8LDwwO9e/fGV1991bknTUSdgkGGiBzO4sWLcdttt+HYsWOYPXs27rzzTvzyyy8AgIqKCkyePBk+Pj44ePAgPvvsM2zbts0mqCxfvhwLFy7E/Pnz8fPPP+Orr75Cr169bL7HCy+8gDvuuAPHjx/HjTfeiNmzZ6O4uLhLz5OI7MBut58kImqFuXPnCqVSKXQ6nc3jpZdeEkLU33H3wQcftHlNXFyceOihh4QQQrz77rvCx8dHlJeXW/d/++23QqFQWO+cHBoaKp599tkWawAg/va3v1mfl5eXCwDi+++/t9t5ElHX4BgZIupyEyZMwPLly222+fr6Wr8ePXq0zb7Ro0fj6NGjAIBffvkFQ4cOhU6ns+4fM2YMLBYLUlJSIEkScnJyMHHixMvWMGTIEOvXOp0Oer0eBQUF7T0lIpIJgwwRdTmdTtekq8de3N3dW3WcWq22eS5JEiwWS2eURESdiGNkiMjh7Nu3r8nz/v37AwD69++PY8eOoaKiwrr/p59+gkKhQN++feHl5YWoqChs3769S2smInmwRYaIupzJZEJeXp7NNpVKBX9/fwDAZ599hlGjRmHs2LH46KOPcODAAbz//vsAgNmzZ+P555/H3LlzsWTJEly8eBGPPPII7rnnHgQFBQEAlixZggcffBCBgYFISEhAWVkZfvrpJzzyyCNde6JE1OkYZIioy23atAkhISE22/r27YvTp08DqJ9R9Mknn2DBggUICQnB2rVrMWDAAACAh4cHNm/ejMceewxXXXUVPDw8cNttt+H111+3vtfcuXNRXV2Nf//733jqqafg7++PmTNndt0JElGXkYQQQu4iiIgaSZKEDRs2YPr06XKXQkROgGNkiIiIyGkxyBAREZHT4hgZInIo7O0morZgiwwRERE5LQYZIiIicloMMkREROS0GGSIiIjIaTHIEBERkdNikCEiIiKnxSBDRERETotBhoiIiJwWgwwRERE5rf8PDaEbNi2E0MAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 3]\n",
      "[6 9 3]\n",
      "\n",
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(64, 128))  # 64 inputs (8x8 images)\n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Dropout(0.25))\n",
    "network.add_layer(Layer(128, 10))  # 10 classes\n",
    "network.add_layer(Softmax())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=200, learning_rate=0.01, batch_size=10)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1) # transoform back the One-Hot encoded array of the labels\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72fcf0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20000 --- Loss: 8.053266721096405\n",
      "Epoch 10/20000 --- Loss: 7.963567522190622\n",
      "Epoch 20/20000 --- Loss: 7.881871852299028\n",
      "Epoch 30/20000 --- Loss: 7.780280698083434\n",
      "Epoch 40/20000 --- Loss: 7.560271588940646\n",
      "Epoch 50/20000 --- Loss: 6.903631202560784\n",
      "Epoch 60/20000 --- Loss: 5.582530195528522\n",
      "Epoch 70/20000 --- Loss: 4.332261581910845\n",
      "Epoch 80/20000 --- Loss: 3.5006796334622208\n",
      "Epoch 90/20000 --- Loss: 2.9659928823497705\n",
      "Epoch 100/20000 --- Loss: 2.5976959903311054\n",
      "Epoch 110/20000 --- Loss: 2.327880692072756\n",
      "Epoch 120/20000 --- Loss: 2.1185382515603273\n",
      "Epoch 130/20000 --- Loss: 1.9505045963655423\n",
      "Epoch 140/20000 --- Loss: 1.8135876769846926\n",
      "Epoch 150/20000 --- Loss: 1.698907253841939\n",
      "Epoch 160/20000 --- Loss: 1.6018412267465656\n",
      "Epoch 170/20000 --- Loss: 1.5188789823703641\n",
      "Epoch 180/20000 --- Loss: 1.4467605969915125\n",
      "Epoch 190/20000 --- Loss: 1.3837495690558774\n",
      "Epoch 200/20000 --- Loss: 1.3290570976138072\n",
      "Epoch 210/20000 --- Loss: 1.2800623637544275\n",
      "Epoch 220/20000 --- Loss: 1.235839922133552\n",
      "Epoch 230/20000 --- Loss: 1.1956162572741749\n",
      "Epoch 240/20000 --- Loss: 1.1599335434692093\n",
      "Epoch 250/20000 --- Loss: 1.126612550075652\n",
      "Epoch 260/20000 --- Loss: 1.0962212149890485\n",
      "Epoch 270/20000 --- Loss: 1.0687297542125762\n",
      "Epoch 280/20000 --- Loss: 1.043380339396393\n",
      "Epoch 290/20000 --- Loss: 1.0196344029854068\n",
      "Epoch 300/20000 --- Loss: 0.9977990488483406\n",
      "Epoch 310/20000 --- Loss: 0.9771046451978513\n",
      "Epoch 320/20000 --- Loss: 0.957976180423002\n",
      "Epoch 330/20000 --- Loss: 0.9404842599587702\n",
      "Epoch 340/20000 --- Loss: 0.9238962155131557\n",
      "Epoch 350/20000 --- Loss: 0.9080795505276865\n",
      "Epoch 360/20000 --- Loss: 0.8934387605859979\n",
      "Epoch 370/20000 --- Loss: 0.8796827927257602\n",
      "Epoch 380/20000 --- Loss: 0.8662120963946079\n",
      "Epoch 390/20000 --- Loss: 0.8538747304288276\n",
      "Epoch 400/20000 --- Loss: 0.8422637143425395\n",
      "Epoch 410/20000 --- Loss: 0.8308663558286306\n",
      "Epoch 420/20000 --- Loss: 0.820163513703758\n",
      "Epoch 430/20000 --- Loss: 0.8098118811517225\n",
      "Epoch 440/20000 --- Loss: 0.800351202854184\n",
      "Epoch 450/20000 --- Loss: 0.7910243080980371\n",
      "Epoch 460/20000 --- Loss: 0.7819032144232063\n",
      "Epoch 470/20000 --- Loss: 0.7735512574904355\n",
      "Epoch 480/20000 --- Loss: 0.7656114200059032\n",
      "Epoch 490/20000 --- Loss: 0.7575748949372523\n",
      "Epoch 500/20000 --- Loss: 0.7499676432626396\n",
      "Epoch 510/20000 --- Loss: 0.7426723615707178\n",
      "Epoch 520/20000 --- Loss: 0.7357768484041847\n",
      "Epoch 530/20000 --- Loss: 0.7293897312473333\n",
      "Epoch 540/20000 --- Loss: 0.722727556346091\n",
      "Epoch 550/20000 --- Loss: 0.7169610914050345\n",
      "Epoch 560/20000 --- Loss: 0.7111430385074352\n",
      "Epoch 570/20000 --- Loss: 0.7051233522190007\n",
      "Epoch 580/20000 --- Loss: 0.6994060473797437\n",
      "Epoch 590/20000 --- Loss: 0.694100843205469\n",
      "Epoch 600/20000 --- Loss: 0.6891159260409965\n",
      "Epoch 610/20000 --- Loss: 0.6841421546163307\n",
      "Epoch 620/20000 --- Loss: 0.6794202528230174\n",
      "Epoch 630/20000 --- Loss: 0.6749468593148998\n",
      "Epoch 640/20000 --- Loss: 0.6698611087202777\n",
      "Epoch 650/20000 --- Loss: 0.6652460281435563\n",
      "Epoch 660/20000 --- Loss: 0.6609343838178154\n",
      "Epoch 670/20000 --- Loss: 0.6566460946497662\n",
      "Epoch 680/20000 --- Loss: 0.6524075267723767\n",
      "Epoch 690/20000 --- Loss: 0.6483838536017346\n",
      "Epoch 700/20000 --- Loss: 0.644351694784926\n",
      "Epoch 710/20000 --- Loss: 0.6402556188224976\n",
      "Epoch 720/20000 --- Loss: 0.6366782461617105\n",
      "Epoch 730/20000 --- Loss: 0.6330416135893088\n",
      "Epoch 740/20000 --- Loss: 0.6291916299081141\n",
      "Epoch 750/20000 --- Loss: 0.6255947190764153\n",
      "Epoch 760/20000 --- Loss: 0.6222620810373279\n",
      "Epoch 770/20000 --- Loss: 0.6190209139674865\n",
      "Epoch 780/20000 --- Loss: 0.6158090775909452\n",
      "Epoch 790/20000 --- Loss: 0.612713708125118\n",
      "Epoch 800/20000 --- Loss: 0.6095282540843456\n",
      "Epoch 810/20000 --- Loss: 0.606551655765319\n",
      "Epoch 820/20000 --- Loss: 0.6035501288467934\n",
      "Epoch 830/20000 --- Loss: 0.6007140488819465\n",
      "Epoch 840/20000 --- Loss: 0.5980229099411497\n",
      "Epoch 850/20000 --- Loss: 0.5953148597077976\n",
      "Epoch 860/20000 --- Loss: 0.5923108720285023\n",
      "Epoch 870/20000 --- Loss: 0.5899821354912496\n",
      "Epoch 880/20000 --- Loss: 0.5875158107501669\n",
      "Epoch 890/20000 --- Loss: 0.5848122239000936\n",
      "Epoch 900/20000 --- Loss: 0.582142242536095\n",
      "Epoch 910/20000 --- Loss: 0.5795936557773879\n",
      "Epoch 920/20000 --- Loss: 0.5774485544776387\n",
      "Epoch 930/20000 --- Loss: 0.574890633060909\n",
      "Epoch 940/20000 --- Loss: 0.5722075744880502\n",
      "Epoch 950/20000 --- Loss: 0.5700220479838658\n",
      "Epoch 960/20000 --- Loss: 0.5680495788150859\n",
      "Epoch 970/20000 --- Loss: 0.5656123886527813\n",
      "Epoch 980/20000 --- Loss: 0.5633511139320277\n",
      "Epoch 990/20000 --- Loss: 0.5613725172959965\n",
      "Epoch 1000/20000 --- Loss: 0.5588731820339337\n",
      "Epoch 1010/20000 --- Loss: 0.5567504264897334\n",
      "Epoch 1020/20000 --- Loss: 0.5546126484992232\n",
      "Epoch 1030/20000 --- Loss: 0.5524455372636148\n",
      "Epoch 1040/20000 --- Loss: 0.5508869210402882\n",
      "Epoch 1050/20000 --- Loss: 0.5489042600239746\n",
      "Epoch 1060/20000 --- Loss: 0.54705617349045\n",
      "Epoch 1070/20000 --- Loss: 0.5452920708602536\n",
      "Epoch 1080/20000 --- Loss: 0.5434280285899281\n",
      "Epoch 1090/20000 --- Loss: 0.5413257222088595\n",
      "Epoch 1100/20000 --- Loss: 0.5391289734687341\n",
      "Epoch 1110/20000 --- Loss: 0.5374096592284496\n",
      "Epoch 1120/20000 --- Loss: 0.5354609022736091\n",
      "Epoch 1130/20000 --- Loss: 0.5337764612298839\n",
      "Epoch 1140/20000 --- Loss: 0.5317621713226662\n",
      "Epoch 1150/20000 --- Loss: 0.5302297376442131\n",
      "Epoch 1160/20000 --- Loss: 0.5291750529715149\n",
      "Epoch 1170/20000 --- Loss: 0.5273009785748746\n",
      "Epoch 1180/20000 --- Loss: 0.5259841013969503\n",
      "Epoch 1190/20000 --- Loss: 0.5241972927847269\n",
      "Epoch 1200/20000 --- Loss: 0.522683878911641\n",
      "Epoch 1210/20000 --- Loss: 0.5207456467575141\n",
      "Epoch 1220/20000 --- Loss: 0.5195268320994308\n",
      "Epoch 1230/20000 --- Loss: 0.5181320748891768\n",
      "Epoch 1240/20000 --- Loss: 0.5166043229827978\n",
      "Epoch 1250/20000 --- Loss: 0.5157126544213434\n",
      "Epoch 1260/20000 --- Loss: 0.5138301692302372\n",
      "Epoch 1270/20000 --- Loss: 0.5123897031304883\n",
      "Epoch 1280/20000 --- Loss: 0.5111378625712729\n",
      "Epoch 1290/20000 --- Loss: 0.5095812784282269\n",
      "Epoch 1300/20000 --- Loss: 0.5083198107159289\n",
      "Epoch 1310/20000 --- Loss: 0.5068410965878846\n",
      "Epoch 1320/20000 --- Loss: 0.5055102320916255\n",
      "Epoch 1330/20000 --- Loss: 0.5043476041679897\n",
      "Epoch 1340/20000 --- Loss: 0.5027961028936436\n",
      "Epoch 1350/20000 --- Loss: 0.5017577227830113\n",
      "Epoch 1360/20000 --- Loss: 0.5006564481385353\n",
      "Epoch 1370/20000 --- Loss: 0.49919565083982564\n",
      "Epoch 1380/20000 --- Loss: 0.4979192492570198\n",
      "Epoch 1390/20000 --- Loss: 0.4967840092024016\n",
      "Epoch 1400/20000 --- Loss: 0.49542329594731516\n",
      "Epoch 1410/20000 --- Loss: 0.49464684162295025\n",
      "Epoch 1420/20000 --- Loss: 0.4936698860232202\n",
      "Epoch 1430/20000 --- Loss: 0.49253759136059666\n",
      "Epoch 1440/20000 --- Loss: 0.4916245518650552\n",
      "Epoch 1450/20000 --- Loss: 0.49034851578873595\n",
      "Epoch 1460/20000 --- Loss: 0.4894919192891347\n",
      "Epoch 1470/20000 --- Loss: 0.4882616697915441\n",
      "Epoch 1480/20000 --- Loss: 0.4873028318829132\n",
      "Epoch 1490/20000 --- Loss: 0.486137166005229\n",
      "Epoch 1500/20000 --- Loss: 0.4852155708742596\n",
      "Epoch 1510/20000 --- Loss: 0.4841516374886405\n",
      "Epoch 1520/20000 --- Loss: 0.4830325545283777\n",
      "Epoch 1530/20000 --- Loss: 0.4820538502369637\n",
      "Epoch 1540/20000 --- Loss: 0.48110906000885784\n",
      "Epoch 1550/20000 --- Loss: 0.47986317514856386\n",
      "Epoch 1560/20000 --- Loss: 0.47922320505155847\n",
      "Epoch 1570/20000 --- Loss: 0.4782621527879785\n",
      "Epoch 1580/20000 --- Loss: 0.4773307141236162\n",
      "Epoch 1590/20000 --- Loss: 0.4763198925172957\n",
      "Epoch 1600/20000 --- Loss: 0.4752894476055883\n",
      "Epoch 1610/20000 --- Loss: 0.47463310277533755\n",
      "Epoch 1620/20000 --- Loss: 0.4735199854956017\n",
      "Epoch 1630/20000 --- Loss: 0.47266019961169015\n",
      "Epoch 1640/20000 --- Loss: 0.4718305169785752\n",
      "Epoch 1650/20000 --- Loss: 0.47106658497295173\n",
      "Epoch 1660/20000 --- Loss: 0.47002395182577444\n",
      "Epoch 1670/20000 --- Loss: 0.46896021399551896\n",
      "Epoch 1680/20000 --- Loss: 0.46811032413958775\n",
      "Epoch 1690/20000 --- Loss: 0.467281971410214\n",
      "Epoch 1700/20000 --- Loss: 0.46662908573123657\n",
      "Epoch 1710/20000 --- Loss: 0.46544475728839724\n",
      "Epoch 1720/20000 --- Loss: 0.46424475192362913\n",
      "Epoch 1730/20000 --- Loss: 0.4633944780399837\n",
      "Epoch 1740/20000 --- Loss: 0.46227098301133474\n",
      "Epoch 1750/20000 --- Loss: 0.4611996709856285\n",
      "Epoch 1760/20000 --- Loss: 0.4602317461734534\n",
      "Epoch 1770/20000 --- Loss: 0.4592263486387623\n",
      "Epoch 1780/20000 --- Loss: 0.458186123929083\n",
      "Epoch 1790/20000 --- Loss: 0.45709353848643247\n",
      "Epoch 1800/20000 --- Loss: 0.4558485255797837\n",
      "Epoch 1810/20000 --- Loss: 0.4551455425003074\n",
      "Epoch 1820/20000 --- Loss: 0.4542013684814256\n",
      "Epoch 1830/20000 --- Loss: 0.4534923122899967\n",
      "Epoch 1840/20000 --- Loss: 0.45249729827190666\n",
      "Epoch 1850/20000 --- Loss: 0.4517917621165335\n",
      "Epoch 1860/20000 --- Loss: 0.45155415562223755\n",
      "Epoch 1870/20000 --- Loss: 0.4511315128924035\n",
      "Epoch 1880/20000 --- Loss: 0.45018594470064743\n",
      "Epoch 1890/20000 --- Loss: 0.4493926018075829\n",
      "Epoch 1900/20000 --- Loss: 0.4486436384395346\n",
      "Epoch 1910/20000 --- Loss: 0.447770358374595\n",
      "Epoch 1920/20000 --- Loss: 0.4467774679326113\n",
      "Epoch 1930/20000 --- Loss: 0.4460599491253185\n",
      "Epoch 1940/20000 --- Loss: 0.44563236019622077\n",
      "Epoch 1950/20000 --- Loss: 0.44494400054747274\n",
      "Epoch 1960/20000 --- Loss: 0.4440013567679916\n",
      "Epoch 1970/20000 --- Loss: 0.44319347261454145\n",
      "Epoch 1980/20000 --- Loss: 0.44267705497474513\n",
      "Epoch 1990/20000 --- Loss: 0.4417418042365782\n",
      "Epoch 2000/20000 --- Loss: 0.44118114210905185\n",
      "Epoch 2010/20000 --- Loss: 0.44040360706846643\n",
      "Epoch 2020/20000 --- Loss: 0.43958434711111466\n",
      "Epoch 2030/20000 --- Loss: 0.43880281988325165\n",
      "Epoch 2040/20000 --- Loss: 0.4379185411943863\n",
      "Epoch 2050/20000 --- Loss: 0.4371771123220541\n",
      "Epoch 2060/20000 --- Loss: 0.43682816964253685\n",
      "Epoch 2070/20000 --- Loss: 0.43577979068167183\n",
      "Epoch 2080/20000 --- Loss: 0.4349630628412057\n",
      "Epoch 2090/20000 --- Loss: 0.43417787370009664\n",
      "Epoch 2100/20000 --- Loss: 0.4334346668010558\n",
      "Epoch 2110/20000 --- Loss: 0.4324618343789069\n",
      "Epoch 2120/20000 --- Loss: 0.4315661642588402\n",
      "Epoch 2130/20000 --- Loss: 0.43078544599354557\n",
      "Epoch 2140/20000 --- Loss: 0.43027306306237867\n",
      "Epoch 2150/20000 --- Loss: 0.43022434471213583\n",
      "Epoch 2160/20000 --- Loss: 0.42965590067147147\n",
      "Epoch 2170/20000 --- Loss: 0.429352945808847\n",
      "Epoch 2180/20000 --- Loss: 0.4280488172188544\n",
      "Epoch 2190/20000 --- Loss: 0.4274171163500796\n",
      "Epoch 2200/20000 --- Loss: 0.42636388673811176\n",
      "Epoch 2210/20000 --- Loss: 0.42525595677885153\n",
      "Epoch 2220/20000 --- Loss: 0.4243406492714763\n",
      "Epoch 2230/20000 --- Loss: 0.4233476705362817\n",
      "Epoch 2240/20000 --- Loss: 0.4223755535289567\n",
      "Epoch 2250/20000 --- Loss: 0.4212049210305798\n",
      "Epoch 2260/20000 --- Loss: 0.4202698997443909\n",
      "Epoch 2270/20000 --- Loss: 0.41942114965772404\n",
      "Epoch 2280/20000 --- Loss: 0.41855719107347183\n",
      "Epoch 2290/20000 --- Loss: 0.41749813131183133\n",
      "Epoch 2300/20000 --- Loss: 0.41696632373302056\n",
      "Epoch 2310/20000 --- Loss: 0.4159155287078274\n",
      "Epoch 2320/20000 --- Loss: 0.41507325324409367\n",
      "Epoch 2330/20000 --- Loss: 0.4140328432152257\n",
      "Epoch 2340/20000 --- Loss: 0.41316138900705573\n",
      "Epoch 2350/20000 --- Loss: 0.41276129669432954\n",
      "Epoch 2360/20000 --- Loss: 0.41170447340159855\n",
      "Epoch 2370/20000 --- Loss: 0.4103484244185007\n",
      "Epoch 2380/20000 --- Loss: 0.40946366779776616\n",
      "Epoch 2390/20000 --- Loss: 0.4089369502591028\n",
      "Epoch 2400/20000 --- Loss: 0.40756830629837565\n",
      "Epoch 2410/20000 --- Loss: 0.40653780683587\n",
      "Epoch 2420/20000 --- Loss: 0.40582199177560363\n",
      "Epoch 2430/20000 --- Loss: 0.4047306513276071\n",
      "Epoch 2440/20000 --- Loss: 0.4038090444393006\n",
      "Epoch 2450/20000 --- Loss: 0.4027347757795386\n",
      "Epoch 2460/20000 --- Loss: 0.4017173428781775\n",
      "Epoch 2470/20000 --- Loss: 0.4008548385930117\n",
      "Epoch 2480/20000 --- Loss: 0.39995777884401634\n",
      "Epoch 2490/20000 --- Loss: 0.3992015776465775\n",
      "Epoch 2500/20000 --- Loss: 0.3981325351911067\n",
      "Epoch 2510/20000 --- Loss: 0.3972836917076913\n",
      "Epoch 2520/20000 --- Loss: 0.39635713604999884\n",
      "Epoch 2530/20000 --- Loss: 0.3951198021299947\n",
      "Epoch 2540/20000 --- Loss: 0.39455257108992636\n",
      "Epoch 2550/20000 --- Loss: 0.3935636758984601\n",
      "Epoch 2560/20000 --- Loss: 0.39266950539811957\n",
      "Epoch 2570/20000 --- Loss: 0.39175075091436135\n",
      "Epoch 2580/20000 --- Loss: 0.39117795372344566\n",
      "Epoch 2590/20000 --- Loss: 0.3901995410735178\n",
      "Epoch 2600/20000 --- Loss: 0.38927377880431\n",
      "Epoch 2610/20000 --- Loss: 0.38888767588505524\n",
      "Epoch 2620/20000 --- Loss: 0.3880130278467127\n",
      "Epoch 2630/20000 --- Loss: 0.38687545166397547\n",
      "Epoch 2640/20000 --- Loss: 0.38633376626839916\n",
      "Epoch 2650/20000 --- Loss: 0.38625091525384403\n",
      "Epoch 2660/20000 --- Loss: 0.3849420667534759\n",
      "Epoch 2670/20000 --- Loss: 0.38412685905963906\n",
      "Epoch 2680/20000 --- Loss: 0.38339392577947184\n",
      "Epoch 2690/20000 --- Loss: 0.382514378286434\n",
      "Epoch 2700/20000 --- Loss: 0.3823918639690474\n",
      "Epoch 2710/20000 --- Loss: 0.3814030323044504\n",
      "Epoch 2720/20000 --- Loss: 0.3806616138230429\n",
      "Epoch 2730/20000 --- Loss: 0.3797540794177685\n",
      "Epoch 2740/20000 --- Loss: 0.3786323271652371\n",
      "Epoch 2750/20000 --- Loss: 0.37807003915491577\n",
      "Epoch 2760/20000 --- Loss: 0.37758279579240706\n",
      "Epoch 2770/20000 --- Loss: 0.377432085859415\n",
      "Epoch 2780/20000 --- Loss: 0.3762909280542367\n",
      "Epoch 2790/20000 --- Loss: 0.37555958817588464\n",
      "Epoch 2800/20000 --- Loss: 0.37462551752282697\n",
      "Epoch 2810/20000 --- Loss: 0.37382031771438706\n",
      "Epoch 2820/20000 --- Loss: 0.37309929282530757\n",
      "Epoch 2830/20000 --- Loss: 0.3725752193914018\n",
      "Epoch 2840/20000 --- Loss: 0.3716444746321296\n",
      "Epoch 2850/20000 --- Loss: 0.371159226816758\n",
      "Epoch 2860/20000 --- Loss: 0.37060789694803364\n",
      "Epoch 2870/20000 --- Loss: 0.3696146626696679\n",
      "Epoch 2880/20000 --- Loss: 0.36886764354492063\n",
      "Epoch 2890/20000 --- Loss: 0.3682367560574058\n",
      "Epoch 2900/20000 --- Loss: 0.3671912571786999\n",
      "Epoch 2910/20000 --- Loss: 0.36648992772040295\n",
      "Epoch 2920/20000 --- Loss: 0.3657053110671547\n",
      "Epoch 2930/20000 --- Loss: 0.36470592409179214\n",
      "Epoch 2940/20000 --- Loss: 0.3641018649030299\n",
      "Epoch 2950/20000 --- Loss: 0.363845904470899\n",
      "Epoch 2960/20000 --- Loss: 0.362733810500031\n",
      "Epoch 2970/20000 --- Loss: 0.36216155303223635\n",
      "Epoch 2980/20000 --- Loss: 0.3611065696532196\n",
      "Epoch 2990/20000 --- Loss: 0.3604616622465454\n",
      "Epoch 3000/20000 --- Loss: 0.35961514873065753\n",
      "Epoch 3010/20000 --- Loss: 0.3593204272467675\n",
      "Epoch 3020/20000 --- Loss: 0.3586851375285749\n",
      "Epoch 3030/20000 --- Loss: 0.35787104708949985\n",
      "Epoch 3040/20000 --- Loss: 0.3570597132815758\n",
      "Epoch 3050/20000 --- Loss: 0.3567791304500106\n",
      "Epoch 3060/20000 --- Loss: 0.3559145960737597\n",
      "Epoch 3070/20000 --- Loss: 0.355116840883657\n",
      "Epoch 3080/20000 --- Loss: 0.35440688587661306\n",
      "Epoch 3090/20000 --- Loss: 0.3537044099382415\n",
      "Epoch 3100/20000 --- Loss: 0.35290224252380614\n",
      "Epoch 3110/20000 --- Loss: 0.35232091736057153\n",
      "Epoch 3120/20000 --- Loss: 0.3520769936318012\n",
      "Epoch 3130/20000 --- Loss: 0.35141285859121923\n",
      "Epoch 3140/20000 --- Loss: 0.3511765800725705\n",
      "Epoch 3150/20000 --- Loss: 0.3502176409826524\n",
      "Epoch 3160/20000 --- Loss: 0.3492287483629718\n",
      "Epoch 3170/20000 --- Loss: 0.3483863418757506\n",
      "Epoch 3180/20000 --- Loss: 0.3479689144282661\n",
      "Epoch 3190/20000 --- Loss: 0.34723009121816356\n",
      "Epoch 3200/20000 --- Loss: 0.3463044638810503\n",
      "Epoch 3210/20000 --- Loss: 0.34570726858716616\n",
      "Epoch 3220/20000 --- Loss: 0.34476756261645447\n",
      "Epoch 3230/20000 --- Loss: 0.3446761584197449\n",
      "Epoch 3240/20000 --- Loss: 0.34360558644486994\n",
      "Epoch 3250/20000 --- Loss: 0.34284218686438334\n",
      "Epoch 3260/20000 --- Loss: 0.3422376194533606\n",
      "Epoch 3270/20000 --- Loss: 0.3415361842105616\n",
      "Epoch 3280/20000 --- Loss: 0.34077520335540024\n",
      "Epoch 3290/20000 --- Loss: 0.3404755426136947\n",
      "Epoch 3300/20000 --- Loss: 0.340019381842796\n",
      "Epoch 3310/20000 --- Loss: 0.3393077015684589\n",
      "Epoch 3320/20000 --- Loss: 0.3383743739532267\n",
      "Epoch 3330/20000 --- Loss: 0.3376796555038001\n",
      "Epoch 3340/20000 --- Loss: 0.33691840889480595\n",
      "Epoch 3350/20000 --- Loss: 0.3363492782453711\n",
      "Epoch 3360/20000 --- Loss: 0.33563645647320056\n",
      "Epoch 3370/20000 --- Loss: 0.334789697890269\n",
      "Epoch 3380/20000 --- Loss: 0.3340763462385083\n",
      "Epoch 3390/20000 --- Loss: 0.3336574961543354\n",
      "Epoch 3400/20000 --- Loss: 0.33317785340284684\n",
      "Epoch 3410/20000 --- Loss: 0.3324801094392328\n",
      "Epoch 3420/20000 --- Loss: 0.3317276048267542\n",
      "Epoch 3430/20000 --- Loss: 0.3310368941785296\n",
      "Epoch 3440/20000 --- Loss: 0.33031761673012533\n",
      "Epoch 3450/20000 --- Loss: 0.32977350933782296\n",
      "Epoch 3460/20000 --- Loss: 0.3289819011623678\n",
      "Epoch 3470/20000 --- Loss: 0.3282707292565133\n",
      "Epoch 3480/20000 --- Loss: 0.3274020982769623\n",
      "Epoch 3490/20000 --- Loss: 0.32651130569826925\n",
      "Epoch 3500/20000 --- Loss: 0.32593348792313653\n",
      "Epoch 3510/20000 --- Loss: 0.3251820531063972\n",
      "Epoch 3520/20000 --- Loss: 0.3245150934117534\n",
      "Epoch 3530/20000 --- Loss: 0.3239590260299812\n",
      "Epoch 3540/20000 --- Loss: 0.32368880043039483\n",
      "Epoch 3550/20000 --- Loss: 0.3229344855928121\n",
      "Epoch 3560/20000 --- Loss: 0.3221750679900241\n",
      "Epoch 3570/20000 --- Loss: 0.32144773526922193\n",
      "Epoch 3580/20000 --- Loss: 0.3207550812441044\n",
      "Epoch 3590/20000 --- Loss: 0.32003330842337957\n",
      "Epoch 3600/20000 --- Loss: 0.3193944700334667\n",
      "Epoch 3610/20000 --- Loss: 0.3187251094806707\n",
      "Epoch 3620/20000 --- Loss: 0.31832263276961664\n",
      "Epoch 3630/20000 --- Loss: 0.3176275812331797\n",
      "Epoch 3640/20000 --- Loss: 0.316473371458517\n",
      "Epoch 3650/20000 --- Loss: 0.3158995849346489\n",
      "Epoch 3660/20000 --- Loss: 0.3153256384130618\n",
      "Epoch 3670/20000 --- Loss: 0.31459129913687184\n",
      "Epoch 3680/20000 --- Loss: 0.3139923769871405\n",
      "Epoch 3690/20000 --- Loss: 0.3138045705925185\n",
      "Epoch 3700/20000 --- Loss: 0.3129069534146114\n",
      "Epoch 3710/20000 --- Loss: 0.31256382351338075\n",
      "Epoch 3720/20000 --- Loss: 0.3120413206132809\n",
      "Epoch 3730/20000 --- Loss: 0.3112086902315072\n",
      "Epoch 3740/20000 --- Loss: 0.31053645188736595\n",
      "Epoch 3750/20000 --- Loss: 0.3098994598166989\n",
      "Epoch 3760/20000 --- Loss: 0.3094119389241913\n",
      "Epoch 3770/20000 --- Loss: 0.3085866657546622\n",
      "Epoch 3780/20000 --- Loss: 0.3079309826855972\n",
      "Epoch 3790/20000 --- Loss: 0.30707032824021413\n",
      "Epoch 3800/20000 --- Loss: 0.30627304701332675\n",
      "Epoch 3810/20000 --- Loss: 0.30578769140989437\n",
      "Epoch 3820/20000 --- Loss: 0.3054806590216291\n",
      "Epoch 3830/20000 --- Loss: 0.30434841831566145\n",
      "Epoch 3840/20000 --- Loss: 0.304709711579504\n",
      "Epoch 3850/20000 --- Loss: 0.3033283351730831\n",
      "Epoch 3860/20000 --- Loss: 0.3024155953407438\n",
      "Epoch 3870/20000 --- Loss: 0.3019144612895405\n",
      "Epoch 3880/20000 --- Loss: 0.30121549339977194\n",
      "Epoch 3890/20000 --- Loss: 0.30043185532904315\n",
      "Epoch 3900/20000 --- Loss: 0.29980226370587315\n",
      "Epoch 3910/20000 --- Loss: 0.2990931774543071\n",
      "Epoch 3920/20000 --- Loss: 0.2983515706869874\n",
      "Epoch 3930/20000 --- Loss: 0.29783130738791613\n",
      "Epoch 3940/20000 --- Loss: 0.29715133131641186\n",
      "Epoch 3950/20000 --- Loss: 0.29663332048884633\n",
      "Epoch 3960/20000 --- Loss: 0.29602260248746903\n",
      "Epoch 3970/20000 --- Loss: 0.29519132726201663\n",
      "Epoch 3980/20000 --- Loss: 0.2945450420260687\n",
      "Epoch 3990/20000 --- Loss: 0.2938159254403266\n",
      "Epoch 4000/20000 --- Loss: 0.29354434005309443\n",
      "Epoch 4010/20000 --- Loss: 0.29282806400302214\n",
      "Epoch 4020/20000 --- Loss: 0.292532016708948\n",
      "Epoch 4030/20000 --- Loss: 0.2916214747688081\n",
      "Epoch 4040/20000 --- Loss: 0.290988916368051\n",
      "Epoch 4050/20000 --- Loss: 0.290365263527867\n",
      "Epoch 4060/20000 --- Loss: 0.289712386474077\n",
      "Epoch 4070/20000 --- Loss: 0.2891887671904481\n",
      "Epoch 4080/20000 --- Loss: 0.28849485979141054\n",
      "Epoch 4090/20000 --- Loss: 0.2878343481105854\n",
      "Epoch 4100/20000 --- Loss: 0.2871432064940867\n",
      "Epoch 4110/20000 --- Loss: 0.2867880477498556\n",
      "Epoch 4120/20000 --- Loss: 0.2860625257380604\n",
      "Epoch 4130/20000 --- Loss: 0.2855985429888026\n",
      "Epoch 4140/20000 --- Loss: 0.2851607797561462\n",
      "Epoch 4150/20000 --- Loss: 0.2842826890007782\n",
      "Epoch 4160/20000 --- Loss: 0.28361302523971843\n",
      "Epoch 4170/20000 --- Loss: 0.2831723999198623\n",
      "Epoch 4180/20000 --- Loss: 0.2826045215248266\n",
      "Epoch 4190/20000 --- Loss: 0.28205557755489175\n",
      "Epoch 4200/20000 --- Loss: 0.2812961575553042\n",
      "Epoch 4210/20000 --- Loss: 0.28060968297137334\n",
      "Epoch 4220/20000 --- Loss: 0.28034427795845274\n",
      "Epoch 4230/20000 --- Loss: 0.27966499742917944\n",
      "Epoch 4240/20000 --- Loss: 0.27915664609032487\n",
      "Epoch 4250/20000 --- Loss: 0.2783383962139573\n",
      "Epoch 4260/20000 --- Loss: 0.27779150617515075\n",
      "Epoch 4270/20000 --- Loss: 0.277224142281997\n",
      "Epoch 4280/20000 --- Loss: 0.27655333974917273\n",
      "Epoch 4290/20000 --- Loss: 0.2761184508142172\n",
      "Epoch 4300/20000 --- Loss: 0.27579466125543717\n",
      "Epoch 4310/20000 --- Loss: 0.27510452594264223\n",
      "Epoch 4320/20000 --- Loss: 0.2745082132364686\n",
      "Epoch 4330/20000 --- Loss: 0.27410319879324796\n",
      "Epoch 4340/20000 --- Loss: 0.2733102509238778\n",
      "Epoch 4350/20000 --- Loss: 0.2731010551040939\n",
      "Epoch 4360/20000 --- Loss: 0.2724242207580927\n",
      "Epoch 4370/20000 --- Loss: 0.27233717827746684\n",
      "Epoch 4380/20000 --- Loss: 0.2714706109555528\n",
      "Epoch 4390/20000 --- Loss: 0.27095387511066515\n",
      "Epoch 4400/20000 --- Loss: 0.27022733642074026\n",
      "Epoch 4410/20000 --- Loss: 0.26978578937327385\n",
      "Epoch 4420/20000 --- Loss: 0.26937429750322356\n",
      "Epoch 4430/20000 --- Loss: 0.26873185604011884\n",
      "Epoch 4440/20000 --- Loss: 0.26826861784658235\n",
      "Epoch 4450/20000 --- Loss: 0.26766201688387165\n",
      "Epoch 4460/20000 --- Loss: 0.2675327552472864\n",
      "Epoch 4470/20000 --- Loss: 0.2667209961471283\n",
      "Epoch 4480/20000 --- Loss: 0.266037553040596\n",
      "Epoch 4490/20000 --- Loss: 0.2655006312599391\n",
      "Epoch 4500/20000 --- Loss: 0.26499103783318934\n",
      "Epoch 4510/20000 --- Loss: 0.2645490427730228\n",
      "Epoch 4520/20000 --- Loss: 0.26423993529244727\n",
      "Epoch 4530/20000 --- Loss: 0.26372953842919244\n",
      "Epoch 4540/20000 --- Loss: 0.26310189522858174\n",
      "Epoch 4550/20000 --- Loss: 0.2628605265646313\n",
      "Epoch 4560/20000 --- Loss: 0.26205647852368286\n",
      "Epoch 4570/20000 --- Loss: 0.26154890171859835\n",
      "Epoch 4580/20000 --- Loss: 0.260803518197185\n",
      "Epoch 4590/20000 --- Loss: 0.26036624888109244\n",
      "Epoch 4600/20000 --- Loss: 0.2597846918505342\n",
      "Epoch 4610/20000 --- Loss: 0.25940693383069874\n",
      "Epoch 4620/20000 --- Loss: 0.25962043957616704\n",
      "Epoch 4630/20000 --- Loss: 0.2585554415034612\n",
      "Epoch 4640/20000 --- Loss: 0.257988771422488\n",
      "Epoch 4650/20000 --- Loss: 0.25781768109943887\n",
      "Epoch 4660/20000 --- Loss: 0.25720368383881476\n",
      "Epoch 4670/20000 --- Loss: 0.2566137392679585\n",
      "Epoch 4680/20000 --- Loss: 0.25586756567459407\n",
      "Epoch 4690/20000 --- Loss: 0.25527358546062245\n",
      "Epoch 4700/20000 --- Loss: 0.25534607745033355\n",
      "Epoch 4710/20000 --- Loss: 0.2545437943204951\n",
      "Epoch 4720/20000 --- Loss: 0.2542821356997693\n",
      "Epoch 4730/20000 --- Loss: 0.2537078171717099\n",
      "Epoch 4740/20000 --- Loss: 0.2530418689498274\n",
      "Epoch 4750/20000 --- Loss: 0.2523854574899742\n",
      "Epoch 4760/20000 --- Loss: 0.25179475533834855\n",
      "Epoch 4770/20000 --- Loss: 0.25152447744792644\n",
      "Epoch 4780/20000 --- Loss: 0.2510825724607979\n",
      "Epoch 4790/20000 --- Loss: 0.2507985315086307\n",
      "Epoch 4800/20000 --- Loss: 0.249947348057587\n",
      "Epoch 4810/20000 --- Loss: 0.2494331789980268\n",
      "Epoch 4820/20000 --- Loss: 0.24898165195314167\n",
      "Epoch 4830/20000 --- Loss: 0.24840088034004948\n",
      "Epoch 4840/20000 --- Loss: 0.2478131210274797\n",
      "Epoch 4850/20000 --- Loss: 0.24744960429826596\n",
      "Epoch 4860/20000 --- Loss: 0.24687079153134892\n",
      "Epoch 4870/20000 --- Loss: 0.24630637763219682\n",
      "Epoch 4880/20000 --- Loss: 0.24588360894810748\n",
      "Epoch 4890/20000 --- Loss: 0.24561397036360422\n",
      "Epoch 4900/20000 --- Loss: 0.24502308854051857\n",
      "Epoch 4910/20000 --- Loss: 0.24441556790200752\n",
      "Epoch 4920/20000 --- Loss: 0.24389792135752653\n",
      "Epoch 4930/20000 --- Loss: 0.24345807503575378\n",
      "Epoch 4940/20000 --- Loss: 0.24327482107741116\n",
      "Epoch 4950/20000 --- Loss: 0.2427337791903206\n",
      "Epoch 4960/20000 --- Loss: 0.2422506648128077\n",
      "Epoch 4970/20000 --- Loss: 0.24199990141450498\n",
      "Epoch 4980/20000 --- Loss: 0.24144767421614258\n",
      "Epoch 4990/20000 --- Loss: 0.24073438472103006\n",
      "Epoch 5000/20000 --- Loss: 0.24018742969317702\n",
      "Epoch 5010/20000 --- Loss: 0.23975959991610143\n",
      "Epoch 5020/20000 --- Loss: 0.23931056566934783\n",
      "Epoch 5030/20000 --- Loss: 0.2389105569082649\n",
      "Epoch 5040/20000 --- Loss: 0.23865088001776116\n",
      "Epoch 5050/20000 --- Loss: 0.23817987471623453\n",
      "Epoch 5060/20000 --- Loss: 0.2376156664041159\n",
      "Epoch 5070/20000 --- Loss: 0.2371568970225337\n",
      "Epoch 5080/20000 --- Loss: 0.23677290716099347\n",
      "Epoch 5090/20000 --- Loss: 0.23632711277992444\n",
      "Epoch 5100/20000 --- Loss: 0.2358460247224186\n",
      "Epoch 5110/20000 --- Loss: 0.23573663768197728\n",
      "Epoch 5120/20000 --- Loss: 0.23528112408903276\n",
      "Epoch 5130/20000 --- Loss: 0.23471917343406148\n",
      "Epoch 5140/20000 --- Loss: 0.2343691536583086\n",
      "Epoch 5150/20000 --- Loss: 0.23377189870249895\n",
      "Epoch 5160/20000 --- Loss: 0.2338260685308971\n",
      "Epoch 5170/20000 --- Loss: 0.23329972677000851\n",
      "Epoch 5180/20000 --- Loss: 0.23290627045383566\n",
      "Epoch 5190/20000 --- Loss: 0.23237609999014444\n",
      "Epoch 5200/20000 --- Loss: 0.2319141155473613\n",
      "Epoch 5210/20000 --- Loss: 0.23141577225394125\n",
      "Epoch 5220/20000 --- Loss: 0.23095334000678724\n",
      "Epoch 5230/20000 --- Loss: 0.2307861997270642\n",
      "Epoch 5240/20000 --- Loss: 0.2305547202559559\n",
      "Epoch 5250/20000 --- Loss: 0.23006611289875803\n",
      "Epoch 5260/20000 --- Loss: 0.22958688016355602\n",
      "Epoch 5270/20000 --- Loss: 0.22905480439294448\n",
      "Epoch 5280/20000 --- Loss: 0.22859206419982267\n",
      "Epoch 5290/20000 --- Loss: 0.22817916050745926\n",
      "Epoch 5300/20000 --- Loss: 0.2277472662106299\n",
      "Epoch 5310/20000 --- Loss: 0.22788168481585738\n",
      "Epoch 5320/20000 --- Loss: 0.22730253424138372\n",
      "Epoch 5330/20000 --- Loss: 0.22679126851971174\n",
      "Epoch 5340/20000 --- Loss: 0.22617948148449768\n",
      "Epoch 5350/20000 --- Loss: 0.22574618490905235\n",
      "Epoch 5360/20000 --- Loss: 0.22541185974379038\n",
      "Epoch 5370/20000 --- Loss: 0.22502820508811403\n",
      "Epoch 5380/20000 --- Loss: 0.2246460252219702\n",
      "Epoch 5390/20000 --- Loss: 0.22421231689673385\n",
      "Epoch 5400/20000 --- Loss: 0.22399609289517938\n",
      "Epoch 5410/20000 --- Loss: 0.22336864665147257\n",
      "Epoch 5420/20000 --- Loss: 0.22298447863299545\n",
      "Epoch 5430/20000 --- Loss: 0.22259529834288483\n",
      "Epoch 5440/20000 --- Loss: 0.22221356692857988\n",
      "Epoch 5450/20000 --- Loss: 0.22209804077081724\n",
      "Epoch 5460/20000 --- Loss: 0.22179642476104913\n",
      "Epoch 5470/20000 --- Loss: 0.2212518436328885\n",
      "Epoch 5480/20000 --- Loss: 0.22083859717139645\n",
      "Epoch 5490/20000 --- Loss: 0.22036807646864282\n",
      "Epoch 5500/20000 --- Loss: 0.2199192534497129\n",
      "Epoch 5510/20000 --- Loss: 0.21967889971369176\n",
      "Epoch 5520/20000 --- Loss: 0.2192545750378114\n",
      "Epoch 5530/20000 --- Loss: 0.2191990540259422\n",
      "Epoch 5540/20000 --- Loss: 0.21861928250929755\n",
      "Epoch 5550/20000 --- Loss: 0.2182271666835099\n",
      "Epoch 5560/20000 --- Loss: 0.217846812049092\n",
      "Epoch 5570/20000 --- Loss: 0.2173593213529662\n",
      "Epoch 5580/20000 --- Loss: 0.21719341877103318\n",
      "Epoch 5590/20000 --- Loss: 0.2166716164802619\n",
      "Epoch 5600/20000 --- Loss: 0.21632107718889326\n",
      "Epoch 5610/20000 --- Loss: 0.21600499691872618\n",
      "Epoch 5620/20000 --- Loss: 0.21558415605686274\n",
      "Epoch 5630/20000 --- Loss: 0.2152140996975144\n",
      "Epoch 5640/20000 --- Loss: 0.21506775924534335\n",
      "Epoch 5650/20000 --- Loss: 0.21459610339614704\n",
      "Epoch 5660/20000 --- Loss: 0.21419276852716407\n",
      "Epoch 5670/20000 --- Loss: 0.21384530155095538\n",
      "Epoch 5680/20000 --- Loss: 0.21345980538440473\n",
      "Epoch 5690/20000 --- Loss: 0.21305540622810443\n",
      "Epoch 5700/20000 --- Loss: 0.21263673416862858\n",
      "Epoch 5710/20000 --- Loss: 0.21228429026045323\n",
      "Epoch 5720/20000 --- Loss: 0.2120719068979945\n",
      "Epoch 5730/20000 --- Loss: 0.2115392560201451\n",
      "Epoch 5740/20000 --- Loss: 0.21127128967371966\n",
      "Epoch 5750/20000 --- Loss: 0.21101016969653513\n",
      "Epoch 5760/20000 --- Loss: 0.2104792295746072\n",
      "Epoch 5770/20000 --- Loss: 0.21021622208702204\n",
      "Epoch 5780/20000 --- Loss: 0.21011259404309363\n",
      "Epoch 5790/20000 --- Loss: 0.20974116342091445\n",
      "Epoch 5800/20000 --- Loss: 0.20938559803904724\n",
      "Epoch 5810/20000 --- Loss: 0.20919579502405397\n",
      "Epoch 5820/20000 --- Loss: 0.20943483341554364\n",
      "Epoch 5830/20000 --- Loss: 0.2090988010160387\n",
      "Epoch 5840/20000 --- Loss: 0.20865342775866763\n",
      "Epoch 5850/20000 --- Loss: 0.2082814703312444\n",
      "Epoch 5860/20000 --- Loss: 0.20780452504647962\n",
      "Epoch 5870/20000 --- Loss: 0.20760611685282737\n",
      "Epoch 5880/20000 --- Loss: 0.2072866561731947\n",
      "Epoch 5890/20000 --- Loss: 0.2067923055720176\n",
      "Epoch 5900/20000 --- Loss: 0.20628968172157086\n",
      "Epoch 5910/20000 --- Loss: 0.20586989595752875\n",
      "Epoch 5920/20000 --- Loss: 0.20539539092315862\n",
      "Epoch 5930/20000 --- Loss: 0.20533953935104143\n",
      "Epoch 5940/20000 --- Loss: 0.20505684967374285\n",
      "Epoch 5950/20000 --- Loss: 0.20457406811702966\n",
      "Epoch 5960/20000 --- Loss: 0.2041891955044706\n",
      "Epoch 5970/20000 --- Loss: 0.20404520517048919\n",
      "Epoch 5980/20000 --- Loss: 0.2037009581575417\n",
      "Epoch 5990/20000 --- Loss: 0.20319393589997023\n",
      "Epoch 6000/20000 --- Loss: 0.20300773324286078\n",
      "Epoch 6010/20000 --- Loss: 0.20288206011106916\n",
      "Epoch 6020/20000 --- Loss: 0.20261388256548132\n",
      "Epoch 6030/20000 --- Loss: 0.2021923929699348\n",
      "Epoch 6040/20000 --- Loss: 0.20176232419471432\n",
      "Epoch 6050/20000 --- Loss: 0.20144107297999236\n",
      "Epoch 6060/20000 --- Loss: 0.2011134513830902\n",
      "Epoch 6070/20000 --- Loss: 0.20071201264408342\n",
      "Epoch 6080/20000 --- Loss: 0.20035809066557678\n",
      "Epoch 6090/20000 --- Loss: 0.1998659049891277\n",
      "Epoch 6100/20000 --- Loss: 0.1996838778818021\n",
      "Epoch 6110/20000 --- Loss: 0.19925598294238372\n",
      "Epoch 6120/20000 --- Loss: 0.1989391386782538\n",
      "Epoch 6130/20000 --- Loss: 0.19869844893318991\n",
      "Epoch 6140/20000 --- Loss: 0.19859127760755185\n",
      "Epoch 6150/20000 --- Loss: 0.1981129926439261\n",
      "Epoch 6160/20000 --- Loss: 0.1978244612829437\n",
      "Epoch 6170/20000 --- Loss: 0.19771903303817215\n",
      "Epoch 6180/20000 --- Loss: 0.19738625920565012\n",
      "Epoch 6190/20000 --- Loss: 0.19710307160695842\n",
      "Epoch 6200/20000 --- Loss: 0.1966529947720107\n",
      "Epoch 6210/20000 --- Loss: 0.1966212185850811\n",
      "Epoch 6220/20000 --- Loss: 0.19618700641049547\n",
      "Epoch 6230/20000 --- Loss: 0.19568518718992542\n",
      "Epoch 6240/20000 --- Loss: 0.19539810360145485\n",
      "Epoch 6250/20000 --- Loss: 0.19513128112336411\n",
      "Epoch 6260/20000 --- Loss: 0.1948610709129211\n",
      "Epoch 6270/20000 --- Loss: 0.1947539695255704\n",
      "Epoch 6280/20000 --- Loss: 0.19440632607587188\n",
      "Epoch 6290/20000 --- Loss: 0.194028401330081\n",
      "Epoch 6300/20000 --- Loss: 0.19375818931080646\n",
      "Epoch 6310/20000 --- Loss: 0.193479135071092\n",
      "Epoch 6320/20000 --- Loss: 0.19314341803089954\n",
      "Epoch 6330/20000 --- Loss: 0.1928308970071904\n",
      "Epoch 6340/20000 --- Loss: 0.19246770150219802\n",
      "Epoch 6350/20000 --- Loss: 0.19214814003707614\n",
      "Epoch 6360/20000 --- Loss: 0.1919052595337681\n",
      "Epoch 6370/20000 --- Loss: 0.19165379353905662\n",
      "Epoch 6380/20000 --- Loss: 0.19141707160074456\n",
      "Epoch 6390/20000 --- Loss: 0.19106492050794271\n",
      "Epoch 6400/20000 --- Loss: 0.19084749796725223\n",
      "Epoch 6410/20000 --- Loss: 0.19063811522913862\n",
      "Epoch 6420/20000 --- Loss: 0.1904037142079844\n",
      "Epoch 6430/20000 --- Loss: 0.19026736458477553\n",
      "Epoch 6440/20000 --- Loss: 0.18991917294917332\n",
      "Epoch 6450/20000 --- Loss: 0.1895798445326664\n",
      "Epoch 6460/20000 --- Loss: 0.18929690598723903\n",
      "Epoch 6470/20000 --- Loss: 0.18908362793715053\n",
      "Epoch 6480/20000 --- Loss: 0.18902659484579817\n",
      "Epoch 6490/20000 --- Loss: 0.1886925872235722\n",
      "Epoch 6500/20000 --- Loss: 0.18858232580212245\n",
      "Epoch 6510/20000 --- Loss: 0.18820215530569526\n",
      "Epoch 6520/20000 --- Loss: 0.1878817011740916\n",
      "Epoch 6530/20000 --- Loss: 0.18765531944363448\n",
      "Epoch 6540/20000 --- Loss: 0.18731396651248403\n",
      "Epoch 6550/20000 --- Loss: 0.18715132136174603\n",
      "Epoch 6560/20000 --- Loss: 0.1868413077474231\n",
      "Epoch 6570/20000 --- Loss: 0.18648906730371018\n",
      "Epoch 6580/20000 --- Loss: 0.18624742473472244\n",
      "Epoch 6590/20000 --- Loss: 0.1859478703239262\n",
      "Epoch 6600/20000 --- Loss: 0.18565885399521126\n",
      "Epoch 6610/20000 --- Loss: 0.18560814772177797\n",
      "Epoch 6620/20000 --- Loss: 0.18526212283698007\n",
      "Epoch 6630/20000 --- Loss: 0.18500890910470102\n",
      "Epoch 6640/20000 --- Loss: 0.18467827849631907\n",
      "Epoch 6650/20000 --- Loss: 0.18464893665606655\n",
      "Epoch 6660/20000 --- Loss: 0.18427671072341278\n",
      "Epoch 6670/20000 --- Loss: 0.184193430162717\n",
      "Epoch 6680/20000 --- Loss: 0.1837871540006778\n",
      "Epoch 6690/20000 --- Loss: 0.18343452302212013\n",
      "Epoch 6700/20000 --- Loss: 0.1831482424975289\n",
      "Epoch 6710/20000 --- Loss: 0.1829513156541882\n",
      "Epoch 6720/20000 --- Loss: 0.18263318739683762\n",
      "Epoch 6730/20000 --- Loss: 0.18238514222563634\n",
      "Epoch 6740/20000 --- Loss: 0.1821589997386328\n",
      "Epoch 6750/20000 --- Loss: 0.18192518243254802\n",
      "Epoch 6760/20000 --- Loss: 0.18176286621416393\n",
      "Epoch 6770/20000 --- Loss: 0.181427269771913\n",
      "Epoch 6780/20000 --- Loss: 0.18118267486805728\n",
      "Epoch 6790/20000 --- Loss: 0.18103990401949527\n",
      "Epoch 6800/20000 --- Loss: 0.18073462405433485\n",
      "Epoch 6810/20000 --- Loss: 0.1806375071598084\n",
      "Epoch 6820/20000 --- Loss: 0.18032854711637364\n",
      "Epoch 6830/20000 --- Loss: 0.1802025425808503\n",
      "Epoch 6840/20000 --- Loss: 0.1799227327516102\n",
      "Epoch 6850/20000 --- Loss: 0.1796224992436263\n",
      "Epoch 6860/20000 --- Loss: 0.1793314379007251\n",
      "Epoch 6870/20000 --- Loss: 0.17916570236219026\n",
      "Epoch 6880/20000 --- Loss: 0.17900322089805468\n",
      "Epoch 6890/20000 --- Loss: 0.17885667336082078\n",
      "Epoch 6900/20000 --- Loss: 0.17859051807354784\n",
      "Epoch 6910/20000 --- Loss: 0.17825642929270927\n",
      "Epoch 6920/20000 --- Loss: 0.1778697371832682\n",
      "Epoch 6930/20000 --- Loss: 0.17758570512375554\n",
      "Epoch 6940/20000 --- Loss: 0.17750839025788007\n",
      "Epoch 6950/20000 --- Loss: 0.17716988075888\n",
      "Epoch 6960/20000 --- Loss: 0.1769293936423707\n",
      "Epoch 6970/20000 --- Loss: 0.1767330984905077\n",
      "Epoch 6980/20000 --- Loss: 0.1768357666685979\n",
      "Epoch 6990/20000 --- Loss: 0.17639980974179473\n",
      "Epoch 7000/20000 --- Loss: 0.1760813677828774\n",
      "Epoch 7010/20000 --- Loss: 0.17577219210694248\n",
      "Epoch 7020/20000 --- Loss: 0.17579475191384364\n",
      "Epoch 7030/20000 --- Loss: 0.17557763473213553\n",
      "Epoch 7040/20000 --- Loss: 0.175254500870477\n",
      "Epoch 7050/20000 --- Loss: 0.1749507798407023\n",
      "Epoch 7060/20000 --- Loss: 0.1747143361474226\n",
      "Epoch 7070/20000 --- Loss: 0.174605997966344\n",
      "Epoch 7080/20000 --- Loss: 0.17432853877752222\n",
      "Epoch 7090/20000 --- Loss: 0.1741222445330373\n",
      "Epoch 7100/20000 --- Loss: 0.17387519165699036\n",
      "Epoch 7110/20000 --- Loss: 0.17367337798402113\n",
      "Epoch 7120/20000 --- Loss: 0.17358155919713839\n",
      "Epoch 7130/20000 --- Loss: 0.17330645626966124\n",
      "Epoch 7140/20000 --- Loss: 0.17304056629423756\n",
      "Epoch 7150/20000 --- Loss: 0.17273080451021758\n",
      "Epoch 7160/20000 --- Loss: 0.17252961633104683\n",
      "Epoch 7170/20000 --- Loss: 0.172361593487325\n",
      "Epoch 7180/20000 --- Loss: 0.17243952185370742\n",
      "Epoch 7190/20000 --- Loss: 0.17209644102856275\n",
      "Epoch 7200/20000 --- Loss: 0.17183988979581505\n",
      "Epoch 7210/20000 --- Loss: 0.17157972053716847\n",
      "Epoch 7220/20000 --- Loss: 0.17130878109655778\n",
      "Epoch 7230/20000 --- Loss: 0.1711190040425773\n",
      "Epoch 7240/20000 --- Loss: 0.1708232597644142\n",
      "Epoch 7250/20000 --- Loss: 0.17075963794749227\n",
      "Epoch 7260/20000 --- Loss: 0.17064178826772472\n",
      "Epoch 7270/20000 --- Loss: 0.17031828840604935\n",
      "Epoch 7280/20000 --- Loss: 0.17005716665882853\n",
      "Epoch 7290/20000 --- Loss: 0.16984314310245385\n",
      "Epoch 7300/20000 --- Loss: 0.1695805616991515\n",
      "Epoch 7310/20000 --- Loss: 0.1692605207592139\n",
      "Epoch 7320/20000 --- Loss: 0.16932418420502243\n",
      "Epoch 7330/20000 --- Loss: 0.1692230099390671\n",
      "Epoch 7340/20000 --- Loss: 0.16910613594983398\n",
      "Epoch 7350/20000 --- Loss: 0.16872725700619334\n",
      "Epoch 7360/20000 --- Loss: 0.1685061775948168\n",
      "Epoch 7370/20000 --- Loss: 0.16821797795003135\n",
      "Epoch 7380/20000 --- Loss: 0.16803161975454778\n",
      "Epoch 7390/20000 --- Loss: 0.1677697049260838\n",
      "Epoch 7400/20000 --- Loss: 0.1675883726549674\n",
      "Epoch 7410/20000 --- Loss: 0.1674790526068008\n",
      "Epoch 7420/20000 --- Loss: 0.16735726519226915\n",
      "Epoch 7430/20000 --- Loss: 0.16709553855067022\n",
      "Epoch 7440/20000 --- Loss: 0.16686874675454014\n",
      "Epoch 7450/20000 --- Loss: 0.1666403760900821\n",
      "Epoch 7460/20000 --- Loss: 0.16639956677124618\n",
      "Epoch 7470/20000 --- Loss: 0.16613267977446108\n",
      "Epoch 7480/20000 --- Loss: 0.16590344546363353\n",
      "Epoch 7490/20000 --- Loss: 0.1656959457110424\n",
      "Epoch 7500/20000 --- Loss: 0.1655343598246877\n",
      "Epoch 7510/20000 --- Loss: 0.16551993975779564\n",
      "Epoch 7520/20000 --- Loss: 0.1654040082390744\n",
      "Epoch 7530/20000 --- Loss: 0.16512612500707147\n",
      "Epoch 7540/20000 --- Loss: 0.16489527609117735\n",
      "Epoch 7550/20000 --- Loss: 0.16466291094712757\n",
      "Epoch 7560/20000 --- Loss: 0.16459773162982363\n",
      "Epoch 7570/20000 --- Loss: 0.16430611666389297\n",
      "Epoch 7580/20000 --- Loss: 0.16409458419353035\n",
      "Epoch 7590/20000 --- Loss: 0.16375533275225165\n",
      "Epoch 7600/20000 --- Loss: 0.1636050050621937\n",
      "Epoch 7610/20000 --- Loss: 0.16338928581471576\n",
      "Epoch 7620/20000 --- Loss: 0.16333480990825994\n",
      "Epoch 7630/20000 --- Loss: 0.16314306008847476\n",
      "Epoch 7640/20000 --- Loss: 0.1628105371000794\n",
      "Epoch 7650/20000 --- Loss: 0.1625456049262097\n",
      "Epoch 7660/20000 --- Loss: 0.1625413673921623\n",
      "Epoch 7670/20000 --- Loss: 0.1624322937926264\n",
      "Epoch 7680/20000 --- Loss: 0.16219609897020995\n",
      "Epoch 7690/20000 --- Loss: 0.1618859768275799\n",
      "Epoch 7700/20000 --- Loss: 0.16170588236421776\n",
      "Epoch 7710/20000 --- Loss: 0.16148126472769825\n",
      "Epoch 7720/20000 --- Loss: 0.16119376189548215\n",
      "Epoch 7730/20000 --- Loss: 0.16106063671406326\n",
      "Epoch 7740/20000 --- Loss: 0.1610057584070286\n",
      "Epoch 7750/20000 --- Loss: 0.16076087128777314\n",
      "Epoch 7760/20000 --- Loss: 0.1609733479679921\n",
      "Epoch 7770/20000 --- Loss: 0.1607057395336346\n",
      "Epoch 7780/20000 --- Loss: 0.16044001783937029\n",
      "Epoch 7790/20000 --- Loss: 0.16037339293196431\n",
      "Epoch 7800/20000 --- Loss: 0.16032339684388272\n",
      "Epoch 7810/20000 --- Loss: 0.16006583246316386\n",
      "Epoch 7820/20000 --- Loss: 0.15979905525974838\n",
      "Epoch 7830/20000 --- Loss: 0.1594624405957052\n",
      "Epoch 7840/20000 --- Loss: 0.1592234256100933\n",
      "Epoch 7850/20000 --- Loss: 0.1589908948115727\n",
      "Epoch 7860/20000 --- Loss: 0.15884736708661867\n",
      "Epoch 7870/20000 --- Loss: 0.1586171171463762\n",
      "Epoch 7880/20000 --- Loss: 0.1584608670958465\n",
      "Epoch 7890/20000 --- Loss: 0.15823412528726993\n",
      "Epoch 7900/20000 --- Loss: 0.15826453867097356\n",
      "Epoch 7910/20000 --- Loss: 0.15801777271024206\n",
      "Epoch 7920/20000 --- Loss: 0.15800254643660547\n",
      "Epoch 7930/20000 --- Loss: 0.15794666864482879\n",
      "Epoch 7940/20000 --- Loss: 0.1575069716606141\n",
      "Epoch 7950/20000 --- Loss: 0.15727215862972882\n",
      "Epoch 7960/20000 --- Loss: 0.15701019935001903\n",
      "Epoch 7970/20000 --- Loss: 0.15698994149190693\n",
      "Epoch 7980/20000 --- Loss: 0.1568046760630975\n",
      "Epoch 7990/20000 --- Loss: 0.15667629204164044\n",
      "Epoch 8000/20000 --- Loss: 0.15645981951687005\n",
      "Epoch 8010/20000 --- Loss: 0.15623968285068274\n",
      "Epoch 8020/20000 --- Loss: 0.15612073379280986\n",
      "Epoch 8030/20000 --- Loss: 0.15591636756025867\n",
      "Epoch 8040/20000 --- Loss: 0.15580750515842418\n",
      "Epoch 8050/20000 --- Loss: 0.1556452486243384\n",
      "Epoch 8060/20000 --- Loss: 0.15553695891247923\n",
      "Epoch 8070/20000 --- Loss: 0.15532038722011252\n",
      "Epoch 8080/20000 --- Loss: 0.15509915347852027\n",
      "Epoch 8090/20000 --- Loss: 0.15490442011465144\n",
      "Epoch 8100/20000 --- Loss: 0.15482776962513756\n",
      "Epoch 8110/20000 --- Loss: 0.15460188916014156\n",
      "Epoch 8120/20000 --- Loss: 0.15445147689033298\n",
      "Epoch 8130/20000 --- Loss: 0.15424483279817663\n",
      "Epoch 8140/20000 --- Loss: 0.15405909245489935\n",
      "Epoch 8150/20000 --- Loss: 0.15389626100968246\n",
      "Epoch 8160/20000 --- Loss: 0.15375727333361153\n",
      "Epoch 8170/20000 --- Loss: 0.15350270064874902\n",
      "Epoch 8180/20000 --- Loss: 0.15334068771585338\n",
      "Epoch 8190/20000 --- Loss: 0.15329083314006922\n",
      "Epoch 8200/20000 --- Loss: 0.15309240005600236\n",
      "Epoch 8210/20000 --- Loss: 0.15292192726546047\n",
      "Epoch 8220/20000 --- Loss: 0.15278236027091158\n",
      "Epoch 8230/20000 --- Loss: 0.1526037421872476\n",
      "Epoch 8240/20000 --- Loss: 0.15243562014243298\n",
      "Epoch 8250/20000 --- Loss: 0.1522558906853106\n",
      "Epoch 8260/20000 --- Loss: 0.15204710509189825\n",
      "Epoch 8270/20000 --- Loss: 0.1518974782116739\n",
      "Epoch 8280/20000 --- Loss: 0.15187811489934142\n",
      "Epoch 8290/20000 --- Loss: 0.15162320581586536\n",
      "Epoch 8300/20000 --- Loss: 0.15145534748501296\n",
      "Epoch 8310/20000 --- Loss: 0.15131705515056068\n",
      "Epoch 8320/20000 --- Loss: 0.1511537201225636\n",
      "Epoch 8330/20000 --- Loss: 0.15101542572831173\n",
      "Epoch 8340/20000 --- Loss: 0.15089104739695752\n",
      "Epoch 8350/20000 --- Loss: 0.1507380086693128\n",
      "Epoch 8360/20000 --- Loss: 0.15058077997424038\n",
      "Epoch 8370/20000 --- Loss: 0.15041740147741198\n",
      "Epoch 8380/20000 --- Loss: 0.15021674149199218\n",
      "Epoch 8390/20000 --- Loss: 0.15010942004790812\n",
      "Epoch 8400/20000 --- Loss: 0.1499447864150426\n",
      "Epoch 8410/20000 --- Loss: 0.14981637358320532\n",
      "Epoch 8420/20000 --- Loss: 0.1496182660366495\n",
      "Epoch 8430/20000 --- Loss: 0.1495173450746395\n",
      "Epoch 8440/20000 --- Loss: 0.14945419301764368\n",
      "Epoch 8450/20000 --- Loss: 0.14928818642730637\n",
      "Epoch 8460/20000 --- Loss: 0.1493088641579894\n",
      "Epoch 8470/20000 --- Loss: 0.14898524255706413\n",
      "Epoch 8480/20000 --- Loss: 0.14892213997191686\n",
      "Epoch 8490/20000 --- Loss: 0.14870030691409594\n",
      "Epoch 8500/20000 --- Loss: 0.14857039913638884\n",
      "Epoch 8510/20000 --- Loss: 0.1483649365690513\n",
      "Epoch 8520/20000 --- Loss: 0.14822245160537012\n",
      "Epoch 8530/20000 --- Loss: 0.14817918094080992\n",
      "Epoch 8540/20000 --- Loss: 0.14804129435765515\n",
      "Epoch 8550/20000 --- Loss: 0.14781667591433242\n",
      "Epoch 8560/20000 --- Loss: 0.14763406078384717\n",
      "Epoch 8570/20000 --- Loss: 0.14745357132630982\n",
      "Epoch 8580/20000 --- Loss: 0.14728448838939798\n",
      "Epoch 8590/20000 --- Loss: 0.147114022074617\n",
      "Epoch 8600/20000 --- Loss: 0.14697275498113213\n",
      "Epoch 8610/20000 --- Loss: 0.14683732396077284\n",
      "Epoch 8620/20000 --- Loss: 0.14671552830536666\n",
      "Epoch 8630/20000 --- Loss: 0.14659893642536923\n",
      "Epoch 8640/20000 --- Loss: 0.14659737247484328\n",
      "Epoch 8650/20000 --- Loss: 0.1463950114037549\n",
      "Epoch 8660/20000 --- Loss: 0.14625598741149362\n",
      "Epoch 8670/20000 --- Loss: 0.14617483642093212\n",
      "Epoch 8680/20000 --- Loss: 0.1460117266415158\n",
      "Epoch 8690/20000 --- Loss: 0.14603308506406434\n",
      "Epoch 8700/20000 --- Loss: 0.14580921856666068\n",
      "Epoch 8710/20000 --- Loss: 0.1456936688050414\n",
      "Epoch 8720/20000 --- Loss: 0.14564954419535933\n",
      "Epoch 8730/20000 --- Loss: 0.14542013129153247\n",
      "Epoch 8740/20000 --- Loss: 0.14524312040211634\n",
      "Epoch 8750/20000 --- Loss: 0.14506365355424122\n",
      "Epoch 8760/20000 --- Loss: 0.14498492345344857\n",
      "Epoch 8770/20000 --- Loss: 0.14479105425522598\n",
      "Epoch 8780/20000 --- Loss: 0.14471854000549011\n",
      "Epoch 8790/20000 --- Loss: 0.1444975552721321\n",
      "Epoch 8800/20000 --- Loss: 0.14435735677863004\n",
      "Epoch 8810/20000 --- Loss: 0.1442380883422399\n",
      "Epoch 8820/20000 --- Loss: 0.1440486862587405\n",
      "Epoch 8830/20000 --- Loss: 0.14398567760267061\n",
      "Epoch 8840/20000 --- Loss: 0.14381740503029797\n",
      "Epoch 8850/20000 --- Loss: 0.1436452973420044\n",
      "Epoch 8860/20000 --- Loss: 0.1435020172586361\n",
      "Epoch 8870/20000 --- Loss: 0.1433050336676647\n",
      "Epoch 8880/20000 --- Loss: 0.14356830952107086\n",
      "Epoch 8890/20000 --- Loss: 0.14339300873758037\n",
      "Epoch 8900/20000 --- Loss: 0.14328246486292107\n",
      "Epoch 8910/20000 --- Loss: 0.14299674583683325\n",
      "Epoch 8920/20000 --- Loss: 0.14286234601541353\n",
      "Epoch 8930/20000 --- Loss: 0.14278923729116136\n",
      "Epoch 8940/20000 --- Loss: 0.1426902838406049\n",
      "Epoch 8950/20000 --- Loss: 0.142515931847313\n",
      "Epoch 8960/20000 --- Loss: 0.14231794137927767\n",
      "Epoch 8970/20000 --- Loss: 0.14218273873841464\n",
      "Epoch 8980/20000 --- Loss: 0.14196015167881684\n",
      "Epoch 8990/20000 --- Loss: 0.14181139335488907\n",
      "Epoch 9000/20000 --- Loss: 0.14169326834685284\n",
      "Epoch 9010/20000 --- Loss: 0.1415130319092628\n",
      "Epoch 9020/20000 --- Loss: 0.14137689826261834\n",
      "Epoch 9030/20000 --- Loss: 0.14126354741139266\n",
      "Epoch 9040/20000 --- Loss: 0.14109501766377122\n",
      "Epoch 9050/20000 --- Loss: 0.14096785366156356\n",
      "Epoch 9060/20000 --- Loss: 0.140815482390795\n",
      "Epoch 9070/20000 --- Loss: 0.14068837498167494\n",
      "Epoch 9080/20000 --- Loss: 0.1405736307805173\n",
      "Epoch 9090/20000 --- Loss: 0.14044654363802214\n",
      "Epoch 9100/20000 --- Loss: 0.14028796162827328\n",
      "Epoch 9110/20000 --- Loss: 0.14038863000981827\n",
      "Epoch 9120/20000 --- Loss: 0.14021194270353435\n",
      "Epoch 9130/20000 --- Loss: 0.14004461828751982\n",
      "Epoch 9140/20000 --- Loss: 0.1399060290294198\n",
      "Epoch 9150/20000 --- Loss: 0.1397771217438151\n",
      "Epoch 9160/20000 --- Loss: 0.13964134980438167\n",
      "Epoch 9170/20000 --- Loss: 0.1394970096887232\n",
      "Epoch 9180/20000 --- Loss: 0.13938314743961944\n",
      "Epoch 9190/20000 --- Loss: 0.1392223034586585\n",
      "Epoch 9200/20000 --- Loss: 0.13910981309033918\n",
      "Epoch 9210/20000 --- Loss: 0.1389890017687589\n",
      "Epoch 9220/20000 --- Loss: 0.1388681316422239\n",
      "Epoch 9230/20000 --- Loss: 0.13868668691279434\n",
      "Epoch 9240/20000 --- Loss: 0.13859437206979025\n",
      "Epoch 9250/20000 --- Loss: 0.13854406782523201\n",
      "Epoch 9260/20000 --- Loss: 0.13840774884736828\n",
      "Epoch 9270/20000 --- Loss: 0.13836967762560423\n",
      "Epoch 9280/20000 --- Loss: 0.13821078754888239\n",
      "Epoch 9290/20000 --- Loss: 0.13806718503240623\n",
      "Epoch 9300/20000 --- Loss: 0.13793162386817379\n",
      "Epoch 9310/20000 --- Loss: 0.13787593117891941\n",
      "Epoch 9320/20000 --- Loss: 0.13770564868148344\n",
      "Epoch 9330/20000 --- Loss: 0.13755120393593603\n",
      "Epoch 9340/20000 --- Loss: 0.1373983213286859\n",
      "Epoch 9350/20000 --- Loss: 0.137264922584422\n",
      "Epoch 9360/20000 --- Loss: 0.13715519292238698\n",
      "Epoch 9370/20000 --- Loss: 0.1371428766446653\n",
      "Epoch 9380/20000 --- Loss: 0.1369577924215031\n",
      "Epoch 9390/20000 --- Loss: 0.13682542065960435\n",
      "Epoch 9400/20000 --- Loss: 0.13668384023447885\n",
      "Epoch 9410/20000 --- Loss: 0.1365180159505374\n",
      "Epoch 9420/20000 --- Loss: 0.13641352564081372\n",
      "Epoch 9430/20000 --- Loss: 0.13629423636980328\n",
      "Epoch 9440/20000 --- Loss: 0.13619034428072319\n",
      "Epoch 9450/20000 --- Loss: 0.13608285647759508\n",
      "Epoch 9460/20000 --- Loss: 0.13595600522813944\n",
      "Epoch 9470/20000 --- Loss: 0.13582818493808985\n",
      "Epoch 9480/20000 --- Loss: 0.13579952385682004\n",
      "Epoch 9490/20000 --- Loss: 0.13566127413657506\n",
      "Epoch 9500/20000 --- Loss: 0.1354730493136722\n",
      "Epoch 9510/20000 --- Loss: 0.13537496014218336\n",
      "Epoch 9520/20000 --- Loss: 0.13534583179620457\n",
      "Epoch 9530/20000 --- Loss: 0.13521169568396793\n",
      "Epoch 9540/20000 --- Loss: 0.1350382995290748\n",
      "Epoch 9550/20000 --- Loss: 0.1349230309879217\n",
      "Epoch 9560/20000 --- Loss: 0.1348385219151582\n",
      "Epoch 9570/20000 --- Loss: 0.13471888559016693\n",
      "Epoch 9580/20000 --- Loss: 0.13459063798953452\n",
      "Epoch 9590/20000 --- Loss: 0.1347022393420127\n",
      "Epoch 9600/20000 --- Loss: 0.13452774378895138\n",
      "Epoch 9610/20000 --- Loss: 0.13437716886243034\n",
      "Epoch 9620/20000 --- Loss: 0.13425213943119305\n",
      "Epoch 9630/20000 --- Loss: 0.13412187773560175\n",
      "Epoch 9640/20000 --- Loss: 0.13406905181863552\n",
      "Epoch 9650/20000 --- Loss: 0.13403397396961014\n",
      "Epoch 9660/20000 --- Loss: 0.13385421685776364\n",
      "Epoch 9670/20000 --- Loss: 0.13373070486021724\n",
      "Epoch 9680/20000 --- Loss: 0.1335865782222825\n",
      "Epoch 9690/20000 --- Loss: 0.13348173361838683\n",
      "Epoch 9700/20000 --- Loss: 0.13330613714460227\n",
      "Epoch 9710/20000 --- Loss: 0.13327334451676495\n",
      "Epoch 9720/20000 --- Loss: 0.133122511544804\n",
      "Epoch 9730/20000 --- Loss: 0.13300761948323045\n",
      "Epoch 9740/20000 --- Loss: 0.13286923898846062\n",
      "Epoch 9750/20000 --- Loss: 0.13281377322307258\n",
      "Epoch 9760/20000 --- Loss: 0.13269439030095517\n",
      "Epoch 9770/20000 --- Loss: 0.13255440764057883\n",
      "Epoch 9780/20000 --- Loss: 0.13260188198508893\n",
      "Epoch 9790/20000 --- Loss: 0.13246096615139644\n",
      "Epoch 9800/20000 --- Loss: 0.1323404297544358\n",
      "Epoch 9810/20000 --- Loss: 0.13219253240947426\n",
      "Epoch 9820/20000 --- Loss: 0.13208593901230026\n",
      "Epoch 9830/20000 --- Loss: 0.1319488083346884\n",
      "Epoch 9840/20000 --- Loss: 0.13191102130935198\n",
      "Epoch 9850/20000 --- Loss: 0.1317693968303232\n",
      "Epoch 9860/20000 --- Loss: 0.13179716688814383\n",
      "Epoch 9870/20000 --- Loss: 0.13163167736148207\n",
      "Epoch 9880/20000 --- Loss: 0.13147267560448714\n",
      "Epoch 9890/20000 --- Loss: 0.1313786969420972\n",
      "Epoch 9900/20000 --- Loss: 0.1312363960144018\n",
      "Epoch 9910/20000 --- Loss: 0.1311040881035074\n",
      "Epoch 9920/20000 --- Loss: 0.13103135237716873\n",
      "Epoch 9930/20000 --- Loss: 0.13094299092837206\n",
      "Epoch 9940/20000 --- Loss: 0.13083699078397842\n",
      "Epoch 9950/20000 --- Loss: 0.1306885693366626\n",
      "Epoch 9960/20000 --- Loss: 0.1306625655294934\n",
      "Epoch 9970/20000 --- Loss: 0.13053488455306805\n",
      "Epoch 9980/20000 --- Loss: 0.13042096496943276\n",
      "Epoch 9990/20000 --- Loss: 0.13037310053454296\n",
      "Epoch 10000/20000 --- Loss: 0.1301999222429742\n",
      "Epoch 10010/20000 --- Loss: 0.1302830350096884\n",
      "Epoch 10020/20000 --- Loss: 0.13011000527423083\n",
      "Epoch 10030/20000 --- Loss: 0.13004113794554295\n",
      "Epoch 10040/20000 --- Loss: 0.1299003781305947\n",
      "Epoch 10050/20000 --- Loss: 0.12988649929793505\n",
      "Epoch 10060/20000 --- Loss: 0.12972399323038977\n",
      "Epoch 10070/20000 --- Loss: 0.12957509633027395\n",
      "Epoch 10080/20000 --- Loss: 0.12943986521598017\n",
      "Epoch 10090/20000 --- Loss: 0.12932111140631578\n",
      "Epoch 10100/20000 --- Loss: 0.12923145222066798\n",
      "Epoch 10110/20000 --- Loss: 0.12906323768857234\n",
      "Epoch 10120/20000 --- Loss: 0.1289679527220783\n",
      "Epoch 10130/20000 --- Loss: 0.12891726975173512\n",
      "Epoch 10140/20000 --- Loss: 0.12880568143492874\n",
      "Epoch 10150/20000 --- Loss: 0.12870856236886768\n",
      "Epoch 10160/20000 --- Loss: 0.12857194074493716\n",
      "Epoch 10170/20000 --- Loss: 0.12850871986771115\n",
      "Epoch 10180/20000 --- Loss: 0.12838837904862774\n",
      "Epoch 10190/20000 --- Loss: 0.12838403265286666\n",
      "Epoch 10200/20000 --- Loss: 0.12825281062590024\n",
      "Epoch 10210/20000 --- Loss: 0.1281714649850301\n",
      "Epoch 10220/20000 --- Loss: 0.12805481242209704\n",
      "Epoch 10230/20000 --- Loss: 0.12790955438456095\n",
      "Epoch 10240/20000 --- Loss: 0.12780380266998742\n",
      "Epoch 10250/20000 --- Loss: 0.12769911780424742\n",
      "Epoch 10260/20000 --- Loss: 0.12768271034390835\n",
      "Epoch 10270/20000 --- Loss: 0.12754875341596383\n",
      "Epoch 10280/20000 --- Loss: 0.12746539335994045\n",
      "Epoch 10290/20000 --- Loss: 0.1274268834979549\n",
      "Epoch 10300/20000 --- Loss: 0.1273484039104988\n",
      "Epoch 10310/20000 --- Loss: 0.12722283647295102\n",
      "Epoch 10320/20000 --- Loss: 0.1270620556253485\n",
      "Epoch 10330/20000 --- Loss: 0.12697242674786313\n",
      "Epoch 10340/20000 --- Loss: 0.12687199230122154\n",
      "Epoch 10350/20000 --- Loss: 0.12678180642177572\n",
      "Epoch 10360/20000 --- Loss: 0.1266756848931942\n",
      "Epoch 10370/20000 --- Loss: 0.12655811417297955\n",
      "Epoch 10380/20000 --- Loss: 0.12648449007766938\n",
      "Epoch 10390/20000 --- Loss: 0.12635406464259222\n",
      "Epoch 10400/20000 --- Loss: 0.1262319363819787\n",
      "Epoch 10410/20000 --- Loss: 0.12612568833109544\n",
      "Epoch 10420/20000 --- Loss: 0.12601765822825503\n",
      "Epoch 10430/20000 --- Loss: 0.1259286879573032\n",
      "Epoch 10440/20000 --- Loss: 0.12597813428611623\n",
      "Epoch 10450/20000 --- Loss: 0.12583034973669913\n",
      "Epoch 10460/20000 --- Loss: 0.12572617499952501\n",
      "Epoch 10470/20000 --- Loss: 0.12573099377289967\n",
      "Epoch 10480/20000 --- Loss: 0.12558855089220747\n",
      "Epoch 10490/20000 --- Loss: 0.12547704257155437\n",
      "Epoch 10500/20000 --- Loss: 0.12536923638432837\n",
      "Epoch 10510/20000 --- Loss: 0.12527683530565012\n",
      "Epoch 10520/20000 --- Loss: 0.12524994836137415\n",
      "Epoch 10530/20000 --- Loss: 0.12513694484226126\n",
      "Epoch 10540/20000 --- Loss: 0.12509004619568823\n",
      "Epoch 10550/20000 --- Loss: 0.12493931803738517\n",
      "Epoch 10560/20000 --- Loss: 0.12484935669552152\n",
      "Epoch 10570/20000 --- Loss: 0.12470818617315962\n",
      "Epoch 10580/20000 --- Loss: 0.1246390727250835\n",
      "Epoch 10590/20000 --- Loss: 0.12454221712488636\n",
      "Epoch 10600/20000 --- Loss: 0.1244222109721372\n",
      "Epoch 10610/20000 --- Loss: 0.1243529854974545\n",
      "Epoch 10620/20000 --- Loss: 0.12427170072750224\n",
      "Epoch 10630/20000 --- Loss: 0.12415834261246225\n",
      "Epoch 10640/20000 --- Loss: 0.12408086490801598\n",
      "Epoch 10650/20000 --- Loss: 0.12406646022939354\n",
      "Epoch 10660/20000 --- Loss: 0.12407735142338308\n",
      "Epoch 10670/20000 --- Loss: 0.12394188611330713\n",
      "Epoch 10680/20000 --- Loss: 0.12383129733395984\n",
      "Epoch 10690/20000 --- Loss: 0.12373086052775885\n",
      "Epoch 10700/20000 --- Loss: 0.12365418857279663\n",
      "Epoch 10710/20000 --- Loss: 0.12353702464784866\n",
      "Epoch 10720/20000 --- Loss: 0.12339334167884548\n",
      "Epoch 10730/20000 --- Loss: 0.1232892267289567\n",
      "Epoch 10740/20000 --- Loss: 0.12324982023986866\n",
      "Epoch 10750/20000 --- Loss: 0.12317053411110541\n",
      "Epoch 10760/20000 --- Loss: 0.12306685911102444\n",
      "Epoch 10770/20000 --- Loss: 0.12304773149768641\n",
      "Epoch 10780/20000 --- Loss: 0.12293991158461096\n",
      "Epoch 10790/20000 --- Loss: 0.12285390415662292\n",
      "Epoch 10800/20000 --- Loss: 0.12274282448915455\n",
      "Epoch 10810/20000 --- Loss: 0.12263828372273941\n",
      "Epoch 10820/20000 --- Loss: 0.12262017976484858\n",
      "Epoch 10830/20000 --- Loss: 0.12257995954284849\n",
      "Epoch 10840/20000 --- Loss: 0.12247275933501636\n",
      "Epoch 10850/20000 --- Loss: 0.12234927007181906\n",
      "Epoch 10860/20000 --- Loss: 0.12224454795608912\n",
      "Epoch 10870/20000 --- Loss: 0.12218702912825531\n",
      "Epoch 10880/20000 --- Loss: 0.122095515901546\n",
      "Epoch 10890/20000 --- Loss: 0.12203153217599878\n",
      "Epoch 10900/20000 --- Loss: 0.12192164659288418\n",
      "Epoch 10910/20000 --- Loss: 0.12183008041411092\n",
      "Epoch 10920/20000 --- Loss: 0.12182000323441185\n",
      "Epoch 10930/20000 --- Loss: 0.12177517751026452\n",
      "Epoch 10940/20000 --- Loss: 0.1216637816794024\n",
      "Epoch 10950/20000 --- Loss: 0.12156123161737428\n",
      "Epoch 10960/20000 --- Loss: 0.12146869774303591\n",
      "Epoch 10970/20000 --- Loss: 0.12132681189996608\n",
      "Epoch 10980/20000 --- Loss: 0.12125629737285114\n",
      "Epoch 10990/20000 --- Loss: 0.12117514190257156\n",
      "Epoch 11000/20000 --- Loss: 0.12110004599523355\n",
      "Epoch 11010/20000 --- Loss: 0.12097906380281877\n",
      "Epoch 11020/20000 --- Loss: 0.12088451799426254\n",
      "Epoch 11030/20000 --- Loss: 0.12079577926069052\n",
      "Epoch 11040/20000 --- Loss: 0.12070982547107931\n",
      "Epoch 11050/20000 --- Loss: 0.12063329278322724\n",
      "Epoch 11060/20000 --- Loss: 0.1206111360702662\n",
      "Epoch 11070/20000 --- Loss: 0.12060916146931161\n",
      "Epoch 11080/20000 --- Loss: 0.12057510976518454\n",
      "Epoch 11090/20000 --- Loss: 0.12045153684581934\n",
      "Epoch 11100/20000 --- Loss: 0.12040772483332265\n",
      "Epoch 11110/20000 --- Loss: 0.12036091334836763\n",
      "Epoch 11120/20000 --- Loss: 0.12024958458718144\n",
      "Epoch 11130/20000 --- Loss: 0.1202002985384558\n",
      "Epoch 11140/20000 --- Loss: 0.12008886262756023\n",
      "Epoch 11150/20000 --- Loss: 0.12003255116860653\n",
      "Epoch 11160/20000 --- Loss: 0.11992107177612327\n",
      "Epoch 11170/20000 --- Loss: 0.1198324758059662\n",
      "Epoch 11180/20000 --- Loss: 0.1197425780620779\n",
      "Epoch 11190/20000 --- Loss: 0.11964244608655974\n",
      "Epoch 11200/20000 --- Loss: 0.11955303955428911\n",
      "Epoch 11210/20000 --- Loss: 0.11946265780149412\n",
      "Epoch 11220/20000 --- Loss: 0.11936610315245913\n",
      "Epoch 11230/20000 --- Loss: 0.11928266651448814\n",
      "Epoch 11240/20000 --- Loss: 0.1192026952719971\n",
      "Epoch 11250/20000 --- Loss: 0.11914170490866095\n",
      "Epoch 11260/20000 --- Loss: 0.11909970786784956\n",
      "Epoch 11270/20000 --- Loss: 0.11904710771291674\n",
      "Epoch 11280/20000 --- Loss: 0.11900743604517715\n",
      "Epoch 11290/20000 --- Loss: 0.11895794801149906\n",
      "Epoch 11300/20000 --- Loss: 0.11883470461594783\n",
      "Epoch 11310/20000 --- Loss: 0.11879041203097497\n",
      "Epoch 11320/20000 --- Loss: 0.11868936455195103\n",
      "Epoch 11330/20000 --- Loss: 0.11862488987460956\n",
      "Epoch 11340/20000 --- Loss: 0.11857545304732972\n",
      "Epoch 11350/20000 --- Loss: 0.11846262720196209\n",
      "Epoch 11360/20000 --- Loss: 0.1184394181070609\n",
      "Epoch 11370/20000 --- Loss: 0.11839068746626269\n",
      "Epoch 11380/20000 --- Loss: 0.11826974059811056\n",
      "Epoch 11390/20000 --- Loss: 0.11814622999509308\n",
      "Epoch 11400/20000 --- Loss: 0.11806661310325312\n",
      "Epoch 11410/20000 --- Loss: 0.11798647392363974\n",
      "Epoch 11420/20000 --- Loss: 0.11791002002689557\n",
      "Epoch 11430/20000 --- Loss: 0.11781050950023127\n",
      "Epoch 11440/20000 --- Loss: 0.11778900930126465\n",
      "Epoch 11450/20000 --- Loss: 0.11767396555966499\n",
      "Epoch 11460/20000 --- Loss: 0.11758657701273142\n",
      "Epoch 11470/20000 --- Loss: 0.1174610845178975\n",
      "Epoch 11480/20000 --- Loss: 0.11737669231586144\n",
      "Epoch 11490/20000 --- Loss: 0.11731012879893996\n",
      "Epoch 11500/20000 --- Loss: 0.11723574120322684\n",
      "Epoch 11510/20000 --- Loss: 0.11720097697205084\n",
      "Epoch 11520/20000 --- Loss: 0.11710451608134219\n",
      "Epoch 11530/20000 --- Loss: 0.11702529626996466\n",
      "Epoch 11540/20000 --- Loss: 0.11693110126705841\n",
      "Epoch 11550/20000 --- Loss: 0.11686368684981926\n",
      "Epoch 11560/20000 --- Loss: 0.11677492068699977\n",
      "Epoch 11570/20000 --- Loss: 0.11673872497556038\n",
      "Epoch 11580/20000 --- Loss: 0.11665028927069503\n",
      "Epoch 11590/20000 --- Loss: 0.11655234356958985\n",
      "Epoch 11600/20000 --- Loss: 0.11647909888561385\n",
      "Epoch 11610/20000 --- Loss: 0.11646856047237789\n",
      "Epoch 11620/20000 --- Loss: 0.11638369958938169\n",
      "Epoch 11630/20000 --- Loss: 0.1163222252089899\n",
      "Epoch 11640/20000 --- Loss: 0.11623826661658873\n",
      "Epoch 11650/20000 --- Loss: 0.11620701188297963\n",
      "Epoch 11660/20000 --- Loss: 0.11611905862246791\n",
      "Epoch 11670/20000 --- Loss: 0.1160307302092292\n",
      "Epoch 11680/20000 --- Loss: 0.11595972306322115\n",
      "Epoch 11690/20000 --- Loss: 0.11585804526895307\n",
      "Epoch 11700/20000 --- Loss: 0.11578449578544195\n",
      "Epoch 11710/20000 --- Loss: 0.11571215417425423\n",
      "Epoch 11720/20000 --- Loss: 0.11562143152374846\n",
      "Epoch 11730/20000 --- Loss: 0.1155582406461332\n",
      "Epoch 11740/20000 --- Loss: 0.11553866446566728\n",
      "Epoch 11750/20000 --- Loss: 0.1154466804102264\n",
      "Epoch 11760/20000 --- Loss: 0.1153694012362275\n",
      "Epoch 11770/20000 --- Loss: 0.11528733039692103\n",
      "Epoch 11780/20000 --- Loss: 0.11518981827642391\n",
      "Epoch 11790/20000 --- Loss: 0.11512366628723829\n",
      "Epoch 11800/20000 --- Loss: 0.11507666315339887\n",
      "Epoch 11810/20000 --- Loss: 0.11498336820504378\n",
      "Epoch 11820/20000 --- Loss: 0.1150106115555577\n",
      "Epoch 11830/20000 --- Loss: 0.11492791900958663\n",
      "Epoch 11840/20000 --- Loss: 0.11486380511667113\n",
      "Epoch 11850/20000 --- Loss: 0.11476407026806379\n",
      "Epoch 11860/20000 --- Loss: 0.1146933759486081\n",
      "Epoch 11870/20000 --- Loss: 0.11465505378565198\n",
      "Epoch 11880/20000 --- Loss: 0.11457210231461815\n",
      "Epoch 11890/20000 --- Loss: 0.11451564729851904\n",
      "Epoch 11900/20000 --- Loss: 0.11443870465585308\n",
      "Epoch 11910/20000 --- Loss: 0.1143559915569156\n",
      "Epoch 11920/20000 --- Loss: 0.11426739111944767\n",
      "Epoch 11930/20000 --- Loss: 0.11418357457971823\n",
      "Epoch 11940/20000 --- Loss: 0.11415073121601858\n",
      "Epoch 11950/20000 --- Loss: 0.11410713827080132\n",
      "Epoch 11960/20000 --- Loss: 0.11399632239534925\n",
      "Epoch 11970/20000 --- Loss: 0.11392882790602363\n",
      "Epoch 11980/20000 --- Loss: 0.11386513484210262\n",
      "Epoch 11990/20000 --- Loss: 0.11386022311394359\n",
      "Epoch 12000/20000 --- Loss: 0.11376568627018765\n",
      "Epoch 12010/20000 --- Loss: 0.11373668330422627\n",
      "Epoch 12020/20000 --- Loss: 0.11364038486659397\n",
      "Epoch 12030/20000 --- Loss: 0.11357520815617952\n",
      "Epoch 12040/20000 --- Loss: 0.11350491830955092\n",
      "Epoch 12050/20000 --- Loss: 0.11342017565662595\n",
      "Epoch 12060/20000 --- Loss: 0.1134618051271387\n",
      "Epoch 12070/20000 --- Loss: 0.11335329679199405\n",
      "Epoch 12080/20000 --- Loss: 0.11326928685542788\n",
      "Epoch 12090/20000 --- Loss: 0.1131936386559312\n",
      "Epoch 12100/20000 --- Loss: 0.11309877173590667\n",
      "Epoch 12110/20000 --- Loss: 0.11302271465533678\n",
      "Epoch 12120/20000 --- Loss: 0.1129534488396649\n",
      "Epoch 12130/20000 --- Loss: 0.11288734086657216\n",
      "Epoch 12140/20000 --- Loss: 0.1128129407319317\n",
      "Epoch 12150/20000 --- Loss: 0.11272247845453155\n",
      "Epoch 12160/20000 --- Loss: 0.1126729462883046\n",
      "Epoch 12170/20000 --- Loss: 0.11257545563549677\n",
      "Epoch 12180/20000 --- Loss: 0.11252045183642226\n",
      "Epoch 12190/20000 --- Loss: 0.11243815228530493\n",
      "Epoch 12200/20000 --- Loss: 0.11238372481960397\n",
      "Epoch 12210/20000 --- Loss: 0.1123725160653015\n",
      "Epoch 12220/20000 --- Loss: 0.1122779246424781\n",
      "Epoch 12230/20000 --- Loss: 0.11220560488071003\n",
      "Epoch 12240/20000 --- Loss: 0.11212838217571981\n",
      "Epoch 12250/20000 --- Loss: 0.11212895116385954\n",
      "Epoch 12260/20000 --- Loss: 0.11210422318400382\n",
      "Epoch 12270/20000 --- Loss: 0.11201152919684765\n",
      "Epoch 12280/20000 --- Loss: 0.1119158507518198\n",
      "Epoch 12290/20000 --- Loss: 0.11190879036600038\n",
      "Epoch 12300/20000 --- Loss: 0.11183569301146173\n",
      "Epoch 12310/20000 --- Loss: 0.11175910629097184\n",
      "Epoch 12320/20000 --- Loss: 0.11167949731796084\n",
      "Epoch 12330/20000 --- Loss: 0.1116254359272638\n",
      "Epoch 12340/20000 --- Loss: 0.11153593072899358\n",
      "Epoch 12350/20000 --- Loss: 0.11147998802614478\n",
      "Epoch 12360/20000 --- Loss: 0.11140466586189175\n",
      "Epoch 12370/20000 --- Loss: 0.11133290431740824\n",
      "Epoch 12380/20000 --- Loss: 0.11126944624464213\n",
      "Epoch 12390/20000 --- Loss: 0.11125357733283701\n",
      "Epoch 12400/20000 --- Loss: 0.11121421026701883\n",
      "Epoch 12410/20000 --- Loss: 0.11114423913973215\n",
      "Epoch 12420/20000 --- Loss: 0.11108331911819753\n",
      "Epoch 12430/20000 --- Loss: 0.11099046398546343\n",
      "Epoch 12440/20000 --- Loss: 0.11093083322924073\n",
      "Epoch 12450/20000 --- Loss: 0.11086329816720306\n",
      "Epoch 12460/20000 --- Loss: 0.11078978756432961\n",
      "Epoch 12470/20000 --- Loss: 0.11075409266883236\n",
      "Epoch 12480/20000 --- Loss: 0.11067658731899531\n",
      "Epoch 12490/20000 --- Loss: 0.11061768590047732\n",
      "Epoch 12500/20000 --- Loss: 0.11056348370352112\n",
      "Epoch 12510/20000 --- Loss: 0.11049221181953453\n",
      "Epoch 12520/20000 --- Loss: 0.11042353667050499\n",
      "Epoch 12530/20000 --- Loss: 0.11037399662795323\n",
      "Epoch 12540/20000 --- Loss: 0.11030195397983922\n",
      "Epoch 12550/20000 --- Loss: 0.11024163884348605\n",
      "Epoch 12560/20000 --- Loss: 0.11014673411249054\n",
      "Epoch 12570/20000 --- Loss: 0.11006917988514958\n",
      "Epoch 12580/20000 --- Loss: 0.11000993939207987\n",
      "Epoch 12590/20000 --- Loss: 0.10995303419189238\n",
      "Epoch 12600/20000 --- Loss: 0.10989402151483912\n",
      "Epoch 12610/20000 --- Loss: 0.10986006485746742\n",
      "Epoch 12620/20000 --- Loss: 0.10979869072654476\n",
      "Epoch 12630/20000 --- Loss: 0.10971815447345447\n",
      "Epoch 12640/20000 --- Loss: 0.10965270944610961\n",
      "Epoch 12650/20000 --- Loss: 0.10957403540311167\n",
      "Epoch 12660/20000 --- Loss: 0.10954393670234107\n",
      "Epoch 12670/20000 --- Loss: 0.10952187430563888\n",
      "Epoch 12680/20000 --- Loss: 0.10946441933552434\n",
      "Epoch 12690/20000 --- Loss: 0.1093718406058209\n",
      "Epoch 12700/20000 --- Loss: 0.10932663396975997\n",
      "Epoch 12710/20000 --- Loss: 0.10927945051989463\n",
      "Epoch 12720/20000 --- Loss: 0.10927106262581818\n",
      "Epoch 12730/20000 --- Loss: 0.10919997230417888\n",
      "Epoch 12740/20000 --- Loss: 0.10913775388393596\n",
      "Epoch 12750/20000 --- Loss: 0.10906692117755232\n",
      "Epoch 12760/20000 --- Loss: 0.10901625948612266\n",
      "Epoch 12770/20000 --- Loss: 0.1090236466769443\n",
      "Epoch 12780/20000 --- Loss: 0.10892075266691036\n",
      "Epoch 12790/20000 --- Loss: 0.1088615305252335\n",
      "Epoch 12800/20000 --- Loss: 0.10878627946847727\n",
      "Epoch 12810/20000 --- Loss: 0.10870672026709578\n",
      "Epoch 12820/20000 --- Loss: 0.10862848767134413\n",
      "Epoch 12830/20000 --- Loss: 0.10858175071271979\n",
      "Epoch 12840/20000 --- Loss: 0.10853225431452805\n",
      "Epoch 12850/20000 --- Loss: 0.10847228515509133\n",
      "Epoch 12860/20000 --- Loss: 0.10842287669888778\n",
      "Epoch 12870/20000 --- Loss: 0.10839850149886271\n",
      "Epoch 12880/20000 --- Loss: 0.10831869295942644\n",
      "Epoch 12890/20000 --- Loss: 0.10830364447315757\n",
      "Epoch 12900/20000 --- Loss: 0.10824960752763232\n",
      "Epoch 12910/20000 --- Loss: 0.10820256922901983\n",
      "Epoch 12920/20000 --- Loss: 0.1081782359881351\n",
      "Epoch 12930/20000 --- Loss: 0.10809788480656282\n",
      "Epoch 12940/20000 --- Loss: 0.10802200054848857\n",
      "Epoch 12950/20000 --- Loss: 0.10797482976271877\n",
      "Epoch 12960/20000 --- Loss: 0.10794635884674832\n",
      "Epoch 12970/20000 --- Loss: 0.10785838317653879\n",
      "Epoch 12980/20000 --- Loss: 0.10779719669188904\n",
      "Epoch 12990/20000 --- Loss: 0.10774913844565912\n",
      "Epoch 13000/20000 --- Loss: 0.10768135409246764\n",
      "Epoch 13010/20000 --- Loss: 0.10761700325089585\n",
      "Epoch 13020/20000 --- Loss: 0.1076144425657264\n",
      "Epoch 13030/20000 --- Loss: 0.10751845384304556\n",
      "Epoch 13040/20000 --- Loss: 0.10753347435281198\n",
      "Epoch 13050/20000 --- Loss: 0.10746540893365106\n",
      "Epoch 13060/20000 --- Loss: 0.10739586921265405\n",
      "Epoch 13070/20000 --- Loss: 0.10738124922851557\n",
      "Epoch 13080/20000 --- Loss: 0.10728840498302913\n",
      "Epoch 13090/20000 --- Loss: 0.10723175258543743\n",
      "Epoch 13100/20000 --- Loss: 0.10712055871188178\n",
      "Epoch 13110/20000 --- Loss: 0.10706925185595674\n",
      "Epoch 13120/20000 --- Loss: 0.10701785852420474\n",
      "Epoch 13130/20000 --- Loss: 0.10693790424462968\n",
      "Epoch 13140/20000 --- Loss: 0.10686701110629682\n",
      "Epoch 13150/20000 --- Loss: 0.10682881760509916\n",
      "Epoch 13160/20000 --- Loss: 0.10673296787765016\n",
      "Epoch 13170/20000 --- Loss: 0.10673132031874306\n",
      "Epoch 13180/20000 --- Loss: 0.10667130126286332\n",
      "Epoch 13190/20000 --- Loss: 0.10662088730387806\n",
      "Epoch 13200/20000 --- Loss: 0.10659631319355675\n",
      "Epoch 13210/20000 --- Loss: 0.10650639202505469\n",
      "Epoch 13220/20000 --- Loss: 0.10645528221184872\n",
      "Epoch 13230/20000 --- Loss: 0.10640760348252941\n",
      "Epoch 13240/20000 --- Loss: 0.10637940977503542\n",
      "Epoch 13250/20000 --- Loss: 0.10636134623379796\n",
      "Epoch 13260/20000 --- Loss: 0.10628172995065996\n",
      "Epoch 13270/20000 --- Loss: 0.10621374195174428\n",
      "Epoch 13280/20000 --- Loss: 0.1061727073677757\n",
      "Epoch 13290/20000 --- Loss: 0.10611839744242442\n",
      "Epoch 13300/20000 --- Loss: 0.10614503416860867\n",
      "Epoch 13310/20000 --- Loss: 0.10604685094522229\n",
      "Epoch 13320/20000 --- Loss: 0.10600964232803059\n",
      "Epoch 13330/20000 --- Loss: 0.10594058271261927\n",
      "Epoch 13340/20000 --- Loss: 0.10587465288782677\n",
      "Epoch 13350/20000 --- Loss: 0.10583284900043657\n",
      "Epoch 13360/20000 --- Loss: 0.10576877402435729\n",
      "Epoch 13370/20000 --- Loss: 0.10575000173782789\n",
      "Epoch 13380/20000 --- Loss: 0.10573230209271409\n",
      "Epoch 13390/20000 --- Loss: 0.10565136997202339\n",
      "Epoch 13400/20000 --- Loss: 0.10559094690304172\n",
      "Epoch 13410/20000 --- Loss: 0.10553286129128399\n",
      "Epoch 13420/20000 --- Loss: 0.10545788737434657\n",
      "Epoch 13430/20000 --- Loss: 0.10539640173377654\n",
      "Epoch 13440/20000 --- Loss: 0.10534641425724846\n",
      "Epoch 13450/20000 --- Loss: 0.1052939775228725\n",
      "Epoch 13460/20000 --- Loss: 0.10522940772054483\n",
      "Epoch 13470/20000 --- Loss: 0.1051728358906612\n",
      "Epoch 13480/20000 --- Loss: 0.10516950194149\n",
      "Epoch 13490/20000 --- Loss: 0.10508714932886741\n",
      "Epoch 13500/20000 --- Loss: 0.10501712374636445\n",
      "Epoch 13510/20000 --- Loss: 0.1050136247745968\n",
      "Epoch 13520/20000 --- Loss: 0.10495048921702044\n",
      "Epoch 13530/20000 --- Loss: 0.1048923306069732\n",
      "Epoch 13540/20000 --- Loss: 0.10487663449951252\n",
      "Epoch 13550/20000 --- Loss: 0.10481040305101601\n",
      "Epoch 13560/20000 --- Loss: 0.10474909921571753\n",
      "Epoch 13570/20000 --- Loss: 0.10469272933420351\n",
      "Epoch 13580/20000 --- Loss: 0.10462679035455934\n",
      "Epoch 13590/20000 --- Loss: 0.10459229545282607\n",
      "Epoch 13600/20000 --- Loss: 0.10456542911579797\n",
      "Epoch 13610/20000 --- Loss: 0.10450008585213084\n",
      "Epoch 13620/20000 --- Loss: 0.10442534089920266\n",
      "Epoch 13630/20000 --- Loss: 0.10435538196962121\n",
      "Epoch 13640/20000 --- Loss: 0.10434082636506838\n",
      "Epoch 13650/20000 --- Loss: 0.10427344819882535\n",
      "Epoch 13660/20000 --- Loss: 0.10422368810059725\n",
      "Epoch 13670/20000 --- Loss: 0.10423540370365227\n",
      "Epoch 13680/20000 --- Loss: 0.1041587307683155\n",
      "Epoch 13690/20000 --- Loss: 0.10413196179697301\n",
      "Epoch 13700/20000 --- Loss: 0.1040712772942977\n",
      "Epoch 13710/20000 --- Loss: 0.1040123290334513\n",
      "Epoch 13720/20000 --- Loss: 0.1040031235663565\n",
      "Epoch 13730/20000 --- Loss: 0.10396278790684683\n",
      "Epoch 13740/20000 --- Loss: 0.10393978000167352\n",
      "Epoch 13750/20000 --- Loss: 0.10385825804310574\n",
      "Epoch 13760/20000 --- Loss: 0.10382088024381439\n",
      "Epoch 13770/20000 --- Loss: 0.10378184150865165\n",
      "Epoch 13780/20000 --- Loss: 0.10370968884773585\n",
      "Epoch 13790/20000 --- Loss: 0.10369128941516222\n",
      "Epoch 13800/20000 --- Loss: 0.10362716953363516\n",
      "Epoch 13810/20000 --- Loss: 0.10356163268967768\n",
      "Epoch 13820/20000 --- Loss: 0.10350046683827041\n",
      "Epoch 13830/20000 --- Loss: 0.10344414223352534\n",
      "Epoch 13840/20000 --- Loss: 0.10343247212277513\n",
      "Epoch 13850/20000 --- Loss: 0.10334085808788294\n",
      "Epoch 13860/20000 --- Loss: 0.10334518468408825\n",
      "Epoch 13870/20000 --- Loss: 0.1032618120181585\n",
      "Epoch 13880/20000 --- Loss: 0.10321483177888235\n",
      "Epoch 13890/20000 --- Loss: 0.10314686666442002\n",
      "Epoch 13900/20000 --- Loss: 0.10309889625240477\n",
      "Epoch 13910/20000 --- Loss: 0.10304387085692271\n",
      "Epoch 13920/20000 --- Loss: 0.10300258003168847\n",
      "Epoch 13930/20000 --- Loss: 0.10297957939347609\n",
      "Epoch 13940/20000 --- Loss: 0.10291864638304038\n",
      "Epoch 13950/20000 --- Loss: 0.1028831982251876\n",
      "Epoch 13960/20000 --- Loss: 0.10283210344463903\n",
      "Epoch 13970/20000 --- Loss: 0.10276784439538882\n",
      "Epoch 13980/20000 --- Loss: 0.10272020265400042\n",
      "Epoch 13990/20000 --- Loss: 0.10266681406720027\n",
      "Epoch 14000/20000 --- Loss: 0.10260070191272465\n",
      "Epoch 14010/20000 --- Loss: 0.10254608702549357\n",
      "Epoch 14020/20000 --- Loss: 0.102503588322112\n",
      "Epoch 14030/20000 --- Loss: 0.10248026389885105\n",
      "Epoch 14040/20000 --- Loss: 0.10241520222363772\n",
      "Epoch 14050/20000 --- Loss: 0.10236283446314202\n",
      "Epoch 14060/20000 --- Loss: 0.10228898895131666\n",
      "Epoch 14070/20000 --- Loss: 0.1022460110246201\n",
      "Epoch 14080/20000 --- Loss: 0.1022111422098423\n",
      "Epoch 14090/20000 --- Loss: 0.1021360301616771\n",
      "Epoch 14100/20000 --- Loss: 0.1021221710125969\n",
      "Epoch 14110/20000 --- Loss: 0.10207480550036972\n",
      "Epoch 14120/20000 --- Loss: 0.10202754277974112\n",
      "Epoch 14130/20000 --- Loss: 0.10201591442163878\n",
      "Epoch 14140/20000 --- Loss: 0.10194017081771987\n",
      "Epoch 14150/20000 --- Loss: 0.10189468005693895\n",
      "Epoch 14160/20000 --- Loss: 0.10184093449801937\n",
      "Epoch 14170/20000 --- Loss: 0.10182379224577456\n",
      "Epoch 14180/20000 --- Loss: 0.1017773487973709\n",
      "Epoch 14190/20000 --- Loss: 0.10171858597558411\n",
      "Epoch 14200/20000 --- Loss: 0.1016678700587619\n",
      "Epoch 14210/20000 --- Loss: 0.10161972684077765\n",
      "Epoch 14220/20000 --- Loss: 0.10157256020758372\n",
      "Epoch 14230/20000 --- Loss: 0.10152357447996402\n",
      "Epoch 14240/20000 --- Loss: 0.10146837524203127\n",
      "Epoch 14250/20000 --- Loss: 0.10154169474776942\n",
      "Epoch 14260/20000 --- Loss: 0.10145841954177547\n",
      "Epoch 14270/20000 --- Loss: 0.10142461592050002\n",
      "Epoch 14280/20000 --- Loss: 0.10134933186912762\n",
      "Epoch 14290/20000 --- Loss: 0.1012926031853159\n",
      "Epoch 14300/20000 --- Loss: 0.10123271706914186\n",
      "Epoch 14310/20000 --- Loss: 0.10119986990362459\n",
      "Epoch 14320/20000 --- Loss: 0.10117157353391476\n",
      "Epoch 14330/20000 --- Loss: 0.101112458140581\n",
      "Epoch 14340/20000 --- Loss: 0.10105468783061414\n",
      "Epoch 14350/20000 --- Loss: 0.10101201404024328\n",
      "Epoch 14360/20000 --- Loss: 0.10095761256738812\n",
      "Epoch 14370/20000 --- Loss: 0.10085615288625954\n",
      "Epoch 14380/20000 --- Loss: 0.1008544801911318\n",
      "Epoch 14390/20000 --- Loss: 0.10086665391610118\n",
      "Epoch 14400/20000 --- Loss: 0.10079635058652221\n",
      "Epoch 14410/20000 --- Loss: 0.10074867069587294\n",
      "Epoch 14420/20000 --- Loss: 0.10073046759648958\n",
      "Epoch 14430/20000 --- Loss: 0.10067075923343095\n",
      "Epoch 14440/20000 --- Loss: 0.10062915146512784\n",
      "Epoch 14450/20000 --- Loss: 0.10058015434756386\n",
      "Epoch 14460/20000 --- Loss: 0.10061966269934824\n",
      "Epoch 14470/20000 --- Loss: 0.1005546798129599\n",
      "Epoch 14480/20000 --- Loss: 0.10048189759573939\n",
      "Epoch 14490/20000 --- Loss: 0.1004188484692055\n",
      "Epoch 14500/20000 --- Loss: 0.10043753982704634\n",
      "Epoch 14510/20000 --- Loss: 0.10036012568391842\n",
      "Epoch 14520/20000 --- Loss: 0.10030590679231419\n",
      "Epoch 14530/20000 --- Loss: 0.10025861753513896\n",
      "Epoch 14540/20000 --- Loss: 0.10022434321297939\n",
      "Epoch 14550/20000 --- Loss: 0.10017018401996083\n",
      "Epoch 14560/20000 --- Loss: 0.10016931867491494\n",
      "Epoch 14570/20000 --- Loss: 0.10010254523736795\n",
      "Epoch 14580/20000 --- Loss: 0.10007530418089551\n",
      "Epoch 14590/20000 --- Loss: 0.10002003029899852\n",
      "Epoch 14600/20000 --- Loss: 0.09996942772317037\n",
      "Epoch 14610/20000 --- Loss: 0.09991039686227705\n",
      "Epoch 14620/20000 --- Loss: 0.09984502919341769\n",
      "Epoch 14630/20000 --- Loss: 0.09978400579174221\n",
      "Epoch 14640/20000 --- Loss: 0.09976941860529656\n",
      "Epoch 14650/20000 --- Loss: 0.0997160221366613\n",
      "Epoch 14660/20000 --- Loss: 0.09967135922656502\n",
      "Epoch 14670/20000 --- Loss: 0.09965461781443531\n",
      "Epoch 14680/20000 --- Loss: 0.0996200039795394\n",
      "Epoch 14690/20000 --- Loss: 0.09957746422900943\n",
      "Epoch 14700/20000 --- Loss: 0.09953598244017384\n",
      "Epoch 14710/20000 --- Loss: 0.09950950357830825\n",
      "Epoch 14720/20000 --- Loss: 0.09946268870258926\n",
      "Epoch 14730/20000 --- Loss: 0.09941054571367716\n",
      "Epoch 14740/20000 --- Loss: 0.0993964782850487\n",
      "Epoch 14750/20000 --- Loss: 0.09933380920229053\n",
      "Epoch 14760/20000 --- Loss: 0.09930760650041678\n",
      "Epoch 14770/20000 --- Loss: 0.09928457233641017\n",
      "Epoch 14780/20000 --- Loss: 0.09921564682545855\n",
      "Epoch 14790/20000 --- Loss: 0.0991997717607618\n",
      "Epoch 14800/20000 --- Loss: 0.09914903228052044\n",
      "Epoch 14810/20000 --- Loss: 0.0990947304391385\n",
      "Epoch 14820/20000 --- Loss: 0.09905044933585146\n",
      "Epoch 14830/20000 --- Loss: 0.09899570055041537\n",
      "Epoch 14840/20000 --- Loss: 0.09893883684348984\n",
      "Epoch 14850/20000 --- Loss: 0.09888703839039148\n",
      "Epoch 14860/20000 --- Loss: 0.09883140845065123\n",
      "Epoch 14870/20000 --- Loss: 0.09879232489413714\n",
      "Epoch 14880/20000 --- Loss: 0.09878646427219613\n",
      "Epoch 14890/20000 --- Loss: 0.09870163679157823\n",
      "Epoch 14900/20000 --- Loss: 0.09865389712516633\n",
      "Epoch 14910/20000 --- Loss: 0.0986153590454419\n",
      "Epoch 14920/20000 --- Loss: 0.09856387871771607\n",
      "Epoch 14930/20000 --- Loss: 0.09857237262842601\n",
      "Epoch 14940/20000 --- Loss: 0.09853902129829098\n",
      "Epoch 14950/20000 --- Loss: 0.09847836407448086\n",
      "Epoch 14960/20000 --- Loss: 0.0984363759225105\n",
      "Epoch 14970/20000 --- Loss: 0.09839695915285251\n",
      "Epoch 14980/20000 --- Loss: 0.09835049057178596\n",
      "Epoch 14990/20000 --- Loss: 0.09836272538490194\n",
      "Epoch 15000/20000 --- Loss: 0.09831789935393313\n",
      "Epoch 15010/20000 --- Loss: 0.09826058505917912\n",
      "Epoch 15020/20000 --- Loss: 0.09820842576326157\n",
      "Epoch 15030/20000 --- Loss: 0.09816474111986125\n",
      "Epoch 15040/20000 --- Loss: 0.09816239413663992\n",
      "Epoch 15050/20000 --- Loss: 0.09813392334818644\n",
      "Epoch 15060/20000 --- Loss: 0.09810330956324924\n",
      "Epoch 15070/20000 --- Loss: 0.09805714554086974\n",
      "Epoch 15080/20000 --- Loss: 0.09802039465366619\n",
      "Epoch 15090/20000 --- Loss: 0.09796875117448572\n",
      "Epoch 15100/20000 --- Loss: 0.09790975389619169\n",
      "Epoch 15110/20000 --- Loss: 0.09785547575860737\n",
      "Epoch 15120/20000 --- Loss: 0.09779996462263242\n",
      "Epoch 15130/20000 --- Loss: 0.09779038974240742\n",
      "Epoch 15140/20000 --- Loss: 0.09773198229960284\n",
      "Epoch 15150/20000 --- Loss: 0.09769132846987287\n",
      "Epoch 15160/20000 --- Loss: 0.09762537724375976\n",
      "Epoch 15170/20000 --- Loss: 0.09759030579538619\n",
      "Epoch 15180/20000 --- Loss: 0.09756128530642352\n",
      "Epoch 15190/20000 --- Loss: 0.09752079893104387\n",
      "Epoch 15200/20000 --- Loss: 0.0974720702488168\n",
      "Epoch 15210/20000 --- Loss: 0.09743427202706616\n",
      "Epoch 15220/20000 --- Loss: 0.0973938150141113\n",
      "Epoch 15230/20000 --- Loss: 0.09734836439874464\n",
      "Epoch 15240/20000 --- Loss: 0.09730673568747454\n",
      "Epoch 15250/20000 --- Loss: 0.09728031081607162\n",
      "Epoch 15260/20000 --- Loss: 0.09725979717177309\n",
      "Epoch 15270/20000 --- Loss: 0.09720967912321042\n",
      "Epoch 15280/20000 --- Loss: 0.0971478551150755\n",
      "Epoch 15290/20000 --- Loss: 0.09710481124716215\n",
      "Epoch 15300/20000 --- Loss: 0.09706198595397245\n",
      "Epoch 15310/20000 --- Loss: 0.09701972538750006\n",
      "Epoch 15320/20000 --- Loss: 0.09702932148863841\n",
      "Epoch 15330/20000 --- Loss: 0.09698436861870066\n",
      "Epoch 15340/20000 --- Loss: 0.09692261978078785\n",
      "Epoch 15350/20000 --- Loss: 0.09690511514509288\n",
      "Epoch 15360/20000 --- Loss: 0.09684057370641347\n",
      "Epoch 15370/20000 --- Loss: 0.09679185606923547\n",
      "Epoch 15380/20000 --- Loss: 0.09674806409214544\n",
      "Epoch 15390/20000 --- Loss: 0.09669875827766981\n",
      "Epoch 15400/20000 --- Loss: 0.09666130166539577\n",
      "Epoch 15410/20000 --- Loss: 0.09662375045547789\n",
      "Epoch 15420/20000 --- Loss: 0.09657863162640415\n",
      "Epoch 15430/20000 --- Loss: 0.09653195488296018\n",
      "Epoch 15440/20000 --- Loss: 0.09650428189562811\n",
      "Epoch 15450/20000 --- Loss: 0.09648080619773916\n",
      "Epoch 15460/20000 --- Loss: 0.0964531239373897\n",
      "Epoch 15470/20000 --- Loss: 0.09638340490172308\n",
      "Epoch 15480/20000 --- Loss: 0.09633818130212642\n",
      "Epoch 15490/20000 --- Loss: 0.09630806655678656\n",
      "Epoch 15500/20000 --- Loss: 0.09626391468442295\n",
      "Epoch 15510/20000 --- Loss: 0.0962292593051709\n",
      "Epoch 15520/20000 --- Loss: 0.09618483365055251\n",
      "Epoch 15530/20000 --- Loss: 0.09614489131675766\n",
      "Epoch 15540/20000 --- Loss: 0.09611256240242261\n",
      "Epoch 15550/20000 --- Loss: 0.09606676543033643\n",
      "Epoch 15560/20000 --- Loss: 0.09601673670045631\n",
      "Epoch 15570/20000 --- Loss: 0.09598782421990702\n",
      "Epoch 15580/20000 --- Loss: 0.09594618115902578\n",
      "Epoch 15590/20000 --- Loss: 0.09591098451019713\n",
      "Epoch 15600/20000 --- Loss: 0.09589583398811849\n",
      "Epoch 15610/20000 --- Loss: 0.09589012998548842\n",
      "Epoch 15620/20000 --- Loss: 0.09583796366440925\n",
      "Epoch 15630/20000 --- Loss: 0.09586841014958977\n",
      "Epoch 15640/20000 --- Loss: 0.09580434148878603\n",
      "Epoch 15650/20000 --- Loss: 0.09576259407669471\n",
      "Epoch 15660/20000 --- Loss: 0.09572216637245534\n",
      "Epoch 15670/20000 --- Loss: 0.09569645380656419\n",
      "Epoch 15680/20000 --- Loss: 0.09565269018433767\n",
      "Epoch 15690/20000 --- Loss: 0.09561332309847874\n",
      "Epoch 15700/20000 --- Loss: 0.09560527560498361\n",
      "Epoch 15710/20000 --- Loss: 0.09555298255039438\n",
      "Epoch 15720/20000 --- Loss: 0.09554593284363062\n",
      "Epoch 15730/20000 --- Loss: 0.09548815652241707\n",
      "Epoch 15740/20000 --- Loss: 0.09543652865350037\n",
      "Epoch 15750/20000 --- Loss: 0.09540449376075688\n",
      "Epoch 15760/20000 --- Loss: 0.09541807176881506\n",
      "Epoch 15770/20000 --- Loss: 0.09534421624931826\n",
      "Epoch 15780/20000 --- Loss: 0.09533665795187542\n",
      "Epoch 15790/20000 --- Loss: 0.09528026036584375\n",
      "Epoch 15800/20000 --- Loss: 0.09523775951896082\n",
      "Epoch 15810/20000 --- Loss: 0.09520115530634794\n",
      "Epoch 15820/20000 --- Loss: 0.09516300178140971\n",
      "Epoch 15830/20000 --- Loss: 0.09516462296133794\n",
      "Epoch 15840/20000 --- Loss: 0.09512626647447808\n",
      "Epoch 15850/20000 --- Loss: 0.09509259708791394\n",
      "Epoch 15860/20000 --- Loss: 0.09506398036563567\n",
      "Epoch 15870/20000 --- Loss: 0.09501500026481664\n",
      "Epoch 15880/20000 --- Loss: 0.09500407120553811\n",
      "Epoch 15890/20000 --- Loss: 0.09494324148591919\n",
      "Epoch 15900/20000 --- Loss: 0.09493800210081743\n",
      "Epoch 15910/20000 --- Loss: 0.09487980764147962\n",
      "Epoch 15920/20000 --- Loss: 0.09482904104485407\n",
      "Epoch 15930/20000 --- Loss: 0.0947919375129455\n",
      "Epoch 15940/20000 --- Loss: 0.09474529271749539\n",
      "Epoch 15950/20000 --- Loss: 0.09470631390885545\n",
      "Epoch 15960/20000 --- Loss: 0.0946868061887098\n",
      "Epoch 15970/20000 --- Loss: 0.09463463016096071\n",
      "Epoch 15980/20000 --- Loss: 0.09459640125384637\n",
      "Epoch 15990/20000 --- Loss: 0.09454401454904386\n",
      "Epoch 16000/20000 --- Loss: 0.09451924933362808\n",
      "Epoch 16010/20000 --- Loss: 0.094500944244435\n",
      "Epoch 16020/20000 --- Loss: 0.09445834104705143\n",
      "Epoch 16030/20000 --- Loss: 0.09441512907398267\n",
      "Epoch 16040/20000 --- Loss: 0.0943742446396773\n",
      "Epoch 16050/20000 --- Loss: 0.09436833201763864\n",
      "Epoch 16060/20000 --- Loss: 0.0943778882212102\n",
      "Epoch 16070/20000 --- Loss: 0.0943159947145835\n",
      "Epoch 16080/20000 --- Loss: 0.09426823167522849\n",
      "Epoch 16090/20000 --- Loss: 0.09422294454623295\n",
      "Epoch 16100/20000 --- Loss: 0.09418227437805261\n",
      "Epoch 16110/20000 --- Loss: 0.09414319832855243\n",
      "Epoch 16120/20000 --- Loss: 0.09409953010347126\n",
      "Epoch 16130/20000 --- Loss: 0.09413570587988589\n",
      "Epoch 16140/20000 --- Loss: 0.09410668449592813\n",
      "Epoch 16150/20000 --- Loss: 0.09408555263252533\n",
      "Epoch 16160/20000 --- Loss: 0.09403441676222335\n",
      "Epoch 16170/20000 --- Loss: 0.0939803118621349\n",
      "Epoch 16180/20000 --- Loss: 0.09393382602578541\n",
      "Epoch 16190/20000 --- Loss: 0.09389831585776344\n",
      "Epoch 16200/20000 --- Loss: 0.09385778748110743\n",
      "Epoch 16210/20000 --- Loss: 0.09385293676952092\n",
      "Epoch 16220/20000 --- Loss: 0.09379478800569542\n",
      "Epoch 16230/20000 --- Loss: 0.093764183012189\n",
      "Epoch 16240/20000 --- Loss: 0.0937224902651313\n",
      "Epoch 16250/20000 --- Loss: 0.09370269534498882\n",
      "Epoch 16260/20000 --- Loss: 0.0936774673164295\n",
      "Epoch 16270/20000 --- Loss: 0.09363328695525787\n",
      "Epoch 16280/20000 --- Loss: 0.0936123929802921\n",
      "Epoch 16290/20000 --- Loss: 0.09356643157458787\n",
      "Epoch 16300/20000 --- Loss: 0.09352894016625539\n",
      "Epoch 16310/20000 --- Loss: 0.09350017152001798\n",
      "Epoch 16320/20000 --- Loss: 0.09345844757943957\n",
      "Epoch 16330/20000 --- Loss: 0.09345464802262138\n",
      "Epoch 16340/20000 --- Loss: 0.09344947406917949\n",
      "Epoch 16350/20000 --- Loss: 0.09340771188171704\n",
      "Epoch 16360/20000 --- Loss: 0.09335299852813897\n",
      "Epoch 16370/20000 --- Loss: 0.0933069908671694\n",
      "Epoch 16380/20000 --- Loss: 0.09326809719347659\n",
      "Epoch 16390/20000 --- Loss: 0.09322089475907991\n",
      "Epoch 16400/20000 --- Loss: 0.09316927371350542\n",
      "Epoch 16410/20000 --- Loss: 0.09314139368071231\n",
      "Epoch 16420/20000 --- Loss: 0.09309600888429016\n",
      "Epoch 16430/20000 --- Loss: 0.09305868717333805\n",
      "Epoch 16440/20000 --- Loss: 0.09301294899915408\n",
      "Epoch 16450/20000 --- Loss: 0.09296864485747737\n",
      "Epoch 16460/20000 --- Loss: 0.09294184662071729\n",
      "Epoch 16470/20000 --- Loss: 0.09290845332528168\n",
      "Epoch 16480/20000 --- Loss: 0.09288248749607542\n",
      "Epoch 16490/20000 --- Loss: 0.09285060336573363\n",
      "Epoch 16500/20000 --- Loss: 0.0928146112646416\n",
      "Epoch 16510/20000 --- Loss: 0.09277445284699147\n",
      "Epoch 16520/20000 --- Loss: 0.09274810671368383\n",
      "Epoch 16530/20000 --- Loss: 0.09271016415997281\n",
      "Epoch 16540/20000 --- Loss: 0.09266748046467799\n",
      "Epoch 16550/20000 --- Loss: 0.09263056177823971\n",
      "Epoch 16560/20000 --- Loss: 0.0926037976129996\n",
      "Epoch 16570/20000 --- Loss: 0.0925734152276742\n",
      "Epoch 16580/20000 --- Loss: 0.09255986828803259\n",
      "Epoch 16590/20000 --- Loss: 0.09250808965742616\n",
      "Epoch 16600/20000 --- Loss: 0.0924688434034885\n",
      "Epoch 16610/20000 --- Loss: 0.09243946307848203\n",
      "Epoch 16620/20000 --- Loss: 0.09241968594392934\n",
      "Epoch 16630/20000 --- Loss: 0.09238688193530102\n",
      "Epoch 16640/20000 --- Loss: 0.09236969296938706\n",
      "Epoch 16650/20000 --- Loss: 0.09233083617558203\n",
      "Epoch 16660/20000 --- Loss: 0.0922892571566516\n",
      "Epoch 16670/20000 --- Loss: 0.09225965713332723\n",
      "Epoch 16680/20000 --- Loss: 0.09224444676724511\n",
      "Epoch 16690/20000 --- Loss: 0.09219228494236764\n",
      "Epoch 16700/20000 --- Loss: 0.09215136905925629\n",
      "Epoch 16710/20000 --- Loss: 0.09211395855806684\n",
      "Epoch 16720/20000 --- Loss: 0.09208491478044013\n",
      "Epoch 16730/20000 --- Loss: 0.09205257445405689\n",
      "Epoch 16740/20000 --- Loss: 0.0920188591740205\n",
      "Epoch 16750/20000 --- Loss: 0.09204428952034886\n",
      "Epoch 16760/20000 --- Loss: 0.09202755090766629\n",
      "Epoch 16770/20000 --- Loss: 0.09197725666819326\n",
      "Epoch 16780/20000 --- Loss: 0.0919320565741434\n",
      "Epoch 16790/20000 --- Loss: 0.09190658741168395\n",
      "Epoch 16800/20000 --- Loss: 0.09187289625021429\n",
      "Epoch 16810/20000 --- Loss: 0.09183637122266947\n",
      "Epoch 16820/20000 --- Loss: 0.09180666660960826\n",
      "Epoch 16830/20000 --- Loss: 0.09177644480265307\n",
      "Epoch 16840/20000 --- Loss: 0.09173823995729709\n",
      "Epoch 16850/20000 --- Loss: 0.09170593884310883\n",
      "Epoch 16860/20000 --- Loss: 0.09169170475863744\n",
      "Epoch 16870/20000 --- Loss: 0.09164802705933442\n",
      "Epoch 16880/20000 --- Loss: 0.09162187659473706\n",
      "Epoch 16890/20000 --- Loss: 0.0915763582301216\n",
      "Epoch 16900/20000 --- Loss: 0.09156084554430173\n",
      "Epoch 16910/20000 --- Loss: 0.0915499708629035\n",
      "Epoch 16920/20000 --- Loss: 0.09154405943961096\n",
      "Epoch 16930/20000 --- Loss: 0.0914851206412091\n",
      "Epoch 16940/20000 --- Loss: 0.09144795970690926\n",
      "Epoch 16950/20000 --- Loss: 0.0914115014838561\n",
      "Epoch 16960/20000 --- Loss: 0.09137701983648244\n",
      "Epoch 16970/20000 --- Loss: 0.09134777887954448\n",
      "Epoch 16980/20000 --- Loss: 0.0913037728677317\n",
      "Epoch 16990/20000 --- Loss: 0.09127637285978005\n",
      "Epoch 17000/20000 --- Loss: 0.09123015435881175\n",
      "Epoch 17010/20000 --- Loss: 0.09119297468379692\n",
      "Epoch 17020/20000 --- Loss: 0.0911567255345449\n",
      "Epoch 17030/20000 --- Loss: 0.09112667822638738\n",
      "Epoch 17040/20000 --- Loss: 0.09112751639620062\n",
      "Epoch 17050/20000 --- Loss: 0.09111314612443876\n",
      "Epoch 17060/20000 --- Loss: 0.09105604630797062\n",
      "Epoch 17070/20000 --- Loss: 0.09102866908550625\n",
      "Epoch 17080/20000 --- Loss: 0.09098146465178507\n",
      "Epoch 17090/20000 --- Loss: 0.09097052534052663\n",
      "Epoch 17100/20000 --- Loss: 0.09093468396082569\n",
      "Epoch 17110/20000 --- Loss: 0.09088922558821254\n",
      "Epoch 17120/20000 --- Loss: 0.0908700090675739\n",
      "Epoch 17130/20000 --- Loss: 0.0908370316324378\n",
      "Epoch 17140/20000 --- Loss: 0.09082348942771255\n",
      "Epoch 17150/20000 --- Loss: 0.09076787340620121\n",
      "Epoch 17160/20000 --- Loss: 0.0907406049217984\n",
      "Epoch 17170/20000 --- Loss: 0.09069841361243058\n",
      "Epoch 17180/20000 --- Loss: 0.09068735902646145\n",
      "Epoch 17190/20000 --- Loss: 0.09067232294063267\n",
      "Epoch 17200/20000 --- Loss: 0.0906305316381979\n",
      "Epoch 17210/20000 --- Loss: 0.0906284008151551\n",
      "Epoch 17220/20000 --- Loss: 0.0905636121862038\n",
      "Epoch 17230/20000 --- Loss: 0.090564996341406\n",
      "Epoch 17240/20000 --- Loss: 0.09052596454256483\n",
      "Epoch 17250/20000 --- Loss: 0.09053695875701648\n",
      "Epoch 17260/20000 --- Loss: 0.09051741070904926\n",
      "Epoch 17270/20000 --- Loss: 0.09048522583056155\n",
      "Epoch 17280/20000 --- Loss: 0.0904284653210278\n",
      "Epoch 17290/20000 --- Loss: 0.09038873679711772\n",
      "Epoch 17300/20000 --- Loss: 0.0903569658169787\n",
      "Epoch 17310/20000 --- Loss: 0.09032678291470746\n",
      "Epoch 17320/20000 --- Loss: 0.09031009838496956\n",
      "Epoch 17330/20000 --- Loss: 0.0903063381361255\n",
      "Epoch 17340/20000 --- Loss: 0.09025817262916866\n",
      "Epoch 17350/20000 --- Loss: 0.09022957384020223\n",
      "Epoch 17360/20000 --- Loss: 0.09018987542279336\n",
      "Epoch 17370/20000 --- Loss: 0.09015904617286694\n",
      "Epoch 17380/20000 --- Loss: 0.09012733533405845\n",
      "Epoch 17390/20000 --- Loss: 0.09009985599216763\n",
      "Epoch 17400/20000 --- Loss: 0.09007394136244617\n",
      "Epoch 17410/20000 --- Loss: 0.09003858867424994\n",
      "Epoch 17420/20000 --- Loss: 0.08999537110440133\n",
      "Epoch 17430/20000 --- Loss: 0.08996578993098094\n",
      "Epoch 17440/20000 --- Loss: 0.0899525899437899\n",
      "Epoch 17450/20000 --- Loss: 0.08992181246136441\n",
      "Epoch 17460/20000 --- Loss: 0.08988293508372891\n",
      "Epoch 17470/20000 --- Loss: 0.08987921294042188\n",
      "Epoch 17480/20000 --- Loss: 0.08983090203669947\n",
      "Epoch 17490/20000 --- Loss: 0.08979148698235195\n",
      "Epoch 17500/20000 --- Loss: 0.08975853231911482\n",
      "Epoch 17510/20000 --- Loss: 0.08975346541921639\n",
      "Epoch 17520/20000 --- Loss: 0.08972333170108954\n",
      "Epoch 17530/20000 --- Loss: 0.08968849194575888\n",
      "Epoch 17540/20000 --- Loss: 0.0896552393614051\n",
      "Epoch 17550/20000 --- Loss: 0.08962667096609284\n",
      "Epoch 17560/20000 --- Loss: 0.08958736101264557\n",
      "Epoch 17570/20000 --- Loss: 0.08955966340869638\n",
      "Epoch 17580/20000 --- Loss: 0.08953003709410211\n",
      "Epoch 17590/20000 --- Loss: 0.08949493222687788\n",
      "Epoch 17600/20000 --- Loss: 0.08946830208177525\n",
      "Epoch 17610/20000 --- Loss: 0.0894579506282983\n",
      "Epoch 17620/20000 --- Loss: 0.08942210890797296\n",
      "Epoch 17630/20000 --- Loss: 0.08941633285420698\n",
      "Epoch 17640/20000 --- Loss: 0.08937975026564762\n",
      "Epoch 17650/20000 --- Loss: 0.0893720887936002\n",
      "Epoch 17660/20000 --- Loss: 0.0893279134573962\n",
      "Epoch 17670/20000 --- Loss: 0.08931980843984018\n",
      "Epoch 17680/20000 --- Loss: 0.08929190618282053\n",
      "Epoch 17690/20000 --- Loss: 0.08930110501670172\n",
      "Epoch 17700/20000 --- Loss: 0.08928283155407585\n",
      "Epoch 17710/20000 --- Loss: 0.08923002582263956\n",
      "Epoch 17720/20000 --- Loss: 0.08921753422960112\n",
      "Epoch 17730/20000 --- Loss: 0.08916989309244595\n",
      "Epoch 17740/20000 --- Loss: 0.08913873766938041\n",
      "Epoch 17750/20000 --- Loss: 0.08912113059200062\n",
      "Epoch 17760/20000 --- Loss: 0.08909076951042734\n",
      "Epoch 17770/20000 --- Loss: 0.0890690411134804\n",
      "Epoch 17780/20000 --- Loss: 0.08902960636752454\n",
      "Epoch 17790/20000 --- Loss: 0.08899526010253599\n",
      "Epoch 17800/20000 --- Loss: 0.08898536875983808\n",
      "Epoch 17810/20000 --- Loss: 0.08893941555000752\n",
      "Epoch 17820/20000 --- Loss: 0.0888999904373631\n",
      "Epoch 17830/20000 --- Loss: 0.08887297619752378\n",
      "Epoch 17840/20000 --- Loss: 0.08884310651984456\n",
      "Epoch 17850/20000 --- Loss: 0.08881380377438615\n",
      "Epoch 17860/20000 --- Loss: 0.08878345578019292\n",
      "Epoch 17870/20000 --- Loss: 0.08877583321874934\n",
      "Epoch 17880/20000 --- Loss: 0.08873138974350901\n",
      "Epoch 17890/20000 --- Loss: 0.0887205487438391\n",
      "Epoch 17900/20000 --- Loss: 0.08870321345372664\n",
      "Epoch 17910/20000 --- Loss: 0.08865924112366727\n",
      "Epoch 17920/20000 --- Loss: 0.08865338867808188\n",
      "Epoch 17930/20000 --- Loss: 0.08861562211293236\n",
      "Epoch 17940/20000 --- Loss: 0.08858529336642951\n",
      "Epoch 17950/20000 --- Loss: 0.08857428984438895\n",
      "Epoch 17960/20000 --- Loss: 0.08853632548665223\n",
      "Epoch 17970/20000 --- Loss: 0.08850311457820441\n",
      "Epoch 17980/20000 --- Loss: 0.08848870986960171\n",
      "Epoch 17990/20000 --- Loss: 0.08844629962236729\n",
      "Epoch 18000/20000 --- Loss: 0.08842236544224277\n",
      "Epoch 18010/20000 --- Loss: 0.08838901202977528\n",
      "Epoch 18020/20000 --- Loss: 0.08836039363117518\n",
      "Epoch 18030/20000 --- Loss: 0.08833022699762831\n",
      "Epoch 18040/20000 --- Loss: 0.08829473688825802\n",
      "Epoch 18050/20000 --- Loss: 0.08826808219927398\n",
      "Epoch 18060/20000 --- Loss: 0.0882248753523365\n",
      "Epoch 18070/20000 --- Loss: 0.08819421792817464\n",
      "Epoch 18080/20000 --- Loss: 0.08819106731714846\n",
      "Epoch 18090/20000 --- Loss: 0.08816591242828468\n",
      "Epoch 18100/20000 --- Loss: 0.08815140288287242\n",
      "Epoch 18110/20000 --- Loss: 0.0881202245175874\n",
      "Epoch 18120/20000 --- Loss: 0.08809571910163129\n",
      "Epoch 18130/20000 --- Loss: 0.0880660896699618\n",
      "Epoch 18140/20000 --- Loss: 0.08803272766342178\n",
      "Epoch 18150/20000 --- Loss: 0.08800844351249414\n",
      "Epoch 18160/20000 --- Loss: 0.08797576361275314\n",
      "Epoch 18170/20000 --- Loss: 0.08793796261411747\n",
      "Epoch 18180/20000 --- Loss: 0.08796774736888674\n",
      "Epoch 18190/20000 --- Loss: 0.0879076972816385\n",
      "Epoch 18200/20000 --- Loss: 0.08788196351087874\n",
      "Epoch 18210/20000 --- Loss: 0.08784022531167746\n",
      "Epoch 18220/20000 --- Loss: 0.08780809363880594\n",
      "Epoch 18230/20000 --- Loss: 0.08778160525798424\n",
      "Epoch 18240/20000 --- Loss: 0.08776902707000823\n",
      "Epoch 18250/20000 --- Loss: 0.087737023311632\n",
      "Epoch 18260/20000 --- Loss: 0.08771180678880786\n",
      "Epoch 18270/20000 --- Loss: 0.08769863058770853\n",
      "Epoch 18280/20000 --- Loss: 0.08765929716065951\n",
      "Epoch 18290/20000 --- Loss: 0.08762486301044281\n",
      "Epoch 18300/20000 --- Loss: 0.08760768548390102\n",
      "Epoch 18310/20000 --- Loss: 0.08758010413555195\n",
      "Epoch 18320/20000 --- Loss: 0.0875516429560894\n",
      "Epoch 18330/20000 --- Loss: 0.08752439479410483\n",
      "Epoch 18340/20000 --- Loss: 0.08752748220005045\n",
      "Epoch 18350/20000 --- Loss: 0.08748697466879123\n",
      "Epoch 18360/20000 --- Loss: 0.0874593075197252\n",
      "Epoch 18370/20000 --- Loss: 0.0874272919839111\n",
      "Epoch 18380/20000 --- Loss: 0.08740045257239706\n",
      "Epoch 18390/20000 --- Loss: 0.08739568622525554\n",
      "Epoch 18400/20000 --- Loss: 0.08735533759776667\n",
      "Epoch 18410/20000 --- Loss: 0.08734365791268828\n",
      "Epoch 18420/20000 --- Loss: 0.08731946109673473\n",
      "Epoch 18430/20000 --- Loss: 0.08730124547611774\n",
      "Epoch 18440/20000 --- Loss: 0.08727585052141794\n",
      "Epoch 18450/20000 --- Loss: 0.08724866036800898\n",
      "Epoch 18460/20000 --- Loss: 0.08721097184393442\n",
      "Epoch 18470/20000 --- Loss: 0.08718675457254006\n",
      "Epoch 18480/20000 --- Loss: 0.0871620872455642\n",
      "Epoch 18490/20000 --- Loss: 0.08714294054565395\n",
      "Epoch 18500/20000 --- Loss: 0.08711249994226543\n",
      "Epoch 18510/20000 --- Loss: 0.08707785427973985\n",
      "Epoch 18520/20000 --- Loss: 0.08704943596795817\n",
      "Epoch 18530/20000 --- Loss: 0.08702767439783607\n",
      "Epoch 18540/20000 --- Loss: 0.08700301948147572\n",
      "Epoch 18550/20000 --- Loss: 0.08697973166316678\n",
      "Epoch 18560/20000 --- Loss: 0.08695230195415488\n",
      "Epoch 18570/20000 --- Loss: 0.08693909591442431\n",
      "Epoch 18580/20000 --- Loss: 0.08690759955724832\n",
      "Epoch 18590/20000 --- Loss: 0.08688098736812605\n",
      "Epoch 18600/20000 --- Loss: 0.0868537014987649\n",
      "Epoch 18610/20000 --- Loss: 0.08682777487737596\n",
      "Epoch 18620/20000 --- Loss: 0.08678936700936242\n",
      "Epoch 18630/20000 --- Loss: 0.08675679713535353\n",
      "Epoch 18640/20000 --- Loss: 0.08672430255278483\n",
      "Epoch 18650/20000 --- Loss: 0.08670291891419696\n",
      "Epoch 18660/20000 --- Loss: 0.08666678145121891\n",
      "Epoch 18670/20000 --- Loss: 0.08664342499580355\n",
      "Epoch 18680/20000 --- Loss: 0.08663554638949388\n",
      "Epoch 18690/20000 --- Loss: 0.08663692530946733\n",
      "Epoch 18700/20000 --- Loss: 0.08661118964486292\n",
      "Epoch 18710/20000 --- Loss: 0.08659546024586724\n",
      "Epoch 18720/20000 --- Loss: 0.08656490678598999\n",
      "Epoch 18730/20000 --- Loss: 0.08655002961653863\n",
      "Epoch 18740/20000 --- Loss: 0.0865081247892225\n",
      "Epoch 18750/20000 --- Loss: 0.08647936900429816\n",
      "Epoch 18760/20000 --- Loss: 0.08645892236572615\n",
      "Epoch 18770/20000 --- Loss: 0.08643174027223496\n",
      "Epoch 18780/20000 --- Loss: 0.08640315233985914\n",
      "Epoch 18790/20000 --- Loss: 0.08638240217322987\n",
      "Epoch 18800/20000 --- Loss: 0.08635118906598734\n",
      "Epoch 18810/20000 --- Loss: 0.08631569838174852\n",
      "Epoch 18820/20000 --- Loss: 0.08629636426057857\n",
      "Epoch 18830/20000 --- Loss: 0.08628795682134084\n",
      "Epoch 18840/20000 --- Loss: 0.0862466185313146\n",
      "Epoch 18850/20000 --- Loss: 0.08625969477508781\n",
      "Epoch 18860/20000 --- Loss: 0.08622690655104773\n",
      "Epoch 18870/20000 --- Loss: 0.08621540456982404\n",
      "Epoch 18880/20000 --- Loss: 0.08618201884793833\n",
      "Epoch 18890/20000 --- Loss: 0.08614953238269155\n",
      "Epoch 18900/20000 --- Loss: 0.0861192916309787\n",
      "Epoch 18910/20000 --- Loss: 0.08608157908226799\n",
      "Epoch 18920/20000 --- Loss: 0.08605113844250195\n",
      "Epoch 18930/20000 --- Loss: 0.0860340440794338\n",
      "Epoch 18940/20000 --- Loss: 0.08601675852989776\n",
      "Epoch 18950/20000 --- Loss: 0.08598261691618737\n",
      "Epoch 18960/20000 --- Loss: 0.08596280998178901\n",
      "Epoch 18970/20000 --- Loss: 0.08593655303059354\n",
      "Epoch 18980/20000 --- Loss: 0.08590119232795425\n",
      "Epoch 18990/20000 --- Loss: 0.08587705774847254\n",
      "Epoch 19000/20000 --- Loss: 0.08585265145603406\n",
      "Epoch 19010/20000 --- Loss: 0.08582478783182385\n",
      "Epoch 19020/20000 --- Loss: 0.0858052367228359\n",
      "Epoch 19030/20000 --- Loss: 0.08580238203556614\n",
      "Epoch 19040/20000 --- Loss: 0.08577687058364829\n",
      "Epoch 19050/20000 --- Loss: 0.08577225647787018\n",
      "Epoch 19060/20000 --- Loss: 0.08573799375200018\n",
      "Epoch 19070/20000 --- Loss: 0.08572621049707055\n",
      "Epoch 19080/20000 --- Loss: 0.0856908265144568\n",
      "Epoch 19090/20000 --- Loss: 0.08566071562423254\n",
      "Epoch 19100/20000 --- Loss: 0.08564137078021358\n",
      "Epoch 19110/20000 --- Loss: 0.08560032905188851\n",
      "Epoch 19120/20000 --- Loss: 0.0855920781051153\n",
      "Epoch 19130/20000 --- Loss: 0.08557369655051082\n",
      "Epoch 19140/20000 --- Loss: 0.08554795973257232\n",
      "Epoch 19150/20000 --- Loss: 0.08552605388142341\n",
      "Epoch 19160/20000 --- Loss: 0.08550515942679382\n",
      "Epoch 19170/20000 --- Loss: 0.08547781265860799\n",
      "Epoch 19180/20000 --- Loss: 0.08546690692824686\n",
      "Epoch 19190/20000 --- Loss: 0.08544495395920451\n",
      "Epoch 19200/20000 --- Loss: 0.08542799991794339\n",
      "Epoch 19210/20000 --- Loss: 0.08541741519993959\n",
      "Epoch 19220/20000 --- Loss: 0.08538020201365235\n",
      "Epoch 19230/20000 --- Loss: 0.085355414632373\n",
      "Epoch 19240/20000 --- Loss: 0.08533301609908357\n",
      "Epoch 19250/20000 --- Loss: 0.08531330938823321\n",
      "Epoch 19260/20000 --- Loss: 0.08528739557050026\n",
      "Epoch 19270/20000 --- Loss: 0.08525690691166499\n",
      "Epoch 19280/20000 --- Loss: 0.08523532435316321\n",
      "Epoch 19290/20000 --- Loss: 0.08522616297162426\n",
      "Epoch 19300/20000 --- Loss: 0.08519293164236715\n",
      "Epoch 19310/20000 --- Loss: 0.0851994008884227\n",
      "Epoch 19320/20000 --- Loss: 0.08518838196653862\n",
      "Epoch 19330/20000 --- Loss: 0.08514923767087187\n",
      "Epoch 19340/20000 --- Loss: 0.0851190053690268\n",
      "Epoch 19350/20000 --- Loss: 0.08508899205657386\n",
      "Epoch 19360/20000 --- Loss: 0.08508352212346205\n",
      "Epoch 19370/20000 --- Loss: 0.08504891281191002\n",
      "Epoch 19380/20000 --- Loss: 0.08501477469275852\n",
      "Epoch 19390/20000 --- Loss: 0.08500501538531888\n",
      "Epoch 19400/20000 --- Loss: 0.08496198912547104\n",
      "Epoch 19410/20000 --- Loss: 0.08492981250459479\n",
      "Epoch 19420/20000 --- Loss: 0.08492230477396638\n",
      "Epoch 19430/20000 --- Loss: 0.0849124817757931\n",
      "Epoch 19440/20000 --- Loss: 0.08488025839511777\n",
      "Epoch 19450/20000 --- Loss: 0.08485282509930685\n",
      "Epoch 19460/20000 --- Loss: 0.08481451464744268\n",
      "Epoch 19470/20000 --- Loss: 0.084786517726679\n",
      "Epoch 19480/20000 --- Loss: 0.0847830364924871\n",
      "Epoch 19490/20000 --- Loss: 0.08475518448539356\n",
      "Epoch 19500/20000 --- Loss: 0.08473292649998378\n",
      "Epoch 19510/20000 --- Loss: 0.08471489499597364\n",
      "Epoch 19520/20000 --- Loss: 0.08470386291555551\n",
      "Epoch 19530/20000 --- Loss: 0.08466905172299104\n",
      "Epoch 19540/20000 --- Loss: 0.08465844130950717\n",
      "Epoch 19550/20000 --- Loss: 0.08462681621452939\n",
      "Epoch 19560/20000 --- Loss: 0.0846006459703106\n",
      "Epoch 19570/20000 --- Loss: 0.0845765052719697\n",
      "Epoch 19580/20000 --- Loss: 0.08456491076263108\n",
      "Epoch 19590/20000 --- Loss: 0.08453909281339794\n",
      "Epoch 19600/20000 --- Loss: 0.08451615104098799\n",
      "Epoch 19610/20000 --- Loss: 0.08448397892885486\n",
      "Epoch 19620/20000 --- Loss: 0.08446149593524026\n",
      "Epoch 19630/20000 --- Loss: 0.08443171444081735\n",
      "Epoch 19640/20000 --- Loss: 0.08440092198523218\n",
      "Epoch 19650/20000 --- Loss: 0.0843989020266509\n",
      "Epoch 19660/20000 --- Loss: 0.08436544016780154\n",
      "Epoch 19670/20000 --- Loss: 0.08433442695512446\n",
      "Epoch 19680/20000 --- Loss: 0.08430885685919812\n",
      "Epoch 19690/20000 --- Loss: 0.0843037338426689\n",
      "Epoch 19700/20000 --- Loss: 0.0842710524396543\n",
      "Epoch 19710/20000 --- Loss: 0.08424512924095294\n",
      "Epoch 19720/20000 --- Loss: 0.08424108578463535\n",
      "Epoch 19730/20000 --- Loss: 0.08419202941806388\n",
      "Epoch 19740/20000 --- Loss: 0.08417221258154102\n",
      "Epoch 19750/20000 --- Loss: 0.08414875965332853\n",
      "Epoch 19760/20000 --- Loss: 0.08412252966119955\n",
      "Epoch 19770/20000 --- Loss: 0.08410337969664937\n",
      "Epoch 19780/20000 --- Loss: 0.08408956925244901\n",
      "Epoch 19790/20000 --- Loss: 0.08405338350083337\n",
      "Epoch 19800/20000 --- Loss: 0.08402927623809912\n",
      "Epoch 19810/20000 --- Loss: 0.08400938346638645\n",
      "Epoch 19820/20000 --- Loss: 0.08398690169601679\n",
      "Epoch 19830/20000 --- Loss: 0.08399301672320669\n",
      "Epoch 19840/20000 --- Loss: 0.08396153138287678\n",
      "Epoch 19850/20000 --- Loss: 0.08393067409215366\n",
      "Epoch 19860/20000 --- Loss: 0.08391071684132183\n",
      "Epoch 19870/20000 --- Loss: 0.08389225275400328\n",
      "Epoch 19880/20000 --- Loss: 0.08386103831080849\n",
      "Epoch 19890/20000 --- Loss: 0.08385295571531105\n",
      "Epoch 19900/20000 --- Loss: 0.0838363180243432\n",
      "Epoch 19910/20000 --- Loss: 0.08381213302982962\n",
      "Epoch 19920/20000 --- Loss: 0.0837819686596757\n",
      "Epoch 19930/20000 --- Loss: 0.08375904003389893\n",
      "Epoch 19940/20000 --- Loss: 0.0837408929414544\n",
      "Epoch 19950/20000 --- Loss: 0.08370902519465254\n",
      "Epoch 19960/20000 --- Loss: 0.08368755800918412\n",
      "Epoch 19970/20000 --- Loss: 0.08368146174446582\n",
      "Epoch 19980/20000 --- Loss: 0.08365898668871048\n",
      "Epoch 19990/20000 --- Loss: 0.0836704776721781\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(X_train.shape[1], 128))  # 64 inputs (8x8 images)\n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Layer(128, 2))  # 1 classes\n",
    "network.add_layer(Sigmoid())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=200, learning_rate=0.01, batch_size=16)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "* L1 and L2 regularizers\n",
    "\n",
    "* validation loss\n",
    "\n",
    "* optimization of hyperparameters (random search and grid search function?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
