{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "236dfa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ReLU layer class\n",
    "class ReLU:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data # store the input to use it in the backward pass\n",
    "        return np.maximum(0, input_data) # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return output_gradient * (self.input > 0)\n",
    "        #return output_gradient * np.where(self.input > 0, 1.0, 0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1d0cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid layer class\n",
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.output = 1 / (1 + np.exp(-input_data)) # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('output_gradient'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        return output_gradient * (self.output * (1 - self.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94c275e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax layer class\n",
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - input_data (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'input_data', with the\n",
    "                         same shape as 'input_data'.\n",
    "        ''' \n",
    "        exp_values = np.exp(input_data - np.max(input_data, axis=1, keepdims=True)) # Shift the input data to avoid numerical instability in exponential calculations\n",
    "        output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return output\n",
    "\n",
    "    def backward_pass(self, dvalues):\n",
    "        # The gradient of loss with respect to the input logits \n",
    "        # directly passed through in case of softmax + categorical cross-entropy\n",
    "        return dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bb61882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:    \n",
    "    def __init__(self, probability):\n",
    "        self.probability = probability\n",
    "        \n",
    "    def forward_pass(self, input_data):\n",
    "        self.mask = np.random.binomial(1, 1-self.probability, size=input_data.shape) / (1-self.probability)\n",
    "        return input_data * self.mask\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        return output_gradient * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3a283b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer class\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = 0.01 * np.random.normal(0, 1/np.sqrt(input_size), (input_size, output_size)) # Normal distribution initialisation\n",
    "        self.biases = np.full((1, output_size), 0.001) # Initialise biases with a small positive value\n",
    "        self.velocity_weights = np.zeros_like(self.weights) # Initialise (weights) velocity terms for momentum optimization\n",
    "        self.velocity_biases = np.zeros_like(self.biases) # Initialise (biases) velocity terms for momentum optimization\n",
    "        self.input = None\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data\n",
    "        return np.dot(input_data, self.weights) + self.biases\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate, optimizer='GD', momentum=0.9):\n",
    "        '''\n",
    "        Computes the backward pass of the Dense layer.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient: The gradient of the loss function with respect to the output of the layer.\n",
    "\n",
    "        - learning_rate: A hyperparameter that controls how much the weights and biases are updated during training.\n",
    "\n",
    "        - optimizer: Specifies the optimization technique to use. Can be 'GD' for standard Gradient Descent or 'Momentum' for Gradient Descent with Momentum.\n",
    "\n",
    "        - momentum: A hyperparameter representing the momentum coefficient, typically between 0 (no momentum) and 1.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: the gradient of the loss with respect to the layer's inputs (which will be passed back to the previous layer in the network).\n",
    "        ''' \n",
    "        weights_gradient = np.dot(self.input.T, output_gradient)\n",
    "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
    "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
    "\n",
    "        if optimizer == 'GD':\n",
    "            # Update weights and biases\n",
    "            self.weights += learning_rate * weights_gradient\n",
    "            self.biases += learning_rate * biases_gradient\n",
    "        elif optimizer == 'Momentum':\n",
    "            # Momentum update for weights and biases\n",
    "            self.velocity_weights = momentum * self.velocity_weights + learning_rate * weights_gradient\n",
    "            self.velocity_biases = momentum * self.velocity_biases + learning_rate * biases_gradient\n",
    "\n",
    "            # Update weights and biases using velocity\n",
    "            self.weights += self.velocity_weights\n",
    "            self.biases += self.velocity_biases\n",
    "\n",
    "        return input_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cc0ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network wrapper class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = [] # placeholder for storing the layers of the network so we can propagate the infomation in a sequential order\n",
    "        self.loss_history = [] # placeholder to store the (train) loss for plotting\n",
    "        self.val_loss_history = [] #placeholder to store the loss function calculated on the validation set for plotting\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        '''\n",
    "        Add the layer to the network\n",
    "        '''\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network. \n",
    "        It sequentially passes the input data through each layer, transforming it according to each layer's operation.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def prediction(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network ignoring the dropout.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            if not isinstance(layer, Dropout):\n",
    "                input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate, optimizer='GD', momentum=0.9):\n",
    "        '''\n",
    "        Performs the backward pass (backpropagation) for training. \n",
    "        It propagates the gradient of the loss function backward through the network, updating weights in the process if the layer is a dense one.\n",
    "        '''\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Layer):\n",
    "                output_gradient = layer.backward_pass(output_gradient, learning_rate, optimizer, momentum)\n",
    "            else:\n",
    "                output_gradient = layer.backward_pass(output_gradient)\n",
    "    \n",
    "    def compute_categorical_cross_entropy_loss(self, y_pred, y_true):\n",
    "        '''\n",
    "        Computes the categorical cross entropy loss\n",
    "        '''\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7) # Clip predictions to prevent log(0)\n",
    "\n",
    "        # Calculate the negative log of the probabilities of the correct class\n",
    "        # Multiply with the one-hot encoded true labels and sum across classes\n",
    "        loss = np.sum(y_true * -np.log(y_pred_clipped), axis=1)\n",
    "\n",
    "        # Average loss over all samples\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def compute_categorical_cross_entropy_gradient(self, y_pred, y_true):\n",
    "        '''\n",
    "        Calculates the gradient of the categorical cross entropy loss with respect to the network's output, assuming that the output layer is the softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - y_pred: Output of the softmax activation function.\n",
    "\n",
    "        - y_true: One-hot encoded label array.\n",
    "        '''\n",
    "        # Assuming y_true is one-hot encoded and y_pred is the output of softmax\n",
    "        y_pred_gradient = (y_pred - y_true) / len(y_pred)\n",
    "        return y_pred_gradient\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, learning_rate=0.001, optimizer='GD', momentum=0.9, batch_size=32, validation_split = 0.2, verbose = 1):\n",
    "        '''\n",
    "        Conducts the training process over a specified number of epochs.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: The input features of the training data.\n",
    "\n",
    "        - y_train: The target output (labels) of the training data.\n",
    "\n",
    "        - epochs: The number of times the entire training dataset is passed forward and backward through the neural network.\n",
    "\n",
    "        - learning_rate: The step size at each iteration while moving toward a minimum of the loss function.\n",
    "\n",
    "        - optimizer: Specifies the optimization technique to use. Can be 'GD' for standard Gradient Descent or 'Momentum' for Gradient Descent with Momentum.\n",
    "\n",
    "        - momentum: A hyperparameter representing the momentum coefficient, typically between 0 (no momentum) and 1.\n",
    "\n",
    "        - batch_size: The number of training examples used in one iteration.\n",
    "\n",
    "        - validation_split: Fraction of the training data to be used as validation data.\n",
    "\n",
    "        - verbose: The mode of verbosity (0 = silent, 1 = update every 10 epochs, 2 = update every epoch).\n",
    "\n",
    "        '''\n",
    "        val_sample_size = int(len(X_train) * validation_split) # calculate validation sample size based on validation split parameter\n",
    "\n",
    "        # Shuffles the indices of the training data to ensure random distribution\n",
    "        indices = np.arange(len(X_train))\n",
    "        np.random.shuffle(indices) \n",
    "        X_train, y_train = X_train[indices], y_train[indices]\n",
    "\n",
    "        X_train, y_train = X_train[val_sample_size:], y_train[val_sample_size:] # splits the data into new training set.\n",
    "        X_val, y_val = X_train[:val_sample_size], y_train[:val_sample_size] # splits the data into new validation set.\n",
    "\n",
    "        n_samples = len(X_train)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Shuffles the indices of the training data at the beginning of each epoch to improve generalisation\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X_train = X_train[indices]\n",
    "            y_train = y_train[indices]\n",
    "\n",
    "            # Processing of the training data in batches\n",
    "            for start_idx in range(0, n_samples, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, n_samples)\n",
    "                batch_x = X_train[start_idx:end_idx]\n",
    "                batch_y = y_train[start_idx:end_idx]\n",
    "\n",
    "                output = self.forward_pass(batch_x) # forward pass to get the output predictions\n",
    "                loss_gradient = self.compute_categorical_cross_entropy_gradient(batch_y, output)\n",
    "                self.backward_pass(loss_gradient, learning_rate, optimizer, momentum) # backward pass to update the network's weights\n",
    "\n",
    "            # Calculate training loss for the epoch\n",
    "            output = self.forward_pass(X_train)\n",
    "            train_loss = self.compute_categorical_cross_entropy_loss(output, y_train)\n",
    "            self.loss_history.append(train_loss)\n",
    "\n",
    "            # Calculate validation loss for the epoch\n",
    "            val_output = self.prediction(X_val)  # ensure dropout is not applied\n",
    "            val_loss = self.compute_categorical_cross_entropy_loss(val_output, y_val)\n",
    "            self.val_loss_history.append(val_loss)\n",
    "\n",
    "            # Printing\n",
    "            if verbose == 1:\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f\"Epoch {epoch}/{epochs} --- Train Loss: {train_loss} --- Val Loss: {val_loss}\")\n",
    "            elif verbose == 2:\n",
    "                print(f\"Epoch {epoch}/{epochs} --- Train Loss: {train_loss} --- Val Loss: {val_loss}\")\n",
    "            epoch += 1\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        Uses the trained network to make predictions on new data (X_test).\n",
    "        '''\n",
    "        output = self.prediction(X_test) # use prediction method to avoid dropout\n",
    "\n",
    "        predictions = np.argmax(output, axis=1) # convert probabilities to class predictions\n",
    "        return predictions\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss history stored in self.loss_history over the epochs.\n",
    "        '''\n",
    "        plt.plot(self.loss_history, label = 'Train Loss')\n",
    "        plt.plot(self.val_loss_history, label = 'Val Loss')\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed3504a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(X):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = X.mean(axis=0)\n",
    "    stds = X.std(axis=0)\n",
    "\n",
    "    # Avoid division by zero in case of a constant feature\n",
    "    stds[stds == 0] = 1\n",
    "\n",
    "    # Standardize each feature\n",
    "    X_standardized = (X - means) / stds\n",
    "    return X_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32d43306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5000 --- Train Loss: 2.302516934270899 --- Val Loss: 2.3025240645358815\n",
      "Epoch 10/5000 --- Train Loss: 2.3020392401394627 --- Val Loss: 2.302328203295099\n",
      "Epoch 20/5000 --- Train Loss: 2.301815531851931 --- Val Loss: 2.3023256682328714\n",
      "Epoch 30/5000 --- Train Loss: 2.301693331439089 --- Val Loss: 2.3022591247586295\n",
      "Epoch 40/5000 --- Train Loss: 2.301633013881055 --- Val Loss: 2.3023505622652625\n",
      "Epoch 50/5000 --- Train Loss: 2.301606487587569 --- Val Loss: 2.3023438768403177\n",
      "Epoch 60/5000 --- Train Loss: 2.301590789765391 --- Val Loss: 2.3023733723660134\n",
      "Epoch 70/5000 --- Train Loss: 2.301583345847871 --- Val Loss: 2.3024093004220907\n",
      "Epoch 80/5000 --- Train Loss: 2.3015787708154334 --- Val Loss: 2.3024587307332025\n",
      "Epoch 90/5000 --- Train Loss: 2.3015783167088864 --- Val Loss: 2.3024702544551685\n",
      "Epoch 100/5000 --- Train Loss: 2.3015768456717636 --- Val Loss: 2.302472406746952\n",
      "Epoch 110/5000 --- Train Loss: 2.3015769002349034 --- Val Loss: 2.3024419504999867\n",
      "Epoch 120/5000 --- Train Loss: 2.301576285937366 --- Val Loss: 2.302478918013778\n",
      "Epoch 130/5000 --- Train Loss: 2.30157594282903 --- Val Loss: 2.302495534474542\n",
      "Epoch 140/5000 --- Train Loss: 2.301576113279619 --- Val Loss: 2.3025013503010516\n",
      "Epoch 150/5000 --- Train Loss: 2.301575868835985 --- Val Loss: 2.302468196469664\n",
      "Epoch 160/5000 --- Train Loss: 2.301575769419444 --- Val Loss: 2.302517563641184\n",
      "Epoch 170/5000 --- Train Loss: 2.3015758668072577 --- Val Loss: 2.302453170948805\n",
      "Epoch 180/5000 --- Train Loss: 2.3015757505980434 --- Val Loss: 2.3025014091052647\n",
      "Epoch 190/5000 --- Train Loss: 2.3015755203757253 --- Val Loss: 2.302496024670478\n",
      "Epoch 200/5000 --- Train Loss: 2.301575650410471 --- Val Loss: 2.30247853034122\n",
      "Epoch 210/5000 --- Train Loss: 2.30157556626059 --- Val Loss: 2.3025595617021017\n",
      "Epoch 220/5000 --- Train Loss: 2.3015754537475765 --- Val Loss: 2.302540917355165\n",
      "Epoch 230/5000 --- Train Loss: 2.3015754235901142 --- Val Loss: 2.3024886152274577\n",
      "Epoch 240/5000 --- Train Loss: 2.3015757572125715 --- Val Loss: 2.3024895780009915\n",
      "Epoch 250/5000 --- Train Loss: 2.301575616502974 --- Val Loss: 2.3025465127102307\n",
      "Epoch 260/5000 --- Train Loss: 2.301575110785338 --- Val Loss: 2.3025600207102657\n",
      "Epoch 270/5000 --- Train Loss: 2.3015751682788586 --- Val Loss: 2.302514967848436\n",
      "Epoch 280/5000 --- Train Loss: 2.301574844076727 --- Val Loss: 2.302468090359142\n",
      "Epoch 290/5000 --- Train Loss: 2.3015750071501624 --- Val Loss: 2.3025125150975305\n",
      "Epoch 300/5000 --- Train Loss: 2.3015750603269756 --- Val Loss: 2.302537202141617\n",
      "Epoch 310/5000 --- Train Loss: 2.3015746054021324 --- Val Loss: 2.3024625563624697\n",
      "Epoch 320/5000 --- Train Loss: 2.3015745439891115 --- Val Loss: 2.3024583667209146\n",
      "Epoch 330/5000 --- Train Loss: 2.3015743522774037 --- Val Loss: 2.3024833431993748\n",
      "Epoch 340/5000 --- Train Loss: 2.3015743480095012 --- Val Loss: 2.302462338359854\n",
      "Epoch 350/5000 --- Train Loss: 2.3015741596398116 --- Val Loss: 2.30252358474941\n",
      "Epoch 360/5000 --- Train Loss: 2.301573937829008 --- Val Loss: 2.3025057449379567\n",
      "Epoch 370/5000 --- Train Loss: 2.3015740897063846 --- Val Loss: 2.3025042105582503\n",
      "Epoch 380/5000 --- Train Loss: 2.3015737052699414 --- Val Loss: 2.3024776472084976\n",
      "Epoch 390/5000 --- Train Loss: 2.3015737290081826 --- Val Loss: 2.302532929747727\n",
      "Epoch 400/5000 --- Train Loss: 2.3015733837835914 --- Val Loss: 2.302550475261191\n",
      "Epoch 410/5000 --- Train Loss: 2.301573520999005 --- Val Loss: 2.3024913867185193\n",
      "Epoch 420/5000 --- Train Loss: 2.3015731621123283 --- Val Loss: 2.302574858542036\n",
      "Epoch 430/5000 --- Train Loss: 2.3015728119273713 --- Val Loss: 2.3024838649215353\n",
      "Epoch 440/5000 --- Train Loss: 2.301572282309243 --- Val Loss: 2.30247358510763\n",
      "Epoch 450/5000 --- Train Loss: 2.301572169112311 --- Val Loss: 2.3024855783502183\n",
      "Epoch 460/5000 --- Train Loss: 2.301571683370671 --- Val Loss: 2.3025064460338953\n",
      "Epoch 470/5000 --- Train Loss: 2.301571516114671 --- Val Loss: 2.3024639894128525\n",
      "Epoch 480/5000 --- Train Loss: 2.3015713106102353 --- Val Loss: 2.30250159155952\n",
      "Epoch 490/5000 --- Train Loss: 2.301570629257714 --- Val Loss: 2.302478393087808\n",
      "Epoch 500/5000 --- Train Loss: 2.301570268321383 --- Val Loss: 2.3024554587786032\n",
      "Epoch 510/5000 --- Train Loss: 2.3015697542103113 --- Val Loss: 2.3024659247775365\n",
      "Epoch 520/5000 --- Train Loss: 2.301569544688187 --- Val Loss: 2.3025232557802537\n",
      "Epoch 530/5000 --- Train Loss: 2.3015688649006583 --- Val Loss: 2.302466832196239\n",
      "Epoch 540/5000 --- Train Loss: 2.301568141956275 --- Val Loss: 2.302455484284619\n",
      "Epoch 550/5000 --- Train Loss: 2.301567421516049 --- Val Loss: 2.3024634807025177\n",
      "Epoch 560/5000 --- Train Loss: 2.301566576849602 --- Val Loss: 2.3024617682119635\n",
      "Epoch 570/5000 --- Train Loss: 2.3015659447626313 --- Val Loss: 2.3025368508508066\n",
      "Epoch 580/5000 --- Train Loss: 2.3015649536342475 --- Val Loss: 2.302520905553948\n",
      "Epoch 590/5000 --- Train Loss: 2.301563492823123 --- Val Loss: 2.302505300901186\n",
      "Epoch 600/5000 --- Train Loss: 2.3015625321266246 --- Val Loss: 2.3024145466645716\n",
      "Epoch 610/5000 --- Train Loss: 2.301560845872642 --- Val Loss: 2.3024697065418542\n",
      "Epoch 620/5000 --- Train Loss: 2.3015592379065364 --- Val Loss: 2.3025115064417063\n",
      "Epoch 630/5000 --- Train Loss: 2.3015573115784997 --- Val Loss: 2.3024875082617635\n",
      "Epoch 640/5000 --- Train Loss: 2.3015551283417555 --- Val Loss: 2.302484810133912\n",
      "Epoch 650/5000 --- Train Loss: 2.3015526131496116 --- Val Loss: 2.3024996443595156\n",
      "Epoch 660/5000 --- Train Loss: 2.3015497994586247 --- Val Loss: 2.3025138035805965\n",
      "Epoch 670/5000 --- Train Loss: 2.3015463468853783 --- Val Loss: 2.3025172480289697\n",
      "Epoch 680/5000 --- Train Loss: 2.301542047795182 --- Val Loss: 2.302461029280222\n",
      "Epoch 690/5000 --- Train Loss: 2.301537076796174 --- Val Loss: 2.3024502514981373\n",
      "Epoch 700/5000 --- Train Loss: 2.301531145867625 --- Val Loss: 2.302392273838441\n",
      "Epoch 710/5000 --- Train Loss: 2.301523777190984 --- Val Loss: 2.30247024664262\n",
      "Epoch 720/5000 --- Train Loss: 2.301515002640193 --- Val Loss: 2.302479759587601\n",
      "Epoch 730/5000 --- Train Loss: 2.301504145823115 --- Val Loss: 2.302399026307415\n",
      "Epoch 740/5000 --- Train Loss: 2.3014901681749573 --- Val Loss: 2.302406805468155\n",
      "Epoch 750/5000 --- Train Loss: 2.301472247966137 --- Val Loss: 2.3024226358200064\n",
      "Epoch 760/5000 --- Train Loss: 2.3014491974122833 --- Val Loss: 2.3023620526382405\n",
      "Epoch 770/5000 --- Train Loss: 2.3014187926376826 --- Val Loss: 2.3024075112107263\n",
      "Epoch 780/5000 --- Train Loss: 2.3013777419082473 --- Val Loss: 2.3023015841499843\n",
      "Epoch 790/5000 --- Train Loss: 2.301320800494907 --- Val Loss: 2.302270547119253\n",
      "Epoch 800/5000 --- Train Loss: 2.3012396169857956 --- Val Loss: 2.302144133279547\n",
      "Epoch 810/5000 --- Train Loss: 2.3011198002310462 --- Val Loss: 2.3019911998584583\n",
      "Epoch 820/5000 --- Train Loss: 2.3009359972664294 --- Val Loss: 2.301832051095972\n",
      "Epoch 830/5000 --- Train Loss: 2.3006370229576607 --- Val Loss: 2.3015173469596233\n",
      "Epoch 840/5000 --- Train Loss: 2.300113073162406 --- Val Loss: 2.3009858714333284\n",
      "Epoch 850/5000 --- Train Loss: 2.2990975630525523 --- Val Loss: 2.2999649629048458\n",
      "Epoch 860/5000 --- Train Loss: 2.296789847850549 --- Val Loss: 2.297544829854042\n",
      "Epoch 870/5000 --- Train Loss: 2.2898383635603397 --- Val Loss: 2.290407462626865\n",
      "Epoch 880/5000 --- Train Loss: 2.253959685522558 --- Val Loss: 2.253987132176163\n",
      "Epoch 890/5000 --- Train Loss: 2.0273095680378694 --- Val Loss: 2.019418568945038\n",
      "Epoch 900/5000 --- Train Loss: 1.8923915697505516 --- Val Loss: 1.879287716153847\n",
      "Epoch 910/5000 --- Train Loss: 1.767600233619869 --- Val Loss: 1.7496892326781004\n",
      "Epoch 920/5000 --- Train Loss: 1.524214954275054 --- Val Loss: 1.4962757670166498\n",
      "Epoch 930/5000 --- Train Loss: 1.2438810654167414 --- Val Loss: 1.2042875468565022\n",
      "Epoch 940/5000 --- Train Loss: 0.9947100152859473 --- Val Loss: 0.9577356387457882\n",
      "Epoch 950/5000 --- Train Loss: 0.805226749086838 --- Val Loss: 0.7846402470230917\n",
      "Epoch 960/5000 --- Train Loss: 0.6788303583466335 --- Val Loss: 0.6729283548593291\n",
      "Epoch 970/5000 --- Train Loss: 0.5691782259305718 --- Val Loss: 0.5726967406082893\n",
      "Epoch 980/5000 --- Train Loss: 0.4730445651996561 --- Val Loss: 0.48054550928723544\n",
      "Epoch 990/5000 --- Train Loss: 0.40479963301569344 --- Val Loss: 0.41329373649449785\n",
      "Epoch 1000/5000 --- Train Loss: 0.35183419665622206 --- Val Loss: 0.36039252259989946\n",
      "Epoch 1010/5000 --- Train Loss: 0.3062800178110252 --- Val Loss: 0.3152551073716152\n",
      "Epoch 1020/5000 --- Train Loss: 0.2654306580575691 --- Val Loss: 0.2761052281055869\n",
      "Epoch 1030/5000 --- Train Loss: 0.22769618921770388 --- Val Loss: 0.23946200073964027\n",
      "Epoch 1040/5000 --- Train Loss: 0.1937929837312333 --- Val Loss: 0.20466242032278986\n",
      "Epoch 1050/5000 --- Train Loss: 0.1648724546525279 --- Val Loss: 0.17456126866617777\n",
      "Epoch 1060/5000 --- Train Loss: 0.1408896086008262 --- Val Loss: 0.14934867787051626\n",
      "Epoch 1070/5000 --- Train Loss: 0.12156994960213781 --- Val Loss: 0.12875820485865225\n",
      "Epoch 1080/5000 --- Train Loss: 0.10548288062944042 --- Val Loss: 0.11023753884939586\n",
      "Epoch 1090/5000 --- Train Loss: 0.09203645459885595 --- Val Loss: 0.09528182930338323\n",
      "Epoch 1100/5000 --- Train Loss: 0.08080691686866102 --- Val Loss: 0.082751606782509\n",
      "Epoch 1110/5000 --- Train Loss: 0.07138546681251853 --- Val Loss: 0.0732836408589821\n",
      "Epoch 1120/5000 --- Train Loss: 0.06350825929351654 --- Val Loss: 0.06480998826059088\n",
      "Epoch 1130/5000 --- Train Loss: 0.056843071801466666 --- Val Loss: 0.05793483347403866\n",
      "Epoch 1140/5000 --- Train Loss: 0.05110877182825978 --- Val Loss: 0.05212801674083256\n",
      "Epoch 1150/5000 --- Train Loss: 0.046183560465280125 --- Val Loss: 0.04684847451609157\n",
      "Epoch 1160/5000 --- Train Loss: 0.04189558389352884 --- Val Loss: 0.04259455296144602\n",
      "Epoch 1170/5000 --- Train Loss: 0.03813320222574263 --- Val Loss: 0.03858723696010076\n",
      "Epoch 1180/5000 --- Train Loss: 0.03475426279104574 --- Val Loss: 0.03484824395304797\n",
      "Epoch 1190/5000 --- Train Loss: 0.03170017415982485 --- Val Loss: 0.0324819774177699\n",
      "Epoch 1200/5000 --- Train Loss: 0.029047821984539847 --- Val Loss: 0.02985299923372563\n",
      "Epoch 1210/5000 --- Train Loss: 0.02669575345643387 --- Val Loss: 0.02752669028092917\n",
      "Epoch 1220/5000 --- Train Loss: 0.024632610162842662 --- Val Loss: 0.025258189399035028\n",
      "Epoch 1230/5000 --- Train Loss: 0.022781528660237825 --- Val Loss: 0.023946683949294643\n",
      "Epoch 1240/5000 --- Train Loss: 0.02112592104450072 --- Val Loss: 0.021974536062889433\n",
      "Epoch 1250/5000 --- Train Loss: 0.019639884507407616 --- Val Loss: 0.02048993312386827\n",
      "Epoch 1260/5000 --- Train Loss: 0.018320395767070542 --- Val Loss: 0.019265580083992467\n",
      "Epoch 1270/5000 --- Train Loss: 0.0171364643305173 --- Val Loss: 0.017932197573569703\n",
      "Epoch 1280/5000 --- Train Loss: 0.01606240157874171 --- Val Loss: 0.016960209160502608\n",
      "Epoch 1290/5000 --- Train Loss: 0.015095927373074604 --- Val Loss: 0.015979791652828146\n",
      "Epoch 1300/5000 --- Train Loss: 0.014212420439926187 --- Val Loss: 0.015025359353890677\n",
      "Epoch 1310/5000 --- Train Loss: 0.013415315136889351 --- Val Loss: 0.014085847124064016\n",
      "Epoch 1320/5000 --- Train Loss: 0.012679588256566966 --- Val Loss: 0.013377442946900894\n",
      "Epoch 1330/5000 --- Train Loss: 0.012011586840379758 --- Val Loss: 0.012774039345936112\n",
      "Epoch 1340/5000 --- Train Loss: 0.011397093733678814 --- Val Loss: 0.012103256210734867\n",
      "Epoch 1350/5000 --- Train Loss: 0.010834282044175643 --- Val Loss: 0.011484333245725103\n",
      "Epoch 1360/5000 --- Train Loss: 0.010316366659500274 --- Val Loss: 0.011022499439266354\n",
      "Epoch 1370/5000 --- Train Loss: 0.009837888445418037 --- Val Loss: 0.010438763914085951\n",
      "Epoch 1380/5000 --- Train Loss: 0.009392818640828542 --- Val Loss: 0.009955922805626847\n",
      "Epoch 1390/5000 --- Train Loss: 0.008979379641433444 --- Val Loss: 0.009538985603665104\n",
      "Epoch 1400/5000 --- Train Loss: 0.00859173799331935 --- Val Loss: 0.00914589203338719\n",
      "Epoch 1410/5000 --- Train Loss: 0.008230162584747439 --- Val Loss: 0.008776501079561422\n",
      "Epoch 1420/5000 --- Train Loss: 0.007874999962585182 --- Val Loss: 0.008456221272431837\n",
      "Epoch 1430/5000 --- Train Loss: 0.00754160774064265 --- Val Loss: 0.008120853456792726\n",
      "Epoch 1440/5000 --- Train Loss: 0.007234626534518393 --- Val Loss: 0.007746973057384978\n",
      "Epoch 1450/5000 --- Train Loss: 0.006949708669403065 --- Val Loss: 0.0075178874665405085\n",
      "Epoch 1460/5000 --- Train Loss: 0.006678901540770908 --- Val Loss: 0.007211998507814742\n",
      "Epoch 1470/5000 --- Train Loss: 0.006427677355104746 --- Val Loss: 0.0069639068227768134\n",
      "Epoch 1480/5000 --- Train Loss: 0.006190929074543477 --- Val Loss: 0.006715965618626952\n",
      "Epoch 1490/5000 --- Train Loss: 0.0059682215241669756 --- Val Loss: 0.0064451797840986225\n",
      "Epoch 1500/5000 --- Train Loss: 0.005758691119967376 --- Val Loss: 0.0062502596206459385\n",
      "Epoch 1510/5000 --- Train Loss: 0.005560517334754555 --- Val Loss: 0.006071442001242456\n",
      "Epoch 1520/5000 --- Train Loss: 0.005376478451733996 --- Val Loss: 0.005859790949455145\n",
      "Epoch 1530/5000 --- Train Loss: 0.005200599528968906 --- Val Loss: 0.005661877570551437\n",
      "Epoch 1540/5000 --- Train Loss: 0.005035073088418037 --- Val Loss: 0.005482353992754951\n",
      "Epoch 1550/5000 --- Train Loss: 0.004877229966980093 --- Val Loss: 0.005332189771154205\n",
      "Epoch 1560/5000 --- Train Loss: 0.004728797436774426 --- Val Loss: 0.005184295494268819\n",
      "Epoch 1570/5000 --- Train Loss: 0.004587583348938073 --- Val Loss: 0.005025784065892657\n",
      "Epoch 1580/5000 --- Train Loss: 0.004452949085107136 --- Val Loss: 0.004885023932694289\n",
      "Epoch 1590/5000 --- Train Loss: 0.00432604041591942 --- Val Loss: 0.004745937146157604\n",
      "Epoch 1600/5000 --- Train Loss: 0.0042036512284041195 --- Val Loss: 0.0046115570431186975\n",
      "Epoch 1610/5000 --- Train Loss: 0.004086759193734899 --- Val Loss: 0.004479507620865461\n",
      "Epoch 1620/5000 --- Train Loss: 0.003975201032017181 --- Val Loss: 0.004370838334094752\n",
      "Epoch 1630/5000 --- Train Loss: 0.003869131418127643 --- Val Loss: 0.004261388053703133\n",
      "Epoch 1640/5000 --- Train Loss: 0.0037674969620754787 --- Val Loss: 0.004170842857055014\n",
      "Epoch 1650/5000 --- Train Loss: 0.0036702086928103524 --- Val Loss: 0.004045815413657328\n",
      "Epoch 1660/5000 --- Train Loss: 0.0035775899130105634 --- Val Loss: 0.0039501420293468715\n",
      "Epoch 1670/5000 --- Train Loss: 0.003488455265700429 --- Val Loss: 0.0038619536143035334\n",
      "Epoch 1680/5000 --- Train Loss: 0.0034030776619370234 --- Val Loss: 0.0037564772029431088\n",
      "Epoch 1690/5000 --- Train Loss: 0.003322062418437504 --- Val Loss: 0.003681459673804462\n",
      "Epoch 1700/5000 --- Train Loss: 0.003243219517417827 --- Val Loss: 0.0035896497980052802\n",
      "Epoch 1710/5000 --- Train Loss: 0.003168100300279358 --- Val Loss: 0.0035185059576964555\n",
      "Epoch 1720/5000 --- Train Loss: 0.0030961590553277257 --- Val Loss: 0.003428709595931955\n",
      "Epoch 1730/5000 --- Train Loss: 0.003027109854562269 --- Val Loss: 0.003357775202096182\n",
      "Epoch 1740/5000 --- Train Loss: 0.0029602199551355237 --- Val Loss: 0.0032931610374154364\n",
      "Epoch 1750/5000 --- Train Loss: 0.0028961830654696667 --- Val Loss: 0.0032166737820421205\n",
      "Epoch 1760/5000 --- Train Loss: 0.0028343376238399716 --- Val Loss: 0.003161394139443656\n",
      "Epoch 1770/5000 --- Train Loss: 0.0027745169439596165 --- Val Loss: 0.0030869989747077326\n",
      "Epoch 1780/5000 --- Train Loss: 0.0027174309681123787 --- Val Loss: 0.003027696594325252\n",
      "Epoch 1790/5000 --- Train Loss: 0.00266266648477036 --- Val Loss: 0.002969152415936513\n",
      "Epoch 1800/5000 --- Train Loss: 0.0026097507571684383 --- Val Loss: 0.002911643396934938\n",
      "Epoch 1810/5000 --- Train Loss: 0.002558131338667682 --- Val Loss: 0.0028557878579658622\n",
      "Epoch 1820/5000 --- Train Loss: 0.0025087204427675005 --- Val Loss: 0.0027984242418741625\n",
      "Epoch 1830/5000 --- Train Loss: 0.002460657374620087 --- Val Loss: 0.002745007245612929\n",
      "Epoch 1840/5000 --- Train Loss: 0.002414092200472518 --- Val Loss: 0.002699620917196267\n",
      "Epoch 1850/5000 --- Train Loss: 0.0023690026360901734 --- Val Loss: 0.002645361836373647\n",
      "Epoch 1860/5000 --- Train Loss: 0.0023253417756188923 --- Val Loss: 0.0026014883171863435\n",
      "Epoch 1870/5000 --- Train Loss: 0.0022831366771731963 --- Val Loss: 0.0025559752903346142\n",
      "Epoch 1880/5000 --- Train Loss: 0.00224204079103847 --- Val Loss: 0.0025103238502675986\n",
      "Epoch 1890/5000 --- Train Loss: 0.002202495930341532 --- Val Loss: 0.0024641196554662905\n",
      "Epoch 1900/5000 --- Train Loss: 0.0021640496851244913 --- Val Loss: 0.0024224204607338875\n",
      "Epoch 1910/5000 --- Train Loss: 0.0021264955752794525 --- Val Loss: 0.002384655429056014\n",
      "Epoch 1920/5000 --- Train Loss: 0.002090431979059663 --- Val Loss: 0.0023458002381783654\n",
      "Epoch 1930/5000 --- Train Loss: 0.002055344121063679 --- Val Loss: 0.0023013599629964016\n",
      "Epoch 1940/5000 --- Train Loss: 0.002021126097264353 --- Val Loss: 0.0022663054090432374\n",
      "Epoch 1950/5000 --- Train Loss: 0.0019879830122745395 --- Val Loss: 0.0022305758482171266\n",
      "Epoch 1960/5000 --- Train Loss: 0.0019555104446385444 --- Val Loss: 0.002195723583854508\n",
      "Epoch 1970/5000 --- Train Loss: 0.001924173429952886 --- Val Loss: 0.0021602727561842033\n",
      "Epoch 1980/5000 --- Train Loss: 0.0018936114653172354 --- Val Loss: 0.002121985435228527\n",
      "Epoch 1990/5000 --- Train Loss: 0.0018635884645162787 --- Val Loss: 0.002093910271040932\n",
      "Epoch 2000/5000 --- Train Loss: 0.001834778300751683 --- Val Loss: 0.002060413073692321\n",
      "Epoch 2010/5000 --- Train Loss: 0.0018064152537502394 --- Val Loss: 0.0020328402682499515\n",
      "Epoch 2020/5000 --- Train Loss: 0.0017790472909388053 --- Val Loss: 0.0020007299289364236\n",
      "Epoch 2030/5000 --- Train Loss: 0.0017523422106121807 --- Val Loss: 0.0019719267732212337\n",
      "Epoch 2040/5000 --- Train Loss: 0.0017264019119898623 --- Val Loss: 0.0019415670596210734\n",
      "Epoch 2050/5000 --- Train Loss: 0.001701074903210464 --- Val Loss: 0.001912747241451254\n",
      "Epoch 2060/5000 --- Train Loss: 0.0016763280940957832 --- Val Loss: 0.0018866925878319712\n",
      "Epoch 2070/5000 --- Train Loss: 0.0016523219463093401 --- Val Loss: 0.001863524457884499\n",
      "Epoch 2080/5000 --- Train Loss: 0.0016289468466413938 --- Val Loss: 0.001833708500675742\n",
      "Epoch 2090/5000 --- Train Loss: 0.0016059600161349317 --- Val Loss: 0.0018092863216330624\n",
      "Epoch 2100/5000 --- Train Loss: 0.001583656717214137 --- Val Loss: 0.0017903550816831264\n",
      "Epoch 2110/5000 --- Train Loss: 0.0015618059572191853 --- Val Loss: 0.001763311364537961\n",
      "Epoch 2120/5000 --- Train Loss: 0.0015406512576516221 --- Val Loss: 0.001739149035543156\n",
      "Epoch 2130/5000 --- Train Loss: 0.0015197796603121083 --- Val Loss: 0.0017141466041465604\n",
      "Epoch 2140/5000 --- Train Loss: 0.0014994980405826925 --- Val Loss: 0.0016921891736559813\n",
      "Epoch 2150/5000 --- Train Loss: 0.0014797047027392454 --- Val Loss: 0.0016679437287442649\n",
      "Epoch 2160/5000 --- Train Loss: 0.0014603030257238183 --- Val Loss: 0.001651638464684039\n",
      "Epoch 2170/5000 --- Train Loss: 0.0014415452439318463 --- Val Loss: 0.001627215153235851\n",
      "Epoch 2180/5000 --- Train Loss: 0.0014229939478991227 --- Val Loss: 0.0016072632041816547\n",
      "Epoch 2190/5000 --- Train Loss: 0.0014049116450481792 --- Val Loss: 0.0015862831559286846\n",
      "Epoch 2200/5000 --- Train Loss: 0.0013872496223628094 --- Val Loss: 0.0015680233039486278\n",
      "Epoch 2210/5000 --- Train Loss: 0.001370005224172287 --- Val Loss: 0.0015491363779303814\n",
      "Epoch 2220/5000 --- Train Loss: 0.0013530339134196503 --- Val Loss: 0.0015297176778759924\n",
      "Epoch 2230/5000 --- Train Loss: 0.0013366222017389424 --- Val Loss: 0.0015125374228111665\n",
      "Epoch 2240/5000 --- Train Loss: 0.001320259286332096 --- Val Loss: 0.0014922379930416112\n",
      "Epoch 2250/5000 --- Train Loss: 0.0013045269192151977 --- Val Loss: 0.0014742771051456571\n",
      "Epoch 2260/5000 --- Train Loss: 0.0012890659426758266 --- Val Loss: 0.001457477064502642\n",
      "Epoch 2270/5000 --- Train Loss: 0.0012737680719406377 --- Val Loss: 0.001441603388753239\n",
      "Epoch 2280/5000 --- Train Loss: 0.0012588508637511055 --- Val Loss: 0.0014239576485836375\n",
      "Epoch 2290/5000 --- Train Loss: 0.0012442869806411725 --- Val Loss: 0.0014077669241262195\n",
      "Epoch 2300/5000 --- Train Loss: 0.0012300827744311604 --- Val Loss: 0.0013932399078676308\n",
      "Epoch 2310/5000 --- Train Loss: 0.0012160160558601029 --- Val Loss: 0.0013781700096449883\n",
      "Epoch 2320/5000 --- Train Loss: 0.0012023770748840071 --- Val Loss: 0.0013612454296106\n",
      "Epoch 2330/5000 --- Train Loss: 0.001188931160332492 --- Val Loss: 0.001346574173961174\n",
      "Epoch 2340/5000 --- Train Loss: 0.001175717708508545 --- Val Loss: 0.0013319029187563612\n",
      "Epoch 2350/5000 --- Train Loss: 0.0011628008511569512 --- Val Loss: 0.0013173749380637782\n",
      "Epoch 2360/5000 --- Train Loss: 0.0011500609132361706 --- Val Loss: 0.0013024229130418445\n",
      "Epoch 2370/5000 --- Train Loss: 0.0011376036756262796 --- Val Loss: 0.0012881721459756337\n",
      "Epoch 2380/5000 --- Train Loss: 0.001125411451917971 --- Val Loss: 0.0012751205659898193\n",
      "Epoch 2390/5000 --- Train Loss: 0.001113503887857542 --- Val Loss: 0.0012641630987897728\n",
      "Epoch 2400/5000 --- Train Loss: 0.0011017212546484308 --- Val Loss: 0.0012485348955340713\n",
      "Epoch 2410/5000 --- Train Loss: 0.00109018011294819 --- Val Loss: 0.0012348383209308507\n",
      "Epoch 2420/5000 --- Train Loss: 0.0010788902427645288 --- Val Loss: 0.0012212574286382992\n",
      "Epoch 2430/5000 --- Train Loss: 0.001067827344030365 --- Val Loss: 0.0012100768338993673\n",
      "Epoch 2440/5000 --- Train Loss: 0.0010568666368670871 --- Val Loss: 0.0011986623741360896\n",
      "Epoch 2450/5000 --- Train Loss: 0.001046186951953613 --- Val Loss: 0.0011860710780595331\n",
      "Epoch 2460/5000 --- Train Loss: 0.0010356204692961927 --- Val Loss: 0.0011740868578878861\n",
      "Epoch 2470/5000 --- Train Loss: 0.0010253059262334957 --- Val Loss: 0.0011631720121419897\n",
      "Epoch 2480/5000 --- Train Loss: 0.0010151932951275018 --- Val Loss: 0.0011522283271163324\n",
      "Epoch 2490/5000 --- Train Loss: 0.0010052369486861046 --- Val Loss: 0.0011419824803088367\n",
      "Epoch 2500/5000 --- Train Loss: 0.0009953662196418656 --- Val Loss: 0.0011285876919653805\n",
      "Epoch 2510/5000 --- Train Loss: 0.000985759344433989 --- Val Loss: 0.001118689101926355\n",
      "Epoch 2520/5000 --- Train Loss: 0.0009762945903894904 --- Val Loss: 0.0011083619175389138\n",
      "Epoch 2530/5000 --- Train Loss: 0.0009670338397167856 --- Val Loss: 0.0010967141269813785\n",
      "Epoch 2540/5000 --- Train Loss: 0.0009578731332545653 --- Val Loss: 0.0010878594925055065\n",
      "Epoch 2550/5000 --- Train Loss: 0.0009488979670636169 --- Val Loss: 0.0010763086791730307\n",
      "Epoch 2560/5000 --- Train Loss: 0.0009399877569592349 --- Val Loss: 0.001066763556856262\n",
      "Epoch 2570/5000 --- Train Loss: 0.0009313109189686062 --- Val Loss: 0.001057698164780335\n",
      "Epoch 2580/5000 --- Train Loss: 0.0009227091809020772 --- Val Loss: 0.0010471444000546622\n",
      "Epoch 2590/5000 --- Train Loss: 0.000914328652573469 --- Val Loss: 0.0010374750731476665\n",
      "Epoch 2600/5000 --- Train Loss: 0.0009060366168493057 --- Val Loss: 0.0010287376024064902\n",
      "Epoch 2610/5000 --- Train Loss: 0.0008979042756280623 --- Val Loss: 0.0010197501810131162\n",
      "Epoch 2620/5000 --- Train Loss: 0.0008898758922709887 --- Val Loss: 0.0010098196394181603\n",
      "Epoch 2630/5000 --- Train Loss: 0.0008819951054680203 --- Val Loss: 0.0010014596324861796\n",
      "Epoch 2640/5000 --- Train Loss: 0.0008742444320687406 --- Val Loss: 0.0009929294100721002\n",
      "Epoch 2650/5000 --- Train Loss: 0.0008665916227638835 --- Val Loss: 0.0009853192970700135\n",
      "Epoch 2660/5000 --- Train Loss: 0.0008590648678313467 --- Val Loss: 0.0009755965109026876\n",
      "Epoch 2670/5000 --- Train Loss: 0.0008516670064599764 --- Val Loss: 0.0009674820855155652\n",
      "Epoch 2680/5000 --- Train Loss: 0.0008443393362885852 --- Val Loss: 0.0009599469516135521\n",
      "Epoch 2690/5000 --- Train Loss: 0.000837185607580521 --- Val Loss: 0.0009522022668591588\n",
      "Epoch 2700/5000 --- Train Loss: 0.0008300922300155945 --- Val Loss: 0.0009439297803512359\n",
      "Epoch 2710/5000 --- Train Loss: 0.0008231471713998208 --- Val Loss: 0.0009348231880682944\n",
      "Epoch 2720/5000 --- Train Loss: 0.0008162704505781619 --- Val Loss: 0.0009271813244559129\n",
      "Epoch 2730/5000 --- Train Loss: 0.000809533872861271 --- Val Loss: 0.0009193885357222508\n",
      "Epoch 2740/5000 --- Train Loss: 0.0008028123779370457 --- Val Loss: 0.0009130366995141066\n",
      "Epoch 2750/5000 --- Train Loss: 0.0007962625414098737 --- Val Loss: 0.0009053147094315915\n",
      "Epoch 2760/5000 --- Train Loss: 0.0007897835446947216 --- Val Loss: 0.0008975123383200004\n",
      "Epoch 2770/5000 --- Train Loss: 0.0007834189280841226 --- Val Loss: 0.0008907350288327508\n",
      "Epoch 2780/5000 --- Train Loss: 0.000777107327391423 --- Val Loss: 0.0008847117030828048\n",
      "Epoch 2790/5000 --- Train Loss: 0.0007709255638192228 --- Val Loss: 0.0008764628551691993\n",
      "Epoch 2800/5000 --- Train Loss: 0.0007648037633374538 --- Val Loss: 0.0008704911932994362\n",
      "Epoch 2810/5000 --- Train Loss: 0.0007587818989839735 --- Val Loss: 0.0008628849609851883\n",
      "Epoch 2820/5000 --- Train Loss: 0.0007527987881754211 --- Val Loss: 0.0008565647838483093\n",
      "Epoch 2830/5000 --- Train Loss: 0.0007469524564557695 --- Val Loss: 0.0008503695971033827\n",
      "Epoch 2840/5000 --- Train Loss: 0.0007411686960928708 --- Val Loss: 0.0008437508791287396\n",
      "Epoch 2850/5000 --- Train Loss: 0.0007354703395596529 --- Val Loss: 0.000837335419165238\n",
      "Epoch 2860/5000 --- Train Loss: 0.0007298412289314987 --- Val Loss: 0.000830298865732539\n",
      "Epoch 2870/5000 --- Train Loss: 0.000724316222107295 --- Val Loss: 0.0008244372404752894\n",
      "Epoch 2880/5000 --- Train Loss: 0.0007188108783010347 --- Val Loss: 0.0008187897177993393\n",
      "Epoch 2890/5000 --- Train Loss: 0.0007134159547315254 --- Val Loss: 0.0008125539609913989\n",
      "Epoch 2900/5000 --- Train Loss: 0.0007080726615937606 --- Val Loss: 0.0008066542512564312\n",
      "Epoch 2910/5000 --- Train Loss: 0.0007028583334303855 --- Val Loss: 0.0008003114143118208\n",
      "Epoch 2920/5000 --- Train Loss: 0.0006976702881164814 --- Val Loss: 0.0007943184213110943\n",
      "Epoch 2930/5000 --- Train Loss: 0.0006925451972520946 --- Val Loss: 0.0007891256588221651\n",
      "Epoch 2940/5000 --- Train Loss: 0.0006874958852023105 --- Val Loss: 0.0007834579416154893\n",
      "Epoch 2950/5000 --- Train Loss: 0.0006824996047119994 --- Val Loss: 0.0007773914359443102\n",
      "Epoch 2960/5000 --- Train Loss: 0.0006775629561617783 --- Val Loss: 0.0007722437391288016\n",
      "Epoch 2970/5000 --- Train Loss: 0.0006727133921697022 --- Val Loss: 0.0007661649732494919\n",
      "Epoch 2980/5000 --- Train Loss: 0.000667898675099633 --- Val Loss: 0.0007615003174167978\n",
      "Epoch 2990/5000 --- Train Loss: 0.0006631697712254606 --- Val Loss: 0.0007556443364068073\n",
      "Epoch 3000/5000 --- Train Loss: 0.0006584912954046088 --- Val Loss: 0.0007507638558885569\n",
      "Epoch 3010/5000 --- Train Loss: 0.0006538854401284053 --- Val Loss: 0.0007456352122646955\n",
      "Epoch 3020/5000 --- Train Loss: 0.0006493319299249464 --- Val Loss: 0.0007404634966979133\n",
      "Epoch 3030/5000 --- Train Loss: 0.0006448467463078082 --- Val Loss: 0.0007345357577830554\n",
      "Epoch 3040/5000 --- Train Loss: 0.0006403953618490928 --- Val Loss: 0.0007303248537848117\n",
      "Epoch 3050/5000 --- Train Loss: 0.0006359939485292018 --- Val Loss: 0.0007248591821004152\n",
      "Epoch 3060/5000 --- Train Loss: 0.0006316586701273267 --- Val Loss: 0.0007204902482215263\n",
      "Epoch 3070/5000 --- Train Loss: 0.000627382332392221 --- Val Loss: 0.0007161553335285028\n",
      "Epoch 3080/5000 --- Train Loss: 0.000623129086721954 --- Val Loss: 0.0007104166538141415\n",
      "Epoch 3090/5000 --- Train Loss: 0.0006189587372591548 --- Val Loss: 0.0007061449494760439\n",
      "Epoch 3100/5000 --- Train Loss: 0.0006148208735112646 --- Val Loss: 0.0007013387800992477\n",
      "Epoch 3110/5000 --- Train Loss: 0.000610746945771996 --- Val Loss: 0.0006969901271215492\n",
      "Epoch 3120/5000 --- Train Loss: 0.0006067144080414707 --- Val Loss: 0.0006922320990034909\n",
      "Epoch 3130/5000 --- Train Loss: 0.0006027223265276393 --- Val Loss: 0.0006877525985754057\n",
      "Epoch 3140/5000 --- Train Loss: 0.0005987876660589129 --- Val Loss: 0.0006832517282487802\n",
      "Epoch 3150/5000 --- Train Loss: 0.0005948786921029269 --- Val Loss: 0.0006785257642299833\n",
      "Epoch 3160/5000 --- Train Loss: 0.0005910441524933956 --- Val Loss: 0.0006743152318464782\n",
      "Epoch 3170/5000 --- Train Loss: 0.0005872435629161653 --- Val Loss: 0.0006699696220435813\n",
      "Epoch 3180/5000 --- Train Loss: 0.0005835013691451208 --- Val Loss: 0.0006661905942219845\n",
      "Epoch 3190/5000 --- Train Loss: 0.0005797883273497125 --- Val Loss: 0.000661707521555744\n",
      "Epoch 3200/5000 --- Train Loss: 0.0005761219252927692 --- Val Loss: 0.0006575922392584794\n",
      "Epoch 3210/5000 --- Train Loss: 0.0005724871778344739 --- Val Loss: 0.000653227455693522\n",
      "Epoch 3220/5000 --- Train Loss: 0.0005688870762872946 --- Val Loss: 0.0006494545232451226\n",
      "Epoch 3230/5000 --- Train Loss: 0.0005653586454792729 --- Val Loss: 0.000645398602704077\n",
      "Epoch 3240/5000 --- Train Loss: 0.0005618258438540161 --- Val Loss: 0.0006413916277940966\n",
      "Epoch 3250/5000 --- Train Loss: 0.0005583748620171617 --- Val Loss: 0.0006372323979526044\n",
      "Epoch 3260/5000 --- Train Loss: 0.0005549403566822875 --- Val Loss: 0.0006337699754120664\n",
      "Epoch 3270/5000 --- Train Loss: 0.0005515431930106698 --- Val Loss: 0.0006297698161613437\n",
      "Epoch 3280/5000 --- Train Loss: 0.0005481898877301606 --- Val Loss: 0.0006257496414332521\n",
      "Epoch 3290/5000 --- Train Loss: 0.0005448658245337935 --- Val Loss: 0.0006223015587270517\n",
      "Epoch 3300/5000 --- Train Loss: 0.0005415839492164134 --- Val Loss: 0.0006188993169127647\n",
      "Epoch 3310/5000 --- Train Loss: 0.0005383222495744996 --- Val Loss: 0.0006149060719258942\n",
      "Epoch 3320/5000 --- Train Loss: 0.0005351230604190763 --- Val Loss: 0.0006108831958996806\n",
      "Epoch 3330/5000 --- Train Loss: 0.0005319385113297289 --- Val Loss: 0.0006077427516313197\n",
      "Epoch 3340/5000 --- Train Loss: 0.0005287926608878068 --- Val Loss: 0.0006040683274598381\n",
      "Epoch 3350/5000 --- Train Loss: 0.0005256617775373207 --- Val Loss: 0.0006003534279686123\n",
      "Epoch 3360/5000 --- Train Loss: 0.0005226035625947308 --- Val Loss: 0.0005964970944322438\n",
      "Epoch 3370/5000 --- Train Loss: 0.0005195469299511652 --- Val Loss: 0.0005934667026147907\n",
      "Epoch 3380/5000 --- Train Loss: 0.000516543697653611 --- Val Loss: 0.0005897248745694361\n",
      "Epoch 3390/5000 --- Train Loss: 0.0005135490943080998 --- Val Loss: 0.0005866274680000578\n",
      "Epoch 3400/5000 --- Train Loss: 0.0005105929325441508 --- Val Loss: 0.0005833001203540585\n",
      "Epoch 3410/5000 --- Train Loss: 0.0005076770692844134 --- Val Loss: 0.0005797424023033387\n",
      "Epoch 3420/5000 --- Train Loss: 0.0005047960132023974 --- Val Loss: 0.0005770174137825017\n",
      "Epoch 3430/5000 --- Train Loss: 0.0005019193208679159 --- Val Loss: 0.0005734020888686637\n",
      "Epoch 3440/5000 --- Train Loss: 0.0004990810289818326 --- Val Loss: 0.0005703966496715351\n",
      "Epoch 3450/5000 --- Train Loss: 0.0004962806557705651 --- Val Loss: 0.0005670083778733163\n",
      "Epoch 3460/5000 --- Train Loss: 0.0004934980506404704 --- Val Loss: 0.0005635045180919724\n",
      "Epoch 3470/5000 --- Train Loss: 0.0004907563264204892 --- Val Loss: 0.0005605290282421883\n",
      "Epoch 3480/5000 --- Train Loss: 0.0004880235828617182 --- Val Loss: 0.0005576785233700443\n",
      "Epoch 3490/5000 --- Train Loss: 0.0004853266326060353 --- Val Loss: 0.0005547823731379497\n",
      "Epoch 3500/5000 --- Train Loss: 0.0004826600410125239 --- Val Loss: 0.0005518318869974847\n",
      "Epoch 3510/5000 --- Train Loss: 0.000480015765499375 --- Val Loss: 0.0005487162417508601\n",
      "Epoch 3520/5000 --- Train Loss: 0.000477414727139238 --- Val Loss: 0.0005455633789224317\n",
      "Epoch 3530/5000 --- Train Loss: 0.00047481149388207256 --- Val Loss: 0.0005431646680253404\n",
      "Epoch 3540/5000 --- Train Loss: 0.0004722365848544145 --- Val Loss: 0.0005398567323436014\n",
      "Epoch 3550/5000 --- Train Loss: 0.0004696915510376839 --- Val Loss: 0.0005369440736738834\n",
      "Epoch 3560/5000 --- Train Loss: 0.00046715237536396905 --- Val Loss: 0.0005339808379212151\n",
      "Epoch 3570/5000 --- Train Loss: 0.0004646454737154675 --- Val Loss: 0.0005312645516587747\n",
      "Epoch 3580/5000 --- Train Loss: 0.0004621586449750488 --- Val Loss: 0.0005278342161932067\n",
      "Epoch 3590/5000 --- Train Loss: 0.0004597037509885961 --- Val Loss: 0.0005252519223187024\n",
      "Epoch 3600/5000 --- Train Loss: 0.0004572545207432709 --- Val Loss: 0.0005224391900201742\n",
      "Epoch 3610/5000 --- Train Loss: 0.0004548411379629608 --- Val Loss: 0.0005198354920569292\n",
      "Epoch 3620/5000 --- Train Loss: 0.00045246132910103525 --- Val Loss: 0.0005170135402761306\n",
      "Epoch 3630/5000 --- Train Loss: 0.0004500827998430788 --- Val Loss: 0.0005141463892557552\n",
      "Epoch 3640/5000 --- Train Loss: 0.00044774032316065174 --- Val Loss: 0.0005114623742350003\n",
      "Epoch 3650/5000 --- Train Loss: 0.00044542062525634575 --- Val Loss: 0.0005090507437601727\n",
      "Epoch 3660/5000 --- Train Loss: 0.0004431142785100702 --- Val Loss: 0.0005061145142892534\n",
      "Epoch 3670/5000 --- Train Loss: 0.0004408400000170236 --- Val Loss: 0.0005035721265982021\n",
      "Epoch 3680/5000 --- Train Loss: 0.00043857619568033244 --- Val Loss: 0.0005008531142939542\n",
      "Epoch 3690/5000 --- Train Loss: 0.0004363451865265483 --- Val Loss: 0.0004981982610838147\n",
      "Epoch 3700/5000 --- Train Loss: 0.0004341417962309933 --- Val Loss: 0.0004957580649276487\n",
      "Epoch 3710/5000 --- Train Loss: 0.0004319273426076903 --- Val Loss: 0.0004932852525540482\n",
      "Epoch 3720/5000 --- Train Loss: 0.0004297617695865444 --- Val Loss: 0.0004908290583709\n",
      "Epoch 3730/5000 --- Train Loss: 0.0004276062690488415 --- Val Loss: 0.0004885335554270725\n",
      "Epoch 3740/5000 --- Train Loss: 0.00042546371811441326 --- Val Loss: 0.00048590448870728585\n",
      "Epoch 3750/5000 --- Train Loss: 0.0004233441877663218 --- Val Loss: 0.00048354608976722665\n",
      "Epoch 3760/5000 --- Train Loss: 0.0004212340751603402 --- Val Loss: 0.00048118904361069137\n",
      "Epoch 3770/5000 --- Train Loss: 0.0004191657144166405 --- Val Loss: 0.00047856473350651893\n",
      "Epoch 3780/5000 --- Train Loss: 0.0004170974551628007 --- Val Loss: 0.00047646668566427356\n",
      "Epoch 3790/5000 --- Train Loss: 0.0004150521218672653 --- Val Loss: 0.000473850353486973\n",
      "Epoch 3800/5000 --- Train Loss: 0.0004130268179484867 --- Val Loss: 0.0004719976170833997\n",
      "Epoch 3810/5000 --- Train Loss: 0.00041101713210652696 --- Val Loss: 0.00046954994511444275\n",
      "Epoch 3820/5000 --- Train Loss: 0.00040902187981238606 --- Val Loss: 0.00046724045824508376\n",
      "Epoch 3830/5000 --- Train Loss: 0.00040706703032948144 --- Val Loss: 0.0004647609628325094\n",
      "Epoch 3840/5000 --- Train Loss: 0.00040510692701284905 --- Val Loss: 0.00046263075048034384\n",
      "Epoch 3850/5000 --- Train Loss: 0.0004031672595363929 --- Val Loss: 0.0004606974511700342\n",
      "Epoch 3860/5000 --- Train Loss: 0.0004012476075721843 --- Val Loss: 0.0004584046836903699\n",
      "Epoch 3870/5000 --- Train Loss: 0.0003993336837825104 --- Val Loss: 0.00045618384051881013\n",
      "Epoch 3880/5000 --- Train Loss: 0.0003974429159948466 --- Val Loss: 0.0004540574402484047\n",
      "Epoch 3890/5000 --- Train Loss: 0.0003955760734582205 --- Val Loss: 0.0004517617132377235\n",
      "Epoch 3900/5000 --- Train Loss: 0.0003937175078518843 --- Val Loss: 0.0004496890165842635\n",
      "Epoch 3910/5000 --- Train Loss: 0.0003918676010128613 --- Val Loss: 0.0004477010801296418\n",
      "Epoch 3920/5000 --- Train Loss: 0.00039005067720149065 --- Val Loss: 0.0004455309908846324\n",
      "Epoch 3930/5000 --- Train Loss: 0.0003882365558688158 --- Val Loss: 0.0004436711581830709\n",
      "Epoch 3940/5000 --- Train Loss: 0.0003864452614495098 --- Val Loss: 0.00044146291157827814\n",
      "Epoch 3950/5000 --- Train Loss: 0.00038466215242086485 --- Val Loss: 0.0004393740802048339\n",
      "Epoch 3960/5000 --- Train Loss: 0.00038289191900663794 --- Val Loss: 0.00043743899030685167\n",
      "Epoch 3970/5000 --- Train Loss: 0.0003811494900003349 --- Val Loss: 0.00043552540411484594\n",
      "Epoch 3980/5000 --- Train Loss: 0.00037940996325181993 --- Val Loss: 0.00043342788118882813\n",
      "Epoch 3990/5000 --- Train Loss: 0.0003776814367239573 --- Val Loss: 0.0004316528269471801\n",
      "Epoch 4000/5000 --- Train Loss: 0.000375978955103968 --- Val Loss: 0.0004298245026892397\n",
      "Epoch 4010/5000 --- Train Loss: 0.000374272961026064 --- Val Loss: 0.000427642212434209\n",
      "Epoch 4020/5000 --- Train Loss: 0.00037259762146973484 --- Val Loss: 0.0004258319001929591\n",
      "Epoch 4030/5000 --- Train Loss: 0.0003709292333858472 --- Val Loss: 0.0004237923101015091\n",
      "Epoch 4040/5000 --- Train Loss: 0.00036927961495425806 --- Val Loss: 0.00042194707711944613\n",
      "Epoch 4050/5000 --- Train Loss: 0.0003676394959767051 --- Val Loss: 0.00042000381044056927\n",
      "Epoch 4060/5000 --- Train Loss: 0.0003660130297160351 --- Val Loss: 0.0004182178254752205\n",
      "Epoch 4070/5000 --- Train Loss: 0.00036439419029983864 --- Val Loss: 0.00041641631229266093\n",
      "Epoch 4080/5000 --- Train Loss: 0.00036279552057130347 --- Val Loss: 0.0004146395712344204\n",
      "Epoch 4090/5000 --- Train Loss: 0.00036120811120772073 --- Val Loss: 0.00041263414456078293\n",
      "Epoch 4100/5000 --- Train Loss: 0.0003596275009750671 --- Val Loss: 0.00041089545802415126\n",
      "Epoch 4110/5000 --- Train Loss: 0.00035805970976810804 --- Val Loss: 0.0004090651498208359\n",
      "Epoch 4120/5000 --- Train Loss: 0.0003565141986756449 --- Val Loss: 0.00040749077167013495\n",
      "Epoch 4130/5000 --- Train Loss: 0.0003549660124112079 --- Val Loss: 0.00040562631163477904\n",
      "Epoch 4140/5000 --- Train Loss: 0.00035344087348798876 --- Val Loss: 0.00040374672231415876\n",
      "Epoch 4150/5000 --- Train Loss: 0.00035192293272226266 --- Val Loss: 0.0004021750330485464\n",
      "Epoch 4160/5000 --- Train Loss: 0.0003504273554988851 --- Val Loss: 0.0004003223818394771\n",
      "Epoch 4170/5000 --- Train Loss: 0.00034892506507686315 --- Val Loss: 0.0003988462979529967\n",
      "Epoch 4180/5000 --- Train Loss: 0.0003474404196984559 --- Val Loss: 0.0003969602769069799\n",
      "Epoch 4190/5000 --- Train Loss: 0.0003459741473786768 --- Val Loss: 0.00039543130613474637\n",
      "Epoch 4200/5000 --- Train Loss: 0.0003445181298645925 --- Val Loss: 0.00039368598662714875\n",
      "Epoch 4210/5000 --- Train Loss: 0.0003430659038481557 --- Val Loss: 0.0003920748025633905\n",
      "Epoch 4220/5000 --- Train Loss: 0.00034162872897510735 --- Val Loss: 0.00039040150038314813\n",
      "Epoch 4230/5000 --- Train Loss: 0.0003402039364061722 --- Val Loss: 0.00038887163249080593\n",
      "Epoch 4240/5000 --- Train Loss: 0.00033879261492734513 --- Val Loss: 0.00038723146886329794\n",
      "Epoch 4250/5000 --- Train Loss: 0.0003373800025926921 --- Val Loss: 0.0003856610607156325\n",
      "Epoch 4260/5000 --- Train Loss: 0.0003359907352878188 --- Val Loss: 0.000384214463841118\n",
      "Epoch 4270/5000 --- Train Loss: 0.00033460757634230895 --- Val Loss: 0.00038258587822149857\n",
      "Epoch 4280/5000 --- Train Loss: 0.0003332300923582435 --- Val Loss: 0.0003809119910274281\n",
      "Epoch 4290/5000 --- Train Loss: 0.00033186372063940666 --- Val Loss: 0.00037936580564833493\n",
      "Epoch 4300/5000 --- Train Loss: 0.00033051581167006046 --- Val Loss: 0.00037776257884766947\n",
      "Epoch 4310/5000 --- Train Loss: 0.00032917613259326306 --- Val Loss: 0.00037647386504796663\n",
      "Epoch 4320/5000 --- Train Loss: 0.0003278344068108605 --- Val Loss: 0.00037489629594771116\n",
      "Epoch 4330/5000 --- Train Loss: 0.00032651405815739944 --- Val Loss: 0.0003732917376328028\n",
      "Epoch 4340/5000 --- Train Loss: 0.00032520470823909893 --- Val Loss: 0.00037191756363310106\n",
      "Epoch 4350/5000 --- Train Loss: 0.0003238913527957248 --- Val Loss: 0.0003703667060291278\n",
      "Epoch 4360/5000 --- Train Loss: 0.00032260519717564604 --- Val Loss: 0.00036870769144663716\n",
      "Epoch 4370/5000 --- Train Loss: 0.00032131264479903413 --- Val Loss: 0.00036730248629966163\n",
      "Epoch 4380/5000 --- Train Loss: 0.0003200396242375236 --- Val Loss: 0.0003658356401350789\n",
      "Epoch 4390/5000 --- Train Loss: 0.0003187757155035034 --- Val Loss: 0.0003644752833706778\n",
      "Epoch 4400/5000 --- Train Loss: 0.0003175065646202914 --- Val Loss: 0.00036291423223395905\n",
      "Epoch 4410/5000 --- Train Loss: 0.0003162631015612352 --- Val Loss: 0.0003614944673749168\n",
      "Epoch 4420/5000 --- Train Loss: 0.0003150207619964572 --- Val Loss: 0.00035987338956603837\n",
      "Epoch 4430/5000 --- Train Loss: 0.0003137893790635505 --- Val Loss: 0.0003586472212596929\n",
      "Epoch 4440/5000 --- Train Loss: 0.00031257382618690824 --- Val Loss: 0.00035736948320547185\n",
      "Epoch 4450/5000 --- Train Loss: 0.0003113514085376953 --- Val Loss: 0.00035594565303770923\n",
      "Epoch 4460/5000 --- Train Loss: 0.00031015450699649685 --- Val Loss: 0.00035467386193509584\n",
      "Epoch 4470/5000 --- Train Loss: 0.00030895272429656037 --- Val Loss: 0.0003532907873836631\n",
      "Epoch 4480/5000 --- Train Loss: 0.00030775817329018455 --- Val Loss: 0.00035182433345567267\n",
      "Epoch 4490/5000 --- Train Loss: 0.00030658439375056 --- Val Loss: 0.00035036210427007386\n",
      "Epoch 4500/5000 --- Train Loss: 0.00030540874842470997 --- Val Loss: 0.0003491704711461241\n",
      "Epoch 4510/5000 --- Train Loss: 0.0003042502465960604 --- Val Loss: 0.00034773968338774696\n",
      "Epoch 4520/5000 --- Train Loss: 0.00030309010413037067 --- Val Loss: 0.00034650291889649313\n",
      "Epoch 4530/5000 --- Train Loss: 0.00030194538594728257 --- Val Loss: 0.00034500824323134506\n",
      "Epoch 4540/5000 --- Train Loss: 0.00030080262732931737 --- Val Loss: 0.0003437959204334065\n",
      "Epoch 4550/5000 --- Train Loss: 0.0002996733132916509 --- Val Loss: 0.00034252045041753744\n",
      "Epoch 4560/5000 --- Train Loss: 0.0002985498869170689 --- Val Loss: 0.00034114117390437077\n",
      "Epoch 4570/5000 --- Train Loss: 0.0002974284974242818 --- Val Loss: 0.00033985575226602656\n",
      "Epoch 4580/5000 --- Train Loss: 0.000296322147735656 --- Val Loss: 0.000338643847552338\n",
      "Epoch 4590/5000 --- Train Loss: 0.00029522103448755043 --- Val Loss: 0.0003373487222216825\n",
      "Epoch 4600/5000 --- Train Loss: 0.0002941242615360083 --- Val Loss: 0.00033620099290452166\n",
      "Epoch 4610/5000 --- Train Loss: 0.0002930392493171639 --- Val Loss: 0.0003350115118347567\n",
      "Epoch 4620/5000 --- Train Loss: 0.00029196246732284665 --- Val Loss: 0.0003337574316845377\n",
      "Epoch 4630/5000 --- Train Loss: 0.00029088298156700054 --- Val Loss: 0.00033245519970888403\n",
      "Epoch 4640/5000 --- Train Loss: 0.0002898187167703978 --- Val Loss: 0.00033120609081710407\n",
      "Epoch 4650/5000 --- Train Loss: 0.00028875936728042323 --- Val Loss: 0.00033009142665212354\n",
      "Epoch 4660/5000 --- Train Loss: 0.0002877105811639418 --- Val Loss: 0.00032887445013001816\n",
      "Epoch 4670/5000 --- Train Loss: 0.0002866675456528139 --- Val Loss: 0.00032770059871846705\n",
      "Epoch 4680/5000 --- Train Loss: 0.0002856260247339219 --- Val Loss: 0.0003264139618309555\n",
      "Epoch 4690/5000 --- Train Loss: 0.0002845988892146581 --- Val Loss: 0.00032516721055433114\n",
      "Epoch 4700/5000 --- Train Loss: 0.00028357629861676696 --- Val Loss: 0.0003240061399261266\n",
      "Epoch 4710/5000 --- Train Loss: 0.00028255591128463297 --- Val Loss: 0.0003229932516350145\n",
      "Epoch 4720/5000 --- Train Loss: 0.0002815512561934269 --- Val Loss: 0.0003215580234422915\n",
      "Epoch 4730/5000 --- Train Loss: 0.0002805408533646315 --- Val Loss: 0.0003206437672112378\n",
      "Epoch 4740/5000 --- Train Loss: 0.00027954337958016476 --- Val Loss: 0.0003195633251929873\n",
      "Epoch 4750/5000 --- Train Loss: 0.0002785547431065036 --- Val Loss: 0.0003184095144710882\n",
      "Epoch 4760/5000 --- Train Loss: 0.0002775631403902363 --- Val Loss: 0.0003172228185154604\n",
      "Epoch 4770/5000 --- Train Loss: 0.0002765900752627877 --- Val Loss: 0.0003161053973999238\n",
      "Epoch 4780/5000 --- Train Loss: 0.00027561864876381957 --- Val Loss: 0.0003150951018085565\n",
      "Epoch 4790/5000 --- Train Loss: 0.00027464726219654403 --- Val Loss: 0.0003139190978711803\n",
      "Epoch 4800/5000 --- Train Loss: 0.00027369286034364373 --- Val Loss: 0.0003129048622453224\n",
      "Epoch 4810/5000 --- Train Loss: 0.00027273974149118294 --- Val Loss: 0.00031186753636351324\n",
      "Epoch 4820/5000 --- Train Loss: 0.0002717889238116013 --- Val Loss: 0.00031055724257170034\n",
      "Epoch 4830/5000 --- Train Loss: 0.0002708458811908834 --- Val Loss: 0.000309544281329412\n",
      "Epoch 4840/5000 --- Train Loss: 0.0002699109600455161 --- Val Loss: 0.0003084789029840441\n",
      "Epoch 4850/5000 --- Train Loss: 0.0002689738340092128 --- Val Loss: 0.00030742072178415933\n",
      "Epoch 4860/5000 --- Train Loss: 0.00026805314955968715 --- Val Loss: 0.0003063002211702181\n",
      "Epoch 4870/5000 --- Train Loss: 0.0002671346321915918 --- Val Loss: 0.00030530690675395554\n",
      "Epoch 4880/5000 --- Train Loss: 0.00026622211579562004 --- Val Loss: 0.0003043810870810794\n",
      "Epoch 4890/5000 --- Train Loss: 0.0002653107873522354 --- Val Loss: 0.00030328610287262984\n",
      "Epoch 4900/5000 --- Train Loss: 0.00026441385478214705 --- Val Loss: 0.0003020786566742944\n",
      "Epoch 4910/5000 --- Train Loss: 0.00026351648693919626 --- Val Loss: 0.00030121360935922166\n",
      "Epoch 4920/5000 --- Train Loss: 0.00026262430928187066 --- Val Loss: 0.0003001269251901902\n",
      "Epoch 4930/5000 --- Train Loss: 0.00026173624934631165 --- Val Loss: 0.0002991326972055368\n",
      "Epoch 4940/5000 --- Train Loss: 0.0002608571297547028 --- Val Loss: 0.00029821105424968433\n",
      "Epoch 4950/5000 --- Train Loss: 0.00025998148169890386 --- Val Loss: 0.0002972248409535475\n",
      "Epoch 4960/5000 --- Train Loss: 0.0002591172495373668 --- Val Loss: 0.0002962055861499899\n",
      "Epoch 4970/5000 --- Train Loss: 0.00025824989659942925 --- Val Loss: 0.00029523978421091196\n",
      "Epoch 4980/5000 --- Train Loss: 0.0002573926166589682 --- Val Loss: 0.0002942575629615131\n",
      "Epoch 4990/5000 --- Train Loss: 0.00025653735022313916 --- Val Loss: 0.0002931974447852781\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9416666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(64, 32))  # 64 inputs (8x8 images)\n",
    "network.add_layer(ReLU())\n",
    "#network.add_layer(Dropout(0.25))\n",
    "#network.add_layer(Layer(64, 32)) \n",
    "#network.add_layer(ReLU())\n",
    "network.add_layer(Layer(32, 16)) \n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Layer(16, 10))  # 10 classes\n",
    "network.add_layer(Softmax())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=5000, learning_rate=0.001, optimizer='Momentum', batch_size=32)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1) # transoform back the One-Hot encoded array of the labels\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72fcf0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000 --- Train Loss: 0.692526446734064 --- Val Loss: 0.6925381460102188\n",
      "Epoch 10/10000 --- Train Loss: 0.6916529686920545 --- Val Loss: 0.6917987565804504\n",
      "Epoch 20/10000 --- Train Loss: 0.6908028991808802 --- Val Loss: 0.6910809483032538\n",
      "Epoch 30/10000 --- Train Loss: 0.6899815241278681 --- Val Loss: 0.6903890314026777\n",
      "Epoch 40/10000 --- Train Loss: 0.6891802879490837 --- Val Loss: 0.6897156431405702\n",
      "Epoch 50/10000 --- Train Loss: 0.6883936266478913 --- Val Loss: 0.689056039883448\n",
      "Epoch 60/10000 --- Train Loss: 0.6876257389523771 --- Val Loss: 0.6884136154307421\n",
      "Epoch 70/10000 --- Train Loss: 0.686885043238762 --- Val Loss: 0.6877952054827257\n",
      "Epoch 80/10000 --- Train Loss: 0.6861557991113123 --- Val Loss: 0.6871876238309146\n",
      "Epoch 90/10000 --- Train Loss: 0.6854494689839014 --- Val Loss: 0.6866001792668367\n",
      "Epoch 100/10000 --- Train Loss: 0.684754688682768 --- Val Loss: 0.6860233256705537\n",
      "Epoch 110/10000 --- Train Loss: 0.6840785214229235 --- Val Loss: 0.6854626928642733\n",
      "Epoch 120/10000 --- Train Loss: 0.6834214091401531 --- Val Loss: 0.6849184601233768\n",
      "Epoch 130/10000 --- Train Loss: 0.6827746760101332 --- Val Loss: 0.68438338193194\n",
      "Epoch 140/10000 --- Train Loss: 0.6821400890985437 --- Val Loss: 0.683858690671409\n",
      "Epoch 150/10000 --- Train Loss: 0.6815119439031854 --- Val Loss: 0.683339593447853\n",
      "Epoch 160/10000 --- Train Loss: 0.6809016474044185 --- Val Loss: 0.6828350828840525\n",
      "Epoch 170/10000 --- Train Loss: 0.6803015980079735 --- Val Loss: 0.6823387865370546\n",
      "Epoch 180/10000 --- Train Loss: 0.6797039449453836 --- Val Loss: 0.681844070504377\n",
      "Epoch 190/10000 --- Train Loss: 0.6791178630924478 --- Val Loss: 0.6813580218641884\n",
      "Epoch 200/10000 --- Train Loss: 0.678534461295128 --- Val Loss: 0.6808731912863536\n",
      "Epoch 210/10000 --- Train Loss: 0.6779524947617437 --- Val Loss: 0.6803882785482415\n",
      "Epoch 220/10000 --- Train Loss: 0.6773765090883402 --- Val Loss: 0.679906554229612\n",
      "Epoch 230/10000 --- Train Loss: 0.6767983720370255 --- Val Loss: 0.679421094695152\n",
      "Epoch 240/10000 --- Train Loss: 0.6762212637325706 --- Val Loss: 0.6789339669850758\n",
      "Epoch 250/10000 --- Train Loss: 0.6756375548452436 --- Val Loss: 0.678438721226284\n",
      "Epoch 260/10000 --- Train Loss: 0.6750467336180852 --- Val Loss: 0.6779344277553677\n",
      "Epoch 270/10000 --- Train Loss: 0.6744496936528006 --- Val Loss: 0.6774210595085192\n",
      "Epoch 280/10000 --- Train Loss: 0.6738415221507426 --- Val Loss: 0.6768941584549488\n",
      "Epoch 290/10000 --- Train Loss: 0.6732199971760974 --- Val Loss: 0.6763511411131866\n",
      "Epoch 300/10000 --- Train Loss: 0.6725840137053292 --- Val Loss: 0.6757902792843189\n",
      "Epoch 310/10000 --- Train Loss: 0.6719234939493208 --- Val Loss: 0.6752028956598901\n",
      "Epoch 320/10000 --- Train Loss: 0.6712387850632842 --- Val Loss: 0.6745879261606508\n",
      "Epoch 330/10000 --- Train Loss: 0.6705272369518543 --- Val Loss: 0.6739422690769452\n",
      "Epoch 340/10000 --- Train Loss: 0.6697815927876296 --- Val Loss: 0.6732589136329584\n",
      "Epoch 350/10000 --- Train Loss: 0.6689984354199686 --- Val Loss: 0.6725337272518537\n",
      "Epoch 360/10000 --- Train Loss: 0.668164508231806 --- Val Loss: 0.6717548987791948\n",
      "Epoch 370/10000 --- Train Loss: 0.6672830538186388 --- Val Loss: 0.6709227294550777\n",
      "Epoch 380/10000 --- Train Loss: 0.6663453161792192 --- Val Loss: 0.6700289362480267\n",
      "Epoch 390/10000 --- Train Loss: 0.665340319167056 --- Val Loss: 0.6690629838160258\n",
      "Epoch 400/10000 --- Train Loss: 0.6642586854692254 --- Val Loss: 0.6680148449869501\n",
      "Epoch 410/10000 --- Train Loss: 0.6630956178889392 --- Val Loss: 0.6668777269741175\n",
      "Epoch 420/10000 --- Train Loss: 0.66183784568987 --- Val Loss: 0.6656392760442744\n",
      "Epoch 430/10000 --- Train Loss: 0.6604748929532176 --- Val Loss: 0.6642872734139409\n",
      "Epoch 440/10000 --- Train Loss: 0.6589912647326301 --- Val Loss: 0.6628065581448372\n",
      "Epoch 450/10000 --- Train Loss: 0.6573784216713401 --- Val Loss: 0.6611863364368522\n",
      "Epoch 460/10000 --- Train Loss: 0.6556162993395438 --- Val Loss: 0.6594071803179783\n",
      "Epoch 470/10000 --- Train Loss: 0.6536938234650513 --- Val Loss: 0.6574556663032884\n",
      "Epoch 480/10000 --- Train Loss: 0.6515910737785114 --- Val Loss: 0.6553092732874061\n",
      "Epoch 490/10000 --- Train Loss: 0.6492896448996794 --- Val Loss: 0.6529494824996909\n",
      "Epoch 500/10000 --- Train Loss: 0.6467713775063981 --- Val Loss: 0.6503558989617422\n",
      "Epoch 510/10000 --- Train Loss: 0.644010867575142 --- Val Loss: 0.6475038988808176\n",
      "Epoch 520/10000 --- Train Loss: 0.640983586866385 --- Val Loss: 0.6443655706004259\n",
      "Epoch 530/10000 --- Train Loss: 0.6376711444350552 --- Val Loss: 0.6409191466672938\n",
      "Epoch 540/10000 --- Train Loss: 0.6340467842749956 --- Val Loss: 0.6371359904713582\n",
      "Epoch 550/10000 --- Train Loss: 0.6300892585674175 --- Val Loss: 0.6329925593995449\n",
      "Epoch 560/10000 --- Train Loss: 0.6257662146426127 --- Val Loss: 0.6284543467414919\n",
      "Epoch 570/10000 --- Train Loss: 0.6210488175111029 --- Val Loss: 0.6234900295015045\n",
      "Epoch 580/10000 --- Train Loss: 0.6159190877255503 --- Val Loss: 0.6180808153514807\n",
      "Epoch 590/10000 --- Train Loss: 0.6103477042106057 --- Val Loss: 0.6121912535294294\n",
      "Epoch 600/10000 --- Train Loss: 0.6043300664551848 --- Val Loss: 0.6058159089249816\n",
      "Epoch 610/10000 --- Train Loss: 0.5978342433115618 --- Val Loss: 0.5989211719259662\n",
      "Epoch 620/10000 --- Train Loss: 0.5908711189204636 --- Val Loss: 0.5915126902459574\n",
      "Epoch 630/10000 --- Train Loss: 0.5834153119706943 --- Val Loss: 0.5835609161422989\n",
      "Epoch 640/10000 --- Train Loss: 0.5754845245649611 --- Val Loss: 0.5750851933563061\n",
      "Epoch 650/10000 --- Train Loss: 0.5671005494354755 --- Val Loss: 0.5661063554851109\n",
      "Epoch 660/10000 --- Train Loss: 0.5582550478901438 --- Val Loss: 0.5566116869718981\n",
      "Epoch 670/10000 --- Train Loss: 0.5490061539356427 --- Val Loss: 0.5466647258912314\n",
      "Epoch 680/10000 --- Train Loss: 0.53938957745576 --- Val Loss: 0.5363000977665603\n",
      "Epoch 690/10000 --- Train Loss: 0.5294575659137306 --- Val Loss: 0.5255711999861705\n",
      "Epoch 700/10000 --- Train Loss: 0.5192696494232524 --- Val Loss: 0.5145419401290248\n",
      "Epoch 710/10000 --- Train Loss: 0.5088572394559431 --- Val Loss: 0.5032502660189601\n",
      "Epoch 720/10000 --- Train Loss: 0.49831604822215236 --- Val Loss: 0.49179432268612167\n",
      "Epoch 730/10000 --- Train Loss: 0.48769476628704 --- Val Loss: 0.48022710411406216\n",
      "Epoch 740/10000 --- Train Loss: 0.47705293743484284 --- Val Loss: 0.4686155738158475\n",
      "Epoch 750/10000 --- Train Loss: 0.4664540347867721 --- Val Loss: 0.4570261568360417\n",
      "Epoch 760/10000 --- Train Loss: 0.45593220196710854 --- Val Loss: 0.44550056592051346\n",
      "Epoch 770/10000 --- Train Loss: 0.44555414362170875 --- Val Loss: 0.43411160777574725\n",
      "Epoch 780/10000 --- Train Loss: 0.435356098089078 --- Val Loss: 0.4228931032699283\n",
      "Epoch 790/10000 --- Train Loss: 0.42536474726833606 --- Val Loss: 0.41188804783857835\n",
      "Epoch 800/10000 --- Train Loss: 0.41561819355186636 --- Val Loss: 0.4011275159059237\n",
      "Epoch 810/10000 --- Train Loss: 0.40611845738698826 --- Val Loss: 0.3906230701957029\n",
      "Epoch 820/10000 --- Train Loss: 0.3968854787219326 --- Val Loss: 0.38039631712756455\n",
      "Epoch 830/10000 --- Train Loss: 0.3879458479620311 --- Val Loss: 0.3704674644047995\n",
      "Epoch 840/10000 --- Train Loss: 0.3792959977713352 --- Val Loss: 0.3608395410395508\n",
      "Epoch 850/10000 --- Train Loss: 0.3709485774477253 --- Val Loss: 0.3515336581804562\n",
      "Epoch 860/10000 --- Train Loss: 0.36289373592152546 --- Val Loss: 0.34254652110231737\n",
      "Epoch 870/10000 --- Train Loss: 0.3551367249291824 --- Val Loss: 0.3338812606210844\n",
      "Epoch 880/10000 --- Train Loss: 0.3476696661163966 --- Val Loss: 0.32553076598289016\n",
      "Epoch 890/10000 --- Train Loss: 0.3404853415076878 --- Val Loss: 0.31749260432003223\n",
      "Epoch 900/10000 --- Train Loss: 0.333593717937435 --- Val Loss: 0.3098000554905737\n",
      "Epoch 910/10000 --- Train Loss: 0.3269775900635285 --- Val Loss: 0.3024147186701889\n",
      "Epoch 920/10000 --- Train Loss: 0.3206180652394086 --- Val Loss: 0.2953071135976231\n",
      "Epoch 930/10000 --- Train Loss: 0.31451101733626197 --- Val Loss: 0.28848266107957454\n",
      "Epoch 940/10000 --- Train Loss: 0.30865195846584464 --- Val Loss: 0.28194218410443284\n",
      "Epoch 950/10000 --- Train Loss: 0.3030214169219199 --- Val Loss: 0.27567536961869077\n",
      "Epoch 960/10000 --- Train Loss: 0.2976193936458842 --- Val Loss: 0.26969409299079533\n",
      "Epoch 970/10000 --- Train Loss: 0.2924352264395066 --- Val Loss: 0.263997040473732\n",
      "Epoch 980/10000 --- Train Loss: 0.2874605297842362 --- Val Loss: 0.25855205142466536\n",
      "Epoch 990/10000 --- Train Loss: 0.28267678214778713 --- Val Loss: 0.25332628807013746\n",
      "Epoch 1000/10000 --- Train Loss: 0.2780730291834058 --- Val Loss: 0.24829781593802686\n",
      "Epoch 1010/10000 --- Train Loss: 0.2736479275451078 --- Val Loss: 0.24346839345759863\n",
      "Epoch 1020/10000 --- Train Loss: 0.2693894503351949 --- Val Loss: 0.23882799649672237\n",
      "Epoch 1030/10000 --- Train Loss: 0.2652870455250728 --- Val Loss: 0.23435880852096158\n",
      "Epoch 1040/10000 --- Train Loss: 0.26132721841535095 --- Val Loss: 0.2300459233035129\n",
      "Epoch 1050/10000 --- Train Loss: 0.2575115196282791 --- Val Loss: 0.22589322073982415\n",
      "Epoch 1060/10000 --- Train Loss: 0.25382714111671373 --- Val Loss: 0.2218841118361849\n",
      "Epoch 1070/10000 --- Train Loss: 0.25026815318133294 --- Val Loss: 0.21800945366249597\n",
      "Epoch 1080/10000 --- Train Loss: 0.2468293482305793 --- Val Loss: 0.21426990224784834\n",
      "Epoch 1090/10000 --- Train Loss: 0.24351172786349773 --- Val Loss: 0.210666185604909\n",
      "Epoch 1100/10000 --- Train Loss: 0.2402952117701178 --- Val Loss: 0.2071717467307839\n",
      "Epoch 1110/10000 --- Train Loss: 0.23718678315398725 --- Val Loss: 0.2037903060234815\n",
      "Epoch 1120/10000 --- Train Loss: 0.23417451666963082 --- Val Loss: 0.20051539790827538\n",
      "Epoch 1130/10000 --- Train Loss: 0.23125890365640747 --- Val Loss: 0.19734622050207298\n",
      "Epoch 1140/10000 --- Train Loss: 0.22842874274351774 --- Val Loss: 0.19427422526971783\n",
      "Epoch 1150/10000 --- Train Loss: 0.22568524026834633 --- Val Loss: 0.19128581158519328\n",
      "Epoch 1160/10000 --- Train Loss: 0.2230208959986068 --- Val Loss: 0.188374799320724\n",
      "Epoch 1170/10000 --- Train Loss: 0.22042399706361582 --- Val Loss: 0.18551722815319074\n",
      "Epoch 1180/10000 --- Train Loss: 0.21790336988624134 --- Val Loss: 0.18273612500377967\n",
      "Epoch 1190/10000 --- Train Loss: 0.21545412764321628 --- Val Loss: 0.18003318359844903\n",
      "Epoch 1200/10000 --- Train Loss: 0.2130675068288592 --- Val Loss: 0.17740221161036812\n",
      "Epoch 1210/10000 --- Train Loss: 0.21075264995069587 --- Val Loss: 0.17485002320488208\n",
      "Epoch 1220/10000 --- Train Loss: 0.20850254677774713 --- Val Loss: 0.1723667294508807\n",
      "Epoch 1230/10000 --- Train Loss: 0.2063139832353814 --- Val Loss: 0.16994977346459736\n",
      "Epoch 1240/10000 --- Train Loss: 0.2041766150576105 --- Val Loss: 0.16759243771929236\n",
      "Epoch 1250/10000 --- Train Loss: 0.2020946565023229 --- Val Loss: 0.16529012587606134\n",
      "Epoch 1260/10000 --- Train Loss: 0.20006277424729607 --- Val Loss: 0.16304112956812106\n",
      "Epoch 1270/10000 --- Train Loss: 0.19807976639890004 --- Val Loss: 0.16085061845260623\n",
      "Epoch 1280/10000 --- Train Loss: 0.19615170394351916 --- Val Loss: 0.15872210846041968\n",
      "Epoch 1290/10000 --- Train Loss: 0.19426252971327176 --- Val Loss: 0.1566372885846796\n",
      "Epoch 1300/10000 --- Train Loss: 0.19242452673547122 --- Val Loss: 0.15461693186618686\n",
      "Epoch 1310/10000 --- Train Loss: 0.1906302470782215 --- Val Loss: 0.1526488466021237\n",
      "Epoch 1320/10000 --- Train Loss: 0.18887804623508028 --- Val Loss: 0.15073314447980202\n",
      "Epoch 1330/10000 --- Train Loss: 0.18716575327161392 --- Val Loss: 0.1488642641829277\n",
      "Epoch 1340/10000 --- Train Loss: 0.1854976057658957 --- Val Loss: 0.14704008125620727\n",
      "Epoch 1350/10000 --- Train Loss: 0.18386926222225655 --- Val Loss: 0.14526452835926165\n",
      "Epoch 1360/10000 --- Train Loss: 0.18227717637313354 --- Val Loss: 0.14352902783657576\n",
      "Epoch 1370/10000 --- Train Loss: 0.18071854543288277 --- Val Loss: 0.14183124603189576\n",
      "Epoch 1380/10000 --- Train Loss: 0.1791944054812527 --- Val Loss: 0.14017055509316104\n",
      "Epoch 1390/10000 --- Train Loss: 0.17770705174996956 --- Val Loss: 0.1385548642077176\n",
      "Epoch 1400/10000 --- Train Loss: 0.176252596221067 --- Val Loss: 0.1369755883608269\n",
      "Epoch 1410/10000 --- Train Loss: 0.17483104689410753 --- Val Loss: 0.1354357555712982\n",
      "Epoch 1420/10000 --- Train Loss: 0.1734373123797527 --- Val Loss: 0.13392501688975497\n",
      "Epoch 1430/10000 --- Train Loss: 0.17207772123789164 --- Val Loss: 0.13245671737440043\n",
      "Epoch 1440/10000 --- Train Loss: 0.1707448388233257 --- Val Loss: 0.13101533700048607\n",
      "Epoch 1450/10000 --- Train Loss: 0.16944360256949795 --- Val Loss: 0.12961229281208922\n",
      "Epoch 1460/10000 --- Train Loss: 0.16817547833617763 --- Val Loss: 0.12824886500020605\n",
      "Epoch 1470/10000 --- Train Loss: 0.1669269073607142 --- Val Loss: 0.12690581567354017\n",
      "Epoch 1480/10000 --- Train Loss: 0.16570634162392767 --- Val Loss: 0.12559623639895798\n",
      "Epoch 1490/10000 --- Train Loss: 0.16450925519504606 --- Val Loss: 0.12431680982440661\n",
      "Epoch 1500/10000 --- Train Loss: 0.16333673478305977 --- Val Loss: 0.12306408347700223\n",
      "Epoch 1510/10000 --- Train Loss: 0.1621879192975829 --- Val Loss: 0.12184258313871313\n",
      "Epoch 1520/10000 --- Train Loss: 0.16106346583158593 --- Val Loss: 0.12065056927370411\n",
      "Epoch 1530/10000 --- Train Loss: 0.15995864122560274 --- Val Loss: 0.11948162762051369\n",
      "Epoch 1540/10000 --- Train Loss: 0.1588773640928064 --- Val Loss: 0.11834019793930836\n",
      "Epoch 1550/10000 --- Train Loss: 0.15781207376288517 --- Val Loss: 0.11721851900737516\n",
      "Epoch 1560/10000 --- Train Loss: 0.15676702055440958 --- Val Loss: 0.11612248594164877\n",
      "Epoch 1570/10000 --- Train Loss: 0.15574298109427065 --- Val Loss: 0.11505160895981958\n",
      "Epoch 1580/10000 --- Train Loss: 0.15473371597039423 --- Val Loss: 0.11399578305627844\n",
      "Epoch 1590/10000 --- Train Loss: 0.15374303861838076 --- Val Loss: 0.11296149522819832\n",
      "Epoch 1600/10000 --- Train Loss: 0.15276918468790304 --- Val Loss: 0.11194483873833466\n",
      "Epoch 1610/10000 --- Train Loss: 0.15181327346175366 --- Val Loss: 0.11094953152186786\n",
      "Epoch 1620/10000 --- Train Loss: 0.15087252713928878 --- Val Loss: 0.10997401238437049\n",
      "Epoch 1630/10000 --- Train Loss: 0.14994919475975602 --- Val Loss: 0.10902173190123678\n",
      "Epoch 1640/10000 --- Train Loss: 0.14904089075005317 --- Val Loss: 0.10808443875987041\n",
      "Epoch 1650/10000 --- Train Loss: 0.14814706531653443 --- Val Loss: 0.10716554199714654\n",
      "Epoch 1660/10000 --- Train Loss: 0.14726984400958829 --- Val Loss: 0.10625991541493665\n",
      "Epoch 1670/10000 --- Train Loss: 0.14640563071553575 --- Val Loss: 0.10536891066162213\n",
      "Epoch 1680/10000 --- Train Loss: 0.14555924688556143 --- Val Loss: 0.10450212432310751\n",
      "Epoch 1690/10000 --- Train Loss: 0.14472517247636846 --- Val Loss: 0.10364495169707978\n",
      "Epoch 1700/10000 --- Train Loss: 0.14390815512634472 --- Val Loss: 0.10280513873962532\n",
      "Epoch 1710/10000 --- Train Loss: 0.14310521251829947 --- Val Loss: 0.10198428454970268\n",
      "Epoch 1720/10000 --- Train Loss: 0.14231137025413798 --- Val Loss: 0.10117036342386417\n",
      "Epoch 1730/10000 --- Train Loss: 0.14153272718471252 --- Val Loss: 0.10037401948438668\n",
      "Epoch 1740/10000 --- Train Loss: 0.14076861564254753 --- Val Loss: 0.09959415086405041\n",
      "Epoch 1750/10000 --- Train Loss: 0.14001664670906913 --- Val Loss: 0.09883064967761525\n",
      "Epoch 1760/10000 --- Train Loss: 0.13927581449938614 --- Val Loss: 0.09807621355992444\n",
      "Epoch 1770/10000 --- Train Loss: 0.13854632245668444 --- Val Loss: 0.09733487013781025\n",
      "Epoch 1780/10000 --- Train Loss: 0.13783055909039427 --- Val Loss: 0.0966093526171795\n",
      "Epoch 1790/10000 --- Train Loss: 0.1371280093604781 --- Val Loss: 0.09589916652575016\n",
      "Epoch 1800/10000 --- Train Loss: 0.13643344651276554 --- Val Loss: 0.09519633789789778\n",
      "Epoch 1810/10000 --- Train Loss: 0.13574935321316794 --- Val Loss: 0.09450531892339045\n",
      "Epoch 1820/10000 --- Train Loss: 0.13507759025397173 --- Val Loss: 0.09383012777638972\n",
      "Epoch 1830/10000 --- Train Loss: 0.13441686987807547 --- Val Loss: 0.09316480942639604\n",
      "Epoch 1840/10000 --- Train Loss: 0.13376655881143207 --- Val Loss: 0.09251177563499004\n",
      "Epoch 1850/10000 --- Train Loss: 0.13312530404044218 --- Val Loss: 0.09187048538553629\n",
      "Epoch 1860/10000 --- Train Loss: 0.13249311508476483 --- Val Loss: 0.09123908717674178\n",
      "Epoch 1870/10000 --- Train Loss: 0.13186973800319382 --- Val Loss: 0.09061638980886645\n",
      "Epoch 1880/10000 --- Train Loss: 0.13125600926248437 --- Val Loss: 0.09000768788267698\n",
      "Epoch 1890/10000 --- Train Loss: 0.13065002093970154 --- Val Loss: 0.08940237368200248\n",
      "Epoch 1900/10000 --- Train Loss: 0.13005132248669696 --- Val Loss: 0.08880654875373144\n",
      "Epoch 1910/10000 --- Train Loss: 0.12946413983846966 --- Val Loss: 0.08822473060861755\n",
      "Epoch 1920/10000 --- Train Loss: 0.12888356191697614 --- Val Loss: 0.08764910107098156\n",
      "Epoch 1930/10000 --- Train Loss: 0.1283116542743746 --- Val Loss: 0.08708590846963786\n",
      "Epoch 1940/10000 --- Train Loss: 0.1277472893709388 --- Val Loss: 0.08652741503766445\n",
      "Epoch 1950/10000 --- Train Loss: 0.1271899771045378 --- Val Loss: 0.08597678121471067\n",
      "Epoch 1960/10000 --- Train Loss: 0.1266405477059289 --- Val Loss: 0.08543723749892082\n",
      "Epoch 1970/10000 --- Train Loss: 0.12610114340153528 --- Val Loss: 0.08490949182489707\n",
      "Epoch 1980/10000 --- Train Loss: 0.12556812353810978 --- Val Loss: 0.08438912596514345\n",
      "Epoch 1990/10000 --- Train Loss: 0.1250442542638495 --- Val Loss: 0.08387720103232438\n",
      "Epoch 2000/10000 --- Train Loss: 0.12452469108564473 --- Val Loss: 0.08337127054689401\n",
      "Epoch 2010/10000 --- Train Loss: 0.12401081567044019 --- Val Loss: 0.08287107745219764\n",
      "Epoch 2020/10000 --- Train Loss: 0.12350818637805352 --- Val Loss: 0.08238371486136345\n",
      "Epoch 2030/10000 --- Train Loss: 0.12301077707531251 --- Val Loss: 0.08190020159530939\n",
      "Epoch 2040/10000 --- Train Loss: 0.1225194607510417 --- Val Loss: 0.08142245895841418\n",
      "Epoch 2050/10000 --- Train Loss: 0.12203432624053061 --- Val Loss: 0.08095153004780274\n",
      "Epoch 2060/10000 --- Train Loss: 0.12155477878835254 --- Val Loss: 0.08048374102120893\n",
      "Epoch 2070/10000 --- Train Loss: 0.12108066098099404 --- Val Loss: 0.08002447926759132\n",
      "Epoch 2080/10000 --- Train Loss: 0.12061560360934852 --- Val Loss: 0.0795748521379926\n",
      "Epoch 2090/10000 --- Train Loss: 0.12015679479662823 --- Val Loss: 0.07912903852239263\n",
      "Epoch 2100/10000 --- Train Loss: 0.1197030097683106 --- Val Loss: 0.07869034602771426\n",
      "Epoch 2110/10000 --- Train Loss: 0.11925433377669942 --- Val Loss: 0.0782560803540454\n",
      "Epoch 2120/10000 --- Train Loss: 0.1188116401247172 --- Val Loss: 0.07782931276425469\n",
      "Epoch 2130/10000 --- Train Loss: 0.11837525313463512 --- Val Loss: 0.07740694579058488\n",
      "Epoch 2140/10000 --- Train Loss: 0.11794143241361325 --- Val Loss: 0.07698877262188963\n",
      "Epoch 2150/10000 --- Train Loss: 0.11751673429550617 --- Val Loss: 0.07657986490335944\n",
      "Epoch 2160/10000 --- Train Loss: 0.11709558977519495 --- Val Loss: 0.07617327084501772\n",
      "Epoch 2170/10000 --- Train Loss: 0.11667964462729383 --- Val Loss: 0.07577096474110614\n",
      "Epoch 2180/10000 --- Train Loss: 0.11626819906439163 --- Val Loss: 0.07537410211170338\n",
      "Epoch 2190/10000 --- Train Loss: 0.1158632586442551 --- Val Loss: 0.07498058688526849\n",
      "Epoch 2200/10000 --- Train Loss: 0.11546480828817636 --- Val Loss: 0.07459331603879792\n",
      "Epoch 2210/10000 --- Train Loss: 0.11507058894171358 --- Val Loss: 0.07421184110288247\n",
      "Epoch 2220/10000 --- Train Loss: 0.11468114518479557 --- Val Loss: 0.07383647866123234\n",
      "Epoch 2230/10000 --- Train Loss: 0.1142953838400221 --- Val Loss: 0.07346469580227068\n",
      "Epoch 2240/10000 --- Train Loss: 0.11391410722494061 --- Val Loss: 0.07309740823317493\n",
      "Epoch 2250/10000 --- Train Loss: 0.11353773804665863 --- Val Loss: 0.07273526000337319\n",
      "Epoch 2260/10000 --- Train Loss: 0.11316605676858689 --- Val Loss: 0.07237728963178848\n",
      "Epoch 2270/10000 --- Train Loss: 0.11279908649016948 --- Val Loss: 0.07202451330925565\n",
      "Epoch 2280/10000 --- Train Loss: 0.11243522342969466 --- Val Loss: 0.07167509883790245\n",
      "Epoch 2290/10000 --- Train Loss: 0.11207533994946936 --- Val Loss: 0.07133023132311947\n",
      "Epoch 2300/10000 --- Train Loss: 0.11171920689390613 --- Val Loss: 0.07099102352671342\n",
      "Epoch 2310/10000 --- Train Loss: 0.11136574872165686 --- Val Loss: 0.07065131174750865\n",
      "Epoch 2320/10000 --- Train Loss: 0.11101773684429687 --- Val Loss: 0.07032004694364666\n",
      "Epoch 2330/10000 --- Train Loss: 0.11067286503884165 --- Val Loss: 0.06998911570007028\n",
      "Epoch 2340/10000 --- Train Loss: 0.11033256759192918 --- Val Loss: 0.06966355177410283\n",
      "Epoch 2350/10000 --- Train Loss: 0.10999505618331656 --- Val Loss: 0.06934561586191725\n",
      "Epoch 2360/10000 --- Train Loss: 0.10966266212664424 --- Val Loss: 0.06902961383891311\n",
      "Epoch 2370/10000 --- Train Loss: 0.10933321949510572 --- Val Loss: 0.06871502818230163\n",
      "Epoch 2380/10000 --- Train Loss: 0.10900748517101543 --- Val Loss: 0.06840494667058888\n",
      "Epoch 2390/10000 --- Train Loss: 0.10868602564597171 --- Val Loss: 0.06809991260134175\n",
      "Epoch 2400/10000 --- Train Loss: 0.10836827903782575 --- Val Loss: 0.06779912133472524\n",
      "Epoch 2410/10000 --- Train Loss: 0.10805285225079182 --- Val Loss: 0.06749993787546726\n",
      "Epoch 2420/10000 --- Train Loss: 0.10774057237497639 --- Val Loss: 0.06720242250866877\n",
      "Epoch 2430/10000 --- Train Loss: 0.10743258251125645 --- Val Loss: 0.06691086961215242\n",
      "Epoch 2440/10000 --- Train Loss: 0.10712654641491613 --- Val Loss: 0.06661751852470849\n",
      "Epoch 2450/10000 --- Train Loss: 0.10682486073321333 --- Val Loss: 0.06633152422719532\n",
      "Epoch 2460/10000 --- Train Loss: 0.10652712616534071 --- Val Loss: 0.06604832624380005\n",
      "Epoch 2470/10000 --- Train Loss: 0.10623199099920083 --- Val Loss: 0.06576775104510592\n",
      "Epoch 2480/10000 --- Train Loss: 0.10593846422039051 --- Val Loss: 0.0654892139682772\n",
      "Epoch 2490/10000 --- Train Loss: 0.10564795856019613 --- Val Loss: 0.06521117821917563\n",
      "Epoch 2500/10000 --- Train Loss: 0.10536049209770107 --- Val Loss: 0.06493867266315809\n",
      "Epoch 2510/10000 --- Train Loss: 0.10507806802020869 --- Val Loss: 0.06467151393292582\n",
      "Epoch 2520/10000 --- Train Loss: 0.10479699009072974 --- Val Loss: 0.06440657063873385\n",
      "Epoch 2530/10000 --- Train Loss: 0.10451867436777569 --- Val Loss: 0.06414273955222557\n",
      "Epoch 2540/10000 --- Train Loss: 0.1042448632397201 --- Val Loss: 0.06388341079908083\n",
      "Epoch 2550/10000 --- Train Loss: 0.10397332470571899 --- Val Loss: 0.06362689470755857\n",
      "Epoch 2560/10000 --- Train Loss: 0.1037039768728729 --- Val Loss: 0.0633740619020095\n",
      "Epoch 2570/10000 --- Train Loss: 0.10343675385413285 --- Val Loss: 0.06311910617281036\n",
      "Epoch 2580/10000 --- Train Loss: 0.10317146824327686 --- Val Loss: 0.06286731879184507\n",
      "Epoch 2590/10000 --- Train Loss: 0.10290917824994537 --- Val Loss: 0.06261677375941253\n",
      "Epoch 2600/10000 --- Train Loss: 0.10264847304751587 --- Val Loss: 0.0623695549068993\n",
      "Epoch 2610/10000 --- Train Loss: 0.10239086794985772 --- Val Loss: 0.062124161544854936\n",
      "Epoch 2620/10000 --- Train Loss: 0.10213731126319621 --- Val Loss: 0.06188696041420454\n",
      "Epoch 2630/10000 --- Train Loss: 0.10188545480895936 --- Val Loss: 0.061648115853780765\n",
      "Epoch 2640/10000 --- Train Loss: 0.1016364855822257 --- Val Loss: 0.06141088034159821\n",
      "Epoch 2650/10000 --- Train Loss: 0.1013884271915709 --- Val Loss: 0.06117405200896187\n",
      "Epoch 2660/10000 --- Train Loss: 0.10114367448165797 --- Val Loss: 0.06094076363562184\n",
      "Epoch 2670/10000 --- Train Loss: 0.10090143501460093 --- Val Loss: 0.06071049179795728\n",
      "Epoch 2680/10000 --- Train Loss: 0.10066124973536988 --- Val Loss: 0.06048189557561961\n",
      "Epoch 2690/10000 --- Train Loss: 0.10042364476664446 --- Val Loss: 0.06025597169405731\n",
      "Epoch 2700/10000 --- Train Loss: 0.10018833458420381 --- Val Loss: 0.06003061948503138\n",
      "Epoch 2710/10000 --- Train Loss: 0.09995523942254127 --- Val Loss: 0.05981159611230095\n",
      "Epoch 2720/10000 --- Train Loss: 0.09972443055018688 --- Val Loss: 0.05959212476509683\n",
      "Epoch 2730/10000 --- Train Loss: 0.09949552464697982 --- Val Loss: 0.05937406917385788\n",
      "Epoch 2740/10000 --- Train Loss: 0.09926879065646135 --- Val Loss: 0.0591572380931029\n",
      "Epoch 2750/10000 --- Train Loss: 0.09904389783439556 --- Val Loss: 0.058944238816042174\n",
      "Epoch 2760/10000 --- Train Loss: 0.09882118431865979 --- Val Loss: 0.058735221114268654\n",
      "Epoch 2770/10000 --- Train Loss: 0.09860109049516767 --- Val Loss: 0.05852686341927406\n",
      "Epoch 2780/10000 --- Train Loss: 0.09838226429648034 --- Val Loss: 0.058317909959707606\n",
      "Epoch 2790/10000 --- Train Loss: 0.09816467796543545 --- Val Loss: 0.05810949873184452\n",
      "Epoch 2800/10000 --- Train Loss: 0.09795050191515575 --- Val Loss: 0.05790774012014963\n",
      "Epoch 2810/10000 --- Train Loss: 0.09773727786235452 --- Val Loss: 0.05770567449436924\n",
      "Epoch 2820/10000 --- Train Loss: 0.09752676404283224 --- Val Loss: 0.05750646455052106\n",
      "Epoch 2830/10000 --- Train Loss: 0.09731747305302803 --- Val Loss: 0.057307237222588875\n",
      "Epoch 2840/10000 --- Train Loss: 0.09711049237054821 --- Val Loss: 0.05711166519354216\n",
      "Epoch 2850/10000 --- Train Loss: 0.09690580422545747 --- Val Loss: 0.05691717195950614\n",
      "Epoch 2860/10000 --- Train Loss: 0.09670209907121051 --- Val Loss: 0.0567228429625203\n",
      "Epoch 2870/10000 --- Train Loss: 0.09650021392942315 --- Val Loss: 0.05653174654521558\n",
      "Epoch 2880/10000 --- Train Loss: 0.09630039810068476 --- Val Loss: 0.056342983329645595\n",
      "Epoch 2890/10000 --- Train Loss: 0.09610229218630713 --- Val Loss: 0.056157919897719524\n",
      "Epoch 2900/10000 --- Train Loss: 0.0959064656154344 --- Val Loss: 0.05597409269767936\n",
      "Epoch 2910/10000 --- Train Loss: 0.0957116960629061 --- Val Loss: 0.055789570100119965\n",
      "Epoch 2920/10000 --- Train Loss: 0.09551821390587985 --- Val Loss: 0.055605803536232484\n",
      "Epoch 2930/10000 --- Train Loss: 0.0953257518242291 --- Val Loss: 0.05542344476473935\n",
      "Epoch 2940/10000 --- Train Loss: 0.09513623739792532 --- Val Loss: 0.05524290726780789\n",
      "Epoch 2950/10000 --- Train Loss: 0.09494862049315979 --- Val Loss: 0.05506727317092293\n",
      "Epoch 2960/10000 --- Train Loss: 0.0947623210811899 --- Val Loss: 0.05489200684879617\n",
      "Epoch 2970/10000 --- Train Loss: 0.09457718797841698 --- Val Loss: 0.05471683356016509\n",
      "Epoch 2980/10000 --- Train Loss: 0.09439342289400755 --- Val Loss: 0.05454514605582261\n",
      "Epoch 2990/10000 --- Train Loss: 0.09421119399430024 --- Val Loss: 0.05437240515328393\n",
      "Epoch 3000/10000 --- Train Loss: 0.09403050719128966 --- Val Loss: 0.05420103146952946\n",
      "Epoch 3010/10000 --- Train Loss: 0.09385236033765611 --- Val Loss: 0.05403447822987851\n",
      "Epoch 3020/10000 --- Train Loss: 0.0936749578111156 --- Val Loss: 0.05386697483484021\n",
      "Epoch 3030/10000 --- Train Loss: 0.09349792090818977 --- Val Loss: 0.0536993214135629\n",
      "Epoch 3040/10000 --- Train Loss: 0.09332297166883652 --- Val Loss: 0.05353487598012985\n",
      "Epoch 3050/10000 --- Train Loss: 0.09314915456629888 --- Val Loss: 0.053370886475630125\n",
      "Epoch 3060/10000 --- Train Loss: 0.09297682340108515 --- Val Loss: 0.05320822594427517\n",
      "Epoch 3070/10000 --- Train Loss: 0.09280559968804372 --- Val Loss: 0.053047188509029126\n",
      "Epoch 3080/10000 --- Train Loss: 0.09263600732676348 --- Val Loss: 0.0528892739042201\n",
      "Epoch 3090/10000 --- Train Loss: 0.09246785634998456 --- Val Loss: 0.052730643672751015\n",
      "Epoch 3100/10000 --- Train Loss: 0.09230124296753618 --- Val Loss: 0.05257414821073401\n",
      "Epoch 3110/10000 --- Train Loss: 0.0921360173771754 --- Val Loss: 0.0524181678219749\n",
      "Epoch 3120/10000 --- Train Loss: 0.09197330854717974 --- Val Loss: 0.05226832387869959\n",
      "Epoch 3130/10000 --- Train Loss: 0.09181104447895272 --- Val Loss: 0.05211613488180595\n",
      "Epoch 3140/10000 --- Train Loss: 0.09164938546938467 --- Val Loss: 0.05196451103954233\n",
      "Epoch 3150/10000 --- Train Loss: 0.09148832390847132 --- Val Loss: 0.051812655609633836\n",
      "Epoch 3160/10000 --- Train Loss: 0.09132959346843934 --- Val Loss: 0.0516662484889978\n",
      "Epoch 3170/10000 --- Train Loss: 0.09117123690010878 --- Val Loss: 0.05151595879416518\n",
      "Epoch 3180/10000 --- Train Loss: 0.09101499132515677 --- Val Loss: 0.05136964163674283\n",
      "Epoch 3190/10000 --- Train Loss: 0.09085915057920528 --- Val Loss: 0.05122143924299378\n",
      "Epoch 3200/10000 --- Train Loss: 0.09070431880876105 --- Val Loss: 0.05107639699944115\n",
      "Epoch 3210/10000 --- Train Loss: 0.09055216574072926 --- Val Loss: 0.050932976839606126\n",
      "Epoch 3220/10000 --- Train Loss: 0.0904006416424704 --- Val Loss: 0.050789623965892254\n",
      "Epoch 3230/10000 --- Train Loss: 0.09024862037128685 --- Val Loss: 0.05064527604557167\n",
      "Epoch 3240/10000 --- Train Loss: 0.09010011790935889 --- Val Loss: 0.05050705313207901\n",
      "Epoch 3250/10000 --- Train Loss: 0.08995151927885293 --- Val Loss: 0.050367612511936326\n",
      "Epoch 3260/10000 --- Train Loss: 0.0898030491351138 --- Val Loss: 0.050229316002289366\n",
      "Epoch 3270/10000 --- Train Loss: 0.08965685862439338 --- Val Loss: 0.050091165098629334\n",
      "Epoch 3280/10000 --- Train Loss: 0.08951126338625412 --- Val Loss: 0.04995357625384325\n",
      "Epoch 3290/10000 --- Train Loss: 0.08936621848832982 --- Val Loss: 0.04981528988586945\n",
      "Epoch 3300/10000 --- Train Loss: 0.08922292010552854 --- Val Loss: 0.04968013417761838\n",
      "Epoch 3310/10000 --- Train Loss: 0.08908053449651325 --- Val Loss: 0.049548590326302315\n",
      "Epoch 3320/10000 --- Train Loss: 0.08893847711879137 --- Val Loss: 0.04941353204593391\n",
      "Epoch 3330/10000 --- Train Loss: 0.08879902735997336 --- Val Loss: 0.04928323155836039\n",
      "Epoch 3340/10000 --- Train Loss: 0.08865941790604209 --- Val Loss: 0.04915391146340811\n",
      "Epoch 3350/10000 --- Train Loss: 0.08852193322498124 --- Val Loss: 0.049027549550968386\n",
      "Epoch 3360/10000 --- Train Loss: 0.08838349327363325 --- Val Loss: 0.048898123820713346\n",
      "Epoch 3370/10000 --- Train Loss: 0.08824697520239204 --- Val Loss: 0.04876711121307719\n",
      "Epoch 3380/10000 --- Train Loss: 0.08811210263026863 --- Val Loss: 0.048644838727213376\n",
      "Epoch 3390/10000 --- Train Loss: 0.08797762702131265 --- Val Loss: 0.04851830408824959\n",
      "Epoch 3400/10000 --- Train Loss: 0.08784411628000842 --- Val Loss: 0.04839409339246786\n",
      "Epoch 3410/10000 --- Train Loss: 0.08771163978079738 --- Val Loss: 0.048270478882944015\n",
      "Epoch 3420/10000 --- Train Loss: 0.08757993302436146 --- Val Loss: 0.04814649825719365\n",
      "Epoch 3430/10000 --- Train Loss: 0.08744952881392636 --- Val Loss: 0.0480244481788973\n",
      "Epoch 3440/10000 --- Train Loss: 0.0873192490747375 --- Val Loss: 0.04790180285554715\n",
      "Epoch 3450/10000 --- Train Loss: 0.08719049456524687 --- Val Loss: 0.047780639586271705\n",
      "Epoch 3460/10000 --- Train Loss: 0.08706254236074819 --- Val Loss: 0.04766130248950818\n",
      "Epoch 3470/10000 --- Train Loss: 0.08693678619501656 --- Val Loss: 0.047545166104428986\n",
      "Epoch 3480/10000 --- Train Loss: 0.08681163317441545 --- Val Loss: 0.04742874895043452\n",
      "Epoch 3490/10000 --- Train Loss: 0.08668617740237455 --- Val Loss: 0.047311566101353224\n",
      "Epoch 3500/10000 --- Train Loss: 0.086561103401513 --- Val Loss: 0.04719119316094436\n",
      "Epoch 3510/10000 --- Train Loss: 0.08643839008944595 --- Val Loss: 0.047078214429383175\n",
      "Epoch 3520/10000 --- Train Loss: 0.08631530282373906 --- Val Loss: 0.0469613367633487\n",
      "Epoch 3530/10000 --- Train Loss: 0.08619275396858847 --- Val Loss: 0.04684776448147365\n",
      "Epoch 3540/10000 --- Train Loss: 0.08607238696882918 --- Val Loss: 0.04673738376470798\n",
      "Epoch 3550/10000 --- Train Loss: 0.08595173440472331 --- Val Loss: 0.046623248749751794\n",
      "Epoch 3560/10000 --- Train Loss: 0.08583208425886887 --- Val Loss: 0.046510526982667465\n",
      "Epoch 3570/10000 --- Train Loss: 0.08571360788716227 --- Val Loss: 0.046401384012025475\n",
      "Epoch 3580/10000 --- Train Loss: 0.08559531129079745 --- Val Loss: 0.046288837371253805\n",
      "Epoch 3590/10000 --- Train Loss: 0.08547781779760773 --- Val Loss: 0.04618034140209686\n",
      "Epoch 3600/10000 --- Train Loss: 0.0853615146741231 --- Val Loss: 0.04607222764769496\n",
      "Epoch 3610/10000 --- Train Loss: 0.08524531702807932 --- Val Loss: 0.045960914496447236\n",
      "Epoch 3620/10000 --- Train Loss: 0.08513068167767525 --- Val Loss: 0.045852949035881455\n",
      "Epoch 3630/10000 --- Train Loss: 0.08501680968491757 --- Val Loss: 0.04574813885308897\n",
      "Epoch 3640/10000 --- Train Loss: 0.08490346311865936 --- Val Loss: 0.04564247772631855\n",
      "Epoch 3650/10000 --- Train Loss: 0.08479079109874131 --- Val Loss: 0.045537961677441535\n",
      "Epoch 3660/10000 --- Train Loss: 0.08467904196986127 --- Val Loss: 0.04543349766334724\n",
      "Epoch 3670/10000 --- Train Loss: 0.0845675845918134 --- Val Loss: 0.04532823496545718\n",
      "Epoch 3680/10000 --- Train Loss: 0.08445789408866566 --- Val Loss: 0.04522695286644055\n",
      "Epoch 3690/10000 --- Train Loss: 0.0843476480179868 --- Val Loss: 0.04512193932021357\n",
      "Epoch 3700/10000 --- Train Loss: 0.08423859248180274 --- Val Loss: 0.04501902784770309\n",
      "Epoch 3710/10000 --- Train Loss: 0.08413016132857057 --- Val Loss: 0.044919852457589206\n",
      "Epoch 3720/10000 --- Train Loss: 0.0840221547067583 --- Val Loss: 0.04481857410082906\n",
      "Epoch 3730/10000 --- Train Loss: 0.08391541209289075 --- Val Loss: 0.044718202274226154\n",
      "Epoch 3740/10000 --- Train Loss: 0.08380874856705835 --- Val Loss: 0.04461858305316605\n",
      "Epoch 3750/10000 --- Train Loss: 0.08370257996031985 --- Val Loss: 0.04451723117126636\n",
      "Epoch 3760/10000 --- Train Loss: 0.08359765646488071 --- Val Loss: 0.04442162464555665\n",
      "Epoch 3770/10000 --- Train Loss: 0.08349374103607575 --- Val Loss: 0.0443248261055481\n",
      "Epoch 3780/10000 --- Train Loss: 0.08339086264150256 --- Val Loss: 0.04423025262427505\n",
      "Epoch 3790/10000 --- Train Loss: 0.08328840443129457 --- Val Loss: 0.04413622303029151\n",
      "Epoch 3800/10000 --- Train Loss: 0.08318547654624689 --- Val Loss: 0.04403976208839127\n",
      "Epoch 3810/10000 --- Train Loss: 0.0830836321301211 --- Val Loss: 0.043945183538325515\n",
      "Epoch 3820/10000 --- Train Loss: 0.08298167317952328 --- Val Loss: 0.043848290006964816\n",
      "Epoch 3830/10000 --- Train Loss: 0.08288091747943588 --- Val Loss: 0.04375331381520049\n",
      "Epoch 3840/10000 --- Train Loss: 0.08278050926791587 --- Val Loss: 0.043660001090463564\n",
      "Epoch 3850/10000 --- Train Loss: 0.08268097559383329 --- Val Loss: 0.04356421833365725\n",
      "Epoch 3860/10000 --- Train Loss: 0.08258264225899727 --- Val Loss: 0.04347181760724953\n",
      "Epoch 3870/10000 --- Train Loss: 0.08248464344052146 --- Val Loss: 0.04338007487563257\n",
      "Epoch 3880/10000 --- Train Loss: 0.08238744238758354 --- Val Loss: 0.043289202070033714\n",
      "Epoch 3890/10000 --- Train Loss: 0.08229033533962392 --- Val Loss: 0.04319655669003581\n",
      "Epoch 3900/10000 --- Train Loss: 0.08219431494718431 --- Val Loss: 0.04310661044464268\n",
      "Epoch 3910/10000 --- Train Loss: 0.08209857373378264 --- Val Loss: 0.04301567632186285\n",
      "Epoch 3920/10000 --- Train Loss: 0.08200312602361463 --- Val Loss: 0.0429264048768559\n",
      "Epoch 3930/10000 --- Train Loss: 0.08190830966032896 --- Val Loss: 0.04283802184362026\n",
      "Epoch 3940/10000 --- Train Loss: 0.08181387360854775 --- Val Loss: 0.042749099790379684\n",
      "Epoch 3950/10000 --- Train Loss: 0.08171990563980858 --- Val Loss: 0.04265888652442959\n",
      "Epoch 3960/10000 --- Train Loss: 0.08162677313830181 --- Val Loss: 0.04257056033213667\n",
      "Epoch 3970/10000 --- Train Loss: 0.08153446206671673 --- Val Loss: 0.04248504051944054\n",
      "Epoch 3980/10000 --- Train Loss: 0.08144212463115773 --- Val Loss: 0.04239730091706163\n",
      "Epoch 3990/10000 --- Train Loss: 0.0813509230422514 --- Val Loss: 0.04231395688848553\n",
      "Epoch 4000/10000 --- Train Loss: 0.08126021746264733 --- Val Loss: 0.04222959258402303\n",
      "Epoch 4010/10000 --- Train Loss: 0.08117024681461 --- Val Loss: 0.04214665371632249\n",
      "Epoch 4020/10000 --- Train Loss: 0.0810812356015891 --- Val Loss: 0.042065224573816624\n",
      "Epoch 4030/10000 --- Train Loss: 0.08099313175223437 --- Val Loss: 0.04198607525563613\n",
      "Epoch 4040/10000 --- Train Loss: 0.08090369533772415 --- Val Loss: 0.04190362063637383\n",
      "Epoch 4050/10000 --- Train Loss: 0.08081535266943767 --- Val Loss: 0.041820074614877085\n",
      "Epoch 4060/10000 --- Train Loss: 0.08072761210299756 --- Val Loss: 0.041737981714257175\n",
      "Epoch 4070/10000 --- Train Loss: 0.0806410262441581 --- Val Loss: 0.041659482674821384\n",
      "Epoch 4080/10000 --- Train Loss: 0.08055441727586501 --- Val Loss: 0.04157932497111305\n",
      "Epoch 4090/10000 --- Train Loss: 0.08046780423127953 --- Val Loss: 0.04149700000779672\n",
      "Epoch 4100/10000 --- Train Loss: 0.08038194368513742 --- Val Loss: 0.04141625031318227\n",
      "Epoch 4110/10000 --- Train Loss: 0.08029734137012072 --- Val Loss: 0.04134169815507017\n",
      "Epoch 4120/10000 --- Train Loss: 0.0802130516465169 --- Val Loss: 0.041264054404916185\n",
      "Epoch 4130/10000 --- Train Loss: 0.080127962343799 --- Val Loss: 0.04118389871331733\n",
      "Epoch 4140/10000 --- Train Loss: 0.0800440579129824 --- Val Loss: 0.04110525767004553\n",
      "Epoch 4150/10000 --- Train Loss: 0.0799604638455642 --- Val Loss: 0.041025182635426684\n",
      "Epoch 4160/10000 --- Train Loss: 0.07987781449963025 --- Val Loss: 0.04094940403639717\n",
      "Epoch 4170/10000 --- Train Loss: 0.07979514561880612 --- Val Loss: 0.04087121261752739\n",
      "Epoch 4180/10000 --- Train Loss: 0.07971295293907661 --- Val Loss: 0.040795280468415046\n",
      "Epoch 4190/10000 --- Train Loss: 0.0796320798484216 --- Val Loss: 0.04072236757672082\n",
      "Epoch 4200/10000 --- Train Loss: 0.07955095333154916 --- Val Loss: 0.04064577262310655\n",
      "Epoch 4210/10000 --- Train Loss: 0.07947017361390613 --- Val Loss: 0.040571182790515484\n",
      "Epoch 4220/10000 --- Train Loss: 0.07938942970855206 --- Val Loss: 0.04049545758066161\n",
      "Epoch 4230/10000 --- Train Loss: 0.07930978241421106 --- Val Loss: 0.04042013575200801\n",
      "Epoch 4240/10000 --- Train Loss: 0.07923060021624938 --- Val Loss: 0.04034865348566772\n",
      "Epoch 4250/10000 --- Train Loss: 0.07915158700329569 --- Val Loss: 0.04027695391650393\n",
      "Epoch 4260/10000 --- Train Loss: 0.07907258262864458 --- Val Loss: 0.04020133195939605\n",
      "Epoch 4270/10000 --- Train Loss: 0.07899490923723589 --- Val Loss: 0.04013053402314559\n",
      "Epoch 4280/10000 --- Train Loss: 0.07891756464257066 --- Val Loss: 0.040058140558304034\n",
      "Epoch 4290/10000 --- Train Loss: 0.0788399030176372 --- Val Loss: 0.039985230800104535\n",
      "Epoch 4300/10000 --- Train Loss: 0.07876299169194517 --- Val Loss: 0.03991386063781739\n",
      "Epoch 4310/10000 --- Train Loss: 0.07868684886713613 --- Val Loss: 0.03984370584858511\n",
      "Epoch 4320/10000 --- Train Loss: 0.07861074322393773 --- Val Loss: 0.039773314981538854\n",
      "Epoch 4330/10000 --- Train Loss: 0.07853460644990062 --- Val Loss: 0.039700747496138396\n",
      "Epoch 4340/10000 --- Train Loss: 0.07845883830851175 --- Val Loss: 0.03963022861650679\n",
      "Epoch 4350/10000 --- Train Loss: 0.0783828163855187 --- Val Loss: 0.03955880651700984\n",
      "Epoch 4360/10000 --- Train Loss: 0.07830809321509519 --- Val Loss: 0.03948858449840512\n",
      "Epoch 4370/10000 --- Train Loss: 0.07823376730419504 --- Val Loss: 0.039421494310691314\n",
      "Epoch 4380/10000 --- Train Loss: 0.07815990919088944 --- Val Loss: 0.0393510160685865\n",
      "Epoch 4390/10000 --- Train Loss: 0.07808634900254563 --- Val Loss: 0.039282405288116086\n",
      "Epoch 4400/10000 --- Train Loss: 0.07801300238529303 --- Val Loss: 0.03921477550581339\n",
      "Epoch 4410/10000 --- Train Loss: 0.07794014445565761 --- Val Loss: 0.039146951479041514\n",
      "Epoch 4420/10000 --- Train Loss: 0.07786725841622906 --- Val Loss: 0.039079122540020064\n",
      "Epoch 4430/10000 --- Train Loss: 0.07779489930308676 --- Val Loss: 0.03901148658267997\n",
      "Epoch 4440/10000 --- Train Loss: 0.07772352197366761 --- Val Loss: 0.03894637159447448\n",
      "Epoch 4450/10000 --- Train Loss: 0.07765222169189973 --- Val Loss: 0.03887967284388908\n",
      "Epoch 4460/10000 --- Train Loss: 0.07758173254847228 --- Val Loss: 0.03881432784362926\n",
      "Epoch 4470/10000 --- Train Loss: 0.07751137833966759 --- Val Loss: 0.03874996938543839\n",
      "Epoch 4480/10000 --- Train Loss: 0.07744114657539218 --- Val Loss: 0.03868681440338842\n",
      "Epoch 4490/10000 --- Train Loss: 0.07737109645924732 --- Val Loss: 0.03862229720799928\n",
      "Epoch 4500/10000 --- Train Loss: 0.07730132768623432 --- Val Loss: 0.03855801747110149\n",
      "Epoch 4510/10000 --- Train Loss: 0.07723225946208787 --- Val Loss: 0.03849449319030141\n",
      "Epoch 4520/10000 --- Train Loss: 0.07716385559521696 --- Val Loss: 0.0384328552237537\n",
      "Epoch 4530/10000 --- Train Loss: 0.07709521646569852 --- Val Loss: 0.03836963990044552\n",
      "Epoch 4540/10000 --- Train Loss: 0.07702667782044723 --- Val Loss: 0.03830609405094845\n",
      "Epoch 4550/10000 --- Train Loss: 0.07695824931104568 --- Val Loss: 0.03824083613176978\n",
      "Epoch 4560/10000 --- Train Loss: 0.07689088466286224 --- Val Loss: 0.038178961601168473\n",
      "Epoch 4570/10000 --- Train Loss: 0.07682366094764838 --- Val Loss: 0.03811741746874347\n",
      "Epoch 4580/10000 --- Train Loss: 0.07675742919362089 --- Val Loss: 0.038055670365118505\n",
      "Epoch 4590/10000 --- Train Loss: 0.0766912367102764 --- Val Loss: 0.03799603113089867\n",
      "Epoch 4600/10000 --- Train Loss: 0.07662471896798714 --- Val Loss: 0.0379336297830825\n",
      "Epoch 4610/10000 --- Train Loss: 0.07655886755173097 --- Val Loss: 0.037873323470067756\n",
      "Epoch 4620/10000 --- Train Loss: 0.07649311747000838 --- Val Loss: 0.037812591379825226\n",
      "Epoch 4630/10000 --- Train Loss: 0.07642833950011772 --- Val Loss: 0.03775364483629469\n",
      "Epoch 4640/10000 --- Train Loss: 0.076362662238502 --- Val Loss: 0.03769118770236124\n",
      "Epoch 4650/10000 --- Train Loss: 0.07629862497012761 --- Val Loss: 0.03763265402176471\n",
      "Epoch 4660/10000 --- Train Loss: 0.07623407484110284 --- Val Loss: 0.037573159108145404\n",
      "Epoch 4670/10000 --- Train Loss: 0.07616996213805598 --- Val Loss: 0.03751415653326736\n",
      "Epoch 4680/10000 --- Train Loss: 0.07610645181481093 --- Val Loss: 0.03745547877515215\n",
      "Epoch 4690/10000 --- Train Loss: 0.07604294540056539 --- Val Loss: 0.0373972423580728\n",
      "Epoch 4700/10000 --- Train Loss: 0.0759807977704167 --- Val Loss: 0.03734178820659196\n",
      "Epoch 4710/10000 --- Train Loss: 0.0759186380504653 --- Val Loss: 0.03728610837650572\n",
      "Epoch 4720/10000 --- Train Loss: 0.07585639801846729 --- Val Loss: 0.037230421435550415\n",
      "Epoch 4730/10000 --- Train Loss: 0.07579428869010621 --- Val Loss: 0.0371717716344077\n",
      "Epoch 4740/10000 --- Train Loss: 0.0757327063526919 --- Val Loss: 0.03711550299295319\n",
      "Epoch 4750/10000 --- Train Loss: 0.07567168089215544 --- Val Loss: 0.03706213708858059\n",
      "Epoch 4760/10000 --- Train Loss: 0.07561059527233316 --- Val Loss: 0.037006569814461314\n",
      "Epoch 4770/10000 --- Train Loss: 0.07555013377736619 --- Val Loss: 0.036953171410700585\n",
      "Epoch 4780/10000 --- Train Loss: 0.07548943349334407 --- Val Loss: 0.03689697713416481\n",
      "Epoch 4790/10000 --- Train Loss: 0.07542866909761269 --- Val Loss: 0.03684118663920102\n",
      "Epoch 4800/10000 --- Train Loss: 0.07536837328388823 --- Val Loss: 0.036786521264236795\n",
      "Epoch 4810/10000 --- Train Loss: 0.0753081199963162 --- Val Loss: 0.03673063877261504\n",
      "Epoch 4820/10000 --- Train Loss: 0.07524848324651776 --- Val Loss: 0.03667679981645252\n",
      "Epoch 4830/10000 --- Train Loss: 0.07518932621824916 --- Val Loss: 0.03662424213543122\n",
      "Epoch 4840/10000 --- Train Loss: 0.07513016781964789 --- Val Loss: 0.036569969432125\n",
      "Epoch 4850/10000 --- Train Loss: 0.07507165088946732 --- Val Loss: 0.03651608190118048\n",
      "Epoch 4860/10000 --- Train Loss: 0.07501294437540332 --- Val Loss: 0.03646094096681213\n",
      "Epoch 4870/10000 --- Train Loss: 0.07495451504374886 --- Val Loss: 0.03640651094944594\n",
      "Epoch 4880/10000 --- Train Loss: 0.07489663646712293 --- Val Loss: 0.03635333113498543\n",
      "Epoch 4890/10000 --- Train Loss: 0.07483913118624294 --- Val Loss: 0.03630082521832009\n",
      "Epoch 4900/10000 --- Train Loss: 0.0747817884122878 --- Val Loss: 0.036248932040296576\n",
      "Epoch 4910/10000 --- Train Loss: 0.07472478154172615 --- Val Loss: 0.03619551365420744\n",
      "Epoch 4920/10000 --- Train Loss: 0.07466798116674499 --- Val Loss: 0.03614335946827684\n",
      "Epoch 4930/10000 --- Train Loss: 0.07461089832507216 --- Val Loss: 0.036088312101627266\n",
      "Epoch 4940/10000 --- Train Loss: 0.07455463019392114 --- Val Loss: 0.03603776148333341\n",
      "Epoch 4950/10000 --- Train Loss: 0.07449868618774769 --- Val Loss: 0.035986638651855224\n",
      "Epoch 4960/10000 --- Train Loss: 0.07444262018359087 --- Val Loss: 0.03593420549601023\n",
      "Epoch 4970/10000 --- Train Loss: 0.07438685720148157 --- Val Loss: 0.03588186681558785\n",
      "Epoch 4980/10000 --- Train Loss: 0.07433095543073243 --- Val Loss: 0.03583065034115454\n",
      "Epoch 4990/10000 --- Train Loss: 0.07427574631185038 --- Val Loss: 0.035779267631171514\n",
      "Epoch 5000/10000 --- Train Loss: 0.07422053388949595 --- Val Loss: 0.03572755737820514\n",
      "Epoch 5010/10000 --- Train Loss: 0.0741659462136033 --- Val Loss: 0.035680218183839124\n",
      "Epoch 5020/10000 --- Train Loss: 0.074111354088511 --- Val Loss: 0.035629119151988464\n",
      "Epoch 5030/10000 --- Train Loss: 0.07405682433356736 --- Val Loss: 0.03557849979160551\n",
      "Epoch 5040/10000 --- Train Loss: 0.07400286969037674 --- Val Loss: 0.03553014563786597\n",
      "Epoch 5050/10000 --- Train Loss: 0.07394914983390999 --- Val Loss: 0.03548162746614995\n",
      "Epoch 5060/10000 --- Train Loss: 0.07389548179185089 --- Val Loss: 0.03543277617399261\n",
      "Epoch 5070/10000 --- Train Loss: 0.07384177342642574 --- Val Loss: 0.035382291926682366\n",
      "Epoch 5080/10000 --- Train Loss: 0.07378902209046491 --- Val Loss: 0.035334969519181615\n",
      "Epoch 5090/10000 --- Train Loss: 0.07373639855183851 --- Val Loss: 0.03528744579898554\n",
      "Epoch 5100/10000 --- Train Loss: 0.07368431887694063 --- Val Loss: 0.03524085297100678\n",
      "Epoch 5110/10000 --- Train Loss: 0.07363177301609666 --- Val Loss: 0.03519117174758673\n",
      "Epoch 5120/10000 --- Train Loss: 0.07357969736459781 --- Val Loss: 0.035144047123389706\n",
      "Epoch 5130/10000 --- Train Loss: 0.07352816515063047 --- Val Loss: 0.0350998645169491\n",
      "Epoch 5140/10000 --- Train Loss: 0.07347651316436855 --- Val Loss: 0.035053949455821465\n",
      "Epoch 5150/10000 --- Train Loss: 0.0734247690197509 --- Val Loss: 0.03500702669939642\n",
      "Epoch 5160/10000 --- Train Loss: 0.07337361003795499 --- Val Loss: 0.03495994057371105\n",
      "Epoch 5170/10000 --- Train Loss: 0.07332278731548346 --- Val Loss: 0.03491562617131246\n",
      "Epoch 5180/10000 --- Train Loss: 0.07327213332705015 --- Val Loss: 0.034870828234212246\n",
      "Epoch 5190/10000 --- Train Loss: 0.07322145609635229 --- Val Loss: 0.03482495245414841\n",
      "Epoch 5200/10000 --- Train Loss: 0.07317075956135077 --- Val Loss: 0.034777999391122257\n",
      "Epoch 5210/10000 --- Train Loss: 0.07312040328841556 --- Val Loss: 0.034732833004435276\n",
      "Epoch 5220/10000 --- Train Loss: 0.07307006669841411 --- Val Loss: 0.03468818479718808\n",
      "Epoch 5230/10000 --- Train Loss: 0.07301986879462563 --- Val Loss: 0.03464269103079832\n",
      "Epoch 5240/10000 --- Train Loss: 0.0729699680106031 --- Val Loss: 0.03459971404578591\n",
      "Epoch 5250/10000 --- Train Loss: 0.07292047454828522 --- Val Loss: 0.03455805991882021\n",
      "Epoch 5260/10000 --- Train Loss: 0.07287132425369981 --- Val Loss: 0.034514657337533845\n",
      "Epoch 5270/10000 --- Train Loss: 0.07282205131651533 --- Val Loss: 0.03446991701289532\n",
      "Epoch 5280/10000 --- Train Loss: 0.07277305535353135 --- Val Loss: 0.03442732851205439\n",
      "Epoch 5290/10000 --- Train Loss: 0.07272431758623102 --- Val Loss: 0.0343838783663014\n",
      "Epoch 5300/10000 --- Train Loss: 0.0726758421474051 --- Val Loss: 0.03434042175630016\n",
      "Epoch 5310/10000 --- Train Loss: 0.07262792377897997 --- Val Loss: 0.03429847398382049\n",
      "Epoch 5320/10000 --- Train Loss: 0.07257985238976798 --- Val Loss: 0.034258189401357\n",
      "Epoch 5330/10000 --- Train Loss: 0.07253203082001099 --- Val Loss: 0.034216913826278075\n",
      "Epoch 5340/10000 --- Train Loss: 0.07248425793958127 --- Val Loss: 0.03417363348042254\n",
      "Epoch 5350/10000 --- Train Loss: 0.07243699281551373 --- Val Loss: 0.03413011462068663\n",
      "Epoch 5360/10000 --- Train Loss: 0.07238991233302508 --- Val Loss: 0.03409035338247183\n",
      "Epoch 5370/10000 --- Train Loss: 0.07234276343565818 --- Val Loss: 0.034049206290102024\n",
      "Epoch 5380/10000 --- Train Loss: 0.07229578418593742 --- Val Loss: 0.034005419893802465\n",
      "Epoch 5390/10000 --- Train Loss: 0.0722486168763879 --- Val Loss: 0.03396237283689569\n",
      "Epoch 5400/10000 --- Train Loss: 0.07220222186572821 --- Val Loss: 0.03392166134464111\n",
      "Epoch 5410/10000 --- Train Loss: 0.07215604925901468 --- Val Loss: 0.03388239854329675\n",
      "Epoch 5420/10000 --- Train Loss: 0.07210966829937852 --- Val Loss: 0.03383943881032975\n",
      "Epoch 5430/10000 --- Train Loss: 0.07206352979247709 --- Val Loss: 0.033796879106458164\n",
      "Epoch 5440/10000 --- Train Loss: 0.0720177829699247 --- Val Loss: 0.033756590771550056\n",
      "Epoch 5450/10000 --- Train Loss: 0.07197249717687561 --- Val Loss: 0.03371735192708046\n",
      "Epoch 5460/10000 --- Train Loss: 0.07192706719010858 --- Val Loss: 0.03367816618067619\n",
      "Epoch 5470/10000 --- Train Loss: 0.07188243792146748 --- Val Loss: 0.033640679077971886\n",
      "Epoch 5480/10000 --- Train Loss: 0.07183733639008517 --- Val Loss: 0.033601122369410014\n",
      "Epoch 5490/10000 --- Train Loss: 0.07179271472072475 --- Val Loss: 0.03356389202964429\n",
      "Epoch 5500/10000 --- Train Loss: 0.07174745526858209 --- Val Loss: 0.03352269203615549\n",
      "Epoch 5510/10000 --- Train Loss: 0.07170267864466871 --- Val Loss: 0.03348503878645951\n",
      "Epoch 5520/10000 --- Train Loss: 0.07165796430647915 --- Val Loss: 0.03344904723919721\n",
      "Epoch 5530/10000 --- Train Loss: 0.07161298000613942 --- Val Loss: 0.033407972693626095\n",
      "Epoch 5540/10000 --- Train Loss: 0.07156813602615707 --- Val Loss: 0.033368884526899165\n",
      "Epoch 5550/10000 --- Train Loss: 0.0715236920116458 --- Val Loss: 0.03333112991534123\n",
      "Epoch 5560/10000 --- Train Loss: 0.07147907238801811 --- Val Loss: 0.03329158736731435\n",
      "Epoch 5570/10000 --- Train Loss: 0.0714349694895723 --- Val Loss: 0.03325443885613962\n",
      "Epoch 5580/10000 --- Train Loss: 0.07139077577886585 --- Val Loss: 0.0332143984977643\n",
      "Epoch 5590/10000 --- Train Loss: 0.07134648076626292 --- Val Loss: 0.03317452569220441\n",
      "Epoch 5600/10000 --- Train Loss: 0.07130263155508662 --- Val Loss: 0.03313640025574172\n",
      "Epoch 5610/10000 --- Train Loss: 0.07125911839686297 --- Val Loss: 0.03309710078467846\n",
      "Epoch 5620/10000 --- Train Loss: 0.0712154927807862 --- Val Loss: 0.033060942978027516\n",
      "Epoch 5630/10000 --- Train Loss: 0.07117152579828312 --- Val Loss: 0.03302268673514742\n",
      "Epoch 5640/10000 --- Train Loss: 0.07112771144796791 --- Val Loss: 0.03298453467594613\n",
      "Epoch 5650/10000 --- Train Loss: 0.07108438409628041 --- Val Loss: 0.03294790607145675\n",
      "Epoch 5660/10000 --- Train Loss: 0.07104106427866201 --- Val Loss: 0.032909366107795525\n",
      "Epoch 5670/10000 --- Train Loss: 0.07099796656217186 --- Val Loss: 0.03287256923545242\n",
      "Epoch 5680/10000 --- Train Loss: 0.07095494685218529 --- Val Loss: 0.032835549338073866\n",
      "Epoch 5690/10000 --- Train Loss: 0.07091180902047767 --- Val Loss: 0.032796620409301785\n",
      "Epoch 5700/10000 --- Train Loss: 0.0708695182432064 --- Val Loss: 0.03276158108218826\n",
      "Epoch 5710/10000 --- Train Loss: 0.07082699811209299 --- Val Loss: 0.03272543256727779\n",
      "Epoch 5720/10000 --- Train Loss: 0.07078490810248285 --- Val Loss: 0.032690702226445545\n",
      "Epoch 5730/10000 --- Train Loss: 0.07074288602129439 --- Val Loss: 0.032652534370422696\n",
      "Epoch 5740/10000 --- Train Loss: 0.07070068241680667 --- Val Loss: 0.032616503898892556\n",
      "Epoch 5750/10000 --- Train Loss: 0.07065892227263167 --- Val Loss: 0.0325817569832696\n",
      "Epoch 5760/10000 --- Train Loss: 0.0706169667732161 --- Val Loss: 0.03254399647859244\n",
      "Epoch 5770/10000 --- Train Loss: 0.07057476048864941 --- Val Loss: 0.03250897052098588\n",
      "Epoch 5780/10000 --- Train Loss: 0.07053297808658317 --- Val Loss: 0.03247485834664648\n",
      "Epoch 5790/10000 --- Train Loss: 0.07049136200800947 --- Val Loss: 0.032442736377501495\n",
      "Epoch 5800/10000 --- Train Loss: 0.07044961967481941 --- Val Loss: 0.03240894325228853\n",
      "Epoch 5810/10000 --- Train Loss: 0.07040838016463405 --- Val Loss: 0.03237560786939895\n",
      "Epoch 5820/10000 --- Train Loss: 0.07036717423285525 --- Val Loss: 0.032340808702541336\n",
      "Epoch 5830/10000 --- Train Loss: 0.07032582706780398 --- Val Loss: 0.03230842303446924\n",
      "Epoch 5840/10000 --- Train Loss: 0.07028382199296132 --- Val Loss: 0.03227317875789269\n",
      "Epoch 5850/10000 --- Train Loss: 0.07024243378238204 --- Val Loss: 0.032238752756211284\n",
      "Epoch 5860/10000 --- Train Loss: 0.07020115898930256 --- Val Loss: 0.032206018401052534\n",
      "Epoch 5870/10000 --- Train Loss: 0.07016035926513385 --- Val Loss: 0.03217412660615209\n",
      "Epoch 5880/10000 --- Train Loss: 0.07011925932580876 --- Val Loss: 0.03213923218894575\n",
      "Epoch 5890/10000 --- Train Loss: 0.07007836071137231 --- Val Loss: 0.03210597377587655\n",
      "Epoch 5900/10000 --- Train Loss: 0.07003730906047856 --- Val Loss: 0.032072548414234604\n",
      "Epoch 5910/10000 --- Train Loss: 0.0699968906385084 --- Val Loss: 0.03204000283224096\n",
      "Epoch 5920/10000 --- Train Loss: 0.06995600856583976 --- Val Loss: 0.032005957227185\n",
      "Epoch 5930/10000 --- Train Loss: 0.06991565787138065 --- Val Loss: 0.031972872956748236\n",
      "Epoch 5940/10000 --- Train Loss: 0.06987556510684936 --- Val Loss: 0.03193895294291341\n",
      "Epoch 5950/10000 --- Train Loss: 0.06983538049331882 --- Val Loss: 0.031906298386904196\n",
      "Epoch 5960/10000 --- Train Loss: 0.06979551293140136 --- Val Loss: 0.031875080494952926\n",
      "Epoch 5970/10000 --- Train Loss: 0.06975577984072023 --- Val Loss: 0.031840533403889\n",
      "Epoch 5980/10000 --- Train Loss: 0.06971601566685595 --- Val Loss: 0.031808411358733045\n",
      "Epoch 5990/10000 --- Train Loss: 0.06967610308413748 --- Val Loss: 0.03177511151414315\n",
      "Epoch 6000/10000 --- Train Loss: 0.06963669211218565 --- Val Loss: 0.03174432855009929\n",
      "Epoch 6010/10000 --- Train Loss: 0.06959728100038773 --- Val Loss: 0.031713374432351595\n",
      "Epoch 6020/10000 --- Train Loss: 0.06955780311937619 --- Val Loss: 0.03168085449937766\n",
      "Epoch 6030/10000 --- Train Loss: 0.06951847988951329 --- Val Loss: 0.03164868139104524\n",
      "Epoch 6040/10000 --- Train Loss: 0.0694793162434009 --- Val Loss: 0.031616042587303446\n",
      "Epoch 6050/10000 --- Train Loss: 0.06944033884277984 --- Val Loss: 0.03158461974935922\n",
      "Epoch 6060/10000 --- Train Loss: 0.06940122051911776 --- Val Loss: 0.03155252978126933\n",
      "Epoch 6070/10000 --- Train Loss: 0.0693623196613599 --- Val Loss: 0.03152088204822338\n",
      "Epoch 6080/10000 --- Train Loss: 0.06932319592338142 --- Val Loss: 0.03148701624349309\n",
      "Epoch 6090/10000 --- Train Loss: 0.06928490394685785 --- Val Loss: 0.03145758340378414\n",
      "Epoch 6100/10000 --- Train Loss: 0.06924608299365849 --- Val Loss: 0.03142624354444366\n",
      "Epoch 6110/10000 --- Train Loss: 0.06920710598900866 --- Val Loss: 0.03139400955091506\n",
      "Epoch 6120/10000 --- Train Loss: 0.06916881871894652 --- Val Loss: 0.03136360283506267\n",
      "Epoch 6130/10000 --- Train Loss: 0.06913029655661576 --- Val Loss: 0.03133304456333014\n",
      "Epoch 6140/10000 --- Train Loss: 0.06909224116473767 --- Val Loss: 0.03130443285907389\n",
      "Epoch 6150/10000 --- Train Loss: 0.06905399310072352 --- Val Loss: 0.031271581395606984\n",
      "Epoch 6160/10000 --- Train Loss: 0.06901603109652434 --- Val Loss: 0.031242181527149162\n",
      "Epoch 6170/10000 --- Train Loss: 0.0689787134620096 --- Val Loss: 0.03121229132712211\n",
      "Epoch 6180/10000 --- Train Loss: 0.06894097490060752 --- Val Loss: 0.031180803636366484\n",
      "Epoch 6190/10000 --- Train Loss: 0.06890338374943568 --- Val Loss: 0.031151911506545647\n",
      "Epoch 6200/10000 --- Train Loss: 0.06886568962605834 --- Val Loss: 0.031120671225413423\n",
      "Epoch 6210/10000 --- Train Loss: 0.06882794517136885 --- Val Loss: 0.03108826089548161\n",
      "Epoch 6220/10000 --- Train Loss: 0.068790552433389 --- Val Loss: 0.03105611310251379\n",
      "Epoch 6230/10000 --- Train Loss: 0.06875354053502708 --- Val Loss: 0.03102626870583313\n",
      "Epoch 6240/10000 --- Train Loss: 0.06871705341519303 --- Val Loss: 0.030996262033325905\n",
      "Epoch 6250/10000 --- Train Loss: 0.06868065592894146 --- Val Loss: 0.030971246110199663\n",
      "Epoch 6260/10000 --- Train Loss: 0.06864376118199944 --- Val Loss: 0.030940457768013286\n",
      "Epoch 6270/10000 --- Train Loss: 0.06860731520942183 --- Val Loss: 0.030913144619240506\n",
      "Epoch 6280/10000 --- Train Loss: 0.06857083394307513 --- Val Loss: 0.03088020294614231\n",
      "Epoch 6290/10000 --- Train Loss: 0.06853475274251306 --- Val Loss: 0.030850178669853262\n",
      "Epoch 6300/10000 --- Train Loss: 0.06849848814343602 --- Val Loss: 0.030820551596478597\n",
      "Epoch 6310/10000 --- Train Loss: 0.06846262563028373 --- Val Loss: 0.030793766225660983\n",
      "Epoch 6320/10000 --- Train Loss: 0.06842672423574427 --- Val Loss: 0.030761761479280274\n",
      "Epoch 6330/10000 --- Train Loss: 0.06839089018371065 --- Val Loss: 0.03073340945927257\n",
      "Epoch 6340/10000 --- Train Loss: 0.06835499933429384 --- Val Loss: 0.030703741440534095\n",
      "Epoch 6350/10000 --- Train Loss: 0.06831972968190753 --- Val Loss: 0.030674545848589405\n",
      "Epoch 6360/10000 --- Train Loss: 0.06828433782080598 --- Val Loss: 0.030646046784571675\n",
      "Epoch 6370/10000 --- Train Loss: 0.06824894323042748 --- Val Loss: 0.030616857689075808\n",
      "Epoch 6380/10000 --- Train Loss: 0.0682136482147941 --- Val Loss: 0.030587991274174407\n",
      "Epoch 6390/10000 --- Train Loss: 0.06817874946074663 --- Val Loss: 0.03055928822636442\n",
      "Epoch 6400/10000 --- Train Loss: 0.06814398078659069 --- Val Loss: 0.030531086175082954\n",
      "Epoch 6410/10000 --- Train Loss: 0.06810868702043503 --- Val Loss: 0.030500111090568667\n",
      "Epoch 6420/10000 --- Train Loss: 0.06807364203970973 --- Val Loss: 0.030468019607394866\n",
      "Epoch 6430/10000 --- Train Loss: 0.06803897227005813 --- Val Loss: 0.030439015130139586\n",
      "Epoch 6440/10000 --- Train Loss: 0.06800420541954434 --- Val Loss: 0.030408821083860917\n",
      "Epoch 6450/10000 --- Train Loss: 0.06796967352717227 --- Val Loss: 0.030378822920684938\n",
      "Epoch 6460/10000 --- Train Loss: 0.06793482870911824 --- Val Loss: 0.030349605543115696\n",
      "Epoch 6470/10000 --- Train Loss: 0.06790095788427884 --- Val Loss: 0.030321434268315843\n",
      "Epoch 6480/10000 --- Train Loss: 0.06786633707919983 --- Val Loss: 0.03029160761657471\n",
      "Epoch 6490/10000 --- Train Loss: 0.06783200019417082 --- Val Loss: 0.03026162794603349\n",
      "Epoch 6500/10000 --- Train Loss: 0.06779817243001166 --- Val Loss: 0.03023393144388319\n",
      "Epoch 6510/10000 --- Train Loss: 0.06776405344876538 --- Val Loss: 0.030204628569741442\n",
      "Epoch 6520/10000 --- Train Loss: 0.06773023196269123 --- Val Loss: 0.030174936954277743\n",
      "Epoch 6530/10000 --- Train Loss: 0.06769657730517492 --- Val Loss: 0.03014740224933534\n",
      "Epoch 6540/10000 --- Train Loss: 0.06766314059155316 --- Val Loss: 0.030118423920116346\n",
      "Epoch 6550/10000 --- Train Loss: 0.06762963924156098 --- Val Loss: 0.03008896460791527\n",
      "Epoch 6560/10000 --- Train Loss: 0.06759660522513027 --- Val Loss: 0.030062804293589148\n",
      "Epoch 6570/10000 --- Train Loss: 0.06756320494639416 --- Val Loss: 0.030033427976901405\n",
      "Epoch 6580/10000 --- Train Loss: 0.0675306727307032 --- Val Loss: 0.030008180735382115\n",
      "Epoch 6590/10000 --- Train Loss: 0.0674975105696663 --- Val Loss: 0.029980000116718798\n",
      "Epoch 6600/10000 --- Train Loss: 0.06746450145184983 --- Val Loss: 0.029952518094354126\n",
      "Epoch 6610/10000 --- Train Loss: 0.06743164371879305 --- Val Loss: 0.029923436013693367\n",
      "Epoch 6620/10000 --- Train Loss: 0.0673988838686747 --- Val Loss: 0.02989494257836928\n",
      "Epoch 6630/10000 --- Train Loss: 0.06736637105310317 --- Val Loss: 0.02986761178627338\n",
      "Epoch 6640/10000 --- Train Loss: 0.06733403649062202 --- Val Loss: 0.029840564463583255\n",
      "Epoch 6650/10000 --- Train Loss: 0.06730162648391015 --- Val Loss: 0.029812420110752594\n",
      "Epoch 6660/10000 --- Train Loss: 0.06726973415272523 --- Val Loss: 0.029787507877894984\n",
      "Epoch 6670/10000 --- Train Loss: 0.0672377926718814 --- Val Loss: 0.02976095916953456\n",
      "Epoch 6680/10000 --- Train Loss: 0.06720576487381397 --- Val Loss: 0.02973471334456361\n",
      "Epoch 6690/10000 --- Train Loss: 0.06717390288292077 --- Val Loss: 0.029707780820946113\n",
      "Epoch 6700/10000 --- Train Loss: 0.06714198436270742 --- Val Loss: 0.02968128648809574\n",
      "Epoch 6710/10000 --- Train Loss: 0.0671106005231753 --- Val Loss: 0.029656588346785473\n",
      "Epoch 6720/10000 --- Train Loss: 0.06707922511170258 --- Val Loss: 0.029631681407992185\n",
      "Epoch 6730/10000 --- Train Loss: 0.06704777139719444 --- Val Loss: 0.029605939828774137\n",
      "Epoch 6740/10000 --- Train Loss: 0.06701653631625276 --- Val Loss: 0.029580453846899578\n",
      "Epoch 6750/10000 --- Train Loss: 0.06698569529831033 --- Val Loss: 0.029556652592874936\n",
      "Epoch 6760/10000 --- Train Loss: 0.06695470317933921 --- Val Loss: 0.029531784927779872\n",
      "Epoch 6770/10000 --- Train Loss: 0.06692353211718138 --- Val Loss: 0.029506945955601344\n",
      "Epoch 6780/10000 --- Train Loss: 0.06689261595257022 --- Val Loss: 0.029478275564731607\n",
      "Epoch 6790/10000 --- Train Loss: 0.06686199255164141 --- Val Loss: 0.02945407658600646\n",
      "Epoch 6800/10000 --- Train Loss: 0.06683134752977649 --- Val Loss: 0.029429427327977067\n",
      "Epoch 6810/10000 --- Train Loss: 0.06680086729102376 --- Val Loss: 0.029405534700105866\n",
      "Epoch 6820/10000 --- Train Loss: 0.0667703396609127 --- Val Loss: 0.029381531351830234\n",
      "Epoch 6830/10000 --- Train Loss: 0.06673980606677378 --- Val Loss: 0.02935582673360486\n",
      "Epoch 6840/10000 --- Train Loss: 0.06670973888049442 --- Val Loss: 0.029332956754581883\n",
      "Epoch 6850/10000 --- Train Loss: 0.06667952915441566 --- Val Loss: 0.029308030872046514\n",
      "Epoch 6860/10000 --- Train Loss: 0.06664957157081283 --- Val Loss: 0.02928351959784639\n",
      "Epoch 6870/10000 --- Train Loss: 0.06661996252884066 --- Val Loss: 0.029261457846590243\n",
      "Epoch 6880/10000 --- Train Loss: 0.06659051058659007 --- Val Loss: 0.029239615069300735\n",
      "Epoch 6890/10000 --- Train Loss: 0.0665609997242849 --- Val Loss: 0.029216130759760654\n",
      "Epoch 6900/10000 --- Train Loss: 0.06653160065486426 --- Val Loss: 0.02919325448092926\n",
      "Epoch 6910/10000 --- Train Loss: 0.06650223891532311 --- Val Loss: 0.029169773108973996\n",
      "Epoch 6920/10000 --- Train Loss: 0.06647322708404713 --- Val Loss: 0.02914937709264335\n",
      "Epoch 6930/10000 --- Train Loss: 0.06644408518100128 --- Val Loss: 0.02912525576665701\n",
      "Epoch 6940/10000 --- Train Loss: 0.06641545744347174 --- Val Loss: 0.02910567976119103\n",
      "Epoch 6950/10000 --- Train Loss: 0.06638633115731624 --- Val Loss: 0.029082286574760603\n",
      "Epoch 6960/10000 --- Train Loss: 0.06635764632121809 --- Val Loss: 0.02906144618745832\n",
      "Epoch 6970/10000 --- Train Loss: 0.06632900444406728 --- Val Loss: 0.029042059933183477\n",
      "Epoch 6980/10000 --- Train Loss: 0.06630021761817033 --- Val Loss: 0.029019786728982346\n",
      "Epoch 6990/10000 --- Train Loss: 0.06627121171199461 --- Val Loss: 0.02899550055877798\n",
      "Epoch 7000/10000 --- Train Loss: 0.06624253906909339 --- Val Loss: 0.028971628088921595\n",
      "Epoch 7010/10000 --- Train Loss: 0.06621407984572361 --- Val Loss: 0.0289506856491164\n",
      "Epoch 7020/10000 --- Train Loss: 0.06618572060932684 --- Val Loss: 0.028929783853627135\n",
      "Epoch 7030/10000 --- Train Loss: 0.06615720354491174 --- Val Loss: 0.028907454697302777\n",
      "Epoch 7040/10000 --- Train Loss: 0.06612859698982608 --- Val Loss: 0.028881968562213103\n",
      "Epoch 7050/10000 --- Train Loss: 0.06610042339387122 --- Val Loss: 0.02886241685113315\n",
      "Epoch 7060/10000 --- Train Loss: 0.06607253346666934 --- Val Loss: 0.028841895267933595\n",
      "Epoch 7070/10000 --- Train Loss: 0.06604426964178428 --- Val Loss: 0.028817511043923848\n",
      "Epoch 7080/10000 --- Train Loss: 0.06601621946024178 --- Val Loss: 0.028794960715624807\n",
      "Epoch 7090/10000 --- Train Loss: 0.06598839406242457 --- Val Loss: 0.02877312708143544\n",
      "Epoch 7100/10000 --- Train Loss: 0.0659606264649786 --- Val Loss: 0.02875255710049413\n",
      "Epoch 7110/10000 --- Train Loss: 0.06593272600625974 --- Val Loss: 0.028728844142925005\n",
      "Epoch 7120/10000 --- Train Loss: 0.06590523489795434 --- Val Loss: 0.028708741677060477\n",
      "Epoch 7130/10000 --- Train Loss: 0.06587808671817477 --- Val Loss: 0.028688559158956607\n",
      "Epoch 7140/10000 --- Train Loss: 0.06585058631768184 --- Val Loss: 0.028666339283293093\n",
      "Epoch 7150/10000 --- Train Loss: 0.0658232123570738 --- Val Loss: 0.028644211352122913\n",
      "Epoch 7160/10000 --- Train Loss: 0.06579617124115922 --- Val Loss: 0.028622623939587248\n",
      "Epoch 7170/10000 --- Train Loss: 0.0657691758216985 --- Val Loss: 0.028603870030530977\n",
      "Epoch 7180/10000 --- Train Loss: 0.06574196912200117 --- Val Loss: 0.028581192809046918\n",
      "Epoch 7190/10000 --- Train Loss: 0.06571517261749918 --- Val Loss: 0.028562104454020687\n",
      "Epoch 7200/10000 --- Train Loss: 0.06568824368940998 --- Val Loss: 0.028540212885679702\n",
      "Epoch 7210/10000 --- Train Loss: 0.06566144752658044 --- Val Loss: 0.028520151535514623\n",
      "Epoch 7220/10000 --- Train Loss: 0.06563503661812507 --- Val Loss: 0.028499933298483243\n",
      "Epoch 7230/10000 --- Train Loss: 0.06560846049707546 --- Val Loss: 0.02847916683054895\n",
      "Epoch 7240/10000 --- Train Loss: 0.06558221333055596 --- Val Loss: 0.02846056925086535\n",
      "Epoch 7250/10000 --- Train Loss: 0.06555577011190396 --- Val Loss: 0.02844101288874978\n",
      "Epoch 7260/10000 --- Train Loss: 0.06552903878289733 --- Val Loss: 0.02841796183206801\n",
      "Epoch 7270/10000 --- Train Loss: 0.06550253248718928 --- Val Loss: 0.028398984117940188\n",
      "Epoch 7280/10000 --- Train Loss: 0.06547599854341568 --- Val Loss: 0.028377325513030422\n",
      "Epoch 7290/10000 --- Train Loss: 0.06544965168894866 --- Val Loss: 0.028358448799858504\n",
      "Epoch 7300/10000 --- Train Loss: 0.06542338094285961 --- Val Loss: 0.02833697565496375\n",
      "Epoch 7310/10000 --- Train Loss: 0.06539767646298221 --- Val Loss: 0.028319058864066538\n",
      "Epoch 7320/10000 --- Train Loss: 0.0653714993079333 --- Val Loss: 0.02829781664903404\n",
      "Epoch 7330/10000 --- Train Loss: 0.06534541689798436 --- Val Loss: 0.028277456558460094\n",
      "Epoch 7340/10000 --- Train Loss: 0.06531919917456201 --- Val Loss: 0.02825552438817983\n",
      "Epoch 7350/10000 --- Train Loss: 0.0652936189202033 --- Val Loss: 0.028235610823874286\n",
      "Epoch 7360/10000 --- Train Loss: 0.06526785439460485 --- Val Loss: 0.028215142017701127\n",
      "Epoch 7370/10000 --- Train Loss: 0.06524211354655121 --- Val Loss: 0.028193781348507755\n",
      "Epoch 7380/10000 --- Train Loss: 0.06521643176272532 --- Val Loss: 0.028174167849704352\n",
      "Epoch 7390/10000 --- Train Loss: 0.06519124645584419 --- Val Loss: 0.0281568644022311\n",
      "Epoch 7400/10000 --- Train Loss: 0.0651656662661652 --- Val Loss: 0.028135749761149662\n",
      "Epoch 7410/10000 --- Train Loss: 0.06514014733822861 --- Val Loss: 0.028115640664471257\n",
      "Epoch 7420/10000 --- Train Loss: 0.06511488219896173 --- Val Loss: 0.028096058810337884\n",
      "Epoch 7430/10000 --- Train Loss: 0.06508995263795458 --- Val Loss: 0.028077230954183147\n",
      "Epoch 7440/10000 --- Train Loss: 0.06506478888132117 --- Val Loss: 0.028056675529042462\n",
      "Epoch 7450/10000 --- Train Loss: 0.06503988174700079 --- Val Loss: 0.02803816139381503\n",
      "Epoch 7460/10000 --- Train Loss: 0.06501503428122767 --- Val Loss: 0.028019284895715764\n",
      "Epoch 7470/10000 --- Train Loss: 0.06499033559339908 --- Val Loss: 0.028000510430801078\n",
      "Epoch 7480/10000 --- Train Loss: 0.06496560032917141 --- Val Loss: 0.027980001004660058\n",
      "Epoch 7490/10000 --- Train Loss: 0.06494057173079687 --- Val Loss: 0.027960497676146324\n",
      "Epoch 7500/10000 --- Train Loss: 0.06491578535361771 --- Val Loss: 0.027940881412289287\n",
      "Epoch 7510/10000 --- Train Loss: 0.06489098587137912 --- Val Loss: 0.027920489550711254\n",
      "Epoch 7520/10000 --- Train Loss: 0.0648664822820413 --- Val Loss: 0.02790080234241163\n",
      "Epoch 7530/10000 --- Train Loss: 0.06484164949383 --- Val Loss: 0.027881041224428273\n",
      "Epoch 7540/10000 --- Train Loss: 0.06481690227392255 --- Val Loss: 0.027856293238521974\n",
      "Epoch 7550/10000 --- Train Loss: 0.06479241024026001 --- Val Loss: 0.027839344281053315\n",
      "Epoch 7560/10000 --- Train Loss: 0.06476830471918522 --- Val Loss: 0.027819258404003233\n",
      "Epoch 7570/10000 --- Train Loss: 0.06474395058424713 --- Val Loss: 0.02780130431838284\n",
      "Epoch 7580/10000 --- Train Loss: 0.06471973051131977 --- Val Loss: 0.02778308399841392\n",
      "Epoch 7590/10000 --- Train Loss: 0.06469530112714664 --- Val Loss: 0.02776383152716651\n",
      "Epoch 7600/10000 --- Train Loss: 0.06467111818675988 --- Val Loss: 0.027744852524303774\n",
      "Epoch 7610/10000 --- Train Loss: 0.0646471327890712 --- Val Loss: 0.027726237706794287\n",
      "Epoch 7620/10000 --- Train Loss: 0.06462307250352055 --- Val Loss: 0.027708407935621543\n",
      "Epoch 7630/10000 --- Train Loss: 0.06459923840536065 --- Val Loss: 0.027689330090973137\n",
      "Epoch 7640/10000 --- Train Loss: 0.06457544602458715 --- Val Loss: 0.02767153657931085\n",
      "Epoch 7650/10000 --- Train Loss: 0.06455174538713855 --- Val Loss: 0.027652574132466436\n",
      "Epoch 7660/10000 --- Train Loss: 0.06452770984824524 --- Val Loss: 0.027633569543634294\n",
      "Epoch 7670/10000 --- Train Loss: 0.06450381931300725 --- Val Loss: 0.027613517290635985\n",
      "Epoch 7680/10000 --- Train Loss: 0.06448037337373796 --- Val Loss: 0.02759565428226728\n",
      "Epoch 7690/10000 --- Train Loss: 0.0644568221043057 --- Val Loss: 0.02757734955051352\n",
      "Epoch 7700/10000 --- Train Loss: 0.0644334144050416 --- Val Loss: 0.027559264981197516\n",
      "Epoch 7710/10000 --- Train Loss: 0.06440974042775281 --- Val Loss: 0.027539036139635292\n",
      "Epoch 7720/10000 --- Train Loss: 0.06438624101710079 --- Val Loss: 0.02751794756252194\n",
      "Epoch 7730/10000 --- Train Loss: 0.06436274952605386 --- Val Loss: 0.027500029613720476\n",
      "Epoch 7740/10000 --- Train Loss: 0.064339234434553 --- Val Loss: 0.027481414429342738\n",
      "Epoch 7750/10000 --- Train Loss: 0.06431619283298652 --- Val Loss: 0.027463095722817722\n",
      "Epoch 7760/10000 --- Train Loss: 0.06429322727577215 --- Val Loss: 0.027445099956435556\n",
      "Epoch 7770/10000 --- Train Loss: 0.06426978987027648 --- Val Loss: 0.027425216612592822\n",
      "Epoch 7780/10000 --- Train Loss: 0.06424653565992154 --- Val Loss: 0.02740655019759584\n",
      "Epoch 7790/10000 --- Train Loss: 0.06422387554373192 --- Val Loss: 0.027391963225786346\n",
      "Epoch 7800/10000 --- Train Loss: 0.06420094639289557 --- Val Loss: 0.027372409560122313\n",
      "Epoch 7810/10000 --- Train Loss: 0.06417789227120228 --- Val Loss: 0.02735538910055062\n",
      "Epoch 7820/10000 --- Train Loss: 0.06415496198792102 --- Val Loss: 0.02733602786469854\n",
      "Epoch 7830/10000 --- Train Loss: 0.06413226838037304 --- Val Loss: 0.027318190718930917\n",
      "Epoch 7840/10000 --- Train Loss: 0.06410948874315785 --- Val Loss: 0.0272986642652875\n",
      "Epoch 7850/10000 --- Train Loss: 0.06408685101646029 --- Val Loss: 0.02728233269889358\n",
      "Epoch 7860/10000 --- Train Loss: 0.06406450489200097 --- Val Loss: 0.027262657742829505\n",
      "Epoch 7870/10000 --- Train Loss: 0.06404208127803228 --- Val Loss: 0.02724569510441094\n",
      "Epoch 7880/10000 --- Train Loss: 0.06401945400202244 --- Val Loss: 0.02722833660339637\n",
      "Epoch 7890/10000 --- Train Loss: 0.06399699761013738 --- Val Loss: 0.027210472054380486\n",
      "Epoch 7900/10000 --- Train Loss: 0.06397476427823043 --- Val Loss: 0.027193900662209572\n",
      "Epoch 7910/10000 --- Train Loss: 0.06395266284248613 --- Val Loss: 0.02717675724583567\n",
      "Epoch 7920/10000 --- Train Loss: 0.06393045236760296 --- Val Loss: 0.027159423640624104\n",
      "Epoch 7930/10000 --- Train Loss: 0.06390835216030255 --- Val Loss: 0.027142854865166693\n",
      "Epoch 7940/10000 --- Train Loss: 0.06388588254192436 --- Val Loss: 0.02712399235945194\n",
      "Epoch 7950/10000 --- Train Loss: 0.06386404806984432 --- Val Loss: 0.02710551600131488\n",
      "Epoch 7960/10000 --- Train Loss: 0.06384160857735051 --- Val Loss: 0.02708739819184389\n",
      "Epoch 7970/10000 --- Train Loss: 0.06381952346594741 --- Val Loss: 0.027069829767376635\n",
      "Epoch 7980/10000 --- Train Loss: 0.06379789661913374 --- Val Loss: 0.02705252302548857\n",
      "Epoch 7990/10000 --- Train Loss: 0.0637760316608701 --- Val Loss: 0.027036825988229794\n",
      "Epoch 8000/10000 --- Train Loss: 0.06375413652341785 --- Val Loss: 0.027019135520772987\n",
      "Epoch 8010/10000 --- Train Loss: 0.06373216444008634 --- Val Loss: 0.027002575226235417\n",
      "Epoch 8020/10000 --- Train Loss: 0.06371062337632091 --- Val Loss: 0.026987632649769173\n",
      "Epoch 8030/10000 --- Train Loss: 0.06368866820498038 --- Val Loss: 0.026970454841884692\n",
      "Epoch 8040/10000 --- Train Loss: 0.06366684418891917 --- Val Loss: 0.026951860301777056\n",
      "Epoch 8050/10000 --- Train Loss: 0.06364536360877565 --- Val Loss: 0.026936596894259833\n",
      "Epoch 8060/10000 --- Train Loss: 0.06362367172466507 --- Val Loss: 0.026917726709456472\n",
      "Epoch 8070/10000 --- Train Loss: 0.06360204070021663 --- Val Loss: 0.0269005692774353\n",
      "Epoch 8080/10000 --- Train Loss: 0.06358049458925666 --- Val Loss: 0.02688214265186588\n",
      "Epoch 8090/10000 --- Train Loss: 0.06355921828812662 --- Val Loss: 0.02686622489805619\n",
      "Epoch 8100/10000 --- Train Loss: 0.063538012808765 --- Val Loss: 0.026851150261177445\n",
      "Epoch 8110/10000 --- Train Loss: 0.06351643691406351 --- Val Loss: 0.026832490410004666\n",
      "Epoch 8120/10000 --- Train Loss: 0.06349530505522433 --- Val Loss: 0.026815567563922036\n",
      "Epoch 8130/10000 --- Train Loss: 0.06347388086489114 --- Val Loss: 0.02679854314895129\n",
      "Epoch 8140/10000 --- Train Loss: 0.06345253678851147 --- Val Loss: 0.026781305870430604\n",
      "Epoch 8150/10000 --- Train Loss: 0.06343151229227971 --- Val Loss: 0.026765635244103237\n",
      "Epoch 8160/10000 --- Train Loss: 0.0634105884901581 --- Val Loss: 0.026749496055610215\n",
      "Epoch 8170/10000 --- Train Loss: 0.06338959466971722 --- Val Loss: 0.02673321961913916\n",
      "Epoch 8180/10000 --- Train Loss: 0.06336867857616059 --- Val Loss: 0.026716606159563144\n",
      "Epoch 8190/10000 --- Train Loss: 0.06334784721952678 --- Val Loss: 0.026700404818321\n",
      "Epoch 8200/10000 --- Train Loss: 0.06332674396621332 --- Val Loss: 0.02668195066054529\n",
      "Epoch 8210/10000 --- Train Loss: 0.06330597988047895 --- Val Loss: 0.026665898215919536\n",
      "Epoch 8220/10000 --- Train Loss: 0.06328523056675285 --- Val Loss: 0.02664859513410286\n",
      "Epoch 8230/10000 --- Train Loss: 0.06326507296406081 --- Val Loss: 0.026632774094492707\n",
      "Epoch 8240/10000 --- Train Loss: 0.06324436250129421 --- Val Loss: 0.026617468151483407\n",
      "Epoch 8250/10000 --- Train Loss: 0.06322349515587197 --- Val Loss: 0.026601157511287374\n",
      "Epoch 8260/10000 --- Train Loss: 0.06320296537547228 --- Val Loss: 0.026584454756727164\n",
      "Epoch 8270/10000 --- Train Loss: 0.06318244224536584 --- Val Loss: 0.026567232133721117\n",
      "Epoch 8280/10000 --- Train Loss: 0.06316190518831644 --- Val Loss: 0.026549812485146946\n",
      "Epoch 8290/10000 --- Train Loss: 0.0631414790498422 --- Val Loss: 0.026533245879279143\n",
      "Epoch 8300/10000 --- Train Loss: 0.06312146541822702 --- Val Loss: 0.0265182633009848\n",
      "Epoch 8310/10000 --- Train Loss: 0.0631009608992941 --- Val Loss: 0.026502434462371015\n",
      "Epoch 8320/10000 --- Train Loss: 0.06308088438675673 --- Val Loss: 0.02648520583174153\n",
      "Epoch 8330/10000 --- Train Loss: 0.0630605668329144 --- Val Loss: 0.02646972775996972\n",
      "Epoch 8340/10000 --- Train Loss: 0.06304023844983453 --- Val Loss: 0.02645334085729399\n",
      "Epoch 8350/10000 --- Train Loss: 0.06302065932671912 --- Val Loss: 0.026440159783692626\n",
      "Epoch 8360/10000 --- Train Loss: 0.06300056831512066 --- Val Loss: 0.026424135800421144\n",
      "Epoch 8370/10000 --- Train Loss: 0.06298083357134189 --- Val Loss: 0.02640958287051808\n",
      "Epoch 8380/10000 --- Train Loss: 0.0629608894128666 --- Val Loss: 0.026392586708282144\n",
      "Epoch 8390/10000 --- Train Loss: 0.06294080590356482 --- Val Loss: 0.026376179221504377\n",
      "Epoch 8400/10000 --- Train Loss: 0.06292086214696581 --- Val Loss: 0.026360249914383033\n",
      "Epoch 8410/10000 --- Train Loss: 0.06290103910332405 --- Val Loss: 0.026344336105002166\n",
      "Epoch 8420/10000 --- Train Loss: 0.06288146346834132 --- Val Loss: 0.026329586795416415\n",
      "Epoch 8430/10000 --- Train Loss: 0.06286207097629785 --- Val Loss: 0.02631641430512106\n",
      "Epoch 8440/10000 --- Train Loss: 0.06284217400531865 --- Val Loss: 0.026299355664168335\n",
      "Epoch 8450/10000 --- Train Loss: 0.06282256187614703 --- Val Loss: 0.02628335271941769\n",
      "Epoch 8460/10000 --- Train Loss: 0.06280273583097067 --- Val Loss: 0.02626920426310234\n",
      "Epoch 8470/10000 --- Train Loss: 0.0627826662425535 --- Val Loss: 0.026249651926027278\n",
      "Epoch 8480/10000 --- Train Loss: 0.06276321758189994 --- Val Loss: 0.026235459141877554\n",
      "Epoch 8490/10000 --- Train Loss: 0.06274357727287339 --- Val Loss: 0.026219610622392784\n",
      "Epoch 8500/10000 --- Train Loss: 0.0627240720910117 --- Val Loss: 0.026204419637977802\n",
      "Epoch 8510/10000 --- Train Loss: 0.06270478847112869 --- Val Loss: 0.026188873390566858\n",
      "Epoch 8520/10000 --- Train Loss: 0.062684965398214 --- Val Loss: 0.026171244740485603\n",
      "Epoch 8530/10000 --- Train Loss: 0.06266549361319751 --- Val Loss: 0.026154840058661418\n",
      "Epoch 8540/10000 --- Train Loss: 0.06264633968171449 --- Val Loss: 0.026138878666489077\n",
      "Epoch 8550/10000 --- Train Loss: 0.06262726297068832 --- Val Loss: 0.02612339467218361\n",
      "Epoch 8560/10000 --- Train Loss: 0.0626082226628322 --- Val Loss: 0.026108678052755938\n",
      "Epoch 8570/10000 --- Train Loss: 0.06258921977733692 --- Val Loss: 0.026094051865232448\n",
      "Epoch 8580/10000 --- Train Loss: 0.06257002052888354 --- Val Loss: 0.026078270549772156\n",
      "Epoch 8590/10000 --- Train Loss: 0.06255096309449308 --- Val Loss: 0.026062628155743884\n",
      "Epoch 8600/10000 --- Train Loss: 0.06253202974830674 --- Val Loss: 0.026045881562521495\n",
      "Epoch 8610/10000 --- Train Loss: 0.06251353387525922 --- Val Loss: 0.02603235191924429\n",
      "Epoch 8620/10000 --- Train Loss: 0.06249495828281441 --- Val Loss: 0.026018249383504166\n",
      "Epoch 8630/10000 --- Train Loss: 0.06247606342351906 --- Val Loss: 0.026000520562137506\n",
      "Epoch 8640/10000 --- Train Loss: 0.06245713301433107 --- Val Loss: 0.025986438584322872\n",
      "Epoch 8650/10000 --- Train Loss: 0.06243812668253726 --- Val Loss: 0.025970536923170983\n",
      "Epoch 8660/10000 --- Train Loss: 0.062419551968836945 --- Val Loss: 0.02595563177367684\n",
      "Epoch 8670/10000 --- Train Loss: 0.06240119190555129 --- Val Loss: 0.02594161665832052\n",
      "Epoch 8680/10000 --- Train Loss: 0.06238271351999895 --- Val Loss: 0.02592431430930678\n",
      "Epoch 8690/10000 --- Train Loss: 0.062364243527375546 --- Val Loss: 0.02591034815926008\n",
      "Epoch 8700/10000 --- Train Loss: 0.06234593549597518 --- Val Loss: 0.025895634373861404\n",
      "Epoch 8710/10000 --- Train Loss: 0.062327881851860424 --- Val Loss: 0.025881206249885606\n",
      "Epoch 8720/10000 --- Train Loss: 0.06230911520459676 --- Val Loss: 0.025865314922739278\n",
      "Epoch 8730/10000 --- Train Loss: 0.06229113765525076 --- Val Loss: 0.025848287995613787\n",
      "Epoch 8740/10000 --- Train Loss: 0.062272459868896395 --- Val Loss: 0.0258330292135672\n",
      "Epoch 8750/10000 --- Train Loss: 0.062254091820539814 --- Val Loss: 0.025816652400276155\n",
      "Epoch 8760/10000 --- Train Loss: 0.06223560082081544 --- Val Loss: 0.02580023165562367\n",
      "Epoch 8770/10000 --- Train Loss: 0.062217284121823875 --- Val Loss: 0.02578416006696362\n",
      "Epoch 8780/10000 --- Train Loss: 0.062198930512292576 --- Val Loss: 0.02576794000584127\n",
      "Epoch 8790/10000 --- Train Loss: 0.0621808936757287 --- Val Loss: 0.025753241166273116\n",
      "Epoch 8800/10000 --- Train Loss: 0.06216289565066217 --- Val Loss: 0.02574099132867807\n",
      "Epoch 8810/10000 --- Train Loss: 0.06214486379804453 --- Val Loss: 0.0257252133019861\n",
      "Epoch 8820/10000 --- Train Loss: 0.062127028741342544 --- Val Loss: 0.025711360608108882\n",
      "Epoch 8830/10000 --- Train Loss: 0.06210873582712901 --- Val Loss: 0.02569550012300081\n",
      "Epoch 8840/10000 --- Train Loss: 0.06209099292681535 --- Val Loss: 0.025682086996311887\n",
      "Epoch 8850/10000 --- Train Loss: 0.062073608386739254 --- Val Loss: 0.025667903426411117\n",
      "Epoch 8860/10000 --- Train Loss: 0.06205604502383897 --- Val Loss: 0.025654175304742087\n",
      "Epoch 8870/10000 --- Train Loss: 0.06203850605025369 --- Val Loss: 0.025640150737742447\n",
      "Epoch 8880/10000 --- Train Loss: 0.062020930894636686 --- Val Loss: 0.025626775449936672\n",
      "Epoch 8890/10000 --- Train Loss: 0.06200294069137431 --- Val Loss: 0.02561293615938451\n",
      "Epoch 8900/10000 --- Train Loss: 0.06198520327647131 --- Val Loss: 0.025597982806187605\n",
      "Epoch 8910/10000 --- Train Loss: 0.06196760566583771 --- Val Loss: 0.02558461148407711\n",
      "Epoch 8920/10000 --- Train Loss: 0.06194995218211517 --- Val Loss: 0.025569901058101648\n",
      "Epoch 8930/10000 --- Train Loss: 0.06193238096101787 --- Val Loss: 0.02555556875313632\n",
      "Epoch 8940/10000 --- Train Loss: 0.061915483365915014 --- Val Loss: 0.02554432582302793\n",
      "Epoch 8950/10000 --- Train Loss: 0.061897581038528056 --- Val Loss: 0.025527968426156247\n",
      "Epoch 8960/10000 --- Train Loss: 0.0618799210898207 --- Val Loss: 0.02551117671257093\n",
      "Epoch 8970/10000 --- Train Loss: 0.06186280759574398 --- Val Loss: 0.025499651024625248\n",
      "Epoch 8980/10000 --- Train Loss: 0.06184574743108135 --- Val Loss: 0.0254875349751634\n",
      "Epoch 8990/10000 --- Train Loss: 0.0618282634666428 --- Val Loss: 0.025474132749696243\n",
      "Epoch 9000/10000 --- Train Loss: 0.061811011852304316 --- Val Loss: 0.0254599667630732\n",
      "Epoch 9010/10000 --- Train Loss: 0.06179410514577927 --- Val Loss: 0.025448213280188172\n",
      "Epoch 9020/10000 --- Train Loss: 0.0617765273260156 --- Val Loss: 0.02543329277367298\n",
      "Epoch 9030/10000 --- Train Loss: 0.06175915327230836 --- Val Loss: 0.025417871214261162\n",
      "Epoch 9040/10000 --- Train Loss: 0.0617419749216605 --- Val Loss: 0.02540365798005137\n",
      "Epoch 9050/10000 --- Train Loss: 0.06172526556123905 --- Val Loss: 0.02539104943245867\n",
      "Epoch 9060/10000 --- Train Loss: 0.06170800320433756 --- Val Loss: 0.025374686644519265\n",
      "Epoch 9070/10000 --- Train Loss: 0.061690447222274625 --- Val Loss: 0.02536092472005821\n",
      "Epoch 9080/10000 --- Train Loss: 0.06167371222473324 --- Val Loss: 0.0253479028861659\n",
      "Epoch 9090/10000 --- Train Loss: 0.06165679906623508 --- Val Loss: 0.025334887218408163\n",
      "Epoch 9100/10000 --- Train Loss: 0.06163991277949517 --- Val Loss: 0.025319578331872497\n",
      "Epoch 9110/10000 --- Train Loss: 0.06162344162382234 --- Val Loss: 0.02530903021534443\n",
      "Epoch 9120/10000 --- Train Loss: 0.06160655625365941 --- Val Loss: 0.025294197323348762\n",
      "Epoch 9130/10000 --- Train Loss: 0.06158979317477992 --- Val Loss: 0.025280011550579167\n",
      "Epoch 9140/10000 --- Train Loss: 0.06157395649982104 --- Val Loss: 0.025271431921311753\n",
      "Epoch 9150/10000 --- Train Loss: 0.061557383780632476 --- Val Loss: 0.025256190007858108\n",
      "Epoch 9160/10000 --- Train Loss: 0.061540810869119576 --- Val Loss: 0.02524195367159279\n",
      "Epoch 9170/10000 --- Train Loss: 0.06152409699674723 --- Val Loss: 0.02522707853507314\n",
      "Epoch 9180/10000 --- Train Loss: 0.06150728433049841 --- Val Loss: 0.02521355470340519\n",
      "Epoch 9190/10000 --- Train Loss: 0.0614906365824635 --- Val Loss: 0.025199296614627165\n",
      "Epoch 9200/10000 --- Train Loss: 0.06147403180170271 --- Val Loss: 0.02518592733923362\n",
      "Epoch 9210/10000 --- Train Loss: 0.061457275474480266 --- Val Loss: 0.025171698648464465\n",
      "Epoch 9220/10000 --- Train Loss: 0.06144050757236488 --- Val Loss: 0.025157843519064443\n",
      "Epoch 9230/10000 --- Train Loss: 0.06142394160811289 --- Val Loss: 0.025144508376494363\n",
      "Epoch 9240/10000 --- Train Loss: 0.06140781696398479 --- Val Loss: 0.025132386071666287\n",
      "Epoch 9250/10000 --- Train Loss: 0.06139117424273214 --- Val Loss: 0.02511805948699565\n",
      "Epoch 9260/10000 --- Train Loss: 0.06137476238006158 --- Val Loss: 0.025104179056246248\n",
      "Epoch 9270/10000 --- Train Loss: 0.0613583139815797 --- Val Loss: 0.025091246294647866\n",
      "Epoch 9280/10000 --- Train Loss: 0.06134341858394542 --- Val Loss: 0.025086659738060846\n",
      "Epoch 9290/10000 --- Train Loss: 0.06132676638377832 --- Val Loss: 0.025071578191846418\n",
      "Epoch 9300/10000 --- Train Loss: 0.061310207579463066 --- Val Loss: 0.025057734428237402\n",
      "Epoch 9310/10000 --- Train Loss: 0.06129409293643725 --- Val Loss: 0.025043099092217594\n",
      "Epoch 9320/10000 --- Train Loss: 0.06127792285675766 --- Val Loss: 0.02503118518627219\n",
      "Epoch 9330/10000 --- Train Loss: 0.061261517261046346 --- Val Loss: 0.025016782417181554\n",
      "Epoch 9340/10000 --- Train Loss: 0.061246070359146115 --- Val Loss: 0.025004493921707956\n",
      "Epoch 9350/10000 --- Train Loss: 0.06122983697509506 --- Val Loss: 0.02499271238842735\n",
      "Epoch 9360/10000 --- Train Loss: 0.06121392231979977 --- Val Loss: 0.02498136847215727\n",
      "Epoch 9370/10000 --- Train Loss: 0.06119785407973574 --- Val Loss: 0.024968578824519617\n",
      "Epoch 9380/10000 --- Train Loss: 0.061181752804617906 --- Val Loss: 0.024954222971890924\n",
      "Epoch 9390/10000 --- Train Loss: 0.06116588151045793 --- Val Loss: 0.02494059015666861\n",
      "Epoch 9400/10000 --- Train Loss: 0.06114960140956297 --- Val Loss: 0.024925959240225046\n",
      "Epoch 9410/10000 --- Train Loss: 0.06113372632462728 --- Val Loss: 0.024912562392972553\n",
      "Epoch 9420/10000 --- Train Loss: 0.061117951532222985 --- Val Loss: 0.024901047660007395\n",
      "Epoch 9430/10000 --- Train Loss: 0.06110178905940927 --- Val Loss: 0.024887950308437764\n",
      "Epoch 9440/10000 --- Train Loss: 0.06108621637595032 --- Val Loss: 0.024874376741678347\n",
      "Epoch 9450/10000 --- Train Loss: 0.06107010664339347 --- Val Loss: 0.02486048945372189\n",
      "Epoch 9460/10000 --- Train Loss: 0.06105444547692852 --- Val Loss: 0.02484757932520063\n",
      "Epoch 9470/10000 --- Train Loss: 0.06103878303599489 --- Val Loss: 0.024834625608104295\n",
      "Epoch 9480/10000 --- Train Loss: 0.06102302665319286 --- Val Loss: 0.024821949783042616\n",
      "Epoch 9490/10000 --- Train Loss: 0.06100710868819242 --- Val Loss: 0.0248070479985828\n",
      "Epoch 9500/10000 --- Train Loss: 0.06099129241333343 --- Val Loss: 0.024794053019587654\n",
      "Epoch 9510/10000 --- Train Loss: 0.060976060528686954 --- Val Loss: 0.02478177094621659\n",
      "Epoch 9520/10000 --- Train Loss: 0.060960752870202854 --- Val Loss: 0.024772736882241343\n",
      "Epoch 9530/10000 --- Train Loss: 0.06094515237942086 --- Val Loss: 0.024759846556330803\n",
      "Epoch 9540/10000 --- Train Loss: 0.06092954426256094 --- Val Loss: 0.02474654824161808\n",
      "Epoch 9550/10000 --- Train Loss: 0.060913896454600706 --- Val Loss: 0.02473339785302675\n",
      "Epoch 9560/10000 --- Train Loss: 0.06089876894163684 --- Val Loss: 0.02472211701490104\n",
      "Epoch 9570/10000 --- Train Loss: 0.06088331791513571 --- Val Loss: 0.024709494760447443\n",
      "Epoch 9580/10000 --- Train Loss: 0.06086819219926208 --- Val Loss: 0.024696061415842168\n",
      "Epoch 9590/10000 --- Train Loss: 0.06085288609896753 --- Val Loss: 0.024685441928080327\n",
      "Epoch 9600/10000 --- Train Loss: 0.06083731603108919 --- Val Loss: 0.024672549407714742\n",
      "Epoch 9610/10000 --- Train Loss: 0.06082191676045349 --- Val Loss: 0.024657467477006118\n",
      "Epoch 9620/10000 --- Train Loss: 0.060806406524031395 --- Val Loss: 0.02464455283531817\n",
      "Epoch 9630/10000 --- Train Loss: 0.06079108679565925 --- Val Loss: 0.024631973414171865\n",
      "Epoch 9640/10000 --- Train Loss: 0.06077552961334898 --- Val Loss: 0.02461973597752639\n",
      "Epoch 9650/10000 --- Train Loss: 0.060760234317217325 --- Val Loss: 0.024605659971819516\n",
      "Epoch 9660/10000 --- Train Loss: 0.0607453497093989 --- Val Loss: 0.024594245840675606\n",
      "Epoch 9670/10000 --- Train Loss: 0.06073038646784218 --- Val Loss: 0.02458234102876761\n",
      "Epoch 9680/10000 --- Train Loss: 0.06071518511603254 --- Val Loss: 0.024568747692549645\n",
      "Epoch 9690/10000 --- Train Loss: 0.06070007928859087 --- Val Loss: 0.024555393400023096\n",
      "Epoch 9700/10000 --- Train Loss: 0.06068524282769072 --- Val Loss: 0.02454251958481968\n",
      "Epoch 9710/10000 --- Train Loss: 0.060670519718285895 --- Val Loss: 0.024532076201123902\n",
      "Epoch 9720/10000 --- Train Loss: 0.06065533065779253 --- Val Loss: 0.024518033877875125\n",
      "Epoch 9730/10000 --- Train Loss: 0.06064017633481052 --- Val Loss: 0.02450471421257022\n",
      "Epoch 9740/10000 --- Train Loss: 0.06062562862396252 --- Val Loss: 0.02449392794527157\n",
      "Epoch 9750/10000 --- Train Loss: 0.06061087995313898 --- Val Loss: 0.02448368468282131\n",
      "Epoch 9760/10000 --- Train Loss: 0.06059623360921063 --- Val Loss: 0.02447192618374708\n",
      "Epoch 9770/10000 --- Train Loss: 0.060581152690161316 --- Val Loss: 0.0244586391486489\n",
      "Epoch 9780/10000 --- Train Loss: 0.06056610823805735 --- Val Loss: 0.02444529045418905\n",
      "Epoch 9790/10000 --- Train Loss: 0.060551640205095264 --- Val Loss: 0.02443520817922439\n",
      "Epoch 9800/10000 --- Train Loss: 0.06053709836153052 --- Val Loss: 0.0244249424405076\n",
      "Epoch 9810/10000 --- Train Loss: 0.06052230664064816 --- Val Loss: 0.02441270675328793\n",
      "Epoch 9820/10000 --- Train Loss: 0.06050774156676806 --- Val Loss: 0.024399845850277792\n",
      "Epoch 9830/10000 --- Train Loss: 0.06049331015271305 --- Val Loss: 0.024388809352450552\n",
      "Epoch 9840/10000 --- Train Loss: 0.06047915598827225 --- Val Loss: 0.024379507350940667\n",
      "Epoch 9850/10000 --- Train Loss: 0.06046427382715707 --- Val Loss: 0.02436601609579694\n",
      "Epoch 9860/10000 --- Train Loss: 0.06044981214846054 --- Val Loss: 0.024354568092250495\n",
      "Epoch 9870/10000 --- Train Loss: 0.06043623350656865 --- Val Loss: 0.024347188803328725\n",
      "Epoch 9880/10000 --- Train Loss: 0.06042176588663879 --- Val Loss: 0.0243356049529273\n",
      "Epoch 9890/10000 --- Train Loss: 0.060407009286342454 --- Val Loss: 0.02432254514520557\n",
      "Epoch 9900/10000 --- Train Loss: 0.06039259863263932 --- Val Loss: 0.024311919212749274\n",
      "Epoch 9910/10000 --- Train Loss: 0.06037787020830611 --- Val Loss: 0.024299218026500598\n",
      "Epoch 9920/10000 --- Train Loss: 0.06036358269920592 --- Val Loss: 0.02428775765228111\n",
      "Epoch 9930/10000 --- Train Loss: 0.06034934905348135 --- Val Loss: 0.024277546431740668\n",
      "Epoch 9940/10000 --- Train Loss: 0.060335002186366775 --- Val Loss: 0.024266108251538562\n",
      "Epoch 9950/10000 --- Train Loss: 0.060320492605307634 --- Val Loss: 0.024253081398835696\n",
      "Epoch 9960/10000 --- Train Loss: 0.06030677000916235 --- Val Loss: 0.0242429877441277\n",
      "Epoch 9970/10000 --- Train Loss: 0.060292286395935334 --- Val Loss: 0.024231557528791105\n",
      "Epoch 9980/10000 --- Train Loss: 0.060278298266784346 --- Val Loss: 0.02422139655318933\n",
      "Epoch 9990/10000 --- Train Loss: 0.06026458438063041 --- Val Loss: 0.02421274170621942\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(X_train.shape[1], 128))\n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Layer(128, 2))\n",
    "network.add_layer(Sigmoid())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=10000, learning_rate=0.001, batch_size=16)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "* L1 and L2 regularizers\n",
    "\n",
    "* Gradient with momentum\n",
    "\n",
    "* optimization of hyperparameters (random search and grid search function?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
