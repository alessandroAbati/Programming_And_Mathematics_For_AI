{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "236dfa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ReLU layer class\n",
    "class ReLU:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data # store the input to use it in the backward pass\n",
    "        return np.maximum(0, input_data) # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return output_gradient * (self.input > 0)\n",
    "        #return output_gradient * np.where(self.input > 0, 1.0, 0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1d0cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid layer class\n",
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.output = 1 / (1 + np.exp(-input_data)) # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('output_gradient'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        return output_gradient * (self.output * (1 - self.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94c275e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax layer class\n",
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - input_data (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'input_data', with the\n",
    "                         same shape as 'input_data'.\n",
    "        ''' \n",
    "        exp_values = np.exp(input_data - np.max(input_data, axis=1, keepdims=True)) # Shift the input data to avoid numerical instability in exponential calculations\n",
    "        output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return output\n",
    "\n",
    "    def backward_pass(self, dvalues):\n",
    "        # The gradient of loss with respect to the input logits \n",
    "        # directly passed through in case of softmax + categorical cross-entropy\n",
    "        return dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bb61882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:    \n",
    "    def __init__(self, probability):\n",
    "        self.probability = probability\n",
    "        \n",
    "    def forward_pass(self, input_data):\n",
    "        self.mask = np.random.binomial(1, 1-self.probability, size=input_data.shape) / (1-self.probability)\n",
    "        return input_data * self.mask\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        return output_gradient * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3a283b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer class\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size, l1=0.0, l2=0.0):\n",
    "        self.weights = 0.01 * np.random.normal(0, 1/np.sqrt(input_size), (input_size, output_size)) # Normal distribution initialisation\n",
    "        self.biases = np.full((1, output_size), 0.001) # Initialise biases with a small positive value\n",
    "        self.velocity_weights = np.zeros_like(self.weights) # Initialise (weights) velocity terms for momentum optimization\n",
    "        self.velocity_biases = np.zeros_like(self.biases) # Initialise (biases) velocity terms for momentum optimization\n",
    "        self.l1 = l1 # L1 regularization coefficient (default 0.0).\n",
    "        self.l2 = l2 # L2 regularization coefficient (default 0.0).\n",
    "        self.input = None\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data\n",
    "        return np.dot(input_data, self.weights) + self.biases\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate, optimizer='GD', momentum=0.9):\n",
    "        '''\n",
    "        Computes the backward pass of the Dense layer.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient: The gradient of the loss function with respect to the output of the layer.\n",
    "\n",
    "        - learning_rate: A hyperparameter that controls how much the weights and biases are updated during training.\n",
    "\n",
    "        - optimizer: Specifies the optimization technique to use. Can be 'GD' for standard Gradient Descent or 'Momentum' for Gradient Descent with Momentum.\n",
    "\n",
    "        - momentum: A hyperparameter representing the momentum coefficient, typically between 0 (no momentum) and 1.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: the gradient of the loss with respect to the layer's inputs (which will be passed back to the previous layer in the network).\n",
    "        '''\n",
    "        # Regularization terms\n",
    "        l1_reg = self.l1 * np.sign(self.weights)\n",
    "        l2_reg = self.l2 * self.weights\n",
    "\n",
    "        weights_gradient = np.dot(self.input.T, output_gradient) + l1_reg + l2_reg\n",
    "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
    "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
    "\n",
    "        if optimizer == 'GD':\n",
    "            # Update weights and biases\n",
    "            self.weights += learning_rate * weights_gradient\n",
    "            self.biases += learning_rate * biases_gradient\n",
    "        elif optimizer == 'Momentum':\n",
    "            # Momentum update for weights and biases\n",
    "            self.velocity_weights = momentum * self.velocity_weights + learning_rate * weights_gradient\n",
    "            self.velocity_biases = momentum * self.velocity_biases + learning_rate * biases_gradient\n",
    "\n",
    "            # Update weights and biases using velocity\n",
    "            self.weights += self.velocity_weights\n",
    "            self.biases += self.velocity_biases\n",
    "\n",
    "        return input_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cc0ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network wrapper class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = [] # placeholder for storing the layers of the network so we can propagate the infomation in a sequential order\n",
    "        self.loss_history = [] # placeholder to store the (train) loss for plotting\n",
    "        self.val_loss_history = [] #placeholder to store the loss function calculated on the validation set for plotting\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        '''\n",
    "        Add the layer to the network\n",
    "        '''\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network. \n",
    "        It sequentially passes the input data through each layer, transforming it according to each layer's operation.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def prediction(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network ignoring the dropout.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            if not isinstance(layer, Dropout):\n",
    "                input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate, optimizer='GD', momentum=0.9):\n",
    "        '''\n",
    "        Performs the backward pass (backpropagation) for training. \n",
    "        It propagates the gradient of the loss function backward through the network, updating weights in the process if the layer is a dense one.\n",
    "        '''\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Layer):\n",
    "                output_gradient = layer.backward_pass(output_gradient, learning_rate, optimizer, momentum)\n",
    "            else:\n",
    "                output_gradient = layer.backward_pass(output_gradient)\n",
    "    \n",
    "    def compute_categorical_cross_entropy_loss(self, y_pred, y_true):\n",
    "        '''\n",
    "        Computes the categorical cross entropy loss\n",
    "        '''\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7) # Clip predictions to prevent log(0)\n",
    "\n",
    "        # Calculate the negative log of the probabilities of the correct class\n",
    "        # Multiply with the one-hot encoded true labels and sum across classes\n",
    "        loss = np.sum(y_true * -np.log(y_pred_clipped), axis=1)\n",
    "\n",
    "        # Average loss over all samples\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def compute_categorical_cross_entropy_gradient(self, y_pred, y_true):\n",
    "        '''\n",
    "        Calculates the gradient of the categorical cross entropy loss with respect to the network's output, assuming that the output layer is the softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - y_pred: Output of the softmax activation function.\n",
    "\n",
    "        - y_true: One-hot encoded label array.\n",
    "        '''\n",
    "        # Assuming y_true is one-hot encoded and y_pred is the output of softmax\n",
    "        y_pred_gradient = (y_pred - y_true) / len(y_pred)\n",
    "        return y_pred_gradient\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, learning_rate=0.001, optimizer='GD', momentum=0.9, batch_size=32, validation_split = 0.2, verbose = 1):\n",
    "        '''\n",
    "        Conducts the training process over a specified number of epochs.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: The input features of the training data.\n",
    "\n",
    "        - y_train: The target output (labels) of the training data.\n",
    "\n",
    "        - epochs: The number of times the entire training dataset is passed forward and backward through the neural network.\n",
    "\n",
    "        - learning_rate: The step size at each iteration while moving toward a minimum of the loss function.\n",
    "\n",
    "        - optimizer: Specifies the optimization technique to use. Can be 'GD' for standard Gradient Descent or 'Momentum' for Gradient Descent with Momentum.\n",
    "\n",
    "        - momentum: A hyperparameter representing the momentum coefficient, typically between 0 (no momentum) and 1.\n",
    "\n",
    "        - batch_size: The number of training examples used in one iteration.\n",
    "\n",
    "        - validation_split: Fraction of the training data to be used as validation data.\n",
    "\n",
    "        - verbose: The mode of verbosity (0 = silent, 1 = update every 10 epochs, 2 = update every epoch).\n",
    "\n",
    "        '''\n",
    "        val_sample_size = int(len(X_train) * validation_split) # calculate validation sample size based on validation split parameter\n",
    "\n",
    "        # Shuffles the indices of the training data to ensure random distribution\n",
    "        indices = np.arange(len(X_train))\n",
    "        np.random.shuffle(indices) \n",
    "        X_train, y_train = X_train[indices], y_train[indices]\n",
    "\n",
    "        X_train, y_train = X_train[val_sample_size:], y_train[val_sample_size:] # splits the data into new training set.\n",
    "        X_val, y_val = X_train[:val_sample_size], y_train[:val_sample_size] # splits the data into new validation set.\n",
    "\n",
    "        n_samples = len(X_train)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Shuffles the indices of the training data at the beginning of each epoch to improve generalisation\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X_train = X_train[indices]\n",
    "            y_train = y_train[indices]\n",
    "\n",
    "            # Processing of the training data in batches\n",
    "            for start_idx in range(0, n_samples, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, n_samples)\n",
    "                batch_x = X_train[start_idx:end_idx]\n",
    "                batch_y = y_train[start_idx:end_idx]\n",
    "\n",
    "                output = self.forward_pass(batch_x) # forward pass to get the output predictions\n",
    "                loss_gradient = self.compute_categorical_cross_entropy_gradient(batch_y, output)\n",
    "                self.backward_pass(loss_gradient, learning_rate, optimizer, momentum) # backward pass to update the network's weights\n",
    "\n",
    "            # Calculate training loss for the epoch\n",
    "            output = self.forward_pass(X_train)\n",
    "            train_loss = self.compute_categorical_cross_entropy_loss(output, y_train)\n",
    "            self.loss_history.append(train_loss)\n",
    "\n",
    "            # Calculate validation loss for the epoch\n",
    "            val_output = self.prediction(X_val)  # ensure dropout is not applied\n",
    "            val_loss = self.compute_categorical_cross_entropy_loss(val_output, y_val)\n",
    "            self.val_loss_history.append(val_loss)\n",
    "\n",
    "            # Printing\n",
    "            if verbose == 1:\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f\"Epoch {epoch}/{epochs} --- Train Loss: {train_loss} --- Val Loss: {val_loss}\")\n",
    "            elif verbose == 2:\n",
    "                print(f\"Epoch {epoch}/{epochs} --- Train Loss: {train_loss} --- Val Loss: {val_loss}\")\n",
    "            epoch += 1\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        Uses the trained network to make predictions on new data (X_test).\n",
    "        '''\n",
    "        output = self.prediction(X_test) # use prediction method to avoid dropout\n",
    "\n",
    "        predictions = np.argmax(output, axis=1) # convert probabilities to class predictions\n",
    "        return predictions\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss history stored in self.loss_history over the epochs.\n",
    "        '''\n",
    "        plt.plot(self.loss_history, label = 'Train Loss')\n",
    "        plt.plot(self.val_loss_history, label = 'Val Loss')\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed3504a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(X):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = X.mean(axis=0)\n",
    "    stds = X.std(axis=0)\n",
    "\n",
    "    # Avoid division by zero in case of a constant feature\n",
    "    stds[stds == 0] = 1\n",
    "\n",
    "    # Standardize each feature\n",
    "    X_standardized = (X - means) / stds\n",
    "    return X_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32d43306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2000 --- Train Loss: 2.3025745166835447 --- Val Loss: 2.302571462169367\n",
      "Epoch 10/2000 --- Train Loss: 2.302458029225852 --- Val Loss: 2.302484259138583\n",
      "Epoch 20/2000 --- Train Loss: 2.302345811932198 --- Val Loss: 2.3023971936243774\n",
      "Epoch 30/2000 --- Train Loss: 2.302244909927532 --- Val Loss: 2.302321534476496\n",
      "Epoch 40/2000 --- Train Loss: 2.3021474993492186 --- Val Loss: 2.302249970941157\n",
      "Epoch 50/2000 --- Train Loss: 2.3020592695673754 --- Val Loss: 2.3021865667680976\n",
      "Epoch 60/2000 --- Train Loss: 2.3019816218557225 --- Val Loss: 2.3021267332405215\n",
      "Epoch 70/2000 --- Train Loss: 2.3019043897159372 --- Val Loss: 2.3020735983064786\n",
      "Epoch 80/2000 --- Train Loss: 2.3018315984582673 --- Val Loss: 2.3020209068978867\n",
      "Epoch 90/2000 --- Train Loss: 2.301763552635741 --- Val Loss: 2.3019717219089966\n",
      "Epoch 100/2000 --- Train Loss: 2.3016993562303565 --- Val Loss: 2.301926043126798\n",
      "Epoch 110/2000 --- Train Loss: 2.3016437038139173 --- Val Loss: 2.301889934323049\n",
      "Epoch 120/2000 --- Train Loss: 2.301590364468098 --- Val Loss: 2.3018545135888235\n",
      "Epoch 130/2000 --- Train Loss: 2.301540066878294 --- Val Loss: 2.301823908278024\n",
      "Epoch 140/2000 --- Train Loss: 2.3014934924569252 --- Val Loss: 2.301795400956319\n",
      "Epoch 150/2000 --- Train Loss: 2.301451355787928 --- Val Loss: 2.301772771018709\n",
      "Epoch 160/2000 --- Train Loss: 2.3014110280740563 --- Val Loss: 2.301740985492829\n",
      "Epoch 170/2000 --- Train Loss: 2.301372405722482 --- Val Loss: 2.3017269811354235\n",
      "Epoch 180/2000 --- Train Loss: 2.3013374710885386 --- Val Loss: 2.3017024565711055\n",
      "Epoch 190/2000 --- Train Loss: 2.301304466990997 --- Val Loss: 2.3016847405829286\n",
      "Epoch 200/2000 --- Train Loss: 2.3012767780218004 --- Val Loss: 2.301670651671462\n",
      "Epoch 210/2000 --- Train Loss: 2.3012489247671692 --- Val Loss: 2.301658412480255\n",
      "Epoch 220/2000 --- Train Loss: 2.301221056629059 --- Val Loss: 2.3016432326882206\n",
      "Epoch 230/2000 --- Train Loss: 2.3011951374133277 --- Val Loss: 2.301626163929082\n",
      "Epoch 240/2000 --- Train Loss: 2.301173076690468 --- Val Loss: 2.301616922438622\n",
      "Epoch 250/2000 --- Train Loss: 2.301151985547088 --- Val Loss: 2.301612698863743\n",
      "Epoch 260/2000 --- Train Loss: 2.3011323194414235 --- Val Loss: 2.3015987330213834\n",
      "Epoch 270/2000 --- Train Loss: 2.301113678482891 --- Val Loss: 2.3015973290703506\n",
      "Epoch 280/2000 --- Train Loss: 2.301095398159745 --- Val Loss: 2.3015860665499095\n",
      "Epoch 290/2000 --- Train Loss: 2.3010811918697778 --- Val Loss: 2.3015798090973205\n",
      "Epoch 300/2000 --- Train Loss: 2.3010653081676593 --- Val Loss: 2.301579529911482\n",
      "Epoch 310/2000 --- Train Loss: 2.3010501088226434 --- Val Loss: 2.3015732479209743\n",
      "Epoch 320/2000 --- Train Loss: 2.3010375200577475 --- Val Loss: 2.3015718910498313\n",
      "Epoch 330/2000 --- Train Loss: 2.301025783213962 --- Val Loss: 2.3015700310465887\n",
      "Epoch 340/2000 --- Train Loss: 2.3010147831225334 --- Val Loss: 2.301563171768622\n",
      "Epoch 350/2000 --- Train Loss: 2.3010030618986845 --- Val Loss: 2.3015626482175744\n",
      "Epoch 360/2000 --- Train Loss: 2.3009944333143557 --- Val Loss: 2.3015671843193366\n",
      "Epoch 370/2000 --- Train Loss: 2.3009845803070808 --- Val Loss: 2.3015591299191045\n",
      "Epoch 380/2000 --- Train Loss: 2.3009758615774687 --- Val Loss: 2.3015575740987275\n",
      "Epoch 390/2000 --- Train Loss: 2.3009678587583613 --- Val Loss: 2.3015620641813945\n",
      "Epoch 400/2000 --- Train Loss: 2.300960263616669 --- Val Loss: 2.3015637620144047\n",
      "Epoch 410/2000 --- Train Loss: 2.300952515885535 --- Val Loss: 2.3015640879563684\n",
      "Epoch 420/2000 --- Train Loss: 2.30094646670037 --- Val Loss: 2.301559874365417\n",
      "Epoch 430/2000 --- Train Loss: 2.300939680988037 --- Val Loss: 2.3015610006193614\n",
      "Epoch 440/2000 --- Train Loss: 2.3009340171112616 --- Val Loss: 2.3015641477625914\n",
      "Epoch 450/2000 --- Train Loss: 2.3009280012411555 --- Val Loss: 2.3015644043939836\n",
      "Epoch 460/2000 --- Train Loss: 2.300922672571302 --- Val Loss: 2.3015619795206064\n",
      "Epoch 470/2000 --- Train Loss: 2.3009175237410955 --- Val Loss: 2.3015713305379215\n",
      "Epoch 480/2000 --- Train Loss: 2.3009125661868404 --- Val Loss: 2.30157150680841\n",
      "Epoch 490/2000 --- Train Loss: 2.3009079409050446 --- Val Loss: 2.301570679205859\n",
      "Epoch 500/2000 --- Train Loss: 2.300903579479089 --- Val Loss: 2.3015765187170163\n",
      "Epoch 510/2000 --- Train Loss: 2.3008996367729133 --- Val Loss: 2.301576260069381\n",
      "Epoch 520/2000 --- Train Loss: 2.300895137228653 --- Val Loss: 2.3015717221085734\n",
      "Epoch 530/2000 --- Train Loss: 2.300891595588933 --- Val Loss: 2.3015724571032745\n",
      "Epoch 540/2000 --- Train Loss: 2.300887106124441 --- Val Loss: 2.3015793751183136\n",
      "Epoch 550/2000 --- Train Loss: 2.3008837493689485 --- Val Loss: 2.30157566108303\n",
      "Epoch 560/2000 --- Train Loss: 2.3008802119582343 --- Val Loss: 2.3015732781755185\n",
      "Epoch 570/2000 --- Train Loss: 2.3008762752593137 --- Val Loss: 2.3015833608180025\n",
      "Epoch 580/2000 --- Train Loss: 2.300872983434802 --- Val Loss: 2.301585592177405\n",
      "Epoch 590/2000 --- Train Loss: 2.3008693257009747 --- Val Loss: 2.3015843338559385\n",
      "Epoch 600/2000 --- Train Loss: 2.300865623502379 --- Val Loss: 2.3015803973463664\n",
      "Epoch 610/2000 --- Train Loss: 2.3008617146052974 --- Val Loss: 2.3015838904414876\n",
      "Epoch 620/2000 --- Train Loss: 2.3008577814892637 --- Val Loss: 2.301586102310327\n",
      "Epoch 630/2000 --- Train Loss: 2.3008543403748365 --- Val Loss: 2.3015822013975846\n",
      "Epoch 640/2000 --- Train Loss: 2.300849736990624 --- Val Loss: 2.301578295675951\n",
      "Epoch 650/2000 --- Train Loss: 2.3008451617347374 --- Val Loss: 2.3015755397077533\n",
      "Epoch 660/2000 --- Train Loss: 2.300840190097927 --- Val Loss: 2.301576931883127\n",
      "Epoch 670/2000 --- Train Loss: 2.300834853995827 --- Val Loss: 2.3015731417305694\n",
      "Epoch 680/2000 --- Train Loss: 2.300828980723578 --- Val Loss: 2.301566379572231\n",
      "Epoch 690/2000 --- Train Loss: 2.3008227488132387 --- Val Loss: 2.30157091634634\n",
      "Epoch 700/2000 --- Train Loss: 2.300815753039333 --- Val Loss: 2.301565237203901\n",
      "Epoch 710/2000 --- Train Loss: 2.3008075658951324 --- Val Loss: 2.301566290682709\n",
      "Epoch 720/2000 --- Train Loss: 2.3007983839412827 --- Val Loss: 2.3015560038515446\n",
      "Epoch 730/2000 --- Train Loss: 2.3007871891756047 --- Val Loss: 2.3015484567010693\n",
      "Epoch 740/2000 --- Train Loss: 2.3007747143378774 --- Val Loss: 2.3015400266604713\n",
      "Epoch 750/2000 --- Train Loss: 2.3007596939257273 --- Val Loss: 2.301524010199513\n",
      "Epoch 760/2000 --- Train Loss: 2.3007415942562566 --- Val Loss: 2.3015057680985493\n",
      "Epoch 770/2000 --- Train Loss: 2.3007191759376204 --- Val Loss: 2.3014841736109886\n",
      "Epoch 780/2000 --- Train Loss: 2.300691056954968 --- Val Loss: 2.30146486346423\n",
      "Epoch 790/2000 --- Train Loss: 2.300655650660834 --- Val Loss: 2.3014319771042007\n",
      "Epoch 800/2000 --- Train Loss: 2.300609357379123 --- Val Loss: 2.3013806947016544\n",
      "Epoch 810/2000 --- Train Loss: 2.300546936058804 --- Val Loss: 2.3013238012803896\n",
      "Epoch 820/2000 --- Train Loss: 2.3004606800485043 --- Val Loss: 2.301231417086398\n",
      "Epoch 830/2000 --- Train Loss: 2.300336360945098 --- Val Loss: 2.301106778805065\n",
      "Epoch 840/2000 --- Train Loss: 2.300148181878696 --- Val Loss: 2.3009166483746535\n",
      "Epoch 850/2000 --- Train Loss: 2.2998447617449536 --- Val Loss: 2.3006077596608088\n",
      "Epoch 860/2000 --- Train Loss: 2.2993152512049497 --- Val Loss: 2.300054889142153\n",
      "Epoch 870/2000 --- Train Loss: 2.2982842335907656 --- Val Loss: 2.2989897239611086\n",
      "Epoch 880/2000 --- Train Loss: 2.2959428948106964 --- Val Loss: 2.2965717597363384\n",
      "Epoch 890/2000 --- Train Loss: 2.28926765248197 --- Val Loss: 2.2897022948978902\n",
      "Epoch 900/2000 --- Train Loss: 2.2631714633642814 --- Val Loss: 2.262984521827503\n",
      "Epoch 910/2000 --- Train Loss: 2.155993384510059 --- Val Loss: 2.15689568561551\n",
      "Epoch 920/2000 --- Train Loss: 2.045895458529929 --- Val Loss: 2.0554671714970016\n",
      "Epoch 930/2000 --- Train Loss: 1.9994874946618308 --- Val Loss: 2.011838603254841\n",
      "Epoch 940/2000 --- Train Loss: 1.9652167655808381 --- Val Loss: 1.9773839490830258\n",
      "Epoch 950/2000 --- Train Loss: 1.9039400902333645 --- Val Loss: 1.9172303606294308\n",
      "Epoch 960/2000 --- Train Loss: 1.7879322361593737 --- Val Loss: 1.8026102853659218\n",
      "Epoch 970/2000 --- Train Loss: 1.684607961650841 --- Val Loss: 1.7014881647311388\n",
      "Epoch 980/2000 --- Train Loss: 1.6104099898248359 --- Val Loss: 1.6289627130974633\n",
      "Epoch 990/2000 --- Train Loss: 1.5589663741191853 --- Val Loss: 1.5775601275575133\n",
      "Epoch 1000/2000 --- Train Loss: 1.5071004704105873 --- Val Loss: 1.52437836838512\n",
      "Epoch 1010/2000 --- Train Loss: 1.4210792303932451 --- Val Loss: 1.4332618772693242\n",
      "Epoch 1020/2000 --- Train Loss: 1.257034485384445 --- Val Loss: 1.2560416449492495\n",
      "Epoch 1030/2000 --- Train Loss: 1.088163122116197 --- Val Loss: 1.0740382879483266\n",
      "Epoch 1040/2000 --- Train Loss: 0.9787557145372887 --- Val Loss: 0.9599684712081069\n",
      "Epoch 1050/2000 --- Train Loss: 0.9027932038015949 --- Val Loss: 0.888607820695779\n",
      "Epoch 1060/2000 --- Train Loss: 0.8400236602167014 --- Val Loss: 0.8309858327725849\n",
      "Epoch 1070/2000 --- Train Loss: 0.7841790657598402 --- Val Loss: 0.7839880219724876\n",
      "Epoch 1080/2000 --- Train Loss: 0.737013052318585 --- Val Loss: 0.7341591993070272\n",
      "Epoch 1090/2000 --- Train Loss: 0.6905524366487958 --- Val Loss: 0.6931331670904117\n",
      "Epoch 1100/2000 --- Train Loss: 0.6456540651921439 --- Val Loss: 0.6550445647576639\n",
      "Epoch 1110/2000 --- Train Loss: 0.5871501424348098 --- Val Loss: 0.5963937518863585\n",
      "Epoch 1120/2000 --- Train Loss: 0.5279264541138704 --- Val Loss: 0.5363342839951984\n",
      "Epoch 1130/2000 --- Train Loss: 0.46449992704105914 --- Val Loss: 0.4800485140632699\n",
      "Epoch 1140/2000 --- Train Loss: 0.4054176779566666 --- Val Loss: 0.4326378652342748\n",
      "Epoch 1150/2000 --- Train Loss: 0.35704372546537255 --- Val Loss: 0.3869590760516946\n",
      "Epoch 1160/2000 --- Train Loss: 0.3239624093779337 --- Val Loss: 0.3475923935565497\n",
      "Epoch 1170/2000 --- Train Loss: 0.29378558095257795 --- Val Loss: 0.3288527762601722\n",
      "Epoch 1180/2000 --- Train Loss: 0.2698586803959278 --- Val Loss: 0.30145461435528054\n",
      "Epoch 1190/2000 --- Train Loss: 0.2460996267873668 --- Val Loss: 0.2688886430414847\n",
      "Epoch 1200/2000 --- Train Loss: 0.22224813452660458 --- Val Loss: 0.23782976197921873\n",
      "Epoch 1210/2000 --- Train Loss: 0.20392093002530676 --- Val Loss: 0.2085998257849931\n",
      "Epoch 1220/2000 --- Train Loss: 0.1854668148124097 --- Val Loss: 0.18678792081497153\n",
      "Epoch 1230/2000 --- Train Loss: 0.17057206127772817 --- Val Loss: 0.17104605432476774\n",
      "Epoch 1240/2000 --- Train Loss: 0.15743246156839588 --- Val Loss: 0.15515764765546564\n",
      "Epoch 1250/2000 --- Train Loss: 0.1461673225520681 --- Val Loss: 0.142029700204652\n",
      "Epoch 1260/2000 --- Train Loss: 0.1367240023220868 --- Val Loss: 0.13147249207885114\n",
      "Epoch 1270/2000 --- Train Loss: 0.12817864609925927 --- Val Loss: 0.12699634567987408\n",
      "Epoch 1280/2000 --- Train Loss: 0.11996699924720748 --- Val Loss: 0.11686298918676953\n",
      "Epoch 1290/2000 --- Train Loss: 0.11273025001503327 --- Val Loss: 0.10962633101497415\n",
      "Epoch 1300/2000 --- Train Loss: 0.10641841115224646 --- Val Loss: 0.10369704595082324\n",
      "Epoch 1310/2000 --- Train Loss: 0.1003557644357075 --- Val Loss: 0.09925936646916897\n",
      "Epoch 1320/2000 --- Train Loss: 0.09487510755123106 --- Val Loss: 0.09461423005087176\n",
      "Epoch 1330/2000 --- Train Loss: 0.08964111985925188 --- Val Loss: 0.0887168325959158\n",
      "Epoch 1340/2000 --- Train Loss: 0.08510462413398388 --- Val Loss: 0.08530233690808475\n",
      "Epoch 1350/2000 --- Train Loss: 0.0808925412645016 --- Val Loss: 0.0822757954253626\n",
      "Epoch 1360/2000 --- Train Loss: 0.07621546445127225 --- Val Loss: 0.0781375916759339\n",
      "Epoch 1370/2000 --- Train Loss: 0.07233627726436116 --- Val Loss: 0.07561929724627928\n",
      "Epoch 1380/2000 --- Train Loss: 0.06830665237806667 --- Val Loss: 0.06998233379733822\n",
      "Epoch 1390/2000 --- Train Loss: 0.06486223025219345 --- Val Loss: 0.06684735700177805\n",
      "Epoch 1400/2000 --- Train Loss: 0.0612005900951874 --- Val Loss: 0.0640393558007659\n",
      "Epoch 1410/2000 --- Train Loss: 0.057892001905305704 --- Val Loss: 0.06124016162974755\n",
      "Epoch 1420/2000 --- Train Loss: 0.05493553108970407 --- Val Loss: 0.05769824728171917\n",
      "Epoch 1430/2000 --- Train Loss: 0.05172093051470485 --- Val Loss: 0.0553732553748325\n",
      "Epoch 1440/2000 --- Train Loss: 0.04882100276918214 --- Val Loss: 0.05299079469362445\n",
      "Epoch 1450/2000 --- Train Loss: 0.04607223192741144 --- Val Loss: 0.04953961128720631\n",
      "Epoch 1460/2000 --- Train Loss: 0.043459079232005274 --- Val Loss: 0.04730801554600752\n",
      "Epoch 1470/2000 --- Train Loss: 0.04085912277017677 --- Val Loss: 0.04451385281101389\n",
      "Epoch 1480/2000 --- Train Loss: 0.03873268893691203 --- Val Loss: 0.043194630411012104\n",
      "Epoch 1490/2000 --- Train Loss: 0.03622992108183825 --- Val Loss: 0.03957445524800532\n",
      "Epoch 1500/2000 --- Train Loss: 0.03398991049973689 --- Val Loss: 0.03716735653469643\n",
      "Epoch 1510/2000 --- Train Loss: 0.031843716337696316 --- Val Loss: 0.034113490356204604\n",
      "Epoch 1520/2000 --- Train Loss: 0.029843661140540368 --- Val Loss: 0.03184478587148\n",
      "Epoch 1530/2000 --- Train Loss: 0.02806527171584546 --- Val Loss: 0.029588602502277392\n",
      "Epoch 1540/2000 --- Train Loss: 0.02623565194089334 --- Val Loss: 0.027825608302966064\n",
      "Epoch 1550/2000 --- Train Loss: 0.024606310967003716 --- Val Loss: 0.025256090315251112\n",
      "Epoch 1560/2000 --- Train Loss: 0.023056412335989596 --- Val Loss: 0.023534157741284062\n",
      "Epoch 1570/2000 --- Train Loss: 0.02157915794713288 --- Val Loss: 0.022083581943548744\n",
      "Epoch 1580/2000 --- Train Loss: 0.02022717982897981 --- Val Loss: 0.02078179399965632\n",
      "Epoch 1590/2000 --- Train Loss: 0.0189556685615299 --- Val Loss: 0.019435684024489752\n",
      "Epoch 1600/2000 --- Train Loss: 0.017808277607214363 --- Val Loss: 0.018228375978849572\n",
      "Epoch 1610/2000 --- Train Loss: 0.016711592601639028 --- Val Loss: 0.01695988293734979\n",
      "Epoch 1620/2000 --- Train Loss: 0.015694512887289746 --- Val Loss: 0.015851491405226858\n",
      "Epoch 1630/2000 --- Train Loss: 0.014775049079240543 --- Val Loss: 0.014835652987754275\n",
      "Epoch 1640/2000 --- Train Loss: 0.013867870622098662 --- Val Loss: 0.013946540139565306\n",
      "Epoch 1650/2000 --- Train Loss: 0.013045557555636788 --- Val Loss: 0.01312412869548475\n",
      "Epoch 1660/2000 --- Train Loss: 0.012281550763661414 --- Val Loss: 0.01235972818058096\n",
      "Epoch 1670/2000 --- Train Loss: 0.011574775128204842 --- Val Loss: 0.011378977237102404\n",
      "Epoch 1680/2000 --- Train Loss: 0.010935560282048631 --- Val Loss: 0.010970509686910978\n",
      "Epoch 1690/2000 --- Train Loss: 0.010339563084252705 --- Val Loss: 0.010263999190370448\n",
      "Epoch 1700/2000 --- Train Loss: 0.009778251660405612 --- Val Loss: 0.0096135889540004\n",
      "Epoch 1710/2000 --- Train Loss: 0.00924299127240514 --- Val Loss: 0.009143676995513822\n",
      "Epoch 1720/2000 --- Train Loss: 0.008752065779037917 --- Val Loss: 0.008591575542899741\n",
      "Epoch 1730/2000 --- Train Loss: 0.008302046037461886 --- Val Loss: 0.008163135950692773\n",
      "Epoch 1740/2000 --- Train Loss: 0.007870055161092238 --- Val Loss: 0.0077006046586806974\n",
      "Epoch 1750/2000 --- Train Loss: 0.0074728985057809835 --- Val Loss: 0.007301940313912652\n",
      "Epoch 1760/2000 --- Train Loss: 0.007104084240294751 --- Val Loss: 0.006915495701893468\n",
      "Epoch 1770/2000 --- Train Loss: 0.0067503457714312405 --- Val Loss: 0.006557000239671247\n",
      "Epoch 1780/2000 --- Train Loss: 0.006423319425969148 --- Val Loss: 0.006299017952354794\n",
      "Epoch 1790/2000 --- Train Loss: 0.006114675086443701 --- Val Loss: 0.005945169114445472\n",
      "Epoch 1800/2000 --- Train Loss: 0.0058244905328491 --- Val Loss: 0.005707170412277973\n",
      "Epoch 1810/2000 --- Train Loss: 0.005558741879972481 --- Val Loss: 0.00546641295224724\n",
      "Epoch 1820/2000 --- Train Loss: 0.0052931629538707555 --- Val Loss: 0.005180842636969003\n",
      "Epoch 1830/2000 --- Train Loss: 0.00505423301763873 --- Val Loss: 0.00496028215455016\n",
      "Epoch 1840/2000 --- Train Loss: 0.004828237648854113 --- Val Loss: 0.004679752804254194\n",
      "Epoch 1850/2000 --- Train Loss: 0.004617035875611798 --- Val Loss: 0.004530047275403254\n",
      "Epoch 1860/2000 --- Train Loss: 0.004410897640894589 --- Val Loss: 0.004331586562351238\n",
      "Epoch 1870/2000 --- Train Loss: 0.004220676318366457 --- Val Loss: 0.004147019504417211\n",
      "Epoch 1880/2000 --- Train Loss: 0.004038092630114725 --- Val Loss: 0.003960661035560068\n",
      "Epoch 1890/2000 --- Train Loss: 0.0038660302391664452 --- Val Loss: 0.0037781521138924743\n",
      "Epoch 1900/2000 --- Train Loss: 0.003703563045447507 --- Val Loss: 0.0036027570842703297\n",
      "Epoch 1910/2000 --- Train Loss: 0.0035504023733051496 --- Val Loss: 0.0034617538733684302\n",
      "Epoch 1920/2000 --- Train Loss: 0.00340420496273892 --- Val Loss: 0.0033071664738368238\n",
      "Epoch 1930/2000 --- Train Loss: 0.0032649112558950696 --- Val Loss: 0.0032043258720637698\n",
      "Epoch 1940/2000 --- Train Loss: 0.0031326528163330945 --- Val Loss: 0.0030503014502513293\n",
      "Epoch 1950/2000 --- Train Loss: 0.0030094972619546224 --- Val Loss: 0.002949642618846146\n",
      "Epoch 1960/2000 --- Train Loss: 0.002887996956200146 --- Val Loss: 0.002809105131861081\n",
      "Epoch 1970/2000 --- Train Loss: 0.0027753242275477693 --- Val Loss: 0.00270527658286695\n",
      "Epoch 1980/2000 --- Train Loss: 0.0026662813330240293 --- Val Loss: 0.002606296870452263\n",
      "Epoch 1990/2000 --- Train Loss: 0.0025635650488325203 --- Val Loss: 0.002507048488496477\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8861111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(64, 64, l1=0.1))  # 64 inputs (8x8 images)\n",
    "network.add_layer(ReLU())\n",
    "#network.add_layer(Dropout(0.25))\n",
    "network.add_layer(Layer(64, 32)) \n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Layer(32, 16)) \n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Layer(16, 10))  # 10 classes\n",
    "network.add_layer(Softmax())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=2000, learning_rate=0.0001, optimizer='Momentum', batch_size=32)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1) # transoform back the One-Hot encoded array of the labels\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72fcf0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000 --- Train Loss: 0.692540113232889 --- Val Loss: 0.6925866408177288\n",
      "Epoch 10/10000 --- Train Loss: 0.691416503216078 --- Val Loss: 0.691834762502483\n",
      "Epoch 20/10000 --- Train Loss: 0.690322672387779 --- Val Loss: 0.6911077771978053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/10000 --- Train Loss: 0.6892617893167521 --- Val Loss: 0.6904074138410867\n",
      "Epoch 40/10000 --- Train Loss: 0.6882291200187071 --- Val Loss: 0.6897302375345495\n",
      "Epoch 50/10000 --- Train Loss: 0.6872242179785805 --- Val Loss: 0.689075571732006\n",
      "Epoch 60/10000 --- Train Loss: 0.6862421111599545 --- Val Loss: 0.6884398809758693\n",
      "Epoch 70/10000 --- Train Loss: 0.6852896406296445 --- Val Loss: 0.687827143880153\n",
      "Epoch 80/10000 --- Train Loss: 0.6843667722424512 --- Val Loss: 0.6872368598187132\n",
      "Epoch 90/10000 --- Train Loss: 0.683465124172468 --- Val Loss: 0.6866633767154833\n",
      "Epoch 100/10000 --- Train Loss: 0.682585010736554 --- Val Loss: 0.6861065488103757\n",
      "Epoch 110/10000 --- Train Loss: 0.6817227365859974 --- Val Loss: 0.6855636755280313\n",
      "Epoch 120/10000 --- Train Loss: 0.6808804776564805 --- Val Loss: 0.6850356576913806\n",
      "Epoch 130/10000 --- Train Loss: 0.6800580523872125 --- Val Loss: 0.6845218647905223\n",
      "Epoch 140/10000 --- Train Loss: 0.6792583731763174 --- Val Loss: 0.6840235107241045\n",
      "Epoch 150/10000 --- Train Loss: 0.6784728144891586 --- Val Loss: 0.68353490664474\n",
      "Epoch 160/10000 --- Train Loss: 0.6777036156995465 --- Val Loss: 0.6830568160510129\n",
      "Epoch 170/10000 --- Train Loss: 0.6769437013555134 --- Val Loss: 0.6825845501451279\n",
      "Epoch 180/10000 --- Train Loss: 0.6761985373964872 --- Val Loss: 0.682120560581523\n",
      "Epoch 190/10000 --- Train Loss: 0.6754576124533911 --- Val Loss: 0.681658129565461\n",
      "Epoch 200/10000 --- Train Loss: 0.6747249878154056 --- Val Loss: 0.6811987009228673\n",
      "Epoch 210/10000 --- Train Loss: 0.674004432814898 --- Val Loss: 0.6807434476039961\n",
      "Epoch 220/10000 --- Train Loss: 0.6732868867231206 --- Val Loss: 0.6802864294218378\n",
      "Epoch 230/10000 --- Train Loss: 0.6725786001609739 --- Val Loss: 0.6798297814572195\n",
      "Epoch 240/10000 --- Train Loss: 0.6718638060717871 --- Val Loss: 0.6793640352650296\n",
      "Epoch 250/10000 --- Train Loss: 0.671144574930616 --- Val Loss: 0.6788889437807979\n",
      "Epoch 260/10000 --- Train Loss: 0.6704258241769034 --- Val Loss: 0.6784054331796888\n",
      "Epoch 270/10000 --- Train Loss: 0.6696962260127644 --- Val Loss: 0.6779061152021153\n",
      "Epoch 280/10000 --- Train Loss: 0.6689612488629787 --- Val Loss: 0.6773914249846552\n",
      "Epoch 290/10000 --- Train Loss: 0.6682114123896375 --- Val Loss: 0.6768549668366477\n",
      "Epoch 300/10000 --- Train Loss: 0.6674464866555738 --- Val Loss: 0.67629377919917\n",
      "Epoch 310/10000 --- Train Loss: 0.6666616479981445 --- Val Loss: 0.6757030649886433\n",
      "Epoch 320/10000 --- Train Loss: 0.6658563408554206 --- Val Loss: 0.6750790357281524\n",
      "Epoch 330/10000 --- Train Loss: 0.6650127453352296 --- Val Loss: 0.6744105654209068\n",
      "Epoch 340/10000 --- Train Loss: 0.6641317531826927 --- Val Loss: 0.6736932043165217\n",
      "Epoch 350/10000 --- Train Loss: 0.6632051615574069 --- Val Loss: 0.6729204290980574\n",
      "Epoch 360/10000 --- Train Loss: 0.6622308588960323 --- Val Loss: 0.6720841907843953\n",
      "Epoch 370/10000 --- Train Loss: 0.6611989124650876 --- Val Loss: 0.67117650727842\n",
      "Epoch 380/10000 --- Train Loss: 0.6601000857361157 --- Val Loss: 0.6701872286739029\n",
      "Epoch 390/10000 --- Train Loss: 0.6589317194134845 --- Val Loss: 0.6691061053695496\n",
      "Epoch 400/10000 --- Train Loss: 0.6576762021112106 --- Val Loss: 0.6679181064963631\n",
      "Epoch 410/10000 --- Train Loss: 0.6563244204248726 --- Val Loss: 0.6666124353701635\n",
      "Epoch 420/10000 --- Train Loss: 0.6548644783062346 --- Val Loss: 0.6651748580004435\n",
      "Epoch 430/10000 --- Train Loss: 0.6532835242380832 --- Val Loss: 0.6635879471232472\n",
      "Epoch 440/10000 --- Train Loss: 0.6515641473354428 --- Val Loss: 0.6618323519577994\n",
      "Epoch 450/10000 --- Train Loss: 0.6496967108652892 --- Val Loss: 0.6598979775390228\n",
      "Epoch 460/10000 --- Train Loss: 0.6476565371098241 --- Val Loss: 0.6577499654025081\n",
      "Epoch 470/10000 --- Train Loss: 0.6454297391413069 --- Val Loss: 0.6553797724042297\n",
      "Epoch 480/10000 --- Train Loss: 0.6429973758504709 --- Val Loss: 0.6527566056222133\n",
      "Epoch 490/10000 --- Train Loss: 0.6403297400742474 --- Val Loss: 0.6498492396452795\n",
      "Epoch 500/10000 --- Train Loss: 0.6374070161764029 --- Val Loss: 0.6466312459173649\n",
      "Epoch 510/10000 --- Train Loss: 0.6342039321131819 --- Val Loss: 0.643077910438052\n",
      "Epoch 520/10000 --- Train Loss: 0.6306988288861651 --- Val Loss: 0.6391537688163155\n",
      "Epoch 530/10000 --- Train Loss: 0.6268618319456788 --- Val Loss: 0.6348343987054521\n",
      "Epoch 540/10000 --- Train Loss: 0.6226617969304831 --- Val Loss: 0.6300754471839123\n",
      "Epoch 550/10000 --- Train Loss: 0.6180782061627027 --- Val Loss: 0.62484986552994\n",
      "Epoch 560/10000 --- Train Loss: 0.6130849770155724 --- Val Loss: 0.6191371121364485\n",
      "Epoch 570/10000 --- Train Loss: 0.6076606661962279 --- Val Loss: 0.61291183597821\n",
      "Epoch 580/10000 --- Train Loss: 0.6017778949163725 --- Val Loss: 0.6061368819048866\n",
      "Epoch 590/10000 --- Train Loss: 0.5954288617019304 --- Val Loss: 0.5988159754593086\n",
      "Epoch 600/10000 --- Train Loss: 0.5886096351417917 --- Val Loss: 0.5909462967295852\n",
      "Epoch 610/10000 --- Train Loss: 0.5812967994618176 --- Val Loss: 0.5824969900531154\n",
      "Epoch 620/10000 --- Train Loss: 0.5735090072245246 --- Val Loss: 0.5735087598275526\n",
      "Epoch 630/10000 --- Train Loss: 0.5652621146793879 --- Val Loss: 0.5639970698416589\n",
      "Epoch 640/10000 --- Train Loss: 0.5565720020256607 --- Val Loss: 0.5540004156931742\n",
      "Epoch 650/10000 --- Train Loss: 0.5474637762646563 --- Val Loss: 0.5435450917304554\n",
      "Epoch 660/10000 --- Train Loss: 0.5380087291659139 --- Val Loss: 0.5327321944540022\n",
      "Epoch 670/10000 --- Train Loss: 0.5282500259844551 --- Val Loss: 0.5216114276413187\n",
      "Epoch 680/10000 --- Train Loss: 0.5182166138580224 --- Val Loss: 0.5102196214892515\n",
      "Epoch 690/10000 --- Train Loss: 0.5080024994860814 --- Val Loss: 0.4986777319898869\n",
      "Epoch 700/10000 --- Train Loss: 0.4976418910242264 --- Val Loss: 0.48702482827035826\n",
      "Epoch 710/10000 --- Train Loss: 0.48721692609830514 --- Val Loss: 0.47535875950419904\n",
      "Epoch 720/10000 --- Train Loss: 0.476782606267847 --- Val Loss: 0.4637468455415275\n",
      "Epoch 730/10000 --- Train Loss: 0.46640379184545894 --- Val Loss: 0.4522543241466875\n",
      "Epoch 740/10000 --- Train Loss: 0.4561041275479778 --- Val Loss: 0.4409113840825757\n",
      "Epoch 750/10000 --- Train Loss: 0.4459336018138216 --- Val Loss: 0.42976472837172774\n",
      "Epoch 760/10000 --- Train Loss: 0.43594903480557934 --- Val Loss: 0.41887712982654407\n",
      "Epoch 770/10000 --- Train Loss: 0.4261483852088949 --- Val Loss: 0.40823719135903125\n",
      "Epoch 780/10000 --- Train Loss: 0.4165957834088176 --- Val Loss: 0.39792270060113916\n",
      "Epoch 790/10000 --- Train Loss: 0.40730290008971154 --- Val Loss: 0.38793582907567314\n",
      "Epoch 800/10000 --- Train Loss: 0.3982749188226444 --- Val Loss: 0.37827771098270413\n",
      "Epoch 810/10000 --- Train Loss: 0.38952934532004924 --- Val Loss: 0.36896825898387103\n",
      "Epoch 820/10000 --- Train Loss: 0.3810777811765099 --- Val Loss: 0.3600117036087988\n",
      "Epoch 830/10000 --- Train Loss: 0.3729125667800271 --- Val Loss: 0.3513937390077008\n",
      "Epoch 840/10000 --- Train Loss: 0.36503394855103677 --- Val Loss: 0.3431057534576638\n",
      "Epoch 850/10000 --- Train Loss: 0.3574494390616675 --- Val Loss: 0.33516226463795057\n",
      "Epoch 860/10000 --- Train Loss: 0.3501481902110981 --- Val Loss: 0.32754223228172213\n",
      "Epoch 870/10000 --- Train Loss: 0.34312464935487524 --- Val Loss: 0.3202334472059758\n",
      "Epoch 880/10000 --- Train Loss: 0.33636632643432157 --- Val Loss: 0.3132208397120718\n",
      "Epoch 890/10000 --- Train Loss: 0.32986814147804927 --- Val Loss: 0.30649900148211673\n",
      "Epoch 900/10000 --- Train Loss: 0.3236237955549352 --- Val Loss: 0.3000602720521434\n",
      "Epoch 910/10000 --- Train Loss: 0.31762336645183026 --- Val Loss: 0.29388595192528544\n",
      "Epoch 920/10000 --- Train Loss: 0.31185509875905115 --- Val Loss: 0.2879628296928439\n",
      "Epoch 930/10000 --- Train Loss: 0.3063136925541677 --- Val Loss: 0.28228408802915866\n",
      "Epoch 940/10000 --- Train Loss: 0.3009895748371856 --- Val Loss: 0.276830415343638\n",
      "Epoch 950/10000 --- Train Loss: 0.29587066177095594 --- Val Loss: 0.2715904310824077\n",
      "Epoch 960/10000 --- Train Loss: 0.2909572180577123 --- Val Loss: 0.2665649526638724\n",
      "Epoch 970/10000 --- Train Loss: 0.28623147901784407 --- Val Loss: 0.2617332380449375\n",
      "Epoch 980/10000 --- Train Loss: 0.28168595246539285 --- Val Loss: 0.2570878523698227\n",
      "Epoch 990/10000 --- Train Loss: 0.2773183196276973 --- Val Loss: 0.2526259413953195\n",
      "Epoch 1000/10000 --- Train Loss: 0.27311141329466404 --- Val Loss: 0.2483286375151602\n",
      "Epoch 1010/10000 --- Train Loss: 0.26906395349478307 --- Val Loss: 0.244181173230473\n",
      "Epoch 1020/10000 --- Train Loss: 0.26517938373955313 --- Val Loss: 0.24019960413682945\n",
      "Epoch 1030/10000 --- Train Loss: 0.26143878333166026 --- Val Loss: 0.2363627290184996\n",
      "Epoch 1040/10000 --- Train Loss: 0.2578417163987392 --- Val Loss: 0.23265993161259624\n",
      "Epoch 1050/10000 --- Train Loss: 0.25437113726952226 --- Val Loss: 0.22908552775908658\n",
      "Epoch 1060/10000 --- Train Loss: 0.2510180155486233 --- Val Loss: 0.22563594870562922\n",
      "Epoch 1070/10000 --- Train Loss: 0.24778615923762842 --- Val Loss: 0.22230858247883606\n",
      "Epoch 1080/10000 --- Train Loss: 0.24466306141812708 --- Val Loss: 0.21909590849168398\n",
      "Epoch 1090/10000 --- Train Loss: 0.24165231501646137 --- Val Loss: 0.21599936123105926\n",
      "Epoch 1100/10000 --- Train Loss: 0.23873864837334616 --- Val Loss: 0.213003407620554\n",
      "Epoch 1110/10000 --- Train Loss: 0.2359162656120624 --- Val Loss: 0.21010306449777366\n",
      "Epoch 1120/10000 --- Train Loss: 0.23318172356591868 --- Val Loss: 0.20729398541118985\n",
      "Epoch 1130/10000 --- Train Loss: 0.23053706534236593 --- Val Loss: 0.20457882155762586\n",
      "Epoch 1140/10000 --- Train Loss: 0.22796809719084052 --- Val Loss: 0.2019438111532996\n",
      "Epoch 1150/10000 --- Train Loss: 0.2254788182133446 --- Val Loss: 0.1993918063350627\n",
      "Epoch 1160/10000 --- Train Loss: 0.22306143656625735 --- Val Loss: 0.19691574283040802\n",
      "Epoch 1170/10000 --- Train Loss: 0.2207170324206165 --- Val Loss: 0.19451639965203313\n",
      "Epoch 1180/10000 --- Train Loss: 0.2184398022389521 --- Val Loss: 0.19218783392521618\n",
      "Epoch 1190/10000 --- Train Loss: 0.2162249508716002 --- Val Loss: 0.18992325794415682\n",
      "Epoch 1200/10000 --- Train Loss: 0.21407724684132176 --- Val Loss: 0.1877303675255439\n",
      "Epoch 1210/10000 --- Train Loss: 0.21199066200663516 --- Val Loss: 0.18560225272874045\n",
      "Epoch 1220/10000 --- Train Loss: 0.20996406991966238 --- Val Loss: 0.18354084476067203\n",
      "Epoch 1230/10000 --- Train Loss: 0.20798966262416296 --- Val Loss: 0.1815324622407884\n",
      "Epoch 1240/10000 --- Train Loss: 0.20606911076118012 --- Val Loss: 0.1795830312613345\n",
      "Epoch 1250/10000 --- Train Loss: 0.20419381549118565 --- Val Loss: 0.1776788539065935\n",
      "Epoch 1260/10000 --- Train Loss: 0.20236490615085634 --- Val Loss: 0.17582157005104887\n",
      "Epoch 1270/10000 --- Train Loss: 0.20058595026611076 --- Val Loss: 0.17401615934886575\n",
      "Epoch 1280/10000 --- Train Loss: 0.19884696479962038 --- Val Loss: 0.1722546997008037\n",
      "Epoch 1290/10000 --- Train Loss: 0.19715201284975994 --- Val Loss: 0.17053952171427134\n",
      "Epoch 1300/10000 --- Train Loss: 0.1954948284531504 --- Val Loss: 0.16886167400380347\n",
      "Epoch 1310/10000 --- Train Loss: 0.19387644584825536 --- Val Loss: 0.16722542561224213\n",
      "Epoch 1320/10000 --- Train Loss: 0.19229806930597096 --- Val Loss: 0.16562934488413078\n",
      "Epoch 1330/10000 --- Train Loss: 0.1907529550123139 --- Val Loss: 0.16406678637183103\n",
      "Epoch 1340/10000 --- Train Loss: 0.18924329844770807 --- Val Loss: 0.16254178696456356\n",
      "Epoch 1350/10000 --- Train Loss: 0.1877681330632182 --- Val Loss: 0.16105239530064508\n",
      "Epoch 1360/10000 --- Train Loss: 0.18632336639816277 --- Val Loss: 0.15959338734777023\n",
      "Epoch 1370/10000 --- Train Loss: 0.18491218736376033 --- Val Loss: 0.15816965036300398\n",
      "Epoch 1380/10000 --- Train Loss: 0.18352890346641318 --- Val Loss: 0.15677374569056546\n",
      "Epoch 1390/10000 --- Train Loss: 0.18217264533455838 --- Val Loss: 0.15540644156636818\n",
      "Epoch 1400/10000 --- Train Loss: 0.1808453887907654 --- Val Loss: 0.15406999955669434\n",
      "Epoch 1410/10000 --- Train Loss: 0.17954399154207687 --- Val Loss: 0.1527591313278727\n",
      "Epoch 1420/10000 --- Train Loss: 0.17826893192042623 --- Val Loss: 0.1514756135527073\n",
      "Epoch 1430/10000 --- Train Loss: 0.17701281510759148 --- Val Loss: 0.15020865768397929\n",
      "Epoch 1440/10000 --- Train Loss: 0.17577895896232856 --- Val Loss: 0.14896765825683905\n",
      "Epoch 1450/10000 --- Train Loss: 0.17456596042555114 --- Val Loss: 0.14775040754230112\n",
      "Epoch 1460/10000 --- Train Loss: 0.17337314184972585 --- Val Loss: 0.14655539508492263\n",
      "Epoch 1470/10000 --- Train Loss: 0.17220296162830817 --- Val Loss: 0.14538250204208103\n",
      "Epoch 1480/10000 --- Train Loss: 0.17105485505681933 --- Val Loss: 0.1442314274777264\n",
      "Epoch 1490/10000 --- Train Loss: 0.16992611409663128 --- Val Loss: 0.14309974624563543\n",
      "Epoch 1500/10000 --- Train Loss: 0.16880927994602257 --- Val Loss: 0.14198029369987183\n",
      "Epoch 1510/10000 --- Train Loss: 0.16771483818070526 --- Val Loss: 0.14087898433474388\n",
      "Epoch 1520/10000 --- Train Loss: 0.166632953617303 --- Val Loss: 0.13978613176955185\n",
      "Epoch 1530/10000 --- Train Loss: 0.16556578755187873 --- Val Loss: 0.1387111326375299\n",
      "Epoch 1540/10000 --- Train Loss: 0.16451283227122981 --- Val Loss: 0.13765277195786585\n",
      "Epoch 1550/10000 --- Train Loss: 0.16347644746187817 --- Val Loss: 0.13661134976675748\n",
      "Epoch 1560/10000 --- Train Loss: 0.16245576036880074 --- Val Loss: 0.13558006203136452\n",
      "Epoch 1570/10000 --- Train Loss: 0.16144810518085603 --- Val Loss: 0.13456149245621568\n",
      "Epoch 1580/10000 --- Train Loss: 0.160449247420958 --- Val Loss: 0.13355639157421398\n",
      "Epoch 1590/10000 --- Train Loss: 0.1594561113275612 --- Val Loss: 0.1325586164558885\n",
      "Epoch 1600/10000 --- Train Loss: 0.15848170684437962 --- Val Loss: 0.13158391398280628\n",
      "Epoch 1610/10000 --- Train Loss: 0.15751942308234662 --- Val Loss: 0.1306187995573241\n",
      "Epoch 1620/10000 --- Train Loss: 0.15657279236045454 --- Val Loss: 0.12967330783277128\n",
      "Epoch 1630/10000 --- Train Loss: 0.1556390385281339 --- Val Loss: 0.12874221756094276\n",
      "Epoch 1640/10000 --- Train Loss: 0.15472202263715124 --- Val Loss: 0.12782663692810461\n",
      "Epoch 1650/10000 --- Train Loss: 0.15382253047216876 --- Val Loss: 0.1269318901364684\n",
      "Epoch 1660/10000 --- Train Loss: 0.15293834166561923 --- Val Loss: 0.1260517124250092\n",
      "Epoch 1670/10000 --- Train Loss: 0.152067031575405 --- Val Loss: 0.12518439968149184\n",
      "Epoch 1680/10000 --- Train Loss: 0.15121050500750305 --- Val Loss: 0.12433544354468713\n",
      "Epoch 1690/10000 --- Train Loss: 0.15037138347628923 --- Val Loss: 0.12349956932093469\n",
      "Epoch 1700/10000 --- Train Loss: 0.14954241897222334 --- Val Loss: 0.12267608117340616\n",
      "Epoch 1710/10000 --- Train Loss: 0.14872476880342314 --- Val Loss: 0.12186305381505577\n",
      "Epoch 1720/10000 --- Train Loss: 0.147920337015037 --- Val Loss: 0.12106319209494965\n",
      "Epoch 1730/10000 --- Train Loss: 0.14712812314133844 --- Val Loss: 0.12027660363288303\n",
      "Epoch 1740/10000 --- Train Loss: 0.14634826365902218 --- Val Loss: 0.11950187396505713\n",
      "Epoch 1750/10000 --- Train Loss: 0.14558214753037826 --- Val Loss: 0.11874123977068916\n",
      "Epoch 1760/10000 --- Train Loss: 0.14483039020263322 --- Val Loss: 0.11799798077600165\n",
      "Epoch 1770/10000 --- Train Loss: 0.14408925599553962 --- Val Loss: 0.11726533416686946\n",
      "Epoch 1780/10000 --- Train Loss: 0.14336094290934887 --- Val Loss: 0.11654632706015278\n",
      "Epoch 1790/10000 --- Train Loss: 0.1426444752388417 --- Val Loss: 0.11584031072312598\n",
      "Epoch 1800/10000 --- Train Loss: 0.14193877629737764 --- Val Loss: 0.11514662350267324\n",
      "Epoch 1810/10000 --- Train Loss: 0.14124205229988596 --- Val Loss: 0.114461059040406\n",
      "Epoch 1820/10000 --- Train Loss: 0.140558247392287 --- Val Loss: 0.11378961496119884\n",
      "Epoch 1830/10000 --- Train Loss: 0.13988690625347674 --- Val Loss: 0.11313281738131399\n",
      "Epoch 1840/10000 --- Train Loss: 0.13922281891981164 --- Val Loss: 0.11248204632118418\n",
      "Epoch 1850/10000 --- Train Loss: 0.13856937452586246 --- Val Loss: 0.11184334916873805\n",
      "Epoch 1860/10000 --- Train Loss: 0.13792435090192964 --- Val Loss: 0.1112168734584138\n",
      "Epoch 1870/10000 --- Train Loss: 0.1372905807549186 --- Val Loss: 0.11060055855562836\n",
      "Epoch 1880/10000 --- Train Loss: 0.1366642403017926 --- Val Loss: 0.10999253455192379\n",
      "Epoch 1890/10000 --- Train Loss: 0.13604788174934004 --- Val Loss: 0.10939674557226893\n",
      "Epoch 1900/10000 --- Train Loss: 0.13543964472541126 --- Val Loss: 0.10880799761550658\n",
      "Epoch 1910/10000 --- Train Loss: 0.13484168043047753 --- Val Loss: 0.1082279625884312\n",
      "Epoch 1920/10000 --- Train Loss: 0.13425257545587269 --- Val Loss: 0.10765781302849589\n",
      "Epoch 1930/10000 --- Train Loss: 0.13366977097779598 --- Val Loss: 0.10709330654399543\n",
      "Epoch 1940/10000 --- Train Loss: 0.13309456360750735 --- Val Loss: 0.10653790865140872\n",
      "Epoch 1950/10000 --- Train Loss: 0.1325293237094632 --- Val Loss: 0.10599139251485414\n",
      "Epoch 1960/10000 --- Train Loss: 0.1319709271973745 --- Val Loss: 0.10545120569710223\n",
      "Epoch 1970/10000 --- Train Loss: 0.1314210702225294 --- Val Loss: 0.10491941777184975\n",
      "Epoch 1980/10000 --- Train Loss: 0.13088030406084986 --- Val Loss: 0.10439581686118919\n",
      "Epoch 1990/10000 --- Train Loss: 0.1303462958683628 --- Val Loss: 0.10388055512382621\n",
      "Epoch 2000/10000 --- Train Loss: 0.12981955730429107 --- Val Loss: 0.10337316078901976\n",
      "Epoch 2010/10000 --- Train Loss: 0.1292983180044899 --- Val Loss: 0.10286964276085639\n",
      "Epoch 2020/10000 --- Train Loss: 0.128785859498705 --- Val Loss: 0.10237321431235169\n",
      "Epoch 2030/10000 --- Train Loss: 0.12827741058294528 --- Val Loss: 0.10188256755750412\n",
      "Epoch 2040/10000 --- Train Loss: 0.12777745260093248 --- Val Loss: 0.10139843246899587\n",
      "Epoch 2050/10000 --- Train Loss: 0.1272852652750897 --- Val Loss: 0.10092396852403931\n",
      "Epoch 2060/10000 --- Train Loss: 0.1267987460517967 --- Val Loss: 0.1004564908219152\n",
      "Epoch 2070/10000 --- Train Loss: 0.12631879786435113 --- Val Loss: 0.0999942139046454\n",
      "Epoch 2080/10000 --- Train Loss: 0.12584488060719984 --- Val Loss: 0.09953507443204944\n",
      "Epoch 2090/10000 --- Train Loss: 0.12537948723260348 --- Val Loss: 0.09908614646571133\n",
      "Epoch 2100/10000 --- Train Loss: 0.12491891996080591 --- Val Loss: 0.09864402726652664\n",
      "Epoch 2110/10000 --- Train Loss: 0.12446426318978598 --- Val Loss: 0.09820699343130979\n",
      "Epoch 2120/10000 --- Train Loss: 0.12401402687180921 --- Val Loss: 0.09777698334622677\n",
      "Epoch 2130/10000 --- Train Loss: 0.12357149113316863 --- Val Loss: 0.09735158489915736\n",
      "Epoch 2140/10000 --- Train Loss: 0.1231343792414049 --- Val Loss: 0.09693096270412324\n",
      "Epoch 2150/10000 --- Train Loss: 0.12270222736209697 --- Val Loss: 0.09651568261481448\n",
      "Epoch 2160/10000 --- Train Loss: 0.12227810907120407 --- Val Loss: 0.0961073250075067\n",
      "Epoch 2170/10000 --- Train Loss: 0.12185630494968612 --- Val Loss: 0.09570169808308765\n",
      "Epoch 2180/10000 --- Train Loss: 0.1214410368289094 --- Val Loss: 0.09530524698615389\n",
      "Epoch 2190/10000 --- Train Loss: 0.12103256131027341 --- Val Loss: 0.09491141965936896\n",
      "Epoch 2200/10000 --- Train Loss: 0.12062828246109657 --- Val Loss: 0.0945234289064384\n",
      "Epoch 2210/10000 --- Train Loss: 0.12022869322374473 --- Val Loss: 0.0941402515340841\n",
      "Epoch 2220/10000 --- Train Loss: 0.11983400263405779 --- Val Loss: 0.09376321118360867\n",
      "Epoch 2230/10000 --- Train Loss: 0.1194458435945153 --- Val Loss: 0.09339156820344315\n",
      "Epoch 2240/10000 --- Train Loss: 0.11906115878955968 --- Val Loss: 0.09302249214109982\n",
      "Epoch 2250/10000 --- Train Loss: 0.11868175503725481 --- Val Loss: 0.0926603612876132\n",
      "Epoch 2260/10000 --- Train Loss: 0.11830539713662286 --- Val Loss: 0.09230078419358025\n",
      "Epoch 2270/10000 --- Train Loss: 0.11793272217258348 --- Val Loss: 0.09194797938314847\n",
      "Epoch 2280/10000 --- Train Loss: 0.11756767118735602 --- Val Loss: 0.09160085362494813\n",
      "Epoch 2290/10000 --- Train Loss: 0.11720716574420949 --- Val Loss: 0.09125881002320305\n",
      "Epoch 2300/10000 --- Train Loss: 0.11684899282746601 --- Val Loss: 0.09091797722537955\n",
      "Epoch 2310/10000 --- Train Loss: 0.11649576927173853 --- Val Loss: 0.09058072349686566\n",
      "Epoch 2320/10000 --- Train Loss: 0.11614586641456938 --- Val Loss: 0.09024703757380523\n",
      "Epoch 2330/10000 --- Train Loss: 0.11580000685447506 --- Val Loss: 0.08991908460750404\n",
      "Epoch 2340/10000 --- Train Loss: 0.11545710508504627 --- Val Loss: 0.08959472976730253\n",
      "Epoch 2350/10000 --- Train Loss: 0.11511891763095086 --- Val Loss: 0.0892727070661098\n",
      "Epoch 2360/10000 --- Train Loss: 0.11478420635808874 --- Val Loss: 0.0889544790781777\n",
      "Epoch 2370/10000 --- Train Loss: 0.11445424082576171 --- Val Loss: 0.08863994979034734\n",
      "Epoch 2380/10000 --- Train Loss: 0.11412820431887968 --- Val Loss: 0.08833165545502213\n",
      "Epoch 2390/10000 --- Train Loss: 0.11380457766144297 --- Val Loss: 0.08802686866447275\n",
      "Epoch 2400/10000 --- Train Loss: 0.11348507266231836 --- Val Loss: 0.08772548385871295\n",
      "Epoch 2410/10000 --- Train Loss: 0.1131708528073202 --- Val Loss: 0.0874281512970708\n",
      "Epoch 2420/10000 --- Train Loss: 0.11285989456707313 --- Val Loss: 0.08713500246528232\n",
      "Epoch 2430/10000 --- Train Loss: 0.11255203936729079 --- Val Loss: 0.0868478834536971\n",
      "Epoch 2440/10000 --- Train Loss: 0.11224673355631638 --- Val Loss: 0.08656225571506995\n",
      "Epoch 2450/10000 --- Train Loss: 0.11194469196966068 --- Val Loss: 0.08627834969704498\n",
      "Epoch 2460/10000 --- Train Loss: 0.11164551591236183 --- Val Loss: 0.08599599998879809\n",
      "Epoch 2470/10000 --- Train Loss: 0.11135027891280447 --- Val Loss: 0.08571899247358859\n",
      "Epoch 2480/10000 --- Train Loss: 0.11105899753760441 --- Val Loss: 0.0854473480425429\n",
      "Epoch 2490/10000 --- Train Loss: 0.11077129546463019 --- Val Loss: 0.08517629769558994\n",
      "Epoch 2500/10000 --- Train Loss: 0.11048685156640864 --- Val Loss: 0.0849103866680901\n",
      "Epoch 2510/10000 --- Train Loss: 0.11020411595214576 --- Val Loss: 0.08464467222926149\n",
      "Epoch 2520/10000 --- Train Loss: 0.10992413022904955 --- Val Loss: 0.08438342336833148\n",
      "Epoch 2530/10000 --- Train Loss: 0.10964770881174063 --- Val Loss: 0.08412562567638439\n",
      "Epoch 2540/10000 --- Train Loss: 0.10937288297954753 --- Val Loss: 0.08387018520419001\n",
      "Epoch 2550/10000 --- Train Loss: 0.10910068037273381 --- Val Loss: 0.08361629586956136\n",
      "Epoch 2560/10000 --- Train Loss: 0.10883196735539293 --- Val Loss: 0.0833677383418748\n",
      "Epoch 2570/10000 --- Train Loss: 0.10856539642239091 --- Val Loss: 0.08311959681589202\n",
      "Epoch 2580/10000 --- Train Loss: 0.1083019157987922 --- Val Loss: 0.08287521750541856\n",
      "Epoch 2590/10000 --- Train Loss: 0.10804174342623436 --- Val Loss: 0.08263527947861735\n",
      "Epoch 2600/10000 --- Train Loss: 0.10778325484877693 --- Val Loss: 0.08239446947110249\n",
      "Epoch 2610/10000 --- Train Loss: 0.10752736900881751 --- Val Loss: 0.0821544598676748\n",
      "Epoch 2620/10000 --- Train Loss: 0.10727431037281412 --- Val Loss: 0.0819190373966416\n",
      "Epoch 2630/10000 --- Train Loss: 0.1070244277354538 --- Val Loss: 0.08168500521646124\n",
      "Epoch 2640/10000 --- Train Loss: 0.10677601405941052 --- Val Loss: 0.08145549639625317\n",
      "Epoch 2650/10000 --- Train Loss: 0.10653022128838723 --- Val Loss: 0.08122794913811462\n",
      "Epoch 2660/10000 --- Train Loss: 0.10628933419375261 --- Val Loss: 0.08100216208827533\n",
      "Epoch 2670/10000 --- Train Loss: 0.1060490801886673 --- Val Loss: 0.08077562932931744\n",
      "Epoch 2680/10000 --- Train Loss: 0.10581048954324146 --- Val Loss: 0.08055289335976346\n",
      "Epoch 2690/10000 --- Train Loss: 0.1055741618374241 --- Val Loss: 0.08033291920548612\n",
      "Epoch 2700/10000 --- Train Loss: 0.10533931445507576 --- Val Loss: 0.08011461575952256\n",
      "Epoch 2710/10000 --- Train Loss: 0.10510646532869126 --- Val Loss: 0.07989944095819482\n",
      "Epoch 2720/10000 --- Train Loss: 0.10487575011073257 --- Val Loss: 0.07968561011702807\n",
      "Epoch 2730/10000 --- Train Loss: 0.10464688621904554 --- Val Loss: 0.07947564227277716\n",
      "Epoch 2740/10000 --- Train Loss: 0.10442141195602016 --- Val Loss: 0.07926659337766616\n",
      "Epoch 2750/10000 --- Train Loss: 0.10419768716931391 --- Val Loss: 0.07905904999530088\n",
      "Epoch 2760/10000 --- Train Loss: 0.10397704162155814 --- Val Loss: 0.0788522505434019\n",
      "Epoch 2770/10000 --- Train Loss: 0.10375846461499631 --- Val Loss: 0.07865028589920756\n",
      "Epoch 2780/10000 --- Train Loss: 0.10354117422630961 --- Val Loss: 0.07844761520461181\n",
      "Epoch 2790/10000 --- Train Loss: 0.10332506308487659 --- Val Loss: 0.07824758129672844\n",
      "Epoch 2800/10000 --- Train Loss: 0.10311239156241321 --- Val Loss: 0.07804949295828123\n",
      "Epoch 2810/10000 --- Train Loss: 0.10290029535603448 --- Val Loss: 0.07785380730163913\n",
      "Epoch 2820/10000 --- Train Loss: 0.10269153416355868 --- Val Loss: 0.07766203129097321\n",
      "Epoch 2830/10000 --- Train Loss: 0.10248366253724867 --- Val Loss: 0.07746922091472064\n",
      "Epoch 2840/10000 --- Train Loss: 0.10227736961993208 --- Val Loss: 0.07727735742254756\n",
      "Epoch 2850/10000 --- Train Loss: 0.1020724815352897 --- Val Loss: 0.07708970391236936\n",
      "Epoch 2860/10000 --- Train Loss: 0.10187016181720454 --- Val Loss: 0.07690371461670932\n",
      "Epoch 2870/10000 --- Train Loss: 0.10166947067859004 --- Val Loss: 0.07671862872309153\n",
      "Epoch 2880/10000 --- Train Loss: 0.10147095733173371 --- Val Loss: 0.07653369178377782\n",
      "Epoch 2890/10000 --- Train Loss: 0.10127275935005067 --- Val Loss: 0.07634975190460765\n",
      "Epoch 2900/10000 --- Train Loss: 0.10107736611727913 --- Val Loss: 0.07616567230843536\n",
      "Epoch 2910/10000 --- Train Loss: 0.10088374281127875 --- Val Loss: 0.0759843923603112\n",
      "Epoch 2920/10000 --- Train Loss: 0.10069139897528079 --- Val Loss: 0.07580593250271696\n",
      "Epoch 2930/10000 --- Train Loss: 0.10050112922482736 --- Val Loss: 0.07562782574193279\n",
      "Epoch 2940/10000 --- Train Loss: 0.10031130968211652 --- Val Loss: 0.07545449759620698\n",
      "Epoch 2950/10000 --- Train Loss: 0.10012262152286353 --- Val Loss: 0.07528138235117324\n",
      "Epoch 2960/10000 --- Train Loss: 0.09993652664522316 --- Val Loss: 0.07510845227749567\n",
      "Epoch 2970/10000 --- Train Loss: 0.09975210892827391 --- Val Loss: 0.07493824707756996\n",
      "Epoch 2980/10000 --- Train Loss: 0.09956885130010373 --- Val Loss: 0.07476803339911185\n",
      "Epoch 2990/10000 --- Train Loss: 0.09938750112253882 --- Val Loss: 0.07459879079589345\n",
      "Epoch 3000/10000 --- Train Loss: 0.09920820930416467 --- Val Loss: 0.07443306401233035\n",
      "Epoch 3010/10000 --- Train Loss: 0.09902909223144328 --- Val Loss: 0.07426777036650246\n",
      "Epoch 3020/10000 --- Train Loss: 0.09885219502758184 --- Val Loss: 0.07410369934115571\n",
      "Epoch 3030/10000 --- Train Loss: 0.09867564131703266 --- Val Loss: 0.07394211285049282\n",
      "Epoch 3040/10000 --- Train Loss: 0.09850173116698357 --- Val Loss: 0.07377958197764573\n",
      "Epoch 3050/10000 --- Train Loss: 0.09832958125985043 --- Val Loss: 0.07361798410224937\n",
      "Epoch 3060/10000 --- Train Loss: 0.09815803465319398 --- Val Loss: 0.07345901407742929\n",
      "Epoch 3070/10000 --- Train Loss: 0.09798887038810744 --- Val Loss: 0.07330089463349163\n",
      "Epoch 3080/10000 --- Train Loss: 0.09781995017854406 --- Val Loss: 0.07314522080207742\n",
      "Epoch 3090/10000 --- Train Loss: 0.09765290257005452 --- Val Loss: 0.07298873710710972\n",
      "Epoch 3100/10000 --- Train Loss: 0.0974869322254116 --- Val Loss: 0.0728351840862374\n",
      "Epoch 3110/10000 --- Train Loss: 0.0973222276009578 --- Val Loss: 0.07268391335163848\n",
      "Epoch 3120/10000 --- Train Loss: 0.09715879271527991 --- Val Loss: 0.07253100718148713\n",
      "Epoch 3130/10000 --- Train Loss: 0.09699593696882058 --- Val Loss: 0.07238011253795269\n",
      "Epoch 3140/10000 --- Train Loss: 0.09683458054950064 --- Val Loss: 0.07223098171091845\n",
      "Epoch 3150/10000 --- Train Loss: 0.09667500116910654 --- Val Loss: 0.07208245439292404\n",
      "Epoch 3160/10000 --- Train Loss: 0.09651623110134312 --- Val Loss: 0.07193522198216763\n",
      "Epoch 3170/10000 --- Train Loss: 0.09635952923569116 --- Val Loss: 0.07178964498850315\n",
      "Epoch 3180/10000 --- Train Loss: 0.09620388853691864 --- Val Loss: 0.07164464605348018\n",
      "Epoch 3190/10000 --- Train Loss: 0.09604934678970768 --- Val Loss: 0.07150154921283568\n",
      "Epoch 3200/10000 --- Train Loss: 0.0958963767427215 --- Val Loss: 0.07135713763818233\n",
      "Epoch 3210/10000 --- Train Loss: 0.09574426032167752 --- Val Loss: 0.07121625172054054\n",
      "Epoch 3220/10000 --- Train Loss: 0.0955925075740058 --- Val Loss: 0.07107398401500452\n",
      "Epoch 3230/10000 --- Train Loss: 0.09544256704101246 --- Val Loss: 0.07093475771961438\n",
      "Epoch 3240/10000 --- Train Loss: 0.09529355873173893 --- Val Loss: 0.0707967114267269\n",
      "Epoch 3250/10000 --- Train Loss: 0.09514477462024991 --- Val Loss: 0.07065804071323561\n",
      "Epoch 3260/10000 --- Train Loss: 0.09499761285723855 --- Val Loss: 0.07052095227326248\n",
      "Epoch 3270/10000 --- Train Loss: 0.09485129717179103 --- Val Loss: 0.07038688938184444\n",
      "Epoch 3280/10000 --- Train Loss: 0.0947065583377061 --- Val Loss: 0.07025317249573938\n",
      "Epoch 3290/10000 --- Train Loss: 0.09456328921851005 --- Val Loss: 0.07011705945833849\n",
      "Epoch 3300/10000 --- Train Loss: 0.09442124190676028 --- Val Loss: 0.06998561837355435\n",
      "Epoch 3310/10000 --- Train Loss: 0.09427975550358261 --- Val Loss: 0.06985573397812551\n",
      "Epoch 3320/10000 --- Train Loss: 0.0941389076058829 --- Val Loss: 0.069725290357188\n",
      "Epoch 3330/10000 --- Train Loss: 0.09399954148412114 --- Val Loss: 0.06959410979459835\n",
      "Epoch 3340/10000 --- Train Loss: 0.09386027088026268 --- Val Loss: 0.0694638491237214\n",
      "Epoch 3350/10000 --- Train Loss: 0.09372357450447574 --- Val Loss: 0.06933505945575016\n",
      "Epoch 3360/10000 --- Train Loss: 0.09358666517149918 --- Val Loss: 0.06920853506400926\n",
      "Epoch 3370/10000 --- Train Loss: 0.09345120592187664 --- Val Loss: 0.0690825873693121\n",
      "Epoch 3380/10000 --- Train Loss: 0.0933166873319821 --- Val Loss: 0.06895735571467844\n",
      "Epoch 3390/10000 --- Train Loss: 0.09318291114629727 --- Val Loss: 0.06883547952441686\n",
      "Epoch 3400/10000 --- Train Loss: 0.09305025678318916 --- Val Loss: 0.06871259919928573\n",
      "Epoch 3410/10000 --- Train Loss: 0.09291786581954378 --- Val Loss: 0.06859063185209147\n",
      "Epoch 3420/10000 --- Train Loss: 0.09278576320929707 --- Val Loss: 0.06846851280939803\n",
      "Epoch 3430/10000 --- Train Loss: 0.09265631018114891 --- Val Loss: 0.06834784834889275\n",
      "Epoch 3440/10000 --- Train Loss: 0.09252628167858043 --- Val Loss: 0.06822749118024492\n",
      "Epoch 3450/10000 --- Train Loss: 0.09239723349374859 --- Val Loss: 0.06810870055248798\n",
      "Epoch 3460/10000 --- Train Loss: 0.09226895976219923 --- Val Loss: 0.06799000407322592\n",
      "Epoch 3470/10000 --- Train Loss: 0.09214107865843173 --- Val Loss: 0.06787446674572248\n",
      "Epoch 3480/10000 --- Train Loss: 0.09201473459769678 --- Val Loss: 0.06775757251857323\n",
      "Epoch 3490/10000 --- Train Loss: 0.09188988727666067 --- Val Loss: 0.06764190160260414\n",
      "Epoch 3500/10000 --- Train Loss: 0.09176571401855745 --- Val Loss: 0.0675269300298267\n",
      "Epoch 3510/10000 --- Train Loss: 0.09164191817112602 --- Val Loss: 0.06741281864616162\n",
      "Epoch 3520/10000 --- Train Loss: 0.0915199343515063 --- Val Loss: 0.06730062264324999\n",
      "Epoch 3530/10000 --- Train Loss: 0.09139778652285845 --- Val Loss: 0.06718915453584239\n",
      "Epoch 3540/10000 --- Train Loss: 0.09127612215042367 --- Val Loss: 0.0670770943230099\n",
      "Epoch 3550/10000 --- Train Loss: 0.09115483415672518 --- Val Loss: 0.06696558396223186\n",
      "Epoch 3560/10000 --- Train Loss: 0.09103493602297899 --- Val Loss: 0.06685483367492034\n",
      "Epoch 3570/10000 --- Train Loss: 0.09091530259068403 --- Val Loss: 0.06674532175722507\n",
      "Epoch 3580/10000 --- Train Loss: 0.09079606091677123 --- Val Loss: 0.06663692445918518\n",
      "Epoch 3590/10000 --- Train Loss: 0.09067855507772274 --- Val Loss: 0.06652662391081152\n",
      "Epoch 3600/10000 --- Train Loss: 0.09056081274038648 --- Val Loss: 0.06641799371902538\n",
      "Epoch 3610/10000 --- Train Loss: 0.09044446347807047 --- Val Loss: 0.06631181722415685\n",
      "Epoch 3620/10000 --- Train Loss: 0.09032955819641754 --- Val Loss: 0.06620414220956591\n",
      "Epoch 3630/10000 --- Train Loss: 0.09021382126026983 --- Val Loss: 0.0661001374576941\n",
      "Epoch 3640/10000 --- Train Loss: 0.090099997881084 --- Val Loss: 0.06599332572681664\n",
      "Epoch 3650/10000 --- Train Loss: 0.08998713596961265 --- Val Loss: 0.06588804477226963\n",
      "Epoch 3660/10000 --- Train Loss: 0.08987414593681968 --- Val Loss: 0.06578367064483999\n",
      "Epoch 3670/10000 --- Train Loss: 0.08976157804779182 --- Val Loss: 0.06568166471318886\n",
      "Epoch 3680/10000 --- Train Loss: 0.0896500912665009 --- Val Loss: 0.06558069625451446\n",
      "Epoch 3690/10000 --- Train Loss: 0.08953957748733964 --- Val Loss: 0.06547776127715553\n",
      "Epoch 3700/10000 --- Train Loss: 0.08942916478296287 --- Val Loss: 0.06537624898380702\n",
      "Epoch 3710/10000 --- Train Loss: 0.08932023991721731 --- Val Loss: 0.06527614496864849\n",
      "Epoch 3720/10000 --- Train Loss: 0.08921070712037886 --- Val Loss: 0.06517640313502816\n",
      "Epoch 3730/10000 --- Train Loss: 0.08910279063670716 --- Val Loss: 0.06507675752730141\n",
      "Epoch 3740/10000 --- Train Loss: 0.08899479560948872 --- Val Loss: 0.06497923880649653\n",
      "Epoch 3750/10000 --- Train Loss: 0.08888808766377483 --- Val Loss: 0.06488122042326332\n",
      "Epoch 3760/10000 --- Train Loss: 0.08878166201581776 --- Val Loss: 0.0647842023882833\n",
      "Epoch 3770/10000 --- Train Loss: 0.0886758295592581 --- Val Loss: 0.06468809159116312\n",
      "Epoch 3780/10000 --- Train Loss: 0.08857063574166292 --- Val Loss: 0.0645918883773088\n",
      "Epoch 3790/10000 --- Train Loss: 0.08846565814238659 --- Val Loss: 0.0644958922789421\n",
      "Epoch 3800/10000 --- Train Loss: 0.08836180665962044 --- Val Loss: 0.06439926216142974\n",
      "Epoch 3810/10000 --- Train Loss: 0.08825843706165575 --- Val Loss: 0.06430541207954787\n",
      "Epoch 3820/10000 --- Train Loss: 0.08815573759228153 --- Val Loss: 0.06421114108621202\n",
      "Epoch 3830/10000 --- Train Loss: 0.08805363305529178 --- Val Loss: 0.06411866737846005\n",
      "Epoch 3840/10000 --- Train Loss: 0.08795184003007953 --- Val Loss: 0.06402579591885581\n",
      "Epoch 3850/10000 --- Train Loss: 0.08785143805154806 --- Val Loss: 0.06393132204921305\n",
      "Epoch 3860/10000 --- Train Loss: 0.08775085759798866 --- Val Loss: 0.06384039962507376\n",
      "Epoch 3870/10000 --- Train Loss: 0.08765073704261744 --- Val Loss: 0.06375044052564219\n",
      "Epoch 3880/10000 --- Train Loss: 0.08755167878818228 --- Val Loss: 0.06365945021743089\n",
      "Epoch 3890/10000 --- Train Loss: 0.08745234887454054 --- Val Loss: 0.06356997319228803\n",
      "Epoch 3900/10000 --- Train Loss: 0.08735393322065961 --- Val Loss: 0.06347777940379212\n",
      "Epoch 3910/10000 --- Train Loss: 0.08725622279728686 --- Val Loss: 0.06338857153300348\n",
      "Epoch 3920/10000 --- Train Loss: 0.08715985933389611 --- Val Loss: 0.06329873178758498\n",
      "Epoch 3930/10000 --- Train Loss: 0.08706290481309939 --- Val Loss: 0.06321021147906287\n",
      "Epoch 3940/10000 --- Train Loss: 0.08696667886184836 --- Val Loss: 0.0631223644912235\n",
      "Epoch 3950/10000 --- Train Loss: 0.0868706249112306 --- Val Loss: 0.06303528129097692\n",
      "Epoch 3960/10000 --- Train Loss: 0.0867758692931444 --- Val Loss: 0.06294772730429682\n",
      "Epoch 3970/10000 --- Train Loss: 0.0866816254967124 --- Val Loss: 0.06286175627333608\n",
      "Epoch 3980/10000 --- Train Loss: 0.08658815301528364 --- Val Loss: 0.06277572635198664\n",
      "Epoch 3990/10000 --- Train Loss: 0.08649453553122649 --- Val Loss: 0.0626892457454283\n",
      "Epoch 4000/10000 --- Train Loss: 0.08640233458404853 --- Val Loss: 0.06260551360838797\n",
      "Epoch 4010/10000 --- Train Loss: 0.0863092004674305 --- Val Loss: 0.06252151155714153\n",
      "Epoch 4020/10000 --- Train Loss: 0.0862181599179252 --- Val Loss: 0.062438629755134985\n",
      "Epoch 4030/10000 --- Train Loss: 0.08612718929752196 --- Val Loss: 0.06235641987700158\n",
      "Epoch 4040/10000 --- Train Loss: 0.0860359974691152 --- Val Loss: 0.06227272527357915\n",
      "Epoch 4050/10000 --- Train Loss: 0.08594651999859164 --- Val Loss: 0.0621896674696897\n",
      "Epoch 4060/10000 --- Train Loss: 0.08585636060934689 --- Val Loss: 0.062108541549504015\n",
      "Epoch 4070/10000 --- Train Loss: 0.08576760195520139 --- Val Loss: 0.06202679033844334\n",
      "Epoch 4080/10000 --- Train Loss: 0.08567888471610068 --- Val Loss: 0.06194510470306041\n",
      "Epoch 4090/10000 --- Train Loss: 0.08558954642086973 --- Val Loss: 0.061865273853705084\n",
      "Epoch 4100/10000 --- Train Loss: 0.08550182107778569 --- Val Loss: 0.06178468211821457\n",
      "Epoch 4110/10000 --- Train Loss: 0.08541434585869496 --- Val Loss: 0.061704887878575615\n",
      "Epoch 4120/10000 --- Train Loss: 0.08532708782945174 --- Val Loss: 0.0616256224856307\n",
      "Epoch 4130/10000 --- Train Loss: 0.08524071580144349 --- Val Loss: 0.06154659281782522\n",
      "Epoch 4140/10000 --- Train Loss: 0.08515464888531131 --- Val Loss: 0.06146641237443997\n",
      "Epoch 4150/10000 --- Train Loss: 0.08506961105839361 --- Val Loss: 0.061385775313680224\n",
      "Epoch 4160/10000 --- Train Loss: 0.0849840875043468 --- Val Loss: 0.06130741686073836\n",
      "Epoch 4170/10000 --- Train Loss: 0.08489938574638167 --- Val Loss: 0.061227844117161326\n",
      "Epoch 4180/10000 --- Train Loss: 0.08481500781136266 --- Val Loss: 0.06115034968861308\n",
      "Epoch 4190/10000 --- Train Loss: 0.08473119315234073 --- Val Loss: 0.06107286416022611\n",
      "Epoch 4200/10000 --- Train Loss: 0.08464810303271637 --- Val Loss: 0.06099405517948189\n",
      "Epoch 4210/10000 --- Train Loss: 0.08456516412909554 --- Val Loss: 0.06091717516705873\n",
      "Epoch 4220/10000 --- Train Loss: 0.08448226695763426 --- Val Loss: 0.0608420425256717\n",
      "Epoch 4230/10000 --- Train Loss: 0.08440029407251212 --- Val Loss: 0.06076614540793052\n",
      "Epoch 4240/10000 --- Train Loss: 0.08431930100318497 --- Val Loss: 0.060692541356992924\n",
      "Epoch 4250/10000 --- Train Loss: 0.0842374361369679 --- Val Loss: 0.06061819983962464\n",
      "Epoch 4260/10000 --- Train Loss: 0.08415604362558998 --- Val Loss: 0.06054432880002671\n",
      "Epoch 4270/10000 --- Train Loss: 0.08407543798075459 --- Val Loss: 0.060470352365975755\n",
      "Epoch 4280/10000 --- Train Loss: 0.08399512985750486 --- Val Loss: 0.060396625574901004\n",
      "Epoch 4290/10000 --- Train Loss: 0.08391553215192436 --- Val Loss: 0.060321617042077995\n",
      "Epoch 4300/10000 --- Train Loss: 0.08383668305702442 --- Val Loss: 0.06025017620149459\n",
      "Epoch 4310/10000 --- Train Loss: 0.08375761953171228 --- Val Loss: 0.06017840332842499\n",
      "Epoch 4320/10000 --- Train Loss: 0.08367948434673698 --- Val Loss: 0.06010525159485823\n",
      "Epoch 4330/10000 --- Train Loss: 0.08360134902529258 --- Val Loss: 0.06003399418965912\n",
      "Epoch 4340/10000 --- Train Loss: 0.08352320300148468 --- Val Loss: 0.059962139070165024\n",
      "Epoch 4350/10000 --- Train Loss: 0.08344583133978732 --- Val Loss: 0.05989093173604278\n",
      "Epoch 4360/10000 --- Train Loss: 0.08336897108529209 --- Val Loss: 0.059817069322128796\n",
      "Epoch 4370/10000 --- Train Loss: 0.0832923534482324 --- Val Loss: 0.05974772925363561\n",
      "Epoch 4380/10000 --- Train Loss: 0.08321585660720494 --- Val Loss: 0.059676568364503094\n",
      "Epoch 4390/10000 --- Train Loss: 0.08313992964374212 --- Val Loss: 0.05960645328495181\n",
      "Epoch 4400/10000 --- Train Loss: 0.0830645503299806 --- Val Loss: 0.059536029805760615\n",
      "Epoch 4410/10000 --- Train Loss: 0.08298911606344764 --- Val Loss: 0.05946515354538954\n",
      "Epoch 4420/10000 --- Train Loss: 0.08291453571846136 --- Val Loss: 0.05939625037352789\n",
      "Epoch 4430/10000 --- Train Loss: 0.0828400848265206 --- Val Loss: 0.059326870418066474\n",
      "Epoch 4440/10000 --- Train Loss: 0.08276621167571012 --- Val Loss: 0.059255572036495265\n",
      "Epoch 4450/10000 --- Train Loss: 0.08269231464049139 --- Val Loss: 0.05918650372446521\n",
      "Epoch 4460/10000 --- Train Loss: 0.0826191071895436 --- Val Loss: 0.05911626721857436\n",
      "Epoch 4470/10000 --- Train Loss: 0.08254637069772036 --- Val Loss: 0.059047066485052556\n",
      "Epoch 4480/10000 --- Train Loss: 0.08247376843641462 --- Val Loss: 0.058979812556463\n",
      "Epoch 4490/10000 --- Train Loss: 0.08240148857425114 --- Val Loss: 0.05891103612588721\n",
      "Epoch 4500/10000 --- Train Loss: 0.08232961654833608 --- Val Loss: 0.058843776538401046\n",
      "Epoch 4510/10000 --- Train Loss: 0.0822578349629285 --- Val Loss: 0.05877634894357241\n",
      "Epoch 4520/10000 --- Train Loss: 0.08218660887604154 --- Val Loss: 0.058709215289325586\n",
      "Epoch 4530/10000 --- Train Loss: 0.08211527422974961 --- Val Loss: 0.058643261088804244\n",
      "Epoch 4540/10000 --- Train Loss: 0.08204455519802586 --- Val Loss: 0.0585776259334553\n",
      "Epoch 4550/10000 --- Train Loss: 0.08197416823609956 --- Val Loss: 0.05851018651328247\n",
      "Epoch 4560/10000 --- Train Loss: 0.0819043762468233 --- Val Loss: 0.05844499547849793\n",
      "Epoch 4570/10000 --- Train Loss: 0.08183497816851407 --- Val Loss: 0.05837939157841619\n",
      "Epoch 4580/10000 --- Train Loss: 0.08176564260542485 --- Val Loss: 0.058314426752359254\n",
      "Epoch 4590/10000 --- Train Loss: 0.08169674198803388 --- Val Loss: 0.05824973592406661\n",
      "Epoch 4600/10000 --- Train Loss: 0.0816281906247698 --- Val Loss: 0.05818524626060631\n",
      "Epoch 4610/10000 --- Train Loss: 0.08155971421305212 --- Val Loss: 0.058121394982535796\n",
      "Epoch 4620/10000 --- Train Loss: 0.08149201622084894 --- Val Loss: 0.05805922253275058\n",
      "Epoch 4630/10000 --- Train Loss: 0.08142441889420937 --- Val Loss: 0.057995092782001156\n",
      "Epoch 4640/10000 --- Train Loss: 0.08135715141200944 --- Val Loss: 0.057930667684222024\n",
      "Epoch 4650/10000 --- Train Loss: 0.08129008222052521 --- Val Loss: 0.057866392849460005\n",
      "Epoch 4660/10000 --- Train Loss: 0.08122327810732934 --- Val Loss: 0.05780239547381423\n",
      "Epoch 4670/10000 --- Train Loss: 0.08115668712394196 --- Val Loss: 0.05773958111392184\n",
      "Epoch 4680/10000 --- Train Loss: 0.08109129760069209 --- Val Loss: 0.05767514182558048\n",
      "Epoch 4690/10000 --- Train Loss: 0.0810252627753256 --- Val Loss: 0.05761543842080746\n",
      "Epoch 4700/10000 --- Train Loss: 0.08095932542246083 --- Val Loss: 0.05755239668165664\n",
      "Epoch 4710/10000 --- Train Loss: 0.08089371676494733 --- Val Loss: 0.05749217008422361\n",
      "Epoch 4720/10000 --- Train Loss: 0.08082843949510411 --- Val Loss: 0.05743028454621491\n",
      "Epoch 4730/10000 --- Train Loss: 0.0807635642113726 --- Val Loss: 0.05736912554918446\n",
      "Epoch 4740/10000 --- Train Loss: 0.08069886421046557 --- Val Loss: 0.057307306179312886\n",
      "Epoch 4750/10000 --- Train Loss: 0.08063560172387427 --- Val Loss: 0.05724594304632479\n",
      "Epoch 4760/10000 --- Train Loss: 0.08057134995518299 --- Val Loss: 0.05718654412790631\n",
      "Epoch 4770/10000 --- Train Loss: 0.08050776464731187 --- Val Loss: 0.057126219952343425\n",
      "Epoch 4780/10000 --- Train Loss: 0.08044461546775779 --- Val Loss: 0.05706698428616501\n",
      "Epoch 4790/10000 --- Train Loss: 0.08038130762826586 --- Val Loss: 0.05700700352184705\n",
      "Epoch 4800/10000 --- Train Loss: 0.0803181290194609 --- Val Loss: 0.05694789234107386\n",
      "Epoch 4810/10000 --- Train Loss: 0.08025565830328094 --- Val Loss: 0.05688892683538485\n",
      "Epoch 4820/10000 --- Train Loss: 0.0801936417429811 --- Val Loss: 0.056827719397783305\n",
      "Epoch 4830/10000 --- Train Loss: 0.08013154851514963 --- Val Loss: 0.05676925104473608\n",
      "Epoch 4840/10000 --- Train Loss: 0.08007033910320764 --- Val Loss: 0.056709594089681806\n",
      "Epoch 4850/10000 --- Train Loss: 0.08000884345558684 --- Val Loss: 0.0566514815790296\n",
      "Epoch 4860/10000 --- Train Loss: 0.07994717399210936 --- Val Loss: 0.05659456764701424\n",
      "Epoch 4870/10000 --- Train Loss: 0.07988640299427134 --- Val Loss: 0.056532233801977\n",
      "Epoch 4880/10000 --- Train Loss: 0.07982549945665468 --- Val Loss: 0.05647575209794368\n",
      "Epoch 4890/10000 --- Train Loss: 0.07976475949138655 --- Val Loss: 0.056418160145413884\n",
      "Epoch 4900/10000 --- Train Loss: 0.07970439789240284 --- Val Loss: 0.056362829296068354\n",
      "Epoch 4910/10000 --- Train Loss: 0.079644260956609 --- Val Loss: 0.056306282474217255\n",
      "Epoch 4920/10000 --- Train Loss: 0.07958411076545087 --- Val Loss: 0.05624992168848686\n",
      "Epoch 4930/10000 --- Train Loss: 0.07952426025323538 --- Val Loss: 0.05619219287695385\n",
      "Epoch 4940/10000 --- Train Loss: 0.07946519322840354 --- Val Loss: 0.05613608714907328\n",
      "Epoch 4950/10000 --- Train Loss: 0.07940590426988438 --- Val Loss: 0.056078027967913086\n",
      "Epoch 4960/10000 --- Train Loss: 0.07934730189868416 --- Val Loss: 0.056021474422200276\n",
      "Epoch 4970/10000 --- Train Loss: 0.07928839821665716 --- Val Loss: 0.0559658104532574\n",
      "Epoch 4980/10000 --- Train Loss: 0.07922982696324583 --- Val Loss: 0.05590890484265736\n",
      "Epoch 4990/10000 --- Train Loss: 0.07917129356863734 --- Val Loss: 0.05585388629021329\n",
      "Epoch 5000/10000 --- Train Loss: 0.07911393548554264 --- Val Loss: 0.0557989164194644\n",
      "Epoch 5010/10000 --- Train Loss: 0.07905608474190451 --- Val Loss: 0.05574323900466765\n",
      "Epoch 5020/10000 --- Train Loss: 0.07899854786783646 --- Val Loss: 0.05568784526813058\n",
      "Epoch 5030/10000 --- Train Loss: 0.07894125088494246 --- Val Loss: 0.05563295983784385\n",
      "Epoch 5040/10000 --- Train Loss: 0.07888430164294959 --- Val Loss: 0.05557671337538663\n",
      "Epoch 5050/10000 --- Train Loss: 0.07882772527446258 --- Val Loss: 0.055521150413393575\n",
      "Epoch 5060/10000 --- Train Loss: 0.07877092912017421 --- Val Loss: 0.05546696890408621\n",
      "Epoch 5070/10000 --- Train Loss: 0.07871466962052534 --- Val Loss: 0.05541308291964984\n",
      "Epoch 5080/10000 --- Train Loss: 0.0786587623474305 --- Val Loss: 0.05535984339831458\n",
      "Epoch 5090/10000 --- Train Loss: 0.07860285615251324 --- Val Loss: 0.05530617342644414\n",
      "Epoch 5100/10000 --- Train Loss: 0.07854710754374346 --- Val Loss: 0.05525086235575018\n",
      "Epoch 5110/10000 --- Train Loss: 0.07849137481922017 --- Val Loss: 0.055197922813227905\n",
      "Epoch 5120/10000 --- Train Loss: 0.07843614589184222 --- Val Loss: 0.055143931040892324\n",
      "Epoch 5130/10000 --- Train Loss: 0.07838102277693754 --- Val Loss: 0.05509122937075213\n",
      "Epoch 5140/10000 --- Train Loss: 0.0783259911813228 --- Val Loss: 0.055038391397801575\n",
      "Epoch 5150/10000 --- Train Loss: 0.07827132078409704 --- Val Loss: 0.05498640051988617\n",
      "Epoch 5160/10000 --- Train Loss: 0.07821674187667033 --- Val Loss: 0.054932376796419026\n",
      "Epoch 5170/10000 --- Train Loss: 0.07816273158599722 --- Val Loss: 0.05487981119737136\n",
      "Epoch 5180/10000 --- Train Loss: 0.07810823434786533 --- Val Loss: 0.05482833296827624\n",
      "Epoch 5190/10000 --- Train Loss: 0.07805414575169477 --- Val Loss: 0.05477803219854662\n",
      "Epoch 5200/10000 --- Train Loss: 0.07800072603119616 --- Val Loss: 0.05472646598467195\n",
      "Epoch 5210/10000 --- Train Loss: 0.07794706211516998 --- Val Loss: 0.054672295037725964\n",
      "Epoch 5220/10000 --- Train Loss: 0.0778939703915228 --- Val Loss: 0.05462164420934934\n",
      "Epoch 5230/10000 --- Train Loss: 0.07784015296366355 --- Val Loss: 0.054570180785808726\n",
      "Epoch 5240/10000 --- Train Loss: 0.0777872697637072 --- Val Loss: 0.054519428064834764\n",
      "Epoch 5250/10000 --- Train Loss: 0.07773451550992949 --- Val Loss: 0.05446838528910141\n",
      "Epoch 5260/10000 --- Train Loss: 0.07768161141110815 --- Val Loss: 0.05441881762953585\n",
      "Epoch 5270/10000 --- Train Loss: 0.07762925516113309 --- Val Loss: 0.05436745529548222\n",
      "Epoch 5280/10000 --- Train Loss: 0.07757745121110148 --- Val Loss: 0.05431650033647798\n",
      "Epoch 5290/10000 --- Train Loss: 0.07752526076196188 --- Val Loss: 0.05426463292812493\n",
      "Epoch 5300/10000 --- Train Loss: 0.07747326646224194 --- Val Loss: 0.05421350907370068\n",
      "Epoch 5310/10000 --- Train Loss: 0.07742163854565215 --- Val Loss: 0.05416312302615533\n",
      "Epoch 5320/10000 --- Train Loss: 0.07737021271790102 --- Val Loss: 0.054113808093684546\n",
      "Epoch 5330/10000 --- Train Loss: 0.0773187016629357 --- Val Loss: 0.054063891317755276\n",
      "Epoch 5340/10000 --- Train Loss: 0.07726764263967444 --- Val Loss: 0.05401499617127957\n",
      "Epoch 5350/10000 --- Train Loss: 0.07721673532845262 --- Val Loss: 0.05396723540164523\n",
      "Epoch 5360/10000 --- Train Loss: 0.07716682260848305 --- Val Loss: 0.05391883184883347\n",
      "Epoch 5370/10000 --- Train Loss: 0.07711658889809798 --- Val Loss: 0.05386608462393729\n",
      "Epoch 5380/10000 --- Train Loss: 0.07706625474115128 --- Val Loss: 0.05381728415978922\n",
      "Epoch 5390/10000 --- Train Loss: 0.07701618166947076 --- Val Loss: 0.05376926156582289\n",
      "Epoch 5400/10000 --- Train Loss: 0.0769657652838033 --- Val Loss: 0.05371991194512986\n",
      "Epoch 5410/10000 --- Train Loss: 0.07691555765391536 --- Val Loss: 0.05367016282250769\n",
      "Epoch 5420/10000 --- Train Loss: 0.07686598630951533 --- Val Loss: 0.05362226445789011\n",
      "Epoch 5430/10000 --- Train Loss: 0.07681682133929449 --- Val Loss: 0.05357326269194444\n",
      "Epoch 5440/10000 --- Train Loss: 0.0767670024234435 --- Val Loss: 0.05352637229016889\n",
      "Epoch 5450/10000 --- Train Loss: 0.07671743540854406 --- Val Loss: 0.05347816322903014\n",
      "Epoch 5460/10000 --- Train Loss: 0.07666849724165209 --- Val Loss: 0.05342971577337243\n",
      "Epoch 5470/10000 --- Train Loss: 0.07661912291095639 --- Val Loss: 0.053381462780086805\n",
      "Epoch 5480/10000 --- Train Loss: 0.0765705126658095 --- Val Loss: 0.05333181817501057\n",
      "Epoch 5490/10000 --- Train Loss: 0.07652164104206526 --- Val Loss: 0.05328413054252481\n",
      "Epoch 5500/10000 --- Train Loss: 0.07647345839086954 --- Val Loss: 0.053237016409178405\n",
      "Epoch 5510/10000 --- Train Loss: 0.07642494730552088 --- Val Loss: 0.053191538642415846\n",
      "Epoch 5520/10000 --- Train Loss: 0.07637673329883851 --- Val Loss: 0.05314534032108914\n",
      "Epoch 5530/10000 --- Train Loss: 0.07632907538259613 --- Val Loss: 0.05309566133970878\n",
      "Epoch 5540/10000 --- Train Loss: 0.07628098403860555 --- Val Loss: 0.05304668274149507\n",
      "Epoch 5550/10000 --- Train Loss: 0.07623311082905612 --- Val Loss: 0.05299799222061493\n",
      "Epoch 5560/10000 --- Train Loss: 0.07618545844078138 --- Val Loss: 0.052950388678642095\n",
      "Epoch 5570/10000 --- Train Loss: 0.07613810597094817 --- Val Loss: 0.0529047890866844\n",
      "Epoch 5580/10000 --- Train Loss: 0.07609113992751283 --- Val Loss: 0.0528574870975087\n",
      "Epoch 5590/10000 --- Train Loss: 0.07604417280642409 --- Val Loss: 0.05281080831007601\n",
      "Epoch 5600/10000 --- Train Loss: 0.07599745710067453 --- Val Loss: 0.05276421703519954\n",
      "Epoch 5610/10000 --- Train Loss: 0.07595094790518127 --- Val Loss: 0.05271748747280553\n",
      "Epoch 5620/10000 --- Train Loss: 0.07590462904818042 --- Val Loss: 0.0526713427011805\n",
      "Epoch 5630/10000 --- Train Loss: 0.07585775460302707 --- Val Loss: 0.05262484248459643\n",
      "Epoch 5640/10000 --- Train Loss: 0.07581152432455361 --- Val Loss: 0.05257952377466047\n",
      "Epoch 5650/10000 --- Train Loss: 0.0757651732065462 --- Val Loss: 0.052534821580542575\n",
      "Epoch 5660/10000 --- Train Loss: 0.07571914705211809 --- Val Loss: 0.05248905259012899\n",
      "Epoch 5670/10000 --- Train Loss: 0.07567358570927084 --- Val Loss: 0.05244357364762552\n",
      "Epoch 5680/10000 --- Train Loss: 0.07562760320190844 --- Val Loss: 0.052397243972240944\n",
      "Epoch 5690/10000 --- Train Loss: 0.07558232069617657 --- Val Loss: 0.052352491513078844\n",
      "Epoch 5700/10000 --- Train Loss: 0.07553698179500291 --- Val Loss: 0.05230719690105306\n",
      "Epoch 5710/10000 --- Train Loss: 0.07549198943734682 --- Val Loss: 0.05225884472424193\n",
      "Epoch 5720/10000 --- Train Loss: 0.07544672554416161 --- Val Loss: 0.052215310938823256\n",
      "Epoch 5730/10000 --- Train Loss: 0.07540165765502745 --- Val Loss: 0.052172782916965345\n",
      "Epoch 5740/10000 --- Train Loss: 0.0753572724737489 --- Val Loss: 0.05212766133979444\n",
      "Epoch 5750/10000 --- Train Loss: 0.07531341461478651 --- Val Loss: 0.05207966889151974\n",
      "Epoch 5760/10000 --- Train Loss: 0.0752687559949268 --- Val Loss: 0.0520370933580868\n",
      "Epoch 5770/10000 --- Train Loss: 0.07522489887882992 --- Val Loss: 0.05199277343784569\n",
      "Epoch 5780/10000 --- Train Loss: 0.0751809324154543 --- Val Loss: 0.0519482993012666\n",
      "Epoch 5790/10000 --- Train Loss: 0.07513678685231874 --- Val Loss: 0.051905467228305635\n",
      "Epoch 5800/10000 --- Train Loss: 0.07509274337197648 --- Val Loss: 0.05186046182258745\n",
      "Epoch 5810/10000 --- Train Loss: 0.07504873512423593 --- Val Loss: 0.05181697961775562\n",
      "Epoch 5820/10000 --- Train Loss: 0.07500534571770265 --- Val Loss: 0.051772437803656264\n",
      "Epoch 5830/10000 --- Train Loss: 0.07496215256909743 --- Val Loss: 0.051726267793567184\n",
      "Epoch 5840/10000 --- Train Loss: 0.07491871510006189 --- Val Loss: 0.051683429525384426\n",
      "Epoch 5850/10000 --- Train Loss: 0.07487559364209488 --- Val Loss: 0.05164016893454816\n",
      "Epoch 5860/10000 --- Train Loss: 0.07483244370514282 --- Val Loss: 0.05159755716535391\n",
      "Epoch 5870/10000 --- Train Loss: 0.07478951581538619 --- Val Loss: 0.051554390812838205\n",
      "Epoch 5880/10000 --- Train Loss: 0.07474664685949194 --- Val Loss: 0.05150979584057241\n",
      "Epoch 5890/10000 --- Train Loss: 0.07470407524878689 --- Val Loss: 0.05146605743465989\n",
      "Epoch 5900/10000 --- Train Loss: 0.07466171711532664 --- Val Loss: 0.05142311340289991\n",
      "Epoch 5910/10000 --- Train Loss: 0.07461909740956597 --- Val Loss: 0.051381205355004074\n",
      "Epoch 5920/10000 --- Train Loss: 0.07457676016131967 --- Val Loss: 0.05134013698010527\n",
      "Epoch 5930/10000 --- Train Loss: 0.07453439395321385 --- Val Loss: 0.051296185387104176\n",
      "Epoch 5940/10000 --- Train Loss: 0.07449263823470119 --- Val Loss: 0.05125417944038064\n",
      "Epoch 5950/10000 --- Train Loss: 0.07445041441008034 --- Val Loss: 0.051212157433247384\n",
      "Epoch 5960/10000 --- Train Loss: 0.07440878646022657 --- Val Loss: 0.05116901896843234\n",
      "Epoch 5970/10000 --- Train Loss: 0.07436681504295216 --- Val Loss: 0.05112720636534686\n",
      "Epoch 5980/10000 --- Train Loss: 0.07432513968106559 --- Val Loss: 0.051085136367296925\n",
      "Epoch 5990/10000 --- Train Loss: 0.07428354486971972 --- Val Loss: 0.05104343537601377\n",
      "Epoch 6000/10000 --- Train Loss: 0.07424205812884846 --- Val Loss: 0.051001579265650854\n",
      "Epoch 6010/10000 --- Train Loss: 0.07420134062979697 --- Val Loss: 0.050961679536951854\n",
      "Epoch 6020/10000 --- Train Loss: 0.07416019351261895 --- Val Loss: 0.05091977129167694\n",
      "Epoch 6030/10000 --- Train Loss: 0.07411941784924778 --- Val Loss: 0.0508767787736905\n",
      "Epoch 6040/10000 --- Train Loss: 0.0740781693304416 --- Val Loss: 0.05083557769470658\n",
      "Epoch 6050/10000 --- Train Loss: 0.07403784445269218 --- Val Loss: 0.050794035883328335\n",
      "Epoch 6060/10000 --- Train Loss: 0.07399734082650716 --- Val Loss: 0.05075121175645568\n",
      "Epoch 6070/10000 --- Train Loss: 0.07395690512719097 --- Val Loss: 0.05070917645215415\n",
      "Epoch 6080/10000 --- Train Loss: 0.07391628607415823 --- Val Loss: 0.050668698623846514\n",
      "Epoch 6090/10000 --- Train Loss: 0.07387586759313274 --- Val Loss: 0.050627001845499446\n",
      "Epoch 6100/10000 --- Train Loss: 0.07383567598150613 --- Val Loss: 0.05058497868839498\n",
      "Epoch 6110/10000 --- Train Loss: 0.07379556626657512 --- Val Loss: 0.05054377016587029\n",
      "Epoch 6120/10000 --- Train Loss: 0.07375579933187455 --- Val Loss: 0.050504442576813476\n",
      "Epoch 6130/10000 --- Train Loss: 0.07371572515345691 --- Val Loss: 0.0504637974047792\n",
      "Epoch 6140/10000 --- Train Loss: 0.0736765057987261 --- Val Loss: 0.05042251180711669\n",
      "Epoch 6150/10000 --- Train Loss: 0.0736365786596527 --- Val Loss: 0.05038215235996769\n",
      "Epoch 6160/10000 --- Train Loss: 0.07359731968464021 --- Val Loss: 0.0503418554278807\n",
      "Epoch 6170/10000 --- Train Loss: 0.07355760722556125 --- Val Loss: 0.050302657724785683\n",
      "Epoch 6180/10000 --- Train Loss: 0.07351833481908326 --- Val Loss: 0.0502629012845116\n",
      "Epoch 6190/10000 --- Train Loss: 0.07347964764161698 --- Val Loss: 0.050222340019623106\n",
      "Epoch 6200/10000 --- Train Loss: 0.07344066535889879 --- Val Loss: 0.050179586819548455\n",
      "Epoch 6210/10000 --- Train Loss: 0.07340134127900393 --- Val Loss: 0.05014195257406906\n",
      "Epoch 6220/10000 --- Train Loss: 0.07336211862580212 --- Val Loss: 0.05010348503691882\n",
      "Epoch 6230/10000 --- Train Loss: 0.07332329321577705 --- Val Loss: 0.05006213995673222\n",
      "Epoch 6240/10000 --- Train Loss: 0.07328471808162887 --- Val Loss: 0.050022792675739294\n",
      "Epoch 6250/10000 --- Train Loss: 0.07324642289945846 --- Val Loss: 0.04998402634410245\n",
      "Epoch 6260/10000 --- Train Loss: 0.07320810987781044 --- Val Loss: 0.04994323079129384\n",
      "Epoch 6270/10000 --- Train Loss: 0.07317007051731961 --- Val Loss: 0.0499037509414974\n",
      "Epoch 6280/10000 --- Train Loss: 0.07313175741344202 --- Val Loss: 0.04986521753479523\n",
      "Epoch 6290/10000 --- Train Loss: 0.07309344950024278 --- Val Loss: 0.04982683462201874\n",
      "Epoch 6300/10000 --- Train Loss: 0.07305555286975052 --- Val Loss: 0.04978958568716128\n",
      "Epoch 6310/10000 --- Train Loss: 0.07301767422760051 --- Val Loss: 0.04975213085328231\n",
      "Epoch 6320/10000 --- Train Loss: 0.0729804031772815 --- Val Loss: 0.049710876329294225\n",
      "Epoch 6330/10000 --- Train Loss: 0.07294284214113164 --- Val Loss: 0.049673140688496036\n",
      "Epoch 6340/10000 --- Train Loss: 0.07290499799320457 --- Val Loss: 0.04963335907575303\n",
      "Epoch 6350/10000 --- Train Loss: 0.07286737539506974 --- Val Loss: 0.04959762570820174\n",
      "Epoch 6360/10000 --- Train Loss: 0.07283010769733372 --- Val Loss: 0.049559190087185165\n",
      "Epoch 6370/10000 --- Train Loss: 0.07279273372110856 --- Val Loss: 0.04951991050791193\n",
      "Epoch 6380/10000 --- Train Loss: 0.07275550945180091 --- Val Loss: 0.049480331802725666\n",
      "Epoch 6390/10000 --- Train Loss: 0.07271864440416251 --- Val Loss: 0.04943983303290087\n",
      "Epoch 6400/10000 --- Train Loss: 0.07268182589489837 --- Val Loss: 0.04940041691136251\n",
      "Epoch 6410/10000 --- Train Loss: 0.0726448282159255 --- Val Loss: 0.049363059493381066\n",
      "Epoch 6420/10000 --- Train Loss: 0.07260784689692229 --- Val Loss: 0.04932531372989526\n",
      "Epoch 6430/10000 --- Train Loss: 0.07257137044135646 --- Val Loss: 0.04928837410159176\n",
      "Epoch 6440/10000 --- Train Loss: 0.07253522372264484 --- Val Loss: 0.04924786753866106\n",
      "Epoch 6450/10000 --- Train Loss: 0.07249863916406928 --- Val Loss: 0.049212092124493644\n",
      "Epoch 6460/10000 --- Train Loss: 0.07246218796630048 --- Val Loss: 0.04917520508108025\n",
      "Epoch 6470/10000 --- Train Loss: 0.07242590089039899 --- Val Loss: 0.0491372571892849\n",
      "Epoch 6480/10000 --- Train Loss: 0.07238949895465055 --- Val Loss: 0.04910056236968192\n",
      "Epoch 6490/10000 --- Train Loss: 0.07235332232142294 --- Val Loss: 0.04906184348683445\n",
      "Epoch 6500/10000 --- Train Loss: 0.0723178710181821 --- Val Loss: 0.0490229642976037\n",
      "Epoch 6510/10000 --- Train Loss: 0.07228237511500184 --- Val Loss: 0.048987124443503\n",
      "Epoch 6520/10000 --- Train Loss: 0.07224637385000046 --- Val Loss: 0.04895083633339933\n",
      "Epoch 6530/10000 --- Train Loss: 0.0722103939219799 --- Val Loss: 0.04891432731600586\n",
      "Epoch 6540/10000 --- Train Loss: 0.07217445042800351 --- Val Loss: 0.04887900575654178\n",
      "Epoch 6550/10000 --- Train Loss: 0.07213937108250533 --- Val Loss: 0.048842684283323876\n",
      "Epoch 6560/10000 --- Train Loss: 0.07210370550665197 --- Val Loss: 0.0488068941344121\n",
      "Epoch 6570/10000 --- Train Loss: 0.07206806853922029 --- Val Loss: 0.048771999497497054\n",
      "Epoch 6580/10000 --- Train Loss: 0.07203297581011897 --- Val Loss: 0.04873499008095471\n",
      "Epoch 6590/10000 --- Train Loss: 0.07199797334084139 --- Val Loss: 0.0486988772038821\n",
      "Epoch 6600/10000 --- Train Loss: 0.07196280495495333 --- Val Loss: 0.04866210236577322\n",
      "Epoch 6610/10000 --- Train Loss: 0.07192794680326418 --- Val Loss: 0.04862815030738583\n",
      "Epoch 6620/10000 --- Train Loss: 0.07189350988124685 --- Val Loss: 0.04859279987430189\n",
      "Epoch 6630/10000 --- Train Loss: 0.07185861833184805 --- Val Loss: 0.04855678251784165\n",
      "Epoch 6640/10000 --- Train Loss: 0.0718239691850569 --- Val Loss: 0.048520261829244925\n",
      "Epoch 6650/10000 --- Train Loss: 0.07178907391216678 --- Val Loss: 0.04848480259701197\n",
      "Epoch 6660/10000 --- Train Loss: 0.071754390247079 --- Val Loss: 0.04844879178368754\n",
      "Epoch 6670/10000 --- Train Loss: 0.07171988942316185 --- Val Loss: 0.04841466799802922\n",
      "Epoch 6680/10000 --- Train Loss: 0.07168569306443498 --- Val Loss: 0.04837945851548256\n",
      "Epoch 6690/10000 --- Train Loss: 0.07165151241119257 --- Val Loss: 0.04834429458735683\n",
      "Epoch 6700/10000 --- Train Loss: 0.07161773816984707 --- Val Loss: 0.04830960156231542\n",
      "Epoch 6710/10000 --- Train Loss: 0.0715840043953907 --- Val Loss: 0.04827412703642309\n",
      "Epoch 6720/10000 --- Train Loss: 0.07154992392107166 --- Val Loss: 0.04823806694899607\n",
      "Epoch 6730/10000 --- Train Loss: 0.0715158197084541 --- Val Loss: 0.0482020068851052\n",
      "Epoch 6740/10000 --- Train Loss: 0.07148239873567228 --- Val Loss: 0.04816441433291486\n",
      "Epoch 6750/10000 --- Train Loss: 0.071448650964756 --- Val Loss: 0.04813022829872152\n",
      "Epoch 6760/10000 --- Train Loss: 0.07141476564073015 --- Val Loss: 0.04809445830961093\n",
      "Epoch 6770/10000 --- Train Loss: 0.07138123205474636 --- Val Loss: 0.048058484700037596\n",
      "Epoch 6780/10000 --- Train Loss: 0.0713479774324692 --- Val Loss: 0.04802243629498682\n",
      "Epoch 6790/10000 --- Train Loss: 0.07131443993064238 --- Val Loss: 0.04798828797668565\n",
      "Epoch 6800/10000 --- Train Loss: 0.07128097067847576 --- Val Loss: 0.047952777487927506\n",
      "Epoch 6810/10000 --- Train Loss: 0.07124768440366236 --- Val Loss: 0.04791695027075128\n",
      "Epoch 6820/10000 --- Train Loss: 0.07121451371153094 --- Val Loss: 0.04788139798123321\n",
      "Epoch 6830/10000 --- Train Loss: 0.07118127646109443 --- Val Loss: 0.04784740441158757\n",
      "Epoch 6840/10000 --- Train Loss: 0.0711479446025689 --- Val Loss: 0.04781323524084664\n",
      "Epoch 6850/10000 --- Train Loss: 0.07111469916494978 --- Val Loss: 0.04777862567567209\n",
      "Epoch 6860/10000 --- Train Loss: 0.07108187647772098 --- Val Loss: 0.047743665364843875\n",
      "Epoch 6870/10000 --- Train Loss: 0.07104894617282774 --- Val Loss: 0.0477104867396821\n",
      "Epoch 6880/10000 --- Train Loss: 0.07101620729635261 --- Val Loss: 0.047675883164633774\n",
      "Epoch 6890/10000 --- Train Loss: 0.07098363549110251 --- Val Loss: 0.04764159016294475\n",
      "Epoch 6900/10000 --- Train Loss: 0.07095091967091383 --- Val Loss: 0.047608771093742494\n",
      "Epoch 6910/10000 --- Train Loss: 0.07091884252882193 --- Val Loss: 0.047574797641259034\n",
      "Epoch 6920/10000 --- Train Loss: 0.07088651356368737 --- Val Loss: 0.04754149234471952\n",
      "Epoch 6930/10000 --- Train Loss: 0.07085405084206137 --- Val Loss: 0.04750824123352361\n",
      "Epoch 6940/10000 --- Train Loss: 0.07082155700210821 --- Val Loss: 0.047474984219905786\n",
      "Epoch 6950/10000 --- Train Loss: 0.07078978233326019 --- Val Loss: 0.04743988314089685\n",
      "Epoch 6960/10000 --- Train Loss: 0.07075747683894873 --- Val Loss: 0.047405802156747355\n",
      "Epoch 6970/10000 --- Train Loss: 0.07072541403748768 --- Val Loss: 0.047372409987264226\n",
      "Epoch 6980/10000 --- Train Loss: 0.07069356457348287 --- Val Loss: 0.047336904373950744\n",
      "Epoch 6990/10000 --- Train Loss: 0.07066171341400194 --- Val Loss: 0.04730447200409431\n",
      "Epoch 7000/10000 --- Train Loss: 0.07063054592792051 --- Val Loss: 0.04727066919002587\n",
      "Epoch 7010/10000 --- Train Loss: 0.07059921557539219 --- Val Loss: 0.047237259853799396\n",
      "Epoch 7020/10000 --- Train Loss: 0.07056755540534919 --- Val Loss: 0.04720308194903602\n",
      "Epoch 7030/10000 --- Train Loss: 0.07053607215185251 --- Val Loss: 0.0471692702106764\n",
      "Epoch 7040/10000 --- Train Loss: 0.07050480657601889 --- Val Loss: 0.047134654161856554\n",
      "Epoch 7050/10000 --- Train Loss: 0.07047340697039485 --- Val Loss: 0.04710252707334484\n",
      "Epoch 7060/10000 --- Train Loss: 0.07044145640591665 --- Val Loss: 0.04706805834802507\n",
      "Epoch 7070/10000 --- Train Loss: 0.07041027622317889 --- Val Loss: 0.04703519419382772\n",
      "Epoch 7080/10000 --- Train Loss: 0.07037913199861492 --- Val Loss: 0.047002344669065194\n",
      "Epoch 7090/10000 --- Train Loss: 0.07034809853457542 --- Val Loss: 0.046970411125113444\n",
      "Epoch 7100/10000 --- Train Loss: 0.0703172781758493 --- Val Loss: 0.046936749901413145\n",
      "Epoch 7110/10000 --- Train Loss: 0.07028607297764941 --- Val Loss: 0.046905333271351046\n",
      "Epoch 7120/10000 --- Train Loss: 0.07025498338705852 --- Val Loss: 0.046871727870298155\n",
      "Epoch 7130/10000 --- Train Loss: 0.07022410864690444 --- Val Loss: 0.04683969889692785\n",
      "Epoch 7140/10000 --- Train Loss: 0.07019382414917154 --- Val Loss: 0.04680361590793642\n",
      "Epoch 7150/10000 --- Train Loss: 0.07016295899542505 --- Val Loss: 0.04677136189775403\n",
      "Epoch 7160/10000 --- Train Loss: 0.07013259461910654 --- Val Loss: 0.046739122085572474\n",
      "Epoch 7170/10000 --- Train Loss: 0.07010192804107448 --- Val Loss: 0.04670659003555055\n",
      "Epoch 7180/10000 --- Train Loss: 0.07007155829318676 --- Val Loss: 0.046675169063000156\n",
      "Epoch 7190/10000 --- Train Loss: 0.07004086850221244 --- Val Loss: 0.04664240107121735\n",
      "Epoch 7200/10000 --- Train Loss: 0.07001088668686446 --- Val Loss: 0.04661041756474965\n",
      "Epoch 7210/10000 --- Train Loss: 0.06998059807033973 --- Val Loss: 0.04657830217655202\n",
      "Epoch 7220/10000 --- Train Loss: 0.06995040986317967 --- Val Loss: 0.04654898891197449\n",
      "Epoch 7230/10000 --- Train Loss: 0.06991979946885328 --- Val Loss: 0.04651664711253056\n",
      "Epoch 7240/10000 --- Train Loss: 0.06988979637048016 --- Val Loss: 0.04648421822695668\n",
      "Epoch 7250/10000 --- Train Loss: 0.06986009456716313 --- Val Loss: 0.04645272991675843\n",
      "Epoch 7260/10000 --- Train Loss: 0.06982993682356511 --- Val Loss: 0.04642140605420332\n",
      "Epoch 7270/10000 --- Train Loss: 0.06980014085004585 --- Val Loss: 0.04638844324975136\n",
      "Epoch 7280/10000 --- Train Loss: 0.06977012976399774 --- Val Loss: 0.04635638847388573\n",
      "Epoch 7290/10000 --- Train Loss: 0.06974081583286715 --- Val Loss: 0.04632689535040614\n",
      "Epoch 7300/10000 --- Train Loss: 0.06971117154488991 --- Val Loss: 0.046292470536395756\n",
      "Epoch 7310/10000 --- Train Loss: 0.06968115839204958 --- Val Loss: 0.04626137719449063\n",
      "Epoch 7320/10000 --- Train Loss: 0.06965160025365244 --- Val Loss: 0.046230200727480186\n",
      "Epoch 7330/10000 --- Train Loss: 0.06962211792385412 --- Val Loss: 0.046199084172443165\n",
      "Epoch 7340/10000 --- Train Loss: 0.06959299391834171 --- Val Loss: 0.04616875747480291\n",
      "Epoch 7350/10000 --- Train Loss: 0.06956362789178464 --- Val Loss: 0.04613745249230272\n",
      "Epoch 7360/10000 --- Train Loss: 0.06953433666963223 --- Val Loss: 0.04610380640950432\n",
      "Epoch 7370/10000 --- Train Loss: 0.06950480975512628 --- Val Loss: 0.046073096112579585\n",
      "Epoch 7380/10000 --- Train Loss: 0.06947547076335779 --- Val Loss: 0.046045155111862926\n",
      "Epoch 7390/10000 --- Train Loss: 0.06944640275188795 --- Val Loss: 0.046015201750835504\n",
      "Epoch 7400/10000 --- Train Loss: 0.06941774892458746 --- Val Loss: 0.045983084287353766\n",
      "Epoch 7410/10000 --- Train Loss: 0.06938875337783441 --- Val Loss: 0.045953248504534874\n",
      "Epoch 7420/10000 --- Train Loss: 0.06935938754120621 --- Val Loss: 0.045922415841926606\n",
      "Epoch 7430/10000 --- Train Loss: 0.06933071329607397 --- Val Loss: 0.0458924796186607\n",
      "Epoch 7440/10000 --- Train Loss: 0.06930193242455647 --- Val Loss: 0.04586093104206304\n",
      "Epoch 7450/10000 --- Train Loss: 0.06927307444545684 --- Val Loss: 0.045830703792323395\n",
      "Epoch 7460/10000 --- Train Loss: 0.0692437762962764 --- Val Loss: 0.0458018029238337\n",
      "Epoch 7470/10000 --- Train Loss: 0.06921527364079111 --- Val Loss: 0.04577222623102355\n",
      "Epoch 7480/10000 --- Train Loss: 0.069186438316904 --- Val Loss: 0.04574040002725391\n",
      "Epoch 7490/10000 --- Train Loss: 0.06915790764211416 --- Val Loss: 0.04571035962332348\n",
      "Epoch 7500/10000 --- Train Loss: 0.06912998269519592 --- Val Loss: 0.04568215530018682\n",
      "Epoch 7510/10000 --- Train Loss: 0.06910125283233227 --- Val Loss: 0.04565202062156354\n",
      "Epoch 7520/10000 --- Train Loss: 0.06907279155475773 --- Val Loss: 0.0456229302639441\n",
      "Epoch 7530/10000 --- Train Loss: 0.06904426102251641 --- Val Loss: 0.045593234551968766\n",
      "Epoch 7540/10000 --- Train Loss: 0.06901616210519308 --- Val Loss: 0.04556146372354955\n",
      "Epoch 7550/10000 --- Train Loss: 0.06898833706953401 --- Val Loss: 0.045532551616689454\n",
      "Epoch 7560/10000 --- Train Loss: 0.06896020059648401 --- Val Loss: 0.045503919489126014\n",
      "Epoch 7570/10000 --- Train Loss: 0.06893238077038924 --- Val Loss: 0.04547481324649677\n",
      "Epoch 7580/10000 --- Train Loss: 0.06890447033911495 --- Val Loss: 0.0454444005708667\n",
      "Epoch 7590/10000 --- Train Loss: 0.06887683073098289 --- Val Loss: 0.045414299316467996\n",
      "Epoch 7600/10000 --- Train Loss: 0.06884903979099438 --- Val Loss: 0.04538372317349873\n",
      "Epoch 7610/10000 --- Train Loss: 0.06882127389272255 --- Val Loss: 0.04535135414913025\n",
      "Epoch 7620/10000 --- Train Loss: 0.06879353019720393 --- Val Loss: 0.0453217654985117\n",
      "Epoch 7630/10000 --- Train Loss: 0.06876602980054675 --- Val Loss: 0.045292788509555676\n",
      "Epoch 7640/10000 --- Train Loss: 0.06873809900327023 --- Val Loss: 0.045263585246774866\n",
      "Epoch 7650/10000 --- Train Loss: 0.068710799144286 --- Val Loss: 0.045232808188645696\n",
      "Epoch 7660/10000 --- Train Loss: 0.06868334551684574 --- Val Loss: 0.045203683478952594\n",
      "Epoch 7670/10000 --- Train Loss: 0.06865646720291427 --- Val Loss: 0.045172022530382064\n",
      "Epoch 7680/10000 --- Train Loss: 0.06862940378149522 --- Val Loss: 0.045143898157466854\n",
      "Epoch 7690/10000 --- Train Loss: 0.06860233252799056 --- Val Loss: 0.04511165775129688\n",
      "Epoch 7700/10000 --- Train Loss: 0.06857518006174537 --- Val Loss: 0.04508285692382498\n",
      "Epoch 7710/10000 --- Train Loss: 0.06854821251231952 --- Val Loss: 0.04505273795194617\n",
      "Epoch 7720/10000 --- Train Loss: 0.06852061446504018 --- Val Loss: 0.04502331159956223\n",
      "Epoch 7730/10000 --- Train Loss: 0.06849365321886848 --- Val Loss: 0.0449925592815691\n",
      "Epoch 7740/10000 --- Train Loss: 0.06846678028932784 --- Val Loss: 0.04496497108792093\n",
      "Epoch 7750/10000 --- Train Loss: 0.06843971646181074 --- Val Loss: 0.044935809850818735\n",
      "Epoch 7760/10000 --- Train Loss: 0.0684127486594159 --- Val Loss: 0.04490621461740799\n",
      "Epoch 7770/10000 --- Train Loss: 0.06838589409538344 --- Val Loss: 0.04487734717032855\n",
      "Epoch 7780/10000 --- Train Loss: 0.06835947675361291 --- Val Loss: 0.04484799753415554\n",
      "Epoch 7790/10000 --- Train Loss: 0.06833300630250679 --- Val Loss: 0.044818341757327254\n",
      "Epoch 7800/10000 --- Train Loss: 0.06830646009137843 --- Val Loss: 0.04478781605821082\n",
      "Epoch 7810/10000 --- Train Loss: 0.06827981809374271 --- Val Loss: 0.04476100944083598\n",
      "Epoch 7820/10000 --- Train Loss: 0.068253108294043 --- Val Loss: 0.044731910814118175\n",
      "Epoch 7830/10000 --- Train Loss: 0.06822679346259128 --- Val Loss: 0.04470255814644433\n",
      "Epoch 7840/10000 --- Train Loss: 0.06819980118148941 --- Val Loss: 0.04467433794544692\n",
      "Epoch 7850/10000 --- Train Loss: 0.06817342961631741 --- Val Loss: 0.04464523081611612\n",
      "Epoch 7860/10000 --- Train Loss: 0.0681478309881179 --- Val Loss: 0.044613525162957045\n",
      "Epoch 7870/10000 --- Train Loss: 0.06812122009172032 --- Val Loss: 0.04458228056235879\n",
      "Epoch 7880/10000 --- Train Loss: 0.06809495511273518 --- Val Loss: 0.04455310700775624\n",
      "Epoch 7890/10000 --- Train Loss: 0.06806868664763396 --- Val Loss: 0.044526151338700685\n",
      "Epoch 7900/10000 --- Train Loss: 0.06804223460739045 --- Val Loss: 0.044499433267375176\n",
      "Epoch 7910/10000 --- Train Loss: 0.06801578549217947 --- Val Loss: 0.04447036222660335\n",
      "Epoch 7920/10000 --- Train Loss: 0.06798976969876308 --- Val Loss: 0.044443889476951166\n",
      "Epoch 7930/10000 --- Train Loss: 0.0679634672554067 --- Val Loss: 0.0444162536292905\n",
      "Epoch 7940/10000 --- Train Loss: 0.06793728473085459 --- Val Loss: 0.04438585571714828\n",
      "Epoch 7950/10000 --- Train Loss: 0.06791142085505453 --- Val Loss: 0.044360735692420605\n",
      "Epoch 7960/10000 --- Train Loss: 0.06788550855602285 --- Val Loss: 0.044331896699441514\n",
      "Epoch 7970/10000 --- Train Loss: 0.06785921449016954 --- Val Loss: 0.04430452080530752\n",
      "Epoch 7980/10000 --- Train Loss: 0.06783389333892524 --- Val Loss: 0.044277068705952015\n",
      "Epoch 7990/10000 --- Train Loss: 0.0678081841338243 --- Val Loss: 0.04425008011898244\n",
      "Epoch 8000/10000 --- Train Loss: 0.06778250563760566 --- Val Loss: 0.04422135574853971\n",
      "Epoch 8010/10000 --- Train Loss: 0.06775673697537739 --- Val Loss: 0.0441946276078441\n",
      "Epoch 8020/10000 --- Train Loss: 0.0677309443105551 --- Val Loss: 0.04416774629077502\n",
      "Epoch 8030/10000 --- Train Loss: 0.06770518534225911 --- Val Loss: 0.044141667799032704\n",
      "Epoch 8040/10000 --- Train Loss: 0.0676799868034707 --- Val Loss: 0.04411221412974296\n",
      "Epoch 8050/10000 --- Train Loss: 0.06765450745543723 --- Val Loss: 0.04408466188685138\n",
      "Epoch 8060/10000 --- Train Loss: 0.0676290977808846 --- Val Loss: 0.044057223720294185\n",
      "Epoch 8070/10000 --- Train Loss: 0.0676035470534507 --- Val Loss: 0.04402923337822467\n",
      "Epoch 8080/10000 --- Train Loss: 0.06757834526180533 --- Val Loss: 0.04400240675804317\n",
      "Epoch 8090/10000 --- Train Loss: 0.06755348323610116 --- Val Loss: 0.04397625308374143\n",
      "Epoch 8100/10000 --- Train Loss: 0.06752810453559527 --- Val Loss: 0.043949500025985314\n",
      "Epoch 8110/10000 --- Train Loss: 0.067503025730122 --- Val Loss: 0.04392257030563651\n",
      "Epoch 8120/10000 --- Train Loss: 0.06747785182012646 --- Val Loss: 0.043896306418056016\n",
      "Epoch 8130/10000 --- Train Loss: 0.06745282090463524 --- Val Loss: 0.04386703995597712\n",
      "Epoch 8140/10000 --- Train Loss: 0.06742774596473008 --- Val Loss: 0.04384077195019349\n",
      "Epoch 8150/10000 --- Train Loss: 0.06740333232061545 --- Val Loss: 0.04381308288634436\n",
      "Epoch 8160/10000 --- Train Loss: 0.0673785195416278 --- Val Loss: 0.043786236317099596\n",
      "Epoch 8170/10000 --- Train Loss: 0.0673535598481378 --- Val Loss: 0.04375980256838792\n",
      "Epoch 8180/10000 --- Train Loss: 0.06732884857038597 --- Val Loss: 0.04373285085071129\n",
      "Epoch 8190/10000 --- Train Loss: 0.06730405873281545 --- Val Loss: 0.04370742520380824\n",
      "Epoch 8200/10000 --- Train Loss: 0.06727884888766185 --- Val Loss: 0.043682545929441284\n",
      "Epoch 8210/10000 --- Train Loss: 0.06725409267701463 --- Val Loss: 0.04365415629664232\n",
      "Epoch 8220/10000 --- Train Loss: 0.0672299969569624 --- Val Loss: 0.04362731418275722\n",
      "Epoch 8230/10000 --- Train Loss: 0.0672053037246414 --- Val Loss: 0.043601388445198654\n",
      "Epoch 8240/10000 --- Train Loss: 0.06718088715885306 --- Val Loss: 0.04357329036525681\n",
      "Epoch 8250/10000 --- Train Loss: 0.06715630864702697 --- Val Loss: 0.04354597837232586\n",
      "Epoch 8260/10000 --- Train Loss: 0.0671320496772148 --- Val Loss: 0.043517583862467964\n",
      "Epoch 8270/10000 --- Train Loss: 0.06710776578246684 --- Val Loss: 0.043491822582809904\n",
      "Epoch 8280/10000 --- Train Loss: 0.06708358905240634 --- Val Loss: 0.04346515190710101\n",
      "Epoch 8290/10000 --- Train Loss: 0.06705917030066409 --- Val Loss: 0.043440735030069164\n",
      "Epoch 8300/10000 --- Train Loss: 0.06703482031626526 --- Val Loss: 0.04341333745459893\n",
      "Epoch 8310/10000 --- Train Loss: 0.06701059359372914 --- Val Loss: 0.04338643818413752\n",
      "Epoch 8320/10000 --- Train Loss: 0.0669862677436188 --- Val Loss: 0.04336123562429544\n",
      "Epoch 8330/10000 --- Train Loss: 0.0669625481510689 --- Val Loss: 0.04333555286134101\n",
      "Epoch 8340/10000 --- Train Loss: 0.06693818293630469 --- Val Loss: 0.04330800176604432\n",
      "Epoch 8350/10000 --- Train Loss: 0.06691454263443836 --- Val Loss: 0.043280574906391416\n",
      "Epoch 8360/10000 --- Train Loss: 0.066890716480812 --- Val Loss: 0.04325545754745914\n",
      "Epoch 8370/10000 --- Train Loss: 0.06686678982027523 --- Val Loss: 0.04323052425278237\n",
      "Epoch 8380/10000 --- Train Loss: 0.0668430921849015 --- Val Loss: 0.04320604386566624\n",
      "Epoch 8390/10000 --- Train Loss: 0.06681941414353576 --- Val Loss: 0.04318121672008066\n",
      "Epoch 8400/10000 --- Train Loss: 0.06679525317439426 --- Val Loss: 0.04315645308419111\n",
      "Epoch 8410/10000 --- Train Loss: 0.06677133528637452 --- Val Loss: 0.04313118894061159\n",
      "Epoch 8420/10000 --- Train Loss: 0.06674745733634282 --- Val Loss: 0.04310603653015219\n",
      "Epoch 8430/10000 --- Train Loss: 0.0667242678404245 --- Val Loss: 0.0430788864716741\n",
      "Epoch 8440/10000 --- Train Loss: 0.06670044742891483 --- Val Loss: 0.04305236434188829\n",
      "Epoch 8450/10000 --- Train Loss: 0.06667665032285311 --- Val Loss: 0.043027135307229174\n",
      "Epoch 8460/10000 --- Train Loss: 0.06665329373815705 --- Val Loss: 0.04300089512312752\n",
      "Epoch 8470/10000 --- Train Loss: 0.06662976663467145 --- Val Loss: 0.042974485305844363\n",
      "Epoch 8480/10000 --- Train Loss: 0.06660605122866003 --- Val Loss: 0.04295068951017646\n",
      "Epoch 8490/10000 --- Train Loss: 0.0665824579841209 --- Val Loss: 0.042925368236996275\n",
      "Epoch 8500/10000 --- Train Loss: 0.06655917927477732 --- Val Loss: 0.04289925663010791\n",
      "Epoch 8510/10000 --- Train Loss: 0.06653545463321935 --- Val Loss: 0.04287411265996419\n",
      "Epoch 8520/10000 --- Train Loss: 0.06651271146869445 --- Val Loss: 0.042848192768953144\n",
      "Epoch 8530/10000 --- Train Loss: 0.0664894731161928 --- Val Loss: 0.0428236921226252\n",
      "Epoch 8540/10000 --- Train Loss: 0.06646664769815222 --- Val Loss: 0.04279851721591808\n",
      "Epoch 8550/10000 --- Train Loss: 0.06644366987284851 --- Val Loss: 0.04277528954235514\n",
      "Epoch 8560/10000 --- Train Loss: 0.06642050737582557 --- Val Loss: 0.04275014722068713\n",
      "Epoch 8570/10000 --- Train Loss: 0.06639761174122327 --- Val Loss: 0.04272287397565189\n",
      "Epoch 8580/10000 --- Train Loss: 0.0663750104134328 --- Val Loss: 0.04269927295728018\n",
      "Epoch 8590/10000 --- Train Loss: 0.0663516488454621 --- Val Loss: 0.04267420627442121\n",
      "Epoch 8600/10000 --- Train Loss: 0.0663284204245973 --- Val Loss: 0.04264908731634556\n",
      "Epoch 8610/10000 --- Train Loss: 0.06630558942228551 --- Val Loss: 0.04262696667847852\n",
      "Epoch 8620/10000 --- Train Loss: 0.06628269231192442 --- Val Loss: 0.04260067531929769\n",
      "Epoch 8630/10000 --- Train Loss: 0.06626025163060494 --- Val Loss: 0.042575691756163304\n",
      "Epoch 8640/10000 --- Train Loss: 0.06623723468582095 --- Val Loss: 0.042551109083903374\n",
      "Epoch 8650/10000 --- Train Loss: 0.066214698577881 --- Val Loss: 0.042526053896117466\n",
      "Epoch 8660/10000 --- Train Loss: 0.0661921023269031 --- Val Loss: 0.04250182346215624\n",
      "Epoch 8670/10000 --- Train Loss: 0.06616912201801844 --- Val Loss: 0.042477331846424486\n",
      "Epoch 8680/10000 --- Train Loss: 0.06614672781663555 --- Val Loss: 0.04245399120439841\n",
      "Epoch 8690/10000 --- Train Loss: 0.0661241255407685 --- Val Loss: 0.042429246769047725\n",
      "Epoch 8700/10000 --- Train Loss: 0.06610128890856949 --- Val Loss: 0.04240474342298091\n",
      "Epoch 8710/10000 --- Train Loss: 0.0660785536958699 --- Val Loss: 0.04238114853768743\n",
      "Epoch 8720/10000 --- Train Loss: 0.06605638974680512 --- Val Loss: 0.042358305703840304\n",
      "Epoch 8730/10000 --- Train Loss: 0.06603378574546254 --- Val Loss: 0.042332982943549806\n",
      "Epoch 8740/10000 --- Train Loss: 0.06601137142557109 --- Val Loss: 0.042308896554609586\n",
      "Epoch 8750/10000 --- Train Loss: 0.06598927491292995 --- Val Loss: 0.04228317438961792\n",
      "Epoch 8760/10000 --- Train Loss: 0.06596708531048126 --- Val Loss: 0.04226034929755435\n",
      "Epoch 8770/10000 --- Train Loss: 0.06594453112366437 --- Val Loss: 0.042235710964749214\n",
      "Epoch 8780/10000 --- Train Loss: 0.06592245324215508 --- Val Loss: 0.04221252188047547\n",
      "Epoch 8790/10000 --- Train Loss: 0.06590019139563373 --- Val Loss: 0.04219007295794385\n",
      "Epoch 8800/10000 --- Train Loss: 0.06587796490221406 --- Val Loss: 0.042167340880625806\n",
      "Epoch 8810/10000 --- Train Loss: 0.06585642999960684 --- Val Loss: 0.04214458047539225\n",
      "Epoch 8820/10000 --- Train Loss: 0.06583397012189524 --- Val Loss: 0.04212173087369583\n",
      "Epoch 8830/10000 --- Train Loss: 0.06581252686696551 --- Val Loss: 0.04210014696209078\n",
      "Epoch 8840/10000 --- Train Loss: 0.06579107228874209 --- Val Loss: 0.04207339092634424\n",
      "Epoch 8850/10000 --- Train Loss: 0.06576923864341601 --- Val Loss: 0.042049711709556264\n",
      "Epoch 8860/10000 --- Train Loss: 0.06574719191903239 --- Val Loss: 0.04202678504634383\n",
      "Epoch 8870/10000 --- Train Loss: 0.06572520756559586 --- Val Loss: 0.04200374949734795\n",
      "Epoch 8880/10000 --- Train Loss: 0.06570374662793073 --- Val Loss: 0.04197995163943653\n",
      "Epoch 8890/10000 --- Train Loss: 0.06568213546284665 --- Val Loss: 0.04195787193403597\n",
      "Epoch 8900/10000 --- Train Loss: 0.06566038720486596 --- Val Loss: 0.04193405468542402\n",
      "Epoch 8910/10000 --- Train Loss: 0.06563919925730263 --- Val Loss: 0.041909651402387685\n",
      "Epoch 8920/10000 --- Train Loss: 0.06561809433985058 --- Val Loss: 0.04188368747858636\n",
      "Epoch 8930/10000 --- Train Loss: 0.0655967973845822 --- Val Loss: 0.04185880848716671\n",
      "Epoch 8940/10000 --- Train Loss: 0.06557530807966913 --- Val Loss: 0.04183634784058135\n",
      "Epoch 8950/10000 --- Train Loss: 0.0655533104623029 --- Val Loss: 0.0418133395957633\n",
      "Epoch 8960/10000 --- Train Loss: 0.06553164224006115 --- Val Loss: 0.04178979532521506\n",
      "Epoch 8970/10000 --- Train Loss: 0.06551029146297302 --- Val Loss: 0.04176521666310147\n",
      "Epoch 8980/10000 --- Train Loss: 0.06548889197600695 --- Val Loss: 0.04174071183112543\n",
      "Epoch 8990/10000 --- Train Loss: 0.06546760333228933 --- Val Loss: 0.04171817218172007\n",
      "Epoch 9000/10000 --- Train Loss: 0.06544597631375235 --- Val Loss: 0.04169301717345284\n",
      "Epoch 9010/10000 --- Train Loss: 0.06542460588813552 --- Val Loss: 0.04166923388121051\n",
      "Epoch 9020/10000 --- Train Loss: 0.06540383892416791 --- Val Loss: 0.04164809723107047\n",
      "Epoch 9030/10000 --- Train Loss: 0.06538249078479301 --- Val Loss: 0.0416249832909171\n",
      "Epoch 9040/10000 --- Train Loss: 0.06536144989521765 --- Val Loss: 0.04160285940709132\n",
      "Epoch 9050/10000 --- Train Loss: 0.06534042394148078 --- Val Loss: 0.0415812750332109\n",
      "Epoch 9060/10000 --- Train Loss: 0.06531913083836062 --- Val Loss: 0.04155877161826359\n",
      "Epoch 9070/10000 --- Train Loss: 0.06529785277471228 --- Val Loss: 0.04153499861923489\n",
      "Epoch 9080/10000 --- Train Loss: 0.06527750464035806 --- Val Loss: 0.0415111393847523\n",
      "Epoch 9090/10000 --- Train Loss: 0.06525681612420003 --- Val Loss: 0.04148485796042865\n",
      "Epoch 9100/10000 --- Train Loss: 0.06523599055740649 --- Val Loss: 0.04146180874943319\n",
      "Epoch 9110/10000 --- Train Loss: 0.06521482481744423 --- Val Loss: 0.04143960466011306\n",
      "Epoch 9120/10000 --- Train Loss: 0.06519411365723062 --- Val Loss: 0.04141644053317113\n",
      "Epoch 9130/10000 --- Train Loss: 0.06517344990310743 --- Val Loss: 0.04139301857270511\n",
      "Epoch 9140/10000 --- Train Loss: 0.06515253117904676 --- Val Loss: 0.041371071393921405\n",
      "Epoch 9150/10000 --- Train Loss: 0.0651316803827446 --- Val Loss: 0.04134691315335322\n",
      "Epoch 9160/10000 --- Train Loss: 0.06511135245465222 --- Val Loss: 0.0413255594547109\n",
      "Epoch 9170/10000 --- Train Loss: 0.06509037660889128 --- Val Loss: 0.04130467994016756\n",
      "Epoch 9180/10000 --- Train Loss: 0.06506994018779776 --- Val Loss: 0.04128304690341865\n",
      "Epoch 9190/10000 --- Train Loss: 0.06504935775365395 --- Val Loss: 0.041260734674136636\n",
      "Epoch 9200/10000 --- Train Loss: 0.0650287190461869 --- Val Loss: 0.04123599256474115\n",
      "Epoch 9210/10000 --- Train Loss: 0.06500831669898906 --- Val Loss: 0.04121359044667093\n",
      "Epoch 9220/10000 --- Train Loss: 0.06498770937028266 --- Val Loss: 0.041191002616442624\n",
      "Epoch 9230/10000 --- Train Loss: 0.0649672189764284 --- Val Loss: 0.041168806563812166\n",
      "Epoch 9240/10000 --- Train Loss: 0.06494749093826575 --- Val Loss: 0.04114802196748664\n",
      "Epoch 9250/10000 --- Train Loss: 0.06492667207879206 --- Val Loss: 0.04112548324189482\n",
      "Epoch 9260/10000 --- Train Loss: 0.06490621069366906 --- Val Loss: 0.041102226067057206\n",
      "Epoch 9270/10000 --- Train Loss: 0.06488592571487505 --- Val Loss: 0.04107974864625372\n",
      "Epoch 9280/10000 --- Train Loss: 0.06486614964749285 --- Val Loss: 0.04105511637641417\n",
      "Epoch 9290/10000 --- Train Loss: 0.0648459069573408 --- Val Loss: 0.04103399805291267\n",
      "Epoch 9300/10000 --- Train Loss: 0.06482532330623238 --- Val Loss: 0.04101302954605741\n",
      "Epoch 9310/10000 --- Train Loss: 0.06480533985505062 --- Val Loss: 0.04099040257437674\n",
      "Epoch 9320/10000 --- Train Loss: 0.06478523389348909 --- Val Loss: 0.04096571126974447\n",
      "Epoch 9330/10000 --- Train Loss: 0.0647651710258394 --- Val Loss: 0.04094341931437066\n",
      "Epoch 9340/10000 --- Train Loss: 0.06474543980168362 --- Val Loss: 0.04091957340887692\n",
      "Epoch 9350/10000 --- Train Loss: 0.0647254270702497 --- Val Loss: 0.04089747954374025\n",
      "Epoch 9360/10000 --- Train Loss: 0.06470570141383573 --- Val Loss: 0.04087360085503172\n",
      "Epoch 9370/10000 --- Train Loss: 0.06468569430558244 --- Val Loss: 0.0408526467049382\n",
      "Epoch 9380/10000 --- Train Loss: 0.06466563129602255 --- Val Loss: 0.04082854403167414\n",
      "Epoch 9390/10000 --- Train Loss: 0.06464564607881362 --- Val Loss: 0.04080687230276272\n",
      "Epoch 9400/10000 --- Train Loss: 0.06462593246691097 --- Val Loss: 0.04078484872275901\n",
      "Epoch 9410/10000 --- Train Loss: 0.06460586675079646 --- Val Loss: 0.04076238252806342\n",
      "Epoch 9420/10000 --- Train Loss: 0.06458621618473356 --- Val Loss: 0.04074081492549695\n",
      "Epoch 9430/10000 --- Train Loss: 0.06456674587020225 --- Val Loss: 0.04071776125518604\n",
      "Epoch 9440/10000 --- Train Loss: 0.06454671868227185 --- Val Loss: 0.040695226470633394\n",
      "Epoch 9450/10000 --- Train Loss: 0.06452737380398975 --- Val Loss: 0.04067329727675951\n",
      "Epoch 9460/10000 --- Train Loss: 0.06450798661344251 --- Val Loss: 0.040651870022048966\n",
      "Epoch 9470/10000 --- Train Loss: 0.06448829735139015 --- Val Loss: 0.04063040025027417\n",
      "Epoch 9480/10000 --- Train Loss: 0.06446815052044197 --- Val Loss: 0.04060732587803207\n",
      "Epoch 9490/10000 --- Train Loss: 0.06444885854364098 --- Val Loss: 0.040585176293227096\n",
      "Epoch 9500/10000 --- Train Loss: 0.06442931741638046 --- Val Loss: 0.040563796293586696\n",
      "Epoch 9510/10000 --- Train Loss: 0.0644097938497015 --- Val Loss: 0.04054158321314526\n",
      "Epoch 9520/10000 --- Train Loss: 0.06439008680654096 --- Val Loss: 0.04051934181274593\n",
      "Epoch 9530/10000 --- Train Loss: 0.0643709440362383 --- Val Loss: 0.04049769318079142\n",
      "Epoch 9540/10000 --- Train Loss: 0.06435181947387995 --- Val Loss: 0.040476063403515505\n",
      "Epoch 9550/10000 --- Train Loss: 0.06433189794023164 --- Val Loss: 0.040454428441661756\n",
      "Epoch 9560/10000 --- Train Loss: 0.06431248044158568 --- Val Loss: 0.040433258008824774\n",
      "Epoch 9570/10000 --- Train Loss: 0.06429312228438622 --- Val Loss: 0.040411857345938614\n",
      "Epoch 9580/10000 --- Train Loss: 0.06427382791829624 --- Val Loss: 0.04038764901056606\n",
      "Epoch 9590/10000 --- Train Loss: 0.06425455807980847 --- Val Loss: 0.040367305782469276\n",
      "Epoch 9600/10000 --- Train Loss: 0.06423584333979392 --- Val Loss: 0.040344287008936455\n",
      "Epoch 9610/10000 --- Train Loss: 0.06421673713551769 --- Val Loss: 0.0403223384367899\n",
      "Epoch 9620/10000 --- Train Loss: 0.0641972814229884 --- Val Loss: 0.04030266195778987\n",
      "Epoch 9630/10000 --- Train Loss: 0.06417832876038569 --- Val Loss: 0.04027983262617571\n",
      "Epoch 9640/10000 --- Train Loss: 0.06415941120612915 --- Val Loss: 0.040257685368232814\n",
      "Epoch 9650/10000 --- Train Loss: 0.064140268536939 --- Val Loss: 0.040234689846608725\n",
      "Epoch 9660/10000 --- Train Loss: 0.0641213231074173 --- Val Loss: 0.040212346997202345\n",
      "Epoch 9670/10000 --- Train Loss: 0.06410227941889435 --- Val Loss: 0.040192279640396865\n",
      "Epoch 9680/10000 --- Train Loss: 0.06408326363821344 --- Val Loss: 0.040171251330341155\n",
      "Epoch 9690/10000 --- Train Loss: 0.06406478855792208 --- Val Loss: 0.040148383895857225\n",
      "Epoch 9700/10000 --- Train Loss: 0.06404578061726211 --- Val Loss: 0.04012826163281871\n",
      "Epoch 9710/10000 --- Train Loss: 0.06402711951517619 --- Val Loss: 0.04010548709931032\n",
      "Epoch 9720/10000 --- Train Loss: 0.06400811753154914 --- Val Loss: 0.04008351608971506\n",
      "Epoch 9730/10000 --- Train Loss: 0.0639894066319381 --- Val Loss: 0.04006181553041622\n",
      "Epoch 9740/10000 --- Train Loss: 0.06397082321138385 --- Val Loss: 0.04004195554417323\n",
      "Epoch 9750/10000 --- Train Loss: 0.06395233590938916 --- Val Loss: 0.0400214151320142\n",
      "Epoch 9760/10000 --- Train Loss: 0.06393395551150106 --- Val Loss: 0.03999920925295837\n",
      "Epoch 9770/10000 --- Train Loss: 0.06391554664166132 --- Val Loss: 0.03997845929932575\n",
      "Epoch 9780/10000 --- Train Loss: 0.06389690778180032 --- Val Loss: 0.039958364825884864\n",
      "Epoch 9790/10000 --- Train Loss: 0.06387845359856474 --- Val Loss: 0.039937632214715864\n",
      "Epoch 9800/10000 --- Train Loss: 0.06385950558813866 --- Val Loss: 0.03991680568658693\n",
      "Epoch 9810/10000 --- Train Loss: 0.0638410732252709 --- Val Loss: 0.03989521995097156\n",
      "Epoch 9820/10000 --- Train Loss: 0.06382336782554733 --- Val Loss: 0.03987325839712596\n",
      "Epoch 9830/10000 --- Train Loss: 0.06380469847038284 --- Val Loss: 0.0398512882067031\n",
      "Epoch 9840/10000 --- Train Loss: 0.06378605299462785 --- Val Loss: 0.039828535443455944\n",
      "Epoch 9850/10000 --- Train Loss: 0.06376802529641264 --- Val Loss: 0.039805972411445255\n",
      "Epoch 9860/10000 --- Train Loss: 0.06374959461457035 --- Val Loss: 0.03978445183529367\n",
      "Epoch 9870/10000 --- Train Loss: 0.06373122138856584 --- Val Loss: 0.03976335221109724\n",
      "Epoch 9880/10000 --- Train Loss: 0.06371277976717356 --- Val Loss: 0.039741319206128396\n",
      "Epoch 9890/10000 --- Train Loss: 0.06369458912927217 --- Val Loss: 0.03971969357783904\n",
      "Epoch 9900/10000 --- Train Loss: 0.06367624958273757 --- Val Loss: 0.039697979912232374\n",
      "Epoch 9910/10000 --- Train Loss: 0.06365790896653281 --- Val Loss: 0.03967572453568539\n",
      "Epoch 9920/10000 --- Train Loss: 0.06363972110358936 --- Val Loss: 0.03965569561779988\n",
      "Epoch 9930/10000 --- Train Loss: 0.06362179426160502 --- Val Loss: 0.03963419289488235\n",
      "Epoch 9940/10000 --- Train Loss: 0.06360371018101756 --- Val Loss: 0.03961170645571514\n",
      "Epoch 9950/10000 --- Train Loss: 0.06358542015104067 --- Val Loss: 0.03959102949721462\n",
      "Epoch 9960/10000 --- Train Loss: 0.06356724593864875 --- Val Loss: 0.03956982739845816\n",
      "Epoch 9970/10000 --- Train Loss: 0.06354902907930116 --- Val Loss: 0.039549062567947386\n",
      "Epoch 9980/10000 --- Train Loss: 0.06353126156947793 --- Val Loss: 0.039528501890666395\n",
      "Epoch 9990/10000 --- Train Loss: 0.06351322650631316 --- Val Loss: 0.03950588656202829\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(X_train.shape[1], 128))\n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Layer(128, 2))\n",
    "network.add_layer(Sigmoid())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=10000, learning_rate=0.001, batch_size=16)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "* L1 and L2 regularizers\n",
    "\n",
    "* Gradient with momentum\n",
    "\n",
    "* optimization of hyperparameters (random search and grid search function?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
