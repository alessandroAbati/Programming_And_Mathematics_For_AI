{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "236dfa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ReLU layer class\n",
    "class ReLU:\n",
    "    '''\n",
    "    A class representing the Rectified Linear Unit (reLu) activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.input = None # placeholder for storing the input to the layer\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data # store the input to use it in the backward pass\n",
    "        return np.maximum(0, input_data) # apply the relu function: if x is negative, max(0, x) will be 0; otherwise, will be x\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Compute the backward pass through the reLu activation function.\n",
    "\n",
    "        The method calculates the gradient of the reLu function with respect \n",
    "        to its input 'x', given the gradient of the loss function with respect \n",
    "        to the output of the relu layer ('gradient_values').\n",
    "\n",
    "        Parameters:\n",
    "        - gradient_values (numpy.ndarray): The gradient of the loss function with respect \n",
    "                                           to the output of the relu layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the \n",
    "                         input of the relu layer.\n",
    "        '''\n",
    "        # apply the derivative of the relu function: if the input is negative, the derivative is 0; otherwise, the derivative is 1\n",
    "        return output_gradient * (self.input > 0)\n",
    "        #return output_gradient * np.where(self.input > 0, 1.0, 0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1d0cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid layer class\n",
    "class Sigmoid:\n",
    "    '''\n",
    "    A class representing the Sigmoid activation function.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.output = None # placeholder for storing the output of the forward pass\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.output = 1 / (1 + np.exp(-input_data)) # apply the sigmoid function: f(x) = 1 / (1 + exp(-x))\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, output_gradient):\n",
    "        '''\n",
    "        Computes the backward pass of the Sigmoid activation function.\n",
    "\n",
    "        Given the gradient of the loss function with respect to the output of the\n",
    "        Sigmoid layer ('output_gradient'), this method calculates the gradient with respect\n",
    "        to the Sigmoid input.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient (numpy.ndarray): The gradient of the loss function with respect\n",
    "                                           to the output of the Sigmoid layer.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The gradient of the loss function with respect to the\n",
    "                         input of the Sigmoid layer.\n",
    "        '''\n",
    "        return output_gradient * (self.output * (1 - self.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94c275e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax layer class\n",
    "class Softmax:\n",
    "    '''\n",
    "    A class representing the Softmax activation function.\n",
    "    '''\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Computes the forward pass of the Softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - input_data (numpy.ndarray): A numpy array containing the input data to which the Softmax\n",
    "                             function should be applied.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The result of applying the Softmax function to 'input_data', with the\n",
    "                         same shape as 'input_data'.\n",
    "        ''' \n",
    "        exp_values = np.exp(input_data - np.max(input_data, axis=1, keepdims=True)) # Shift the input data to avoid numerical instability in exponential calculations\n",
    "        output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return output\n",
    "\n",
    "    def backward_pass(self, dvalues):\n",
    "        # The gradient of loss with respect to the input logits \n",
    "        # directly passed through in case of softmax + categorical cross-entropy\n",
    "        return dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bb61882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:    \n",
    "    def __init__(self, probability):\n",
    "        self.probability = probability\n",
    "        \n",
    "    def forward_pass(self, input_data):\n",
    "        self.mask = np.random.binomial(1, 1-self.probability, size=input_data.shape) / (1-self.probability)\n",
    "        return input_data * self.mask\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        return output_gradient * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3a283b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer class\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = 0.01 * np.random.normal(0, 1/np.sqrt(input_size), (input_size, output_size)) # Normal distribution initialisation\n",
    "        self.biases = np.full((1, output_size), 0.001) # Initialise biases with a small positive value\n",
    "        self.input = None\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data\n",
    "        return np.dot(input_data, self.weights) + self.biases\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate):\n",
    "        '''\n",
    "        Computes the backward pass of the Dense layer.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient: The gradient of the loss function with respect to the output of the layer.\n",
    "\n",
    "        - learning_rate: A hyperparameter that controls how much the weights and biases are updated during training.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: the gradient of the loss with respect to the layer's inputs (which will be passed back to the previous layer in the network).\n",
    "        ''' \n",
    "        weights_gradient = np.dot(self.input.T, output_gradient)\n",
    "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
    "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights += learning_rate * weights_gradient\n",
    "        self.biases += learning_rate * biases_gradient\n",
    "\n",
    "        return input_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cc0ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network wrapper class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = [] # placeholder for storing the layers of the network so we can propagate the infomation in a sequential order\n",
    "        self.loss_history = [] # placeholder to store the (train) loss for plotting\n",
    "        self.val_loss_history = [] #placeholder to store the loss function calculated on the validation set for plotting\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        '''\n",
    "        Add the layer to the network\n",
    "        '''\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network. \n",
    "        It sequentially passes the input data through each layer, transforming it according to each layer's operation.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def prediction(self, input_data):\n",
    "        '''\n",
    "        Performs a forward pass through the network ignoring the dropout.\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            if not isinstance(layer, Dropout):\n",
    "                input_data = layer.forward_pass(input_data)\n",
    "        return input_data\n",
    "\n",
    "    def backward_pass(self, output_gradient, learning_rate):\n",
    "        '''\n",
    "        Performs the backward pass (backpropagation) for training. \n",
    "        It propagates the gradient of the loss function backward through the network, updating weights in the process if the layer is a dense one.\n",
    "\n",
    "        Parameters:\n",
    "        - output_gradient: The gradient of the loss function with respect to the network's output.\n",
    "\n",
    "        - learning_rate: The step size for weight updates.\n",
    "        '''\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Layer):\n",
    "                output_gradient = layer.backward_pass(output_gradient, learning_rate)\n",
    "            else:\n",
    "                output_gradient = layer.backward_pass(output_gradient)\n",
    "    \n",
    "    def compute_categorical_cross_entropy_loss(self, y_pred, y_true):\n",
    "        '''\n",
    "        Computes the categorical cross entropy loss\n",
    "        '''\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7) # Clip predictions to prevent log(0)\n",
    "\n",
    "        # Calculate the negative log of the probabilities of the correct class\n",
    "        # Multiply with the one-hot encoded true labels and sum across classes\n",
    "        loss = np.sum(y_true * -np.log(y_pred_clipped), axis=1)\n",
    "\n",
    "        # Average loss over all samples\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def compute_categorical_cross_entropy_gradient(self, y_pred, y_true):\n",
    "        '''\n",
    "        Calculates the gradient of the categorical cross entropy loss with respect to the network's output, assuming that the output layer is the softmax activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - y_pred: Output of the softmax activation function.\n",
    "\n",
    "        - y_true: One-hot encoded label array.\n",
    "        '''\n",
    "        # Assuming y_true is one-hot encoded and y_pred is the output of softmax\n",
    "        y_pred_gradient = (y_pred - y_true) / len(y_pred)\n",
    "        return y_pred_gradient\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, learning_rate=0.001, batch_size=32, validation_split = 0.2, verbose = 1):\n",
    "        '''\n",
    "        Conducts the training process over a specified number of epochs.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: The input features of the training data.\n",
    "\n",
    "        - y_train: The target output (labels) of the training data.\n",
    "\n",
    "        - epochs: The number of times the entire training dataset is passed forward and backward through the neural network.\n",
    "\n",
    "        - learning_rate: The step size at each iteration while moving toward a minimum of the loss function.\n",
    "\n",
    "        - batch_size: The number of training examples used in one iteration.\n",
    "\n",
    "        - validation_split: Fraction of the training data to be used as validation data.\n",
    "\n",
    "        - verbose: The mode of verbosity (0 = silent, 1 = update every 10 epochs, 2 = update every epoch).\n",
    "\n",
    "        '''\n",
    "        val_sample_size = int(len(X_train) * validation_split) # calculate validation sample size based on validation split parameter\n",
    "\n",
    "        # Shuffles the indices of the training data to ensure random distribution\n",
    "        indices = np.arange(len(X_train))\n",
    "        np.random.shuffle(indices) \n",
    "        X_train, y_train = X_train[indices], y_train[indices]\n",
    "\n",
    "        X_train, y_train = X_train[val_sample_size:], y_train[val_sample_size:] # splits the data into new training set.\n",
    "        X_val, y_val = X_train[:val_sample_size], y_train[:val_sample_size] # splits the data into new validation set.\n",
    "\n",
    "        n_samples = len(X_train)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X_train = X_train[indices]\n",
    "            y_train = y_train[indices]\n",
    "\n",
    "            for start_idx in range(0, n_samples, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, n_samples)\n",
    "                batch_x = X_train[start_idx:end_idx]\n",
    "                batch_y = y_train[start_idx:end_idx]\n",
    "\n",
    "                output = self.forward_pass(batch_x)\n",
    "                loss_gradient = self.compute_categorical_cross_entropy_gradient(batch_y, output)\n",
    "                self.backward_pass(loss_gradient, learning_rate)\n",
    "\n",
    "            # Calculate training loss for the epoch\n",
    "            output = self.forward_pass(X_train)\n",
    "            train_loss = self.compute_categorical_cross_entropy_loss(output, y_train)\n",
    "            self.loss_history.append(train_loss)\n",
    "\n",
    "            # Calculate validation loss for the epoch\n",
    "            val_output = self.prediction(X_val)  # Ensure dropout is not applied\n",
    "            val_loss = self.compute_categorical_cross_entropy_loss(val_output, y_val)\n",
    "            self.val_loss_history.append(val_loss)\n",
    "\n",
    "            if verbose == 1:\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f\"Epoch {epoch}/{epochs} --- Train Loss: {train_loss} --- Val Loss: {val_loss}\")\n",
    "            elif verbose == 2:\n",
    "                print(f\"Epoch {epoch}/{epochs} --- Train Loss: {train_loss} --- Val Loss: {val_loss}\")\n",
    "            epoch += 1\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        output = self.prediction(X_test)\n",
    "\n",
    "        # Convert probabilities to class predictions\n",
    "        predictions = np.argmax(output, axis=1)\n",
    "        return predictions\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss history stored in self.loss_history over the epochs.\n",
    "        '''\n",
    "        plt.plot(self.loss_history, label = 'Train Loss')\n",
    "        plt.plot(self.val_loss_history, label = 'Val Loss')\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed3504a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(X):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = X.mean(axis=0)\n",
    "    stds = X.std(axis=0)\n",
    "\n",
    "    # Avoid division by zero in case of a constant feature\n",
    "    stds[stds == 0] = 1\n",
    "\n",
    "    # Standardize each feature\n",
    "    X_standardized = (X - means) / stds\n",
    "    return X_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32d43306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500 --- Train Loss: 2.300407577580148 --- Val Loss: 2.3032361245113053\n",
      "Epoch 10/500 --- Train Loss: 0.1962680953113329 --- Val Loss: 0.2202409364054814\n",
      "Epoch 20/500 --- Train Loss: 0.0813632571924383 --- Val Loss: 0.12959245160445637\n",
      "Epoch 30/500 --- Train Loss: 0.0526536313311888 --- Val Loss: 0.11299674512530844\n",
      "Epoch 40/500 --- Train Loss: 0.036685537912854733 --- Val Loss: 0.10788228977053134\n",
      "Epoch 50/500 --- Train Loss: 0.02917025425843816 --- Val Loss: 0.11309197811775436\n",
      "Epoch 60/500 --- Train Loss: 0.02135709042068259 --- Val Loss: 0.10342164678724228\n",
      "Epoch 70/500 --- Train Loss: 0.019834238198986883 --- Val Loss: 0.11094737665640136\n",
      "Epoch 80/500 --- Train Loss: 0.014307883763051634 --- Val Loss: 0.10775041657940315\n",
      "Epoch 90/500 --- Train Loss: 0.015265437527287517 --- Val Loss: 0.10710762564351117\n",
      "Epoch 100/500 --- Train Loss: 0.01688800403710603 --- Val Loss: 0.11192589856875179\n",
      "Epoch 110/500 --- Train Loss: 0.013126961032462782 --- Val Loss: 0.10872625861860248\n",
      "Epoch 120/500 --- Train Loss: 0.012667587222537673 --- Val Loss: 0.10947069993235115\n",
      "Epoch 130/500 --- Train Loss: 0.008991032575512505 --- Val Loss: 0.1039097395937921\n",
      "Epoch 140/500 --- Train Loss: 0.008270559813874543 --- Val Loss: 0.1068025934350817\n",
      "Epoch 150/500 --- Train Loss: 0.00948253876428584 --- Val Loss: 0.10462032206839739\n",
      "Epoch 160/500 --- Train Loss: 0.006036036734004069 --- Val Loss: 0.10707633679778478\n",
      "Epoch 170/500 --- Train Loss: 0.006456110120346492 --- Val Loss: 0.10651482249725325\n",
      "Epoch 180/500 --- Train Loss: 0.006582990606094945 --- Val Loss: 0.1098713589511338\n",
      "Epoch 190/500 --- Train Loss: 0.005313252767771348 --- Val Loss: 0.11259648530965516\n",
      "Epoch 200/500 --- Train Loss: 0.006274322730045236 --- Val Loss: 0.11301114574245377\n",
      "Epoch 210/500 --- Train Loss: 0.00425676097294009 --- Val Loss: 0.11618050417236005\n",
      "Epoch 220/500 --- Train Loss: 0.006143852421987461 --- Val Loss: 0.11346282923976567\n",
      "Epoch 230/500 --- Train Loss: 0.0049626002621098895 --- Val Loss: 0.11593784335236687\n",
      "Epoch 240/500 --- Train Loss: 0.004672179790942773 --- Val Loss: 0.11540625026162092\n",
      "Epoch 250/500 --- Train Loss: 0.0030688993927077213 --- Val Loss: 0.11195365280406999\n",
      "Epoch 260/500 --- Train Loss: 0.004116348682556729 --- Val Loss: 0.11228400537825763\n",
      "Epoch 270/500 --- Train Loss: 0.0032012590513318044 --- Val Loss: 0.11347121458377844\n",
      "Epoch 280/500 --- Train Loss: 0.0037077592729508548 --- Val Loss: 0.11421411096214709\n",
      "Epoch 290/500 --- Train Loss: 0.0026740959979815746 --- Val Loss: 0.11226869506191955\n",
      "Epoch 300/500 --- Train Loss: 0.0035063760023519926 --- Val Loss: 0.11725713501495827\n",
      "Epoch 310/500 --- Train Loss: 0.0036382969647812125 --- Val Loss: 0.11308920213231191\n",
      "Epoch 320/500 --- Train Loss: 0.002733432550490194 --- Val Loss: 0.11257216643995517\n",
      "Epoch 330/500 --- Train Loss: 0.006204504737531697 --- Val Loss: 0.10977274830180166\n",
      "Epoch 340/500 --- Train Loss: 0.00376127840642498 --- Val Loss: 0.11284285693871456\n",
      "Epoch 350/500 --- Train Loss: 0.0036509497459951226 --- Val Loss: 0.11588659511717016\n",
      "Epoch 360/500 --- Train Loss: 0.0040147806899086605 --- Val Loss: 0.11293152834388319\n",
      "Epoch 370/500 --- Train Loss: 0.002333001035402023 --- Val Loss: 0.11294401627469537\n",
      "Epoch 380/500 --- Train Loss: 0.002621051858672684 --- Val Loss: 0.11277710446415587\n",
      "Epoch 390/500 --- Train Loss: 0.0020154480894397685 --- Val Loss: 0.1101213268104106\n",
      "Epoch 400/500 --- Train Loss: 0.002913954015063338 --- Val Loss: 0.11199217697366329\n",
      "Epoch 410/500 --- Train Loss: 0.0018180349698680355 --- Val Loss: 0.11050709119762697\n",
      "Epoch 420/500 --- Train Loss: 0.0022911846803670612 --- Val Loss: 0.1107229463390922\n",
      "Epoch 430/500 --- Train Loss: 0.001757853961853789 --- Val Loss: 0.1143801272445441\n",
      "Epoch 440/500 --- Train Loss: 0.0026077942142902887 --- Val Loss: 0.11448386231669012\n",
      "Epoch 450/500 --- Train Loss: 0.0022192153198339814 --- Val Loss: 0.11213950093434676\n",
      "Epoch 460/500 --- Train Loss: 0.003000296762339629 --- Val Loss: 0.11006223897444432\n",
      "Epoch 470/500 --- Train Loss: 0.0035229818709810764 --- Val Loss: 0.11078515936722068\n",
      "Epoch 480/500 --- Train Loss: 0.002439725485056228 --- Val Loss: 0.11318183313445565\n",
      "Epoch 490/500 --- Train Loss: 0.001632278008360402 --- Val Loss: 0.11330431781722441\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(64, 128))  # 64 inputs (8x8 images)\n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Dropout(0.25))\n",
    "network.add_layer(Layer(128, 10))  # 10 classes\n",
    "network.add_layer(Softmax())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=500, learning_rate=0.01, batch_size=4)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1) # transoform back the One-Hot encoded array of the labels\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72fcf0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aless\\miniconda3\\envs\\IntroductionToAI\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/3000 --- Train Loss: 0.691556647615097 --- Val Loss: 0.6919057536104998\n",
      "Epoch 10/3000 --- Train Loss: 0.6822460798435473 --- Val Loss: 0.6857933811607706\n",
      "Epoch 20/3000 --- Train Loss: 0.6748731578210003 --- Val Loss: 0.6811962156631829\n",
      "Epoch 30/3000 --- Train Loss: 0.6679493765788069 --- Val Loss: 0.676709619319556\n",
      "Epoch 40/3000 --- Train Loss: 0.6582273413465738 --- Val Loss: 0.6691925982782146\n",
      "Epoch 50/3000 --- Train Loss: 0.6369066850075925 --- Val Loss: 0.6500534452833541\n",
      "Epoch 60/3000 --- Train Loss: 0.5838454428486558 --- Val Loss: 0.6000610714586954\n",
      "Epoch 70/3000 --- Train Loss: 0.48750905569186664 --- Val Loss: 0.5107490393099997\n",
      "Epoch 80/3000 --- Train Loss: 0.386904420483883 --- Val Loss: 0.41950926803173166\n",
      "Epoch 90/3000 --- Train Loss: 0.31167954522250374 --- Val Loss: 0.3508864683832083\n",
      "Epoch 100/3000 --- Train Loss: 0.2605064890848712 --- Val Loss: 0.30314795627734104\n",
      "Epoch 110/3000 --- Train Loss: 0.2253789144385254 --- Val Loss: 0.26996960123937763\n",
      "Epoch 120/3000 --- Train Loss: 0.20054342277026727 --- Val Loss: 0.24584746597028034\n",
      "Epoch 130/3000 --- Train Loss: 0.18201997444314266 --- Val Loss: 0.22736859835181827\n",
      "Epoch 140/3000 --- Train Loss: 0.16758093494567214 --- Val Loss: 0.21255399565168093\n",
      "Epoch 150/3000 --- Train Loss: 0.15583934271341657 --- Val Loss: 0.20001539242794134\n",
      "Epoch 160/3000 --- Train Loss: 0.1459552374498963 --- Val Loss: 0.18942507055568758\n",
      "Epoch 170/3000 --- Train Loss: 0.13756502878288032 --- Val Loss: 0.1805824724521996\n",
      "Epoch 180/3000 --- Train Loss: 0.13038794295817796 --- Val Loss: 0.17290487751053943\n",
      "Epoch 190/3000 --- Train Loss: 0.12426874372266887 --- Val Loss: 0.1662021225484722\n",
      "Epoch 200/3000 --- Train Loss: 0.1189543560709821 --- Val Loss: 0.16038269363741545\n",
      "Epoch 210/3000 --- Train Loss: 0.11431265093308807 --- Val Loss: 0.15521745387024277\n",
      "Epoch 220/3000 --- Train Loss: 0.11024716236792972 --- Val Loss: 0.15067571510766045\n",
      "Epoch 230/3000 --- Train Loss: 0.10662902445676704 --- Val Loss: 0.14663975982755184\n",
      "Epoch 240/3000 --- Train Loss: 0.10337448739782308 --- Val Loss: 0.143058498900871\n",
      "Epoch 250/3000 --- Train Loss: 0.10044191937369275 --- Val Loss: 0.1398743221157675\n",
      "Epoch 260/3000 --- Train Loss: 0.09780348201455684 --- Val Loss: 0.13703039127138772\n",
      "Epoch 270/3000 --- Train Loss: 0.09539353098908462 --- Val Loss: 0.1344537026325897\n",
      "Epoch 280/3000 --- Train Loss: 0.09318864808568567 --- Val Loss: 0.13210573655941918\n",
      "Epoch 290/3000 --- Train Loss: 0.0911725603166216 --- Val Loss: 0.13000454476409662\n",
      "Epoch 300/3000 --- Train Loss: 0.08930503878547152 --- Val Loss: 0.1280531007083402\n",
      "Epoch 310/3000 --- Train Loss: 0.0875792190297096 --- Val Loss: 0.1262721515936853\n",
      "Epoch 320/3000 --- Train Loss: 0.08598521966441929 --- Val Loss: 0.12462887825081122\n",
      "Epoch 330/3000 --- Train Loss: 0.08450467273720848 --- Val Loss: 0.12312657956512647\n",
      "Epoch 340/3000 --- Train Loss: 0.0831281837635159 --- Val Loss: 0.12171919856482533\n",
      "Epoch 350/3000 --- Train Loss: 0.08183486248509725 --- Val Loss: 0.12043892138896814\n",
      "Epoch 360/3000 --- Train Loss: 0.08062200137588553 --- Val Loss: 0.11922750781739755\n",
      "Epoch 370/3000 --- Train Loss: 0.07948733434380152 --- Val Loss: 0.11812986687148662\n",
      "Epoch 380/3000 --- Train Loss: 0.07842312975129141 --- Val Loss: 0.11709517083177336\n",
      "Epoch 390/3000 --- Train Loss: 0.07742450453577408 --- Val Loss: 0.11612059302374053\n",
      "Epoch 400/3000 --- Train Loss: 0.07648238882754853 --- Val Loss: 0.1152194810981469\n",
      "Epoch 410/3000 --- Train Loss: 0.07559348481005425 --- Val Loss: 0.11436617110290913\n",
      "Epoch 420/3000 --- Train Loss: 0.07475032312874337 --- Val Loss: 0.11357740371320216\n",
      "Epoch 430/3000 --- Train Loss: 0.07395661700760132 --- Val Loss: 0.11285364979185589\n",
      "Epoch 440/3000 --- Train Loss: 0.07319417515790862 --- Val Loss: 0.11218441275061551\n",
      "Epoch 450/3000 --- Train Loss: 0.07247531166571562 --- Val Loss: 0.11154173966883522\n",
      "Epoch 460/3000 --- Train Loss: 0.07178674254081283 --- Val Loss: 0.11093504972020747\n",
      "Epoch 470/3000 --- Train Loss: 0.07113852349647362 --- Val Loss: 0.11037304142628473\n",
      "Epoch 480/3000 --- Train Loss: 0.07051527534104839 --- Val Loss: 0.10983382878171995\n",
      "Epoch 490/3000 --- Train Loss: 0.06992420585708009 --- Val Loss: 0.10933365503457393\n",
      "Epoch 500/3000 --- Train Loss: 0.06935809930146458 --- Val Loss: 0.10885964298222184\n",
      "Epoch 510/3000 --- Train Loss: 0.06881003066722094 --- Val Loss: 0.10845301682765472\n",
      "Epoch 520/3000 --- Train Loss: 0.06828900279298059 --- Val Loss: 0.10806092064976242\n",
      "Epoch 530/3000 --- Train Loss: 0.06778801085422495 --- Val Loss: 0.10766991076386936\n",
      "Epoch 540/3000 --- Train Loss: 0.0673064739945046 --- Val Loss: 0.10731445555740604\n",
      "Epoch 550/3000 --- Train Loss: 0.06684451210983353 --- Val Loss: 0.10699275066002695\n",
      "Epoch 560/3000 --- Train Loss: 0.06640228643914448 --- Val Loss: 0.10667034396594748\n",
      "Epoch 570/3000 --- Train Loss: 0.0659801167957755 --- Val Loss: 0.10640626700802296\n",
      "Epoch 580/3000 --- Train Loss: 0.06557240915634313 --- Val Loss: 0.10612472049215231\n",
      "Epoch 590/3000 --- Train Loss: 0.06518286828260898 --- Val Loss: 0.10588855313411048\n",
      "Epoch 600/3000 --- Train Loss: 0.06480915942140845 --- Val Loss: 0.10566480648595708\n",
      "Epoch 610/3000 --- Train Loss: 0.06444543529485054 --- Val Loss: 0.10547996217635502\n",
      "Epoch 620/3000 --- Train Loss: 0.06409800714851085 --- Val Loss: 0.1053033834022899\n",
      "Epoch 630/3000 --- Train Loss: 0.06375917943985132 --- Val Loss: 0.10513101787750075\n",
      "Epoch 640/3000 --- Train Loss: 0.06344111546541857 --- Val Loss: 0.10502171203688465\n",
      "Epoch 650/3000 --- Train Loss: 0.06312448287624985 --- Val Loss: 0.10488374115585197\n",
      "Epoch 660/3000 --- Train Loss: 0.06282214638895474 --- Val Loss: 0.10477181103183315\n",
      "Epoch 670/3000 --- Train Loss: 0.06252562546711833 --- Val Loss: 0.1046544293035141\n",
      "Epoch 680/3000 --- Train Loss: 0.06223712678889483 --- Val Loss: 0.10458362022617461\n",
      "Epoch 690/3000 --- Train Loss: 0.06196052778974724 --- Val Loss: 0.10450011624026749\n",
      "Epoch 700/3000 --- Train Loss: 0.06169375649923502 --- Val Loss: 0.10443252151695483\n",
      "Epoch 710/3000 --- Train Loss: 0.061435014971710916 --- Val Loss: 0.1043802762644512\n",
      "Epoch 720/3000 --- Train Loss: 0.06118344724791878 --- Val Loss: 0.104360091325896\n",
      "Epoch 730/3000 --- Train Loss: 0.06093974390514227 --- Val Loss: 0.10435669564583255\n",
      "Epoch 740/3000 --- Train Loss: 0.060703569924295646 --- Val Loss: 0.10431261855985216\n",
      "Epoch 750/3000 --- Train Loss: 0.06047652684922031 --- Val Loss: 0.10428183969535104\n",
      "Epoch 760/3000 --- Train Loss: 0.060254627625328426 --- Val Loss: 0.10428032522138392\n",
      "Epoch 770/3000 --- Train Loss: 0.06003524466551052 --- Val Loss: 0.10430991313964849\n",
      "Epoch 780/3000 --- Train Loss: 0.05982502623631688 --- Val Loss: 0.10432308271473435\n",
      "Epoch 790/3000 --- Train Loss: 0.05962123944682042 --- Val Loss: 0.1043150669824717\n",
      "Epoch 800/3000 --- Train Loss: 0.059424108189095076 --- Val Loss: 0.10434568100585492\n",
      "Epoch 810/3000 --- Train Loss: 0.05923194582759864 --- Val Loss: 0.10439028135176294\n",
      "Epoch 820/3000 --- Train Loss: 0.059041647431376756 --- Val Loss: 0.10441645259518831\n",
      "Epoch 830/3000 --- Train Loss: 0.058859392415299965 --- Val Loss: 0.10446131963744737\n",
      "Epoch 840/3000 --- Train Loss: 0.05868346945644066 --- Val Loss: 0.10449752018781334\n",
      "Epoch 850/3000 --- Train Loss: 0.05851041792090565 --- Val Loss: 0.10455168296321232\n",
      "Epoch 860/3000 --- Train Loss: 0.05834153435324695 --- Val Loss: 0.104618152077841\n",
      "Epoch 870/3000 --- Train Loss: 0.05817723731831648 --- Val Loss: 0.10469343214191441\n",
      "Epoch 880/3000 --- Train Loss: 0.058017460986627675 --- Val Loss: 0.10477314863344724\n",
      "Epoch 890/3000 --- Train Loss: 0.057863150200496705 --- Val Loss: 0.10489357808164194\n",
      "Epoch 900/3000 --- Train Loss: 0.05770731947874863 --- Val Loss: 0.1049623494708249\n",
      "Epoch 910/3000 --- Train Loss: 0.057555451835262755 --- Val Loss: 0.10509188835924184\n",
      "Epoch 920/3000 --- Train Loss: 0.057405537752622686 --- Val Loss: 0.10517745390499798\n",
      "Epoch 930/3000 --- Train Loss: 0.057257798597544915 --- Val Loss: 0.10528046959902643\n",
      "Epoch 940/3000 --- Train Loss: 0.057117856774946595 --- Val Loss: 0.10537758421311262\n",
      "Epoch 950/3000 --- Train Loss: 0.05697873182166587 --- Val Loss: 0.10547777625437897\n",
      "Epoch 960/3000 --- Train Loss: 0.056843453446836494 --- Val Loss: 0.10560068772464133\n",
      "Epoch 970/3000 --- Train Loss: 0.05670765778996201 --- Val Loss: 0.10568668893347263\n",
      "Epoch 980/3000 --- Train Loss: 0.05657610678777087 --- Val Loss: 0.10584394220767734\n",
      "Epoch 990/3000 --- Train Loss: 0.056446477190134826 --- Val Loss: 0.10594393219152719\n",
      "Epoch 1000/3000 --- Train Loss: 0.056322334218851175 --- Val Loss: 0.10607271755541896\n",
      "Epoch 1010/3000 --- Train Loss: 0.05619973339737482 --- Val Loss: 0.106206388259256\n",
      "Epoch 1020/3000 --- Train Loss: 0.05607645703512227 --- Val Loss: 0.10634668402733576\n",
      "Epoch 1030/3000 --- Train Loss: 0.05595429121432002 --- Val Loss: 0.10648468738364907\n",
      "Epoch 1040/3000 --- Train Loss: 0.0558352444764612 --- Val Loss: 0.10661234853902399\n",
      "Epoch 1050/3000 --- Train Loss: 0.055722400593874954 --- Val Loss: 0.10673604584477012\n",
      "Epoch 1060/3000 --- Train Loss: 0.05561186550688599 --- Val Loss: 0.10690439246405747\n",
      "Epoch 1070/3000 --- Train Loss: 0.05549649120528278 --- Val Loss: 0.10708780658683059\n",
      "Epoch 1080/3000 --- Train Loss: 0.0553855071001815 --- Val Loss: 0.10722944865264407\n",
      "Epoch 1090/3000 --- Train Loss: 0.05527433534998865 --- Val Loss: 0.10738138459072966\n",
      "Epoch 1100/3000 --- Train Loss: 0.05516090434283392 --- Val Loss: 0.10752294816546183\n",
      "Epoch 1110/3000 --- Train Loss: 0.05505006018102159 --- Val Loss: 0.10766652096790746\n",
      "Epoch 1120/3000 --- Train Loss: 0.05494189235787938 --- Val Loss: 0.1078095326093363\n",
      "Epoch 1130/3000 --- Train Loss: 0.05483865009262278 --- Val Loss: 0.10796601487333155\n",
      "Epoch 1140/3000 --- Train Loss: 0.054732128847335505 --- Val Loss: 0.10811770746756535\n",
      "Epoch 1150/3000 --- Train Loss: 0.05463063578102743 --- Val Loss: 0.10828086673543436\n",
      "Epoch 1160/3000 --- Train Loss: 0.054532495028952514 --- Val Loss: 0.10845473758559987\n",
      "Epoch 1170/3000 --- Train Loss: 0.054430183522398465 --- Val Loss: 0.10862496406684413\n",
      "Epoch 1180/3000 --- Train Loss: 0.05433277110300699 --- Val Loss: 0.10877642401917599\n",
      "Epoch 1190/3000 --- Train Loss: 0.05423775355727019 --- Val Loss: 0.10892855855870824\n",
      "Epoch 1200/3000 --- Train Loss: 0.05414144012188043 --- Val Loss: 0.10912229810577422\n",
      "Epoch 1210/3000 --- Train Loss: 0.05404746576952101 --- Val Loss: 0.10929537993968395\n",
      "Epoch 1220/3000 --- Train Loss: 0.053953777746868194 --- Val Loss: 0.10947216909582069\n",
      "Epoch 1230/3000 --- Train Loss: 0.053861681995561836 --- Val Loss: 0.10964324894333831\n",
      "Epoch 1240/3000 --- Train Loss: 0.053768800121728945 --- Val Loss: 0.10988454342326595\n",
      "Epoch 1250/3000 --- Train Loss: 0.053681912589725087 --- Val Loss: 0.11007969992373494\n",
      "Epoch 1260/3000 --- Train Loss: 0.05359468634960725 --- Val Loss: 0.11026361154607392\n",
      "Epoch 1270/3000 --- Train Loss: 0.053504583380321345 --- Val Loss: 0.11045934242925119\n",
      "Epoch 1280/3000 --- Train Loss: 0.05341843809668442 --- Val Loss: 0.11067988091994586\n",
      "Epoch 1290/3000 --- Train Loss: 0.053334387325021354 --- Val Loss: 0.110853371557497\n",
      "Epoch 1300/3000 --- Train Loss: 0.05324887283606349 --- Val Loss: 0.11109434316062833\n",
      "Epoch 1310/3000 --- Train Loss: 0.05316604470132744 --- Val Loss: 0.11130022043610747\n",
      "Epoch 1320/3000 --- Train Loss: 0.053085953588023205 --- Val Loss: 0.11142950055934167\n",
      "Epoch 1330/3000 --- Train Loss: 0.053002516417653814 --- Val Loss: 0.11161606960843687\n",
      "Epoch 1340/3000 --- Train Loss: 0.052918322844030495 --- Val Loss: 0.11186230203333668\n",
      "Epoch 1350/3000 --- Train Loss: 0.052839944237638305 --- Val Loss: 0.1120670501393594\n",
      "Epoch 1360/3000 --- Train Loss: 0.052757370020873946 --- Val Loss: 0.11229057452621793\n",
      "Epoch 1370/3000 --- Train Loss: 0.05268018143962618 --- Val Loss: 0.1124852323321103\n",
      "Epoch 1380/3000 --- Train Loss: 0.05260197316265868 --- Val Loss: 0.11269970058995073\n",
      "Epoch 1390/3000 --- Train Loss: 0.05252575402214786 --- Val Loss: 0.11292723617158212\n",
      "Epoch 1400/3000 --- Train Loss: 0.052448131296031035 --- Val Loss: 0.1131943992839456\n",
      "Epoch 1410/3000 --- Train Loss: 0.05237634506311818 --- Val Loss: 0.11341857119543429\n",
      "Epoch 1420/3000 --- Train Loss: 0.05230467466616507 --- Val Loss: 0.11367286930492575\n",
      "Epoch 1430/3000 --- Train Loss: 0.05222637406226661 --- Val Loss: 0.11392897840448864\n",
      "Epoch 1440/3000 --- Train Loss: 0.05215475769950927 --- Val Loss: 0.11420416368040727\n",
      "Epoch 1450/3000 --- Train Loss: 0.052079798514126106 --- Val Loss: 0.11445363126493559\n",
      "Epoch 1460/3000 --- Train Loss: 0.05201181516894622 --- Val Loss: 0.1147438665171057\n",
      "Epoch 1470/3000 --- Train Loss: 0.05193630851464176 --- Val Loss: 0.11506729042472896\n",
      "Epoch 1480/3000 --- Train Loss: 0.05186608293338742 --- Val Loss: 0.115322953661297\n",
      "Epoch 1490/3000 --- Train Loss: 0.051797041231935285 --- Val Loss: 0.11560562138961937\n",
      "Epoch 1500/3000 --- Train Loss: 0.05172786292677536 --- Val Loss: 0.11581865441824553\n",
      "Epoch 1510/3000 --- Train Loss: 0.05165922145924856 --- Val Loss: 0.11612611380655263\n",
      "Epoch 1520/3000 --- Train Loss: 0.05159161437361871 --- Val Loss: 0.11642684644185067\n",
      "Epoch 1530/3000 --- Train Loss: 0.05152455765534045 --- Val Loss: 0.11670271741580152\n",
      "Epoch 1540/3000 --- Train Loss: 0.05145749537295626 --- Val Loss: 0.11697858280582268\n",
      "Epoch 1550/3000 --- Train Loss: 0.051390052995618614 --- Val Loss: 0.11723479202971614\n",
      "Epoch 1560/3000 --- Train Loss: 0.05133047436974284 --- Val Loss: 0.11744823597883308\n",
      "Epoch 1570/3000 --- Train Loss: 0.051263648549156146 --- Val Loss: 0.11772969895989648\n",
      "Epoch 1580/3000 --- Train Loss: 0.05119836975092319 --- Val Loss: 0.1180746039575929\n",
      "Epoch 1590/3000 --- Train Loss: 0.05113371481180676 --- Val Loss: 0.1183612428226059\n",
      "Epoch 1600/3000 --- Train Loss: 0.05106818558132891 --- Val Loss: 0.11864824840588381\n",
      "Epoch 1610/3000 --- Train Loss: 0.05100512111336596 --- Val Loss: 0.11895912952895972\n",
      "Epoch 1620/3000 --- Train Loss: 0.050940509126987124 --- Val Loss: 0.1192678285153893\n",
      "Epoch 1630/3000 --- Train Loss: 0.050881894283022165 --- Val Loss: 0.11953836525078262\n",
      "Epoch 1640/3000 --- Train Loss: 0.05081731368857568 --- Val Loss: 0.11991345672239381\n",
      "Epoch 1650/3000 --- Train Loss: 0.050751766870907065 --- Val Loss: 0.12024582656750879\n",
      "Epoch 1660/3000 --- Train Loss: 0.05068794879935877 --- Val Loss: 0.12058804621677764\n",
      "Epoch 1670/3000 --- Train Loss: 0.050630631361484144 --- Val Loss: 0.1208477156641593\n",
      "Epoch 1680/3000 --- Train Loss: 0.05057066737747563 --- Val Loss: 0.12117408800906342\n",
      "Epoch 1690/3000 --- Train Loss: 0.05050785200423071 --- Val Loss: 0.12149308852438677\n",
      "Epoch 1700/3000 --- Train Loss: 0.05044638994035946 --- Val Loss: 0.12184534017904192\n",
      "Epoch 1710/3000 --- Train Loss: 0.050383827211015905 --- Val Loss: 0.12222050734053605\n",
      "Epoch 1720/3000 --- Train Loss: 0.05032401230711153 --- Val Loss: 0.12256527184762357\n",
      "Epoch 1730/3000 --- Train Loss: 0.050262124844041293 --- Val Loss: 0.12295795627628114\n",
      "Epoch 1740/3000 --- Train Loss: 0.05020179424207316 --- Val Loss: 0.12332014819398873\n",
      "Epoch 1750/3000 --- Train Loss: 0.050140716394190404 --- Val Loss: 0.12368539790630916\n",
      "Epoch 1760/3000 --- Train Loss: 0.05008345033932952 --- Val Loss: 0.12401889224602446\n",
      "Epoch 1770/3000 --- Train Loss: 0.05002525680126485 --- Val Loss: 0.12436805607024116\n",
      "Epoch 1780/3000 --- Train Loss: 0.049970825964423864 --- Val Loss: 0.12465817711985071\n",
      "Epoch 1790/3000 --- Train Loss: 0.04991378282539954 --- Val Loss: 0.12504044406722128\n",
      "Epoch 1800/3000 --- Train Loss: 0.049855799181002636 --- Val Loss: 0.12543809101358325\n",
      "Epoch 1810/3000 --- Train Loss: 0.049798046260891536 --- Val Loss: 0.12579825639399178\n",
      "Epoch 1820/3000 --- Train Loss: 0.049743728947520875 --- Val Loss: 0.12613235969844458\n",
      "Epoch 1830/3000 --- Train Loss: 0.049690899565800174 --- Val Loss: 0.1265101916798516\n",
      "Epoch 1840/3000 --- Train Loss: 0.04963748187426109 --- Val Loss: 0.12683983025707588\n",
      "Epoch 1850/3000 --- Train Loss: 0.04958608353471536 --- Val Loss: 0.1271909699990768\n",
      "Epoch 1860/3000 --- Train Loss: 0.049531846980479105 --- Val Loss: 0.12758326939871437\n",
      "Epoch 1870/3000 --- Train Loss: 0.04947917095898776 --- Val Loss: 0.12799131367838168\n",
      "Epoch 1880/3000 --- Train Loss: 0.04942742484522297 --- Val Loss: 0.12837675858762895\n",
      "Epoch 1890/3000 --- Train Loss: 0.049379696739863456 --- Val Loss: 0.12868704329483394\n",
      "Epoch 1900/3000 --- Train Loss: 0.049328371554656573 --- Val Loss: 0.12909435307705353\n",
      "Epoch 1910/3000 --- Train Loss: 0.0492795771771995 --- Val Loss: 0.12948176584432275\n",
      "Epoch 1920/3000 --- Train Loss: 0.04922878948588864 --- Val Loss: 0.12982333115967576\n",
      "Epoch 1930/3000 --- Train Loss: 0.04917815463013023 --- Val Loss: 0.1302109161298652\n",
      "Epoch 1940/3000 --- Train Loss: 0.04912973934727438 --- Val Loss: 0.13057985714361073\n",
      "Epoch 1950/3000 --- Train Loss: 0.04907825465995736 --- Val Loss: 0.1310020324215731\n",
      "Epoch 1960/3000 --- Train Loss: 0.04902970300682391 --- Val Loss: 0.13142701815893146\n",
      "Epoch 1970/3000 --- Train Loss: 0.04898230313348645 --- Val Loss: 0.13187964367590316\n",
      "Epoch 1980/3000 --- Train Loss: 0.0489333786358813 --- Val Loss: 0.1323447549840905\n",
      "Epoch 1990/3000 --- Train Loss: 0.048888267740570916 --- Val Loss: 0.13274184381894097\n",
      "Epoch 2000/3000 --- Train Loss: 0.04884358017224401 --- Val Loss: 0.13315961108255098\n",
      "Epoch 2010/3000 --- Train Loss: 0.04879875130433038 --- Val Loss: 0.13350720734161403\n",
      "Epoch 2020/3000 --- Train Loss: 0.04874940956888255 --- Val Loss: 0.1339557964802437\n",
      "Epoch 2030/3000 --- Train Loss: 0.04870594239351889 --- Val Loss: 0.1344651241083056\n",
      "Epoch 2040/3000 --- Train Loss: 0.048655275116095756 --- Val Loss: 0.13496969973426987\n",
      "Epoch 2050/3000 --- Train Loss: 0.04861389633859994 --- Val Loss: 0.1353373573936599\n",
      "Epoch 2060/3000 --- Train Loss: 0.04856792131359739 --- Val Loss: 0.13577946291588122\n",
      "Epoch 2070/3000 --- Train Loss: 0.04852254868122154 --- Val Loss: 0.13623091606670112\n",
      "Epoch 2080/3000 --- Train Loss: 0.0484768560812563 --- Val Loss: 0.13668049924187237\n",
      "Epoch 2090/3000 --- Train Loss: 0.048435634262447715 --- Val Loss: 0.13708632318341893\n",
      "Epoch 2100/3000 --- Train Loss: 0.04839048997490589 --- Val Loss: 0.13753554275579824\n",
      "Epoch 2110/3000 --- Train Loss: 0.048348177533019614 --- Val Loss: 0.13798001611312885\n",
      "Epoch 2120/3000 --- Train Loss: 0.04830332564222565 --- Val Loss: 0.13849733343349524\n",
      "Epoch 2130/3000 --- Train Loss: 0.04826114661384029 --- Val Loss: 0.13893909097675472\n",
      "Epoch 2140/3000 --- Train Loss: 0.04821884781180743 --- Val Loss: 0.13941966203528744\n",
      "Epoch 2150/3000 --- Train Loss: 0.04817668978664895 --- Val Loss: 0.13990489417590515\n",
      "Epoch 2160/3000 --- Train Loss: 0.04813790808718811 --- Val Loss: 0.14033726939226532\n",
      "Epoch 2170/3000 --- Train Loss: 0.04809842570166659 --- Val Loss: 0.14079034976751073\n",
      "Epoch 2180/3000 --- Train Loss: 0.04805767941886735 --- Val Loss: 0.141218709252551\n",
      "Epoch 2190/3000 --- Train Loss: 0.048016573678134326 --- Val Loss: 0.14166941699183552\n",
      "Epoch 2200/3000 --- Train Loss: 0.047976458631755155 --- Val Loss: 0.1421997899575482\n",
      "Epoch 2210/3000 --- Train Loss: 0.047936156587638716 --- Val Loss: 0.14271200075701185\n",
      "Epoch 2220/3000 --- Train Loss: 0.047896340868011894 --- Val Loss: 0.1431776465280837\n",
      "Epoch 2230/3000 --- Train Loss: 0.04785603679315995 --- Val Loss: 0.14366953400051372\n",
      "Epoch 2240/3000 --- Train Loss: 0.047821967744095105 --- Val Loss: 0.14411502195125753\n",
      "Epoch 2250/3000 --- Train Loss: 0.04778270078009875 --- Val Loss: 0.14459536219496727\n",
      "Epoch 2260/3000 --- Train Loss: 0.04774533880043472 --- Val Loss: 0.14512334003981278\n",
      "Epoch 2270/3000 --- Train Loss: 0.04770620627152229 --- Val Loss: 0.14561450722220073\n",
      "Epoch 2280/3000 --- Train Loss: 0.04767104701516911 --- Val Loss: 0.14606709638356155\n",
      "Epoch 2290/3000 --- Train Loss: 0.04763584679765403 --- Val Loss: 0.14646929149591523\n",
      "Epoch 2300/3000 --- Train Loss: 0.04759790172609224 --- Val Loss: 0.14694274443015695\n",
      "Epoch 2310/3000 --- Train Loss: 0.04755864389099407 --- Val Loss: 0.14745425073209298\n",
      "Epoch 2320/3000 --- Train Loss: 0.047521237609643455 --- Val Loss: 0.1479183535611537\n",
      "Epoch 2330/3000 --- Train Loss: 0.047482442779589296 --- Val Loss: 0.14841028523770394\n",
      "Epoch 2340/3000 --- Train Loss: 0.04744619124262064 --- Val Loss: 0.14894176062925313\n",
      "Epoch 2350/3000 --- Train Loss: 0.04740729415032099 --- Val Loss: 0.14947498883286275\n",
      "Epoch 2360/3000 --- Train Loss: 0.04737279712719208 --- Val Loss: 0.14998816077868046\n",
      "Epoch 2370/3000 --- Train Loss: 0.04733871819092645 --- Val Loss: 0.15046482590102087\n",
      "Epoch 2380/3000 --- Train Loss: 0.047305394782541074 --- Val Loss: 0.15096997338750295\n",
      "Epoch 2390/3000 --- Train Loss: 0.04727139409444556 --- Val Loss: 0.15144255097016185\n",
      "Epoch 2400/3000 --- Train Loss: 0.047237669685040735 --- Val Loss: 0.1520042170679096\n",
      "Epoch 2410/3000 --- Train Loss: 0.047203667903040765 --- Val Loss: 0.15246238728849046\n",
      "Epoch 2420/3000 --- Train Loss: 0.047170483041356945 --- Val Loss: 0.15294533703379987\n",
      "Epoch 2430/3000 --- Train Loss: 0.04713685547080701 --- Val Loss: 0.15339841961645947\n",
      "Epoch 2440/3000 --- Train Loss: 0.04710435706571653 --- Val Loss: 0.15393412315503935\n",
      "Epoch 2450/3000 --- Train Loss: 0.04707065556446177 --- Val Loss: 0.15440406411363877\n",
      "Epoch 2460/3000 --- Train Loss: 0.04703772664179885 --- Val Loss: 0.15489840744266847\n",
      "Epoch 2470/3000 --- Train Loss: 0.04700896000522626 --- Val Loss: 0.15531612642702305\n",
      "Epoch 2480/3000 --- Train Loss: 0.04697520435250578 --- Val Loss: 0.1558105459530162\n",
      "Epoch 2490/3000 --- Train Loss: 0.04693993040486284 --- Val Loss: 0.15631461368742475\n",
      "Epoch 2500/3000 --- Train Loss: 0.04690555651405047 --- Val Loss: 0.1568163578483761\n",
      "Epoch 2510/3000 --- Train Loss: 0.04687387167122722 --- Val Loss: 0.15733258350436072\n",
      "Epoch 2520/3000 --- Train Loss: 0.04684176792049443 --- Val Loss: 0.1577996403452275\n",
      "Epoch 2530/3000 --- Train Loss: 0.04680958406446803 --- Val Loss: 0.15826586240271998\n",
      "Epoch 2540/3000 --- Train Loss: 0.0467820197474639 --- Val Loss: 0.15860399054952584\n",
      "Epoch 2550/3000 --- Train Loss: 0.04675248597196381 --- Val Loss: 0.15899282258320982\n",
      "Epoch 2560/3000 --- Train Loss: 0.04672154911385063 --- Val Loss: 0.1594305248849301\n",
      "Epoch 2570/3000 --- Train Loss: 0.046690529180559937 --- Val Loss: 0.1598748713292231\n",
      "Epoch 2580/3000 --- Train Loss: 0.04665957276730721 --- Val Loss: 0.16031030043217898\n",
      "Epoch 2590/3000 --- Train Loss: 0.04663452421054785 --- Val Loss: 0.1606468272765142\n",
      "Epoch 2600/3000 --- Train Loss: 0.04660460805993125 --- Val Loss: 0.16107529340139395\n",
      "Epoch 2610/3000 --- Train Loss: 0.046573855691769875 --- Val Loss: 0.16151467142722437\n",
      "Epoch 2620/3000 --- Train Loss: 0.04654223752081316 --- Val Loss: 0.16197571656417248\n",
      "Epoch 2630/3000 --- Train Loss: 0.04651395645686573 --- Val Loss: 0.16241865742458075\n",
      "Epoch 2640/3000 --- Train Loss: 0.04648125867008198 --- Val Loss: 0.1628494026419629\n",
      "Epoch 2650/3000 --- Train Loss: 0.04645218638106827 --- Val Loss: 0.1632247111016818\n",
      "Epoch 2660/3000 --- Train Loss: 0.046422325274443094 --- Val Loss: 0.16359505173109254\n",
      "Epoch 2670/3000 --- Train Loss: 0.046393013904113704 --- Val Loss: 0.16389475920793764\n",
      "Epoch 2680/3000 --- Train Loss: 0.04636703796835103 --- Val Loss: 0.16415721785141793\n",
      "Epoch 2690/3000 --- Train Loss: 0.04634071402163226 --- Val Loss: 0.1644275751628808\n",
      "Epoch 2700/3000 --- Train Loss: 0.046314289966234184 --- Val Loss: 0.16474697400909638\n",
      "Epoch 2710/3000 --- Train Loss: 0.046287125100103965 --- Val Loss: 0.16504055296995887\n",
      "Epoch 2720/3000 --- Train Loss: 0.04626100324433243 --- Val Loss: 0.1653123203182582\n",
      "Epoch 2730/3000 --- Train Loss: 0.04623329923780196 --- Val Loss: 0.165629292200733\n",
      "Epoch 2740/3000 --- Train Loss: 0.04620737208412298 --- Val Loss: 0.16599454407746853\n",
      "Epoch 2750/3000 --- Train Loss: 0.04618115870982309 --- Val Loss: 0.16636490408869803\n",
      "Epoch 2760/3000 --- Train Loss: 0.04615587625290599 --- Val Loss: 0.1666123432140412\n",
      "Epoch 2770/3000 --- Train Loss: 0.04613151851993602 --- Val Loss: 0.1669989050582752\n",
      "Epoch 2780/3000 --- Train Loss: 0.046106012563072445 --- Val Loss: 0.16734308324543423\n",
      "Epoch 2790/3000 --- Train Loss: 0.046082038637234736 --- Val Loss: 0.16776482036531187\n",
      "Epoch 2800/3000 --- Train Loss: 0.046055653735010374 --- Val Loss: 0.16810095082872323\n",
      "Epoch 2810/3000 --- Train Loss: 0.04603157184310288 --- Val Loss: 0.1684897362208175\n",
      "Epoch 2820/3000 --- Train Loss: 0.046006331785675286 --- Val Loss: 0.16881125910668046\n",
      "Epoch 2830/3000 --- Train Loss: 0.04598399352981021 --- Val Loss: 0.169131399217978\n",
      "Epoch 2840/3000 --- Train Loss: 0.04595901757692671 --- Val Loss: 0.16948925444206034\n",
      "Epoch 2850/3000 --- Train Loss: 0.045936544100056216 --- Val Loss: 0.16984441672532635\n",
      "Epoch 2860/3000 --- Train Loss: 0.04591288621035199 --- Val Loss: 0.17025954226010367\n",
      "Epoch 2870/3000 --- Train Loss: 0.045890961581977946 --- Val Loss: 0.17057399976327794\n",
      "Epoch 2880/3000 --- Train Loss: 0.045868779495550634 --- Val Loss: 0.17092948818212633\n",
      "Epoch 2890/3000 --- Train Loss: 0.045844144626422195 --- Val Loss: 0.17132581210774234\n",
      "Epoch 2900/3000 --- Train Loss: 0.04582093126439995 --- Val Loss: 0.17171918264341177\n",
      "Epoch 2910/3000 --- Train Loss: 0.04579977040047417 --- Val Loss: 0.17219503602919808\n",
      "Epoch 2920/3000 --- Train Loss: 0.045778026746504365 --- Val Loss: 0.17260578974362564\n",
      "Epoch 2930/3000 --- Train Loss: 0.04575575669671782 --- Val Loss: 0.17302029409175215\n",
      "Epoch 2940/3000 --- Train Loss: 0.04573423297534616 --- Val Loss: 0.1733900081670937\n",
      "Epoch 2950/3000 --- Train Loss: 0.04571313368674618 --- Val Loss: 0.1738823729957341\n",
      "Epoch 2960/3000 --- Train Loss: 0.04569244666859651 --- Val Loss: 0.1743267821970952\n",
      "Epoch 2970/3000 --- Train Loss: 0.04567184762912053 --- Val Loss: 0.17473201704928798\n",
      "Epoch 2980/3000 --- Train Loss: 0.04565374533399861 --- Val Loss: 0.1750593300618726\n",
      "Epoch 2990/3000 --- Train Loss: 0.04563189853740033 --- Val Loss: 0.17551021472200307\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgFUlEQVR4nO3deXhTVf4/8Hf2NG3Tha6UQtmhLAVBatnEoQq4DItoZRhZBmEURBnUrzIqoI6DI8owo4woCuiMCoKg/gQRqIILVZBVtrIItCzdKN3bpE3O74+bpA1d6JLktun79Tz3SXLuvcknt8W+PefcexVCCAEiIiIiL6GUuwAiIiIiV2K4ISIiIq/CcENEREReheGGiIiIvArDDREREXkVhhsiIiLyKgw3RERE5FUYboiIiMirMNwQERGRV2G4ISJq5s6fPw+FQoHXXntN7lKIWgSGG6IWaO3atVAoFPjll1/kLsUr2MNDbcsrr7wid4lE1ABquQsgImouJk2ahDvvvLNae//+/WWohogai+GGiFqF4uJi+Pr61rnNTTfdhD/+8Y8eqoiI3IXDUkRe7ODBgxgzZgyMRiP8/PwwcuRI/PTTT07blJeX44UXXkDXrl2h1+vRpk0bDB06FDt27HBsk5GRgenTp6Ndu3bQ6XSIjIzE2LFjcf78+RvW8M0332DYsGHw9fVFYGAgxo4dixMnTjjWb9y4EQqFArt3766279tvvw2FQoGjR4862k6ePImJEyciODgYer0eAwcOxBdffOG0n33Ybvfu3Zg9ezbCwsLQrl27+h62OsXExODuu+/G9u3b0a9fP+j1esTGxmLTpk3Vtv3tt99w3333ITg4GAaDAbfccgu2bNlSbbuysjIsXrwY3bp1g16vR2RkJCZMmICzZ89W2/add95B586dodPpcPPNN2Pfvn1O65vysyLyFuy5IfJSx44dw7Bhw2A0GvF///d/0Gg0ePvttzFixAjs3r0b8fHxAIDFixdjyZIleOihhzBo0CAUFBTgl19+wYEDB3D77bcDAO69914cO3YMc+fORUxMDLKysrBjxw6kpaUhJiam1hp27tyJMWPGoFOnTli8eDFKS0vxxhtvYMiQIThw4ABiYmJw1113wc/PD5988gluvfVWp/3Xr1+PXr16oXfv3o7vNGTIEERFReGZZ56Br68vPvnkE4wbNw6ffvopxo8f77T/7NmzERoaioULF6K4uPiGx6ykpAQ5OTnV2gMDA6FWV/7n8vTp00hKSsLDDz+MqVOnYs2aNbjvvvuwbds2xzHLzMzE4MGDUVJSgsceewxt2rTB+++/j9///vfYuHGjo1aLxYK7774bycnJeOCBB/D444+jsLAQO3bswNGjR9G5c2fH53700UcoLCzEn//8ZygUCrz66quYMGECfvvtN2g0mib9rIi8iiCiFmfNmjUCgNi3b1+t24wbN05otVpx9uxZR9vly5eFv7+/GD58uKMtLi5O3HXXXbW+z7Vr1wQAsXTp0gbX2a9fPxEWFiauXr3qaDt8+LBQKpViypQpjrZJkyaJsLAwUVFR4Wi7cuWKUCqV4sUXX3S0jRw5UvTp00eUlZU52qxWqxg8eLDo2rWro81+fIYOHer0nrU5d+6cAFDrkpKS4ti2Q4cOAoD49NNPHW35+fkiMjJS9O/f39E2b948AUB8//33jrbCwkLRsWNHERMTIywWixBCiNWrVwsAYtmyZdXqslqtTvW1adNG5ObmOtZ//vnnAoD4f//v/wkhmvazIvImHJYi8kIWiwXbt2/HuHHj0KlTJ0d7ZGQk/vCHP+CHH35AQUEBAKlX4tixYzh9+nSN7+Xj4wOtVotdu3bh2rVr9a7hypUrOHToEKZNm4bg4GBHe9++fXH77bdj69atjrakpCRkZWVh165djraNGzfCarUiKSkJAJCbm4tvvvkG999/PwoLC5GTk4OcnBxcvXoVo0aNwunTp3Hp0iWnGmbOnAmVSlXvmmfNmoUdO3ZUW2JjY522a9u2rVMvkdFoxJQpU3Dw4EFkZGQAALZu3YpBgwZh6NChju38/Pwwa9YsnD9/HsePHwcAfPrppwgJCcHcuXOr1aNQKJxeJyUlISgoyPF62LBhAKThL6DxPysib8NwQ+SFsrOzUVJSgu7du1db17NnT1itVqSnpwMAXnzxReTl5aFbt27o06cPnnrqKRw5csSxvU6nwz/+8Q989dVXCA8Px/Dhw/Hqq686/ojX5sKFCwBQaw05OTmOoaLRo0cjICAA69evd2yzfv169OvXD926dQMAnDlzBkIIPP/88wgNDXVaFi1aBADIyspy+pyOHTve8FhV1bVrVyQmJlZbjEaj03ZdunSpFjzsddrntly4cKHW725fDwBnz55F9+7dnYa9atO+fXun1/agYw8yjf1ZEXkbhhuiVm748OE4e/YsVq9ejd69e+Pdd9/FTTfdhHfffdexzbx583Dq1CksWbIEer0ezz//PHr27ImDBw+6pAadTodx48Zh8+bNqKiowKVLl/Djjz86em0AwGq1AgCefPLJGntXduzYgS5duji9r4+Pj0vqay5q64USQjieu/tnRdQSMNwQeaHQ0FAYDAakpqZWW3fy5EkolUpER0c72oKDgzF9+nR8/PHHSE9PR9++fbF48WKn/Tp37ownnngC27dvx9GjR2E2m/H666/XWkOHDh0AoNYaQkJCnE7NTkpKQk5ODpKTk7FhwwYIIZzCjX14TaPR1Ni7kpiYCH9///odoCay9yJVderUKQBwTNrt0KFDrd/dvh6QjmtqairKy8tdVl9Df1ZE3obhhsgLqVQq3HHHHfj888+dTgHOzMzERx99hKFDhzqGWq5eveq0r5+fH7p06QKTyQRAOoOorKzMaZvOnTvD39/fsU1NIiMj0a9fP7z//vvIy8tztB89ehTbt2+vdrG8xMREBAcHY/369Vi/fj0GDRrkNKwUFhaGESNG4O2338aVK1eqfV52dnbdB8WFLl++jM2bNzteFxQU4IMPPkC/fv0QEREBALjzzjuxd+9epKSkOLYrLi7GO++8g5iYGMc8nnvvvRc5OTl48803q33O9QHqRhr7syLyNjwVnKgFW716NbZt21at/fHHH8ff/vY37NixA0OHDsXs2bOhVqvx9ttvw2Qy4dVXX3VsGxsbixEjRmDAgAEIDg7GL7/8go0bN+LRRx8FIPVIjBw5Evfffz9iY2OhVquxefNmZGZm4oEHHqizvqVLl2LMmDFISEjAjBkzHKeCBwQEVOsZ0mg0mDBhAtatW4fi4uIa76O0YsUKDB06FH369MHMmTPRqVMnZGZmIiUlBRcvXsThw4cbcRQrHThwAP/73/+qtXfu3BkJCQmO1926dcOMGTOwb98+hIeHY/Xq1cjMzMSaNWsc2zzzzDP4+OOPMWbMGDz22GMIDg7G+++/j3PnzuHTTz+FUin9v+WUKVPwwQcfYP78+di7dy+GDRuG4uJi7Ny5E7Nnz8bYsWPrXX9TflZEXkXWc7WIqFHspzrXtqSnpwshhDhw4IAYNWqU8PPzEwaDQdx2221iz549Tu/1t7/9TQwaNEgEBgYKHx8f0aNHD/Hyyy8Ls9kshBAiJydHzJkzR/To0UP4+vqKgIAAER8fLz755JN61bpz504xZMgQ4ePjI4xGo7jnnnvE8ePHa9x2x44dAoBQKBSO73C9s2fPiilTpoiIiAih0WhEVFSUuPvuu8XGjRurHZ+6TpWv6kangk+dOtWxbYcOHcRdd90lvv76a9G3b1+h0+lEjx49xIYNG2qsdeLEiSIwMFDo9XoxaNAg8eWXX1bbrqSkRDz77LOiY8eOQqPRiIiICDFx4kTHafz2+mo6xRuAWLRokRCi6T8rIm+hEKKB/Z5ERK1YTEwMevfujS+//FLuUoioFpxzQ0RERF6F4YaIiIi8CsMNEREReRXOuSEiIiKvwp4bIiIi8ioMN0RERORVWt1F/KxWKy5fvgx/f/9qN74jIiKi5kkIgcLCQrRt29ZxEczatLpwc/nyZad76hAREVHLkZ6ejnbt2tW5TasLN/Yb66WnpzvurUNERETNW0FBAaKjo+t1g9xWF27sQ1FGo5HhhoiIqIWpz5QSTigmIiIir8JwQ0RERF6F4YaIiIi8Squbc0NERN7FYrGgvLxc7jLIBbRa7Q1P864PhhsiImqRhBDIyMhAXl6e3KWQiyiVSnTs2BFarbZJ79Msws2KFSuwdOlSZGRkIC4uDm+88QYGDRpU47YjRozA7t27q7Xfeeed2LJli7tLJSKiZsIebMLCwmAwGHhh1hbOfpHdK1euoH379k36ecoebtavX4/58+dj5cqViI+Px/LlyzFq1CikpqYiLCys2vabNm2C2Wx2vL569Sri4uJw3333ebJsIiKSkcVicQSbNm3ayF0OuUhoaCguX76MiooKaDSaRr+P7BOKly1bhpkzZ2L69OmIjY3FypUrYTAYsHr16hq3Dw4ORkREhGPZsWMHDAYDww0RUStin2NjMBhkroRcyT4cZbFYmvQ+soYbs9mM/fv3IzEx0dGmVCqRmJiIlJSUer3He++9hwceeAC+vr7uKpOIiJopDkV5F1f9PGUdlsrJyYHFYkF4eLhTe3h4OE6ePHnD/ffu3YujR4/ivffeq3Ubk8kEk8nkeF1QUND4gomIiKjZk31Yqinee+899OnTp9bJxwCwZMkSBAQEOBbeNJOIiLxNTEwMli9fLncZzYas4SYkJAQqlQqZmZlO7ZmZmYiIiKhz3+LiYqxbtw4zZsyoc7sFCxYgPz/fsaSnpze5biIiosZQKBR1LosXL27U++7btw+zZs1qUm0jRozAvHnzmvQezYWsw1JarRYDBgxAcnIyxo0bB0A6FSw5ORmPPvponftu2LABJpMJf/zjH+vcTqfTQafTuarkOomCyyjKzYJ/TD+PfB4REbUsV65ccTxfv349Fi5ciNTUVEebn5+f47kQAhaLBWr1jf9Uh4aGurbQFk72Yan58+dj1apVeP/993HixAk88sgjKC4uxvTp0wEAU6ZMwYIFC6rt995772HcuHHN5hTAE8n/Q8WyPrjy0SNyl0JERM1U1bN9AwICoFAoHK9PnjwJf39/fPXVVxgwYAB0Oh1++OEHnD17FmPHjkV4eDj8/Pxw8803Y+fOnU7ve/2wlEKhwLvvvovx48fDYDCga9eu+OKLL5pU+6effopevXpBp9MhJiYGr7/+utP6//znP+jatSv0ej3Cw8MxceJEx7qNGzeiT58+8PHxQZs2bZCYmIji4uIm1VMX2a9zk5SUhOzsbCxcuBAZGRno168ftm3b5phknJaWVu1SzKmpqfjhhx+wfft2OUqukaHzYFi/A7qZj6P47B74dh4sd0lERK2KEAKl5U07hbixfDQql53p88wzz+C1115Dp06dEBQUhPT0dNx55514+eWXodPp8MEHH+Cee+5Bamoq2rdvX+v7vPDCC3j11VexdOlSvPHGG5g8eTIuXLiA4ODgBte0f/9+3H///Vi8eDGSkpKwZ88ezJ49G23atMG0adPwyy+/4LHHHsN///tfDB48GLm5ufj+++8BSL1VkyZNwquvvorx48ejsLAQ33//PYQQjT5GNyJ7uAGARx99tNZhqF27dlVr6969u1sPSmN0iOmErzS3YkxFMgqTX2e4ISLysNJyC2IXfi3LZx9/cRQMWtf8SX3xxRdx++23O14HBwcjLi7O8fqll17C5s2b8cUXX9Q5hWPatGmYNGkSAODvf/87/v3vf2Pv3r0YPXp0g2tatmwZRo4cieeffx4A0K1bNxw/fhxLly7FtGnTkJaWBl9fX9x9993w9/dHhw4d0L9/fwBSuKmoqMCECRPQoUMHAECfPn0aXENDyD4s5U0udJ8Bi1Ag4vJOIO1nucshIqIWaODAgU6vi4qK8OSTT6Jnz54IDAyEn58fTpw4gbS0tDrfp2/fvo7nvr6+MBqNyMrKalRNJ06cwJAhQ5zahgwZgtOnT8NiseD2229Hhw4d0KlTJzz44IP48MMPUVJSAgCIi4vDyJEj0adPH9x3331YtWoVrl271qg66qtZ9Nx4i7ibbsEnh0dgkvpbWL/+K5QzdgAuuLspERHdmI9GheMvjpLts13l+ovSPvnkk9ixYwdee+01dOnSBT4+Ppg4caLTrYhqcv3tCxQKBaxWq8vqrMrf3x8HDhzArl27sH37dixcuBCLFy/Gvn37EBgYiB07dmDPnj3Yvn073njjDTz77LP4+eef0bFjR7fUw7+8LnRzTBDW6iajWOigvPQLcOhDuUsiImo1FAoFDFq1LIs7r5T8448/Ytq0aRg/fjz69OmDiIgInD9/3m2fV5OePXvixx9/rFZXt27doFJJwU6tViMxMRGvvvoqjhw5gvPnz+Obb74BIP1shgwZghdeeAEHDx6EVqvF5s2b3VYve25cSK1SYmj/XvhnykQ8p/kQ2LEQ6HEXYGj45C0iIiIA6Nq1KzZt2oR77rkHCoUCzz//vNt6YLKzs3Ho0CGntsjISDzxxBO4+eab8dJLLyEpKQkpKSl488038Z///AcA8OWXX+K3337D8OHDERQUhK1bt8JqtaJ79+74+eefkZycjDvuuANhYWH4+eefkZ2djZ49e7rlOwDsuXG58f2jsNYyCqkiGijNBXYulrskIiJqwZYtW4agoCAMHjwY99xzD0aNGoWbbrrJLZ/10UcfoX///k7LqlWrcNNNN+GTTz7BunXr0Lt3byxcuBAvvvgipk2bBgAIDAzEpk2b8Lvf/Q49e/bEypUr8fHHH6NXr14wGo347rvvcOedd6Jbt2547rnn8Prrr2PMmDFu+Q4AoBDN7bQjNysoKEBAQADy8/NhNBpd/v5CCIz51/fwy9yHjboXpcYZO4Hom13+WURErVVZWRnOnTuHjh07Qq/Xy10OuUhdP9eG/P1mz42LKRQKPJjQAb+IHvhK/TupcesTQOvKkERERLJhuHGDcf2i4K9T49mi+2FR6YErh4FL++Uui4iIqFVguHEDX50a9w5oh1wYsU9vuy7ArxvlLYqIiKiVYLhxkwcTpKsw/jevt9RwbreM1RAREbUeDDdu0jnUDzfHBGGPxXaqW9ZxoChb3qKIiIhaAYYbN7pvYDSuwYgLynZSQ8ZheQsiIiJqBRhu3GhUrwiolAr8Wh4lNWQel7cgIiKiVoDhxo0CfDS4OSYIp6zRUkPWCXkLIiIiagUYbtzs1m5hSBW2Yansk/IWQ0RE1Aow3LjZTe0DcVGESi/yL8pbDBEReYURI0Zg3rx5cpfRbDHcuFmfdgHIVIRIL4qzgAqTvAUREZFs7rnnHowePbrGdd9//z0UCgWOHDnS5M9Zu3YtAgMDm/w+LRXDjZsZtGoEtYlAqdBKDQWX5C2IiIhkM2PGDOzYsQMXL1bvyV+zZg0GDhyIvn37ylCZd2G48YDOYf64LNpILzg0RUTUat19990IDQ3F2rVrndqLioqwYcMGzJgxA1evXsWkSZMQFRUFg8GAPn364OOPP3ZpHWlpaRg7diz8/PxgNBpx//33IzMz07H+8OHDuO222+Dv7w+j0YgBAwbgl19+AQBcuHAB99xzD4KCguDr64tevXph69atLq2vqdRyF9AadAr1xeVTbdAZV4B89twQEbmFEEB5iTyfrTEACsUNN1Or1ZgyZQrWrl2LZ599FgrbPhs2bIDFYsGkSZNQVFSEAQMG4Omnn4bRaMSWLVvw4IMPonPnzhg0aFCTS7VarY5gs3v3blRUVGDOnDlISkrCrl27AACTJ09G//798dZbb0GlUuHQoUPQaDQAgDlz5sBsNuO7776Dr68vjh8/Dj8/vybX5UoMNx7QKdQPOQiQXpTkyFsMEZG3Ki8B/t5Wns/+62VA61uvTf/0pz9h6dKl2L17N0aMGAFAGpK69957ERAQgICAADz55JOO7efOnYuvv/4an3zyiUvCTXJyMn799VecO3cO0dHSpUo++OAD9OrVC/v27cPNN9+MtLQ0PPXUU+jRowcAoGvXro7909LScO+996JPnz4AgE6dOjW5JlfjsJQHRAf5IE/YUm1JrrzFEBGRrHr06IHBgwdj9erVAIAzZ87g+++/x4wZMwAAFosFL730Evr06YPg4GD4+fnh66+/Rlpamks+/8SJE4iOjnYEGwCIjY1FYGAgTpyQrsc2f/58PPTQQ0hMTMQrr7yCs2fPOrZ97LHH8Le//Q1DhgzBokWLXDIB2tXYc+MBEQF6/CD8AQCi5Cpu3HFJREQNpjFIPShyfXYDzJgxA3PnzsWKFSuwZs0adO7cGbfeeisAYOnSpfjXv/6F5cuXo0+fPvD19cW8efNgNpvdUXmNFi9ejD/84Q/YsmULvvrqKyxatAjr1q3D+PHj8dBDD2HUqFHYsmULtm/fjiVLluD111/H3LlzPVbfjbDnxgPCjXpcgxRuygs5LEVE5BYKhTQ0JMdSj/k2Vd1///1QKpX46KOP8MEHH+BPf/qTY/7Njz/+iLFjx+KPf/wj4uLi0KlTJ5w6dcplh6lnz55IT09Henq6o+348ePIy8tDbGyso61bt274y1/+gu3bt2PChAlYs2aNY110dDQefvhhbNq0CU888QRWrVrlsvpcgT03HqDXqGDWBgICqCjKhlbugoiISFZ+fn5ISkrCggULUFBQgGnTpjnWde3aFRs3bsSePXsQFBSEZcuWITMz0yl41IfFYsGhQ4ec2nQ6HRITE9GnTx9MnjwZy5cvR0VFBWbPno1bb70VAwcORGlpKZ566ilMnDgRHTt2xMWLF7Fv3z7ce++9AIB58+ZhzJgx6NatG65du4Zvv/0WPXv2bOohcSmGGw9RGNoAxYAo5pwbIiKShqbee+893HnnnWjbtnIi9HPPPYfffvsNo0aNgsFgwKxZszBu3Djk5+c36P2LiorQv39/p7bOnTvjzJkz+PzzzzF37lwMHz4cSqUSo0ePxhtvvAEAUKlUuHr1KqZMmYLMzEyEhIRgwoQJeOGFFwBIoWnOnDm4ePEijEYjRo8ejX/+859NPBqupRBCCLmL8KSCggIEBAQgPz8fRqPRY5/73Nvr8Lcrf0aZNhj6v57z2OcSEXmjsrIynDt3Dh07doRer5e7HHKRun6uDfn7zTk3HqLxlS7ipy3Pl67FQERERG7BcOMhGr9AAIBSWIDyUnmLISIi8mIMNx7i5xcAq7DNpjcVylsMERGRF2O48ZBAXy2KYBs/NBfJWwwREZEXY7jxkECDFkXwkV6YCuQthojIS7Syc2K8nqt+ngw3HhLoo0GRsIcbDksRETWF/SaOJSUy3SiT3MJ+FWaVStWk9+F1bjwkyKnnhuGGiKgpVCoVAgMDkZWVBQAwGAyOK/xSy2S1WpGdnQ2DwQC1umnxhOHGQwINGpxjzw0RkctEREQAgCPgUMunVCrRvn37JgdVhhsP8derHT03ltJ8NK3DjYiIFAoFIiMjERYWhvLycrnLIRfQarVQKps+Y4bhxkN8dWrHnBtzSYF9gIqIiJpIpVI1eY4GeRdOKPYQjUqJEqUBAFBe0rD7gxAREVH9Mdx4ULlKCjeWUp4KTkRE5C4MNx5kUdvm3Jh56iIREZG7MNx4kLCFG6uJ4YaIiMhdZA83K1asQExMDPR6PeLj47F37946t8/Ly8OcOXMQGRkJnU6Hbt26YevWrR6qtonU0rCUKGe4ISIichdZz5Zav3495s+fj5UrVyI+Ph7Lly/HqFGjkJqairCwsGrbm81m3H777QgLC8PGjRsRFRWFCxcuIDAw0PPFN4ZWCje8KzgREZH7yBpuli1bhpkzZ2L69OkAgJUrV2LLli1YvXo1nnnmmWrbr169Grm5udizZ4/j0tsxMTGeLLlJlLZwo2DPDRERkdvINixlNpuxf/9+JCYmVhajVCIxMREpKSk17vPFF18gISEBc+bMQXh4OHr37o2///3vsFgsniq7SZRaac6NsqJM5kqIiIi8l2w9Nzk5ObBYLAgPD3dqDw8Px8mTJ2vc57fffsM333yDyZMnY+vWrThz5gxmz56N8vJyLFq0qMZ9TCYTTCaT43VBgXynYav0vgAApYXDUkRERO4i+4TihrBarQgLC8M777yDAQMGICkpCc8++yxWrlxZ6z5LlixBQECAY4mOjvZgxc40OincqCzsuSEiInIX2cJNSEgIVCoVMjMzndozMzMdN0O7XmRkJLp16+Z0me2ePXsiIyPDcZv06y1YsAD5+fmOJT093XVfooFUOmnOjcbKcENEROQusoUbrVaLAQMGIDk52dFmtVqRnJyMhISEGvcZMmQIzpw5A6vV6mg7deoUIiMjodVqa9xHp9PBaDQ6LXJR2XpuGG6IiIjcR9Zhqfnz52PVqlV4//33ceLECTzyyCMoLi52nD01ZcoULFiwwLH9I488gtzcXDz++OM4deoUtmzZgr///e+YM2eOXF+hQdT2cCPKAWvLmARNRETU0sh6KnhSUhKys7OxcOFCZGRkoF+/fti2bZtjknFaWprTrc+jo6Px9ddf4y9/+Qv69u2LqKgoPP7443j66afl+goNotEbKl+UlwI6P/mKISIi8lIKIYSQuwhPKigoQEBAAPLz8z0+RPXVkUsYsylWevHUWcA3xKOfT0RE1FI15O93izpbqqXTazUoFba5QbyQHxERkVsw3HiQXqNCGezhhte6ISIicgeGGw/Sa5QoBXtuiIiI3InhxoP0GhVKhU56wZ4bIiIit2C48SAfp2Ep9twQERG5A8ONB+k1KpTC1nNjZrghIiJyB4YbD9JrlCgTGgBAhZnDUkRERO7AcONBeo0KJtuwVLmJ4YaIiMgdGG48SKdWwgz23BAREbkTw40HKRQKlCuknpsKM2+eSURE5A4MNx5mUUrhxsJwQ0RE5BYMNx5mdYQbDksRERG5A8ONh1lU0qnglnL23BAREbkDw42HWW3hRnBYioiIyC0YbjzMqpKGpawVDDdERETuwHDjYUKll55wWIqIiMgtGG48zD4sBYtZ3kKIiIi8FMONhwl7uOGwFBERkVsw3HiaWppzo7CYZC6EiIjIOzHceJi950bJcENEROQWDDceplBLE4oZboiIiNyD4cbDFBqGGyIiIndiuPE0W8+NysqzpYiIiNyB4cbDHMNSDDdERERuwXDjYUqtveeGw1JERETuwHDjYUqNdLaUmj03REREbsFw42FK24RitWC4ISIicgeGGw9Ta30AAFphBoSQuRoiIiLvw3DjYUpbuAHA+0sRERG5AcONh6mrhhveX4qIiMjlGG48TG2bUAwAqGDPDRERkasx3HiYTqtCmdBIL9hzQ0RE5HIMNx6mUylhhj3c8Fo3RERErsZw42FatRImsOeGiIjIXRhuPEynVlUJN+y5ISIicjWGGw/TqpUwcc4NERGR2zDceJg0LKWVXjDcEBERuRzDjYfpqs654UX8iIiIXI7hxsOqTigW5ey5ISIicjWGGw/TqpUwCzUAoMJcKnM1RERE3ofhxsN0VebcMNwQERG5XrMINytWrEBMTAz0ej3i4+Oxd+/eWrddu3YtFAqF06LX6z1YbdNoVZXDUhYzh6WIiIhcTfZws379esyfPx+LFi3CgQMHEBcXh1GjRiErK6vWfYxGI65cueJYLly44MGKm0ahUKBcIfXcWNhzQ0RE5HKyh5tly5Zh5syZmD59OmJjY7Fy5UoYDAasXr261n0UCgUiIiIcS3h4uAcrbjp7uLFyQjEREZHLyRpuzGYz9u/fj8TEREebUqlEYmIiUlJSat2vqKgIHTp0QHR0NMaOHYtjx455olyXsSjt4YZXKCYiInI1WcNNTk4OLBZLtZ6X8PBwZGRk1LhP9+7dsXr1anz++ef43//+B6vVisGDB+PixYs1bm8ymVBQUOC0yK3CHm44LEVERORysg9LNVRCQgKmTJmCfv364dZbb8WmTZsQGhqKt99+u8btlyxZgoCAAMcSHR3t4Yqrsyh1AABRwXBDRETkarKGm5CQEKhUKmRmZjq1Z2ZmIiIiol7vodFo0L9/f5w5c6bG9QsWLEB+fr5jSU9Pb3LdTWW19dwIDksRERG5nKzhRqvVYsCAAUhOTna0Wa1WJCcnIyEhoV7vYbFY8OuvvyIyMrLG9TqdDkaj0WmRm0Vl77nhhGIiIiJXU8tdwPz58zF16lQMHDgQgwYNwvLly1FcXIzp06cDAKZMmYKoqCgsWbIEAPDiiy/illtuQZcuXZCXl4elS5fiwoULeOihh+T8Gg1itQ1LKSrYc0NERORqsoebpKQkZGdnY+HChcjIyEC/fv2wbds2xyTjtLQ0KJWVHUzXrl3DzJkzkZGRgaCgIAwYMAB79uxBbGysXF+hwaxq20UH2XNDRETkcgohhJC7CE8qKChAQEAA8vPzZRui+s8b/8Dsq39HVkg8wh7dLksNRERELUlD/n63uLOlvIFQ24el2HNDRETkagw3crANSyktnHNDRETkagw3crD13DDcEBERuR7DjQwU9p4bq1nmSoiIiLwPw40MFBofAICKPTdEREQux3AjA4VG6rlRseeGiIjI5RhuZKC0hRu1lWdLERERuRrDjQzs4UYjzEDruswQERGR2zHcyECl1Ve+sHBoioiIyJUYbmSg1PpUvuCF/IiIiFyK4UYGGo0eVqGQXvDmmURERC7FcCMDrUYFEzTSC/bcEBERuRTDjQy0amVluClnuCEiInIlhhsZ6KqGG/bcEBERuRTDjQy0aiVMwh5uOOeGiIjIlRhuZKBTKWGCVnrBnhsiIiKXYriRgU6jRBnYc0NEROQODDcy0KpUVXpuSuUthoiIyMsw3MiAc26IiIjch+FGBjxbioiIyH0YbmSgZbghIiJyG4YbGVQNN1ZexI+IiMilGG5koFMrUSakCcUWM8MNERGRKzHcyKBqz43FXCJzNURERN6F4UYG2ioX8bOy54aIiMilGG5koFAoUKG0hRtOKCYiInIphhuZWBTsuSEiInIHhhuZWGw9N4I9N0RERC7FcCOTCpUeACB4KjgREZFLMdzIxGrruUE57y1FRETkSgw3MrGqdNIT3luKiIjIpRhuZCJsw1K8/QIREZFrMdzIxKqWem4UFvbcEBERuRLDjVxUDDdERETuwHAjE6GWhqUUnHNDRETkUgw3crENSyktnHNDRETkSgw3ctEYAABqhhsiIiKXYriRibCFGxXDDRERkUsx3MhF4wMAUAszYLXIXAwREZH3YLiRiULrW/mivES+QoiIiLwMw41MVBp95QvegoGIiMhlmkW4WbFiBWJiYqDX6xEfH4+9e/fWa79169ZBoVBg3Lhx7i3QDbQaFUqE7RYM7LkhIiJyGdnDzfr16zF//nwsWrQIBw4cQFxcHEaNGoWsrKw69zt//jyefPJJDBs2zEOVupZOrUQpbDfPNDPcEBERuYrs4WbZsmWYOXMmpk+fjtjYWKxcuRIGgwGrV6+udR+LxYLJkyfjhRdeQKdOnTxYreto1UqUwt5zw2EpIiIiV5E13JjNZuzfvx+JiYmONqVSicTERKSkpNS634svvoiwsDDMmDHDE2W6hValRCmHpYiIiFxOLeeH5+TkwGKxIDw83Kk9PDwcJ0+erHGfH374Ae+99x4OHTpUr88wmUwwmSpvcVBQUNDoel1Jp1FVDkux54aIiMhlZB+WaojCwkI8+OCDWLVqFUJCQuq1z5IlSxAQEOBYoqOj3Vxl/WhVVYeliuUthoiIyIvI2nMTEhIClUqFzMxMp/bMzExERERU2/7s2bM4f/487rnnHkeb1WoFAKjVaqSmpqJz585O+yxYsADz5893vC4oKGgWAUerrjosxZ4bIiIiV5E13Gi1WgwYMADJycmO07mtViuSk5Px6KOPVtu+R48e+PXXX53annvuORQWFuJf//pXjaFFp9NBp9O5pf6mcDpbinNuiIiIXEbWcAMA8+fPx9SpUzFw4EAMGjQIy5cvR3FxMaZPnw4AmDJlCqKiorBkyRLo9Xr07t3baf/AwEAAqNbe3GnVSuTah6V4KjgREZHLNCrcpKenQ6FQoF27dgCAvXv34qOPPkJsbCxmzZrVoPdKSkpCdnY2Fi5ciIyMDPTr1w/btm1zTDJOS0uDUtmipgbVC4eliIiI3EMhhBAN3WnYsGGYNWsWHnzwQWRkZKB79+7o1asXTp8+jblz52LhwoXuqNUlCgoKEBAQgPz8fBiNRtnq2H/hGg6uegQPqb8ChswDbn9BtlqIiIiau4b8/W5Ul8jRo0cxaNAgAMAnn3yC3r17Y8+ePfjwww+xdu3axrxlq6PjRfyIiIjcolHhpry83DFJd+fOnfj9738PQJrwe+XKFddV58X0mqrDUjwVnIiIyFUaFW569eqFlStX4vvvv8eOHTswevRoAMDly5fRpk0blxborfS8iB8REZFbNCrc/OMf/8Dbb7+NESNGYNKkSYiLiwMAfPHFF47hKqqbFG6knhvBs6WIiIhcplFnS40YMQI5OTkoKChAUFCQo33WrFkwGAwuK86b6TUqlAqp58ZqLoZK5nqIiIi8RaN6bkpLS2EymRzB5sKFC1i+fDlSU1MRFhbm0gK9lb7KhGKrmcNSRERErtKocDN27Fh88MEHAIC8vDzEx8fj9ddfx7hx4/DWW2+5tEBvpVYpUa7USy84LEVEROQyjQo3Bw4cwLBhwwAAGzduRHh4OC5cuIAPPvgA//73v11aoDezqHwAAIK3XyAiInKZRoWbkpIS+Pv7AwC2b9+OCRMmQKlU4pZbbsGFCxdcWqA3s2qkcKNguCEiInKZRoWbLl264LPPPkN6ejq+/vpr3HHHHQCArKwsWa/629JY1bZwU8FwQ0RE5CqNCjcLFy7Ek08+iZiYGAwaNAgJCQkApF6c/v37u7RAb2ZV+wIAVOUlQMPvgkFEREQ1aNSp4BMnTsTQoUNx5coVxzVuAGDkyJEYP368y4rzdkLrBwBQCAtQUQbYhqmIiIio8RoVbgAgIiICERERuHjxIgCgXbt2vIBfQ2l8K5+bihhuiIiIXKBRw1JWqxUvvvgiAgIC0KFDB3To0AGBgYF46aWXYLVaXV2j19Jq1Si231/KXChvMURERF6iUT03zz77LN577z288sorGDJkCADghx9+wOLFi1FWVoaXX37ZpUV6Kx+NCsXwgS9MUs8NERERNVmjws3777+Pd99913E3cADo27cvoqKiMHv2bIabetJrVCgUPghT5AFmhhsiIiJXaNSwVG5uLnr06FGtvUePHsjNzW1yUa2F1HNju0qxicNSRERErtCocBMXF4c333yzWvubb76Jvn37Nrmo1kKvUaJY2CYRM9wQERG5RKOGpV599VXcdddd2Llzp+MaNykpKUhPT8fWrVtdWqA302tUKLL33HBYioiIyCUa1XNz66234tSpUxg/fjzy8vKQl5eHCRMm4NixY/jvf//r6hq9lt5pWIrhhoiIyBUafZ2btm3bVps4fPjwYbz33nt45513mlxYa6DXqCqHpdhzQ0RE5BKN6rkh19BrlCgE59wQERG5EsONjHw0KhQLni1FRETkSgw3MtLbLuIHgMNSRERELtKgOTcTJkyoc31eXl5Taml19Bpl5dlSnFBMRETkEg0KNwEBATdcP2XKlCYV1JpwQjEREZHrNSjcrFmzxl11tErSdW44oZiIiMiVOOdGRnqNCkWCF/EjIiJyJYYbGflUnVDMOTdEREQuwXAjI5+qt1/gsBQREZFLMNzIyKBTocg+obiiFLCUy1sQERGRF2C4kZFBq0IBfCsbyvLlK4aIiMhLMNzISK9WQSiUKLD33pTmyVoPERGRN2C4kZFSqYBBU6X3pixP1nqIiIi8AcONzAw6NfKFLdyw54aIiKjJGG5k5qtVVYYb9twQERE1GcONzAxaNfLtw1Kl1+QthoiIyAsw3MjMV8eeGyIiIldiuJGZc89Nnqy1EBEReQOGG5k59dww3BARETUZw43MDFo1TwUnIiJyoWYRblasWIGYmBjo9XrEx8dj7969tW67adMmDBw4EIGBgfD19UW/fv3w3//+14PVupbT2VLsuSEiImoy2cPN+vXrMX/+fCxatAgHDhxAXFwcRo0ahaysrBq3Dw4OxrPPPouUlBQcOXIE06dPx/Tp0/H11197uHLXMOiqzLlhzw0REVGTyR5uli1bhpkzZ2L69OmIjY3FypUrYTAYsHr16hq3HzFiBMaPH4+ePXuic+fOePzxx9G3b1/88MMPHq7cNdhzQ0RE5Fqyhhuz2Yz9+/cjMTHR0aZUKpGYmIiUlJQb7i+EQHJyMlJTUzF8+HB3luo2TmdLseeGiIioydRyfnhOTg4sFgvCw8Od2sPDw3Hy5Mla98vPz0dUVBRMJhNUKhX+85//4Pbbb69xW5PJBJPJ5HhdUFDgmuJdxOlsKXMRYCkHVBp5iyIiImrBZB+Wagx/f38cOnQI+/btw8svv4z58+dj165dNW67ZMkSBAQEOJbo6GjPFnsDPlo18uEHKxRSA69STERE1CSyhpuQkBCoVCpkZmY6tWdmZiIiIqLW/ZRKJbp06YJ+/frhiSeewMSJE7FkyZIat12wYAHy8/MdS3p6uku/Q1P5alWwQokChVFqKM6WtyAiIqIWTtZwo9VqMWDAACQnJzvarFYrkpOTkZCQUO/3sVqtTkNPVel0OhiNRqelOTFopZHBa4oAqYHhhoiIqElknXMDAPPnz8fUqVMxcOBADBo0CMuXL0dxcTGmT58OAJgyZQqioqIcPTNLlizBwIED0blzZ5hMJmzduhX//e9/8dZbb8n5NRrNXy/9CK4KIzoCQHGOrPUQERG1dLKHm6SkJGRnZ2PhwoXIyMhAv379sG3bNsck47S0NCiVlR1MxcXFmD17Ni5evAgfHx/06NED//vf/5CUlCTXV2gSe7jJsvhL/WjsuSEiImoShRBCyF2EJxUUFCAgIAD5+fnNYogqt9iMm17agUXq9zFd/TUw7Alg5EK5yyIiImpWGvL3u0WeLeVNqg5LAWDPDRERURMx3MhMo1LCR6PCVdjDDefcEBERNQXDTTPgr1ez54aIiMhFGG6aAX+9GjmCp4ITERG5AsNNM+Cv13BYioiIyEUYbpoBp2EpcxFgLpG3ICIiohaM4aYZMOo1KIIPKpQ6qaEos+4diIiIqFYMN82AdDq4AkXaUKmh8Iqs9RAREbVkDDfNgP1aN/kaW7gpuCxjNURERC0bw00z4K/XAAByVSFSQ8ElGashIiJq2RhumgGjrecmW9FGaijgsBQREVFjMdw0A/aemwwRLDWw54aIiKjRGG6agQAfKdxcsgRJDZxzQ0RE1GgMN81AkK8Ubs6ZA6UGhhsiIqJGY7hpBgINWgDAmTJ/qaEoA7BUyFgRERFRy8Vw0wwE28LNeZMfhEIFCCsv5EdERNRIDDfNgNFHA4UCsEIJq39bqTE/Xd6iiIiIWiiGm2ZApVQ4JhWb/NtLjbnnZKyIiIio5WK4aSbsQ1NFPu2khmvn5SuGiIioBWO4aSYCDVLPTZ4+SmpguCEiImoUhptmIsjWc5OliZQarnFYioiIqDEYbpqJIF8p3FxRREgN7LkhIiJqFIabZiLINiyVjjCpoSgTMJfIWBEREVHLxHDTTNgv5HfF5APoA6RG9t4QERE1GMNNMxFsG5a6VmIGgmKkRs67ISIiajCGm2bCPix1raQcaNNFasw5LWNFRERELRPDTTPRxk8HAMgpMgGhPaTG7FQZKyIiImqZGG6aiTB/KdxkFZggQrpJjdknZayIiIioZWK4aSZCbeGmtNyCkoCuUmN2KiCEjFURERG1PAw3zYRBq4afTg0AyFC3BZQaoLwYyL8oc2VEREQtC8NNM2IfmsousVZOKua8GyIiogZhuGlG7ENTWYUmILS71Mh5N0RERA3CcNOMhBn1AICsgjIgrKfUmHlMxoqIiIhaHoabZsQxLFVoAiLjpMYrh2WsiIiIqOVhuGlGnIal7OEm+yRQXipjVURERC0Lw00z4rjWTWEZ4B8J+IYBwsKhKSIiogZguGlGwvztc25MgEJR2Xtz+aCMVREREbUsDDfNSGSgFG4u55VCCAG07Set4LwbIiKiemO4aUaiAn0AAMVmC/JLy6tMKj4kX1FEREQtDMNNM6LXqBBiu4HmxWulQNubpBWZxwFTkYyVERERtRwMN81MVJDUe3PxWikQEAUY20mTii/tl7kyIiKilqFZhJsVK1YgJiYGer0e8fHx2Lt3b63brlq1CsOGDUNQUBCCgoKQmJhY5/YtTTvb0NSlPNvp3+3jpcf0n2WqiIiIqGWRPdysX78e8+fPx6JFi3DgwAHExcVh1KhRyMrKqnH7Xbt2YdKkSfj222+RkpKC6Oho3HHHHbh06ZKHK3ePdo6emxKpIfoW6THtJ5kqIiIiallkDzfLli3DzJkzMX36dMTGxmLlypUwGAxYvXp1jdt/+OGHmD17Nvr164cePXrg3XffhdVqRXJysocrdw/7sNSla9f13FzcB1gtMlVFRETUcsgabsxmM/bv34/ExERHm1KpRGJiIlJSUur1HiUlJSgvL0dwcLC7yvQo+xlTF+3hJqwXoPUDTAVA1gkZKyMiImoZZA03OTk5sFgsCA8Pd2oPDw9HRkZGvd7j6aefRtu2bZ0CUlUmkwkFBQVOS3PWLsgAAEjPLZGudaNSA+0GSivT6hf4iIiIWjPZh6Wa4pVXXsG6deuwefNm6PX6GrdZsmQJAgICHEt0dLSHq2yYDm0MUCiAQlMFcorMUmPH4dLj2W/lK4yIiKiFkDXchISEQKVSITMz06k9MzMTERERde772muv4ZVXXsH27dvRt2/fWrdbsGAB8vPzHUt6erpLancXvUblGJr6Ldt2bZvOv5Mez30HWMplqoyIiKhlkDXcaLVaDBgwwGkysH1ycEJCQq37vfrqq3jppZewbds2DBw4sM7P0Ol0MBqNTktz1ynUDwDwW06x1BARB/gEA+ZCXu+GiIjoBmQflpo/fz5WrVqF999/HydOnMAjjzyC4uJiTJ8+HQAwZcoULFiwwLH9P/7xDzz//PNYvXo1YmJikJGRgYyMDBQVec8VfDuF+AKo0nOjVAKdb5Oen/1GpqqIiIhaBtnDTVJSEl577TUsXLgQ/fr1w6FDh7Bt2zbHJOO0tDRcuXLFsf1bb70Fs9mMiRMnIjIy0rG89tprcn0Fl+scZuu5yS6u0mgbmjrjHae8ExERuYta7gIA4NFHH8Wjjz5a47pdu3Y5vT5//rz7C5JZZ1vPzbmcGsLNpf1AYQbgX/ecJCIiotZK9p4bqs4+5yYttwTlFqvUaGwLRA0EIIAT/0++4oiIiJo5hptmKNyog59OjQqrcO69iR0rPR7/XJ7CiIiIWgCGm2ZIoVCgR4Q/AODElSoXHYz9vfR44UegOEeGyoiIiJo/hptmKratdMr68ctVwk1QDBAZBwgre2+IiIhqwXDTTMVG2sLNletuF9F7ovR4+GMPV0RERNQyNIuzpai6qj03QggoFAppRd8kYOdi6S7h2aeA0G7yFUlERK2X1QLkXwRyfwOunQNyz9menwfCYoF7V8lWGsNNM9Ut3B9KBXC12IysQhPCjbZ7Z/mHA11vB05tAw5/BCQulrVOIiLyYuVlQN6FKsGlSojJSwOstdwSSFg9W+d1GG6aKb1Ghc6hfjidVYSjl/Irww0A9JsshZtDHwO3PQuoNPIVSkRELVtZgS20/Obc+5J7Dii4BEDUvq9KK80HDeoIBHcCgjtKz9t09lDxNWO4acbiogNxOqsIB9PyMLJneOWKbqMBv3CgKEOaWNxnonxFEhFR81ZhlkJK/kUgP70yuNgDTcnVuvfX+gPBMVJ4uT7EGNsCSpUnvkWDMNw0YwM6BGHj/ovYf+Ga8wq1Fhg4A9j1d+DnlQw3REStmalICi156UB+mu3xYmVb4RXU2fsCAIaQytDiCDG254Y2gH3eZwvBcNOMDegQBAA4lJ6HCosValWVk9sGTge+WypNLL64H2g3QKYqiYjIbcpLpVvuFF6xLRlAwWWp9yXvghRiSq/d8G2g0gEB7YDAaCCwvXMvTFAMoDe6+5t4FMNNM9Yl1A/+ejUKyypwMqMQvaMCKlf6hUk9Noc/Br5/HZj0kXyFEhFRw1kqpOkF+ZekXpb8i87DR/mXgNLc+r2XPgAIaC+Fl4DoyiBjb/MNbXG9L03BcNOMKZUK9G8fhO9OZWP/hWvO4QYAhs4HjqwHUrcAlw8BbfvJUSYREdWmvFSa13L1LJB7Frh6Rprvkpcm9cAIy43fQ60H/CNtS4Q0zyWwPRDYoTLMeFnPS1Mx3DRzA2zh5pcL1zB1cIzzytBu0kX9fv0E2P0PYBIv7EdE5HEVZmmI6OoZ5xBz9Teg4GLd+yrVUlgJiAaMUVKPS0BU5WtjW8AnqFX1urgCw00zd0unYADAnjM5sFoFlMrrfsGHPwUc3QikbgXSfgLa3yJDlURErUBRFpB1XLqA6tUzlSEmL63u67roA4DgzkCbLtIp0sGdgaAOUoDxC2uWZxu1dAw3zVz/9kEwaFW4WmzGiYwC9Gp73dBUaDeg/x+BAx8A2xYADyUDSt5Vg4io0YpzgKwTQPZJack6CWSfqPuUaY0v0KaTFGCCO1eGmDZdAEMwe148jOGmmdOqlYjvGIxvU7Pxw+mc6uEGAH73PHB0M3D5gDQHp98kzxdKRNTS1BhiTgIlObXsoJDOLgrtAYRUCTFtukjXHmOAaTYYblqAoV1DpXBzJgd/vrWGqz76hQHDn5DuObX9OaDrHYBvG4/XSUTULBXn2MKLPcikSs9rDTGQJuuG9gDCegChPYHQ7tKi9fVc3dRoDDctwLCuIQCAvedyUVZugV5Tw/jsLbOBI59I48FfPQVMXO3hKomIZFZ8VRo+Yohp9RhuWoCuYX6IMOqRUVCGlN+u4rbuYdU3UuuAsSuAdxOBo58CsWOlhYjI2ziFmNTKXpk6Q0x7KbyE9ZDCTGgPhhgvxnDTAigUCiTGhuF/P6Vh+7GMmsMNAETdBAydJ13U74vHgMh+0ox8IqKWyB5iqs6HyT4JFGfXvg9DDIHhpsUY1SsC//spDTuOZ+Jv4wRU158SbnfrM8Bvu4BL+4EN04DpXwEafc3bEhE1B8VXbcHlRMNDTGh3IKynbZJvN0Dn57m6qdliuGkhbunUBka9GjlFZhxIu4abY4Jr3lCtBSauAd4eLp099dkjwL3v8fRwIpJfo0OMrQeGIYbqieGmhdColBjZMxybD17CliNXag83gDQUdf8HwP/uBY5tkq54ecdLniuWiFq3klzbfJgTlZN6GxxiugMh3RliqFEYblqQe+IisfngJfy/w5fx7F09oVHV0RvT6VZg7JvA5j8De/4N6IzArU95rlgi8n6NCTEB7Z3nw4T1YIghl2O4aUGGdQ1FiJ8WOUVmfH86G7/rEV73DnEPAIUZwM5FwLd/Aywm4LZneaEpIqo/S4V036Sc07b7JZ0Gcs4AOakMMdRsMdy0IBqVEvfEtcWaH8/j0wOXbhxuAOnsKYUS2PE88N1S6T9Gd74GqDRur5eIWgghpAvdXbUFmJwqj9fOAdaK2vd1hJjulWcpMcSQzBhuWph7b2qHNT+ex47jmcgtNiPYV3vjnYY8Bqj1wFf/B+xfC+T+Btz3vnS/EyJqPUpygdxz0n8D7Is90JTl176f2ke6xUBIF9vNH7sCIbZF5++5+onqieGmhenV1ojeUUYcvVSAdfvSMHtEl/rtGD9LmrD36Qzg3HfAqtuks6jaDXRvwUTkOfYemKrhpepSllfHzgogMLoyuLSxBZmQroB/W55xSS2KQggh5C7CkwoKChAQEID8/HwYjUa5y2mUjfsv4skNhxEZoMf3/3cb1HVNLL5e5jHg4weAvDRAoQJGPAMM/QuHqYhaigoTkH9RmgeTly49Xj1rCzDnAHNh3fv7R0o3fAzuKC32npjgTrwmFjVrDfn7zXDTApWVWzDklW9wtdiMN//QH3f3bduwNyjNA7Y8ARzdKL0O6wXc8y8g+maX10pEDWSpAAouSf8Dkp8uBZj8NCm4XD0LFGXc4A0U0uUfgjtKgcWxdAaCYgCtwRPfgsjlGG7q4A3hBgCW7TiFfyefRs9II7bMHQplbVcsro0QwK8bgK+eBkpzASiA/n8EbvsrYGxgWCKi+qswAwUXpd6X/Eu2XpjzwLULUi9M/iVAWOp+D41BGmYOiJYegzvaemM6SQGGPTDkhRhu6uAt4SavxIyh//gWRaYKrPzjTRjdO7Jxb1R8VTqT6tCH0mu1Hoh/GBjyOCccEzVGealtuCjNFlbsz9Ol54UZAG7wn12V1hZcoisDTFAM0KYzEBgj/dvkJR2olWG4qYO3hBsAeH17Kt745gx6RPhj62PDGt57U1X6XmDHQiAtRXqtMQD9HwQSZkv/USUiwGoBijKl3pUC+3JZerT3whRevvH7qPVSaAmIAoztpKuKB3awPbYH/CI4gZfoOgw3dfCmcJNfUo6h//gGhaYKvHZfHCYOaNe0NxQCOPU18O3LQMYRqU2hBLrfCQyYBnT+HaBUNbluombJUg4UZdnCykXb42UpsNgDTGHGjYeMAEDrJ4WVwPa2JbpKT0x7wDeEPS9EDcRwUwdvCjcAsHL3Wbzy1UmE+Onw7ZO3wl/vgrOehJDuLL7n38DZbyrbjVHSVY973AW0vYn/caaWobwUKLwCFGZKk3GdHm1LYQZQchU3HC4CpLMMjW1tS1TlY0CU9BjUkcNGRG7AcFMHbws3pgoLRi//HudyijFzWEc8e1esaz8g8zhw4APgyDqg9Fplu39boPsYoMedQMxw6W7kRJ5itUoT4QuvSMGkMAMozpJ6XhxLptRW18XprqdUS7/b9vBiDyzGttLwkbEt4BfGHkwiGTDc1MHbwg0AfHsyC9PX7oNSAWx8ZDBuah/k+g8pLwNStwDHPwdO7wTKiyvXaf2BrolAt9FAh8FSNzxRQ5WXSbcHKc6WelHsz4uzpQvTFedUvi7KrPuWANdT+wD+4dJcllofIwCfYM51IWqmGG7q4I3hBgDmrTuIzw5dRscQX2x5bCgMWjdefLq8TLrKceoWIPUr6Q9NVcZ2QPtbgOhBQNQAILw3T01tTcpLpWsplVytXMrypLayfNtie16aJ/XAFF+98cXnauIbWiWghEu9Kr5h0qNfWGWbPpDDREQtHMNNHbw13OSXlGPU8u+QUVCGSYOisWRCX898sNUKXD4AnNwCnNsNXDlc/f+olRrpZnphsVWWntKFxvgHp/kRAigvAcoKAFOB9GgPJ6XXanh+zfl1RVnjP1upkQKLb0gtj6GAIUTqZfEL45W1iVoRhps6eGu4AYAfTufgwdU/QwjglQl98MAgGYaHzMXApf1A2k/AxV+k5yU5NW+r9a+8BHxQjO2skg6VFyfjlVQbxmqVwoipADAVAeYiwFRoe7z+daEtvBRWBhhTfmV7fc4IqotCKQ3x+IZIjz5BgE8goA+QelH0AdLiEyitM4RI2+oDGHiJqEYtKtysWLECS5cuRUZGBuLi4vDGG29g0KBBNW577NgxLFy4EPv378eFCxfwz3/+E/PmzWvQ53lzuAGAN785jde2n4JWpcTHs27BgA5umH/TEEJIFzDLPApkHZcmKGedkO5EfKM5ExpfwLdN5R8+Q0gNr0MAQxvpzsQaA6Dxab5/HK1WwGKSejYqTNLwTYVJ6iUpL7U92p6bi21tpdL8Jnubucj2WPV5SWVgqc/ZPvWlUAI6I6A3SoHEHkSqPbcHlyrPtf6cu0JELtWQv9+y3hV8/fr1mD9/PlauXIn4+HgsX74co0aNQmpqKsLCwqptX1JSgk6dOuG+++7DX/7yFxkqbv5mj+iCXy/l4+tjmXjo/X3Y8HACuoT5y1eQQiFdmCyog3QKuV2FGcg9K90v59q5Kld0tV3V1VQg/VHPK5ba6v+BgNZXCjpag3SxNJUWUOsqn6s00lkxSpX0B1yhlPZzhCJFZe1CSL0YVovt0Wp7rHBus1ZUbmctt4WWssogU1EmBRtPUOkAnZ90rRWdv+3Rr8qjv/RoDy6OxwBpe3ub1rf5BkUiojrI2nMTHx+Pm2++GW+++SYAwGq1Ijo6GnPnzsUzzzxT574xMTGYN28ee25qUGyqwB9W/YTDF/MRGaDHxkcGIyrQR+6yGqasQBrOKr5qe7SdMVNy1faY4/y6olTuihtGoZTO4FFrpR4qjY+0aO3PDZU9UfagpvGxBRN/abuqi8bXNtRjlIIcEZGXaRE9N2azGfv378eCBQscbUqlEomJiUhJSZGrLK/gq1NjzfRBmLhyD37LLsYD76Tgwxm3oH2bFjSHRW/rTQjuVL/trRZpSMc+ZFNeIg3XWExSL5G956TCLPWsWG29L8Jq652x2t5ISK+rDu8oVJW9PI4eH5Vz74/S9lqhAlRqW3DRV/YYafTOrzkRlojIbWQLNzk5ObBYLAgPD3dqDw8Px8mTJ132OSaTCSZT5XBAQUGBy967OQv21eK/M+Lxh1U/4cLVEkxcuQf/eyge3cJlHKJyJ6VK6tHQeen3IyKievP6GX9LlixBQECAY4mOjpa7JI+JCvTBhj8noHu4P7IKTZj41h58dypb7rKIiIjcSrZwExISApVKhcxM5wvAZWZmIiIiwmWfs2DBAuTn5zuW9PR0l713SxBm1GP9n6WzpgrKKjBtzV6s+u43tLIrABARUSsiW7jRarUYMGAAkpOTHW1WqxXJyclISEhw2efodDoYjUanpbUJNGjx0cx43DegHawCeHnrCfxp7T7kFHno7B0iIiIPknVYav78+Vi1ahXef/99nDhxAo888giKi4sxffp0AMCUKVOcJhybzWYcOnQIhw4dgtlsxqVLl3Do0CGcOXNGrq/QYujUKrw6sS9eGtsLWrUS36ZmY/Ty7/D1sQy5SyMiInIp2S/i9+abbzou4tevXz/8+9//Rnx8PABgxIgRiImJwdq1awEA58+fR8eOHau9x6233opdu3bV6/Naw6ngN5KaUYjHPj6I1EzpXj6JPcOx+PexaBfUgs6mIiKiVqVFXaHY0xhuJGXlFrzxzWm8891vKLcI+GhUeGhYR8wa3gn+ep6mTEREzQvDTR0YbpydzizEs5uPYu/5XADSKeSzR3TGH+Lbu/fO4kRERA3AcFMHhpvqhBD4+lgmXv36JH7LLgYABBk0mDo4BlMTYhDkq5W5QiIiau0YburAcFO7CosVG/ZfxFu7ziIttwQA4KNR4fdxbTEpvj3i2gVAwXsNERGRDBhu6sBwc2MVFiu+OpqBlbvP4tjlyis6x0Ya8cCgaNzZJxIhfrx/EREReQ7DTR0YbupPCIF9569h3d40fPnrFZgrpPsvKRXA4M4huLtvJEb1iuCwFRERuR3DTR0Ybhonr8SMTQcu4bNDl3DkYr6jXakA+rcPwohuoRjRPQy92hqhVHLoioiIXIvhpg4MN0134WoxvjxyBV8euYITV5xvRBrip8XwbqEY3DkEN8cEoX2wgfN0iIioyRhu6sBw41oXr5Vg96ls7ErNxp4zOSg2W5zWh/nrcHNMMAbGBGFgh2B0j/CHVu3192slIiIXY7ipA8ON+5grrPjlQi6+O5WDfedzceRiHsotzr9eGpUC3SP80ScqAL3aBqB3VAB6RPhDr1HJVDUREbUEDDd1YLjxnLJyC45czMe+87n45XwuDqTlIb+0vNp2SgXQoY0vuoT5oUuYH7qG+aFrmD86h/nyQoJERASA4aZODDfyEULg4rVSHL2Uj6OX83H0UgGOXsrH1WJzrftEBfogJsSAdoEGtAvyQbtgH7QLkp6H+euh4uRlIqJWgeGmDgw3zYsQAlmFJpzJKsKZrCKczirE6cwinM0uQk5R7aEHkIa42gb6SKEn0IBoW/CJDNAjzKhHmL8Ovjr2/BAReYOG/P3mf/lJVgqFAuFGPcKNegzpEuK0LrfYjDNZRUjPLcHFa6W4eM32mFeCy3llKLcIXLhaggtXSwBcrfH9fbUqhBn1CPXTIdSoQ5i/DmH+UvAJM+oQ7KtFkEGLYF8t5/0QEXkJ9txQi1RhsSKz0ISLuSVIrxJ80nNLkFFQhqwCE0rLLTd+oyr0GiWCDVoE2sJOoEFje9Qi2KBBkO25v14No14Do14Nf70Geo2Sp7sTEbkZe27I66lVSkQF+iAq0AfxtWxTZKpAVkEZsgpNyC40IavQhKzCMmQXmJBdZEJWgQm5JWbklZhRbhEoK7ficn4ZLueXNawWpQL+tqAjPVY+N17X5qdTw1engq9WDV+dGgatCr4623ONihdAJCJyAYYb8lp+OjX8Qv3QKdSvzu2EECgyVSCvpBy5xWZcK7EtxeU1PC9HYVk5CkrLUWSqgFUAFVaBayXluFZS/UywhvLRqOCrU8FgCz++WhUMtuDjo1VBr1HBR6OCj1YJH4302qBVO732sW3reG177sPwREStBMMNtXoKhcLW06JBdLCh3vsJIVBstqCwrByFZRVS6CmrcDx3fpSeF5kqUGK2oNhUgWKTBcXmChTbQhIAlJZbbMNpdU+mbiydWukUfHRqJXT2R7Wysk2tgl4jPeo0Suhtj3Vto1UpoVXbFpW0bdXXahUv3khEnsFwQ9RICoVC6h3SqREZ0Pj3EULAVGFFsT342AJPscmCEnMFikxS4CkzWxzhp9RsQVmV506P121bVm51fJapwgpThRV5aHovU0MpFXAEHa1a5Qg/GpWiSru0zikcVQ1NVV7r1EpoVEqoVQpoVNL7SI+Vz9VKJbRq5+dqpRIatRIapW17tRJqpQJalZI9W0ReguGGSGYKhQJ6W09KGze8v9UqhafKYCSFKFOFFaZyK0wVUgCq+miqsKKsvHKbsgpLtW2ldRZHYDI7Hi0wW6TX1iqnK1gFUFZutYWtCjd806ZTKgCNyt7TVENYUimhVSmgriFMqe37KRXQqJ2fVwtSails2YOd/bk9rKmV0qNKqYBGqYRKqbC1S+tUKgU0Sml91W3VtjZOcKfWjuGGyMsplQppKErr+VPdKyxWR9BxhJ8qr+tcVyUkmSusMDmtk7atsAjboxXl1z0vt1hRbrGiwipQXmGF2SJQYbWivMKKcqu0/vpzRa2isnerJbOHHI1K6Qg99tBUNSipbKHKsY1TUJKCmEpVGZpUCttj1aWWNmWVsKVUSJ+pVEhtSts2NbWpVLZ19jZXfLbtvaj1YLghIrdR23o7DFq5K6mZxRZy7EHJHojKLcIRzKo+r9ymSni6PlRZrSivsK23Pa+wWqvtZ39edX/7Z1isAhVWaT+LRaDcamuzhbUK22uLteYredi3aekhzdWcgpWyMgQpqwQlpRJSQLKFJKUC0nNF5TqFfdsq66QeMzgClbRUeW3bvnJ/1PwZNayr9pm295Taa/6Mau9dj/eq+lqhkHoyFVW+i71dAelY2Nvt2yhQuY1Oo0SYv16+n7Vsn0xEJDPp//ZVLfYCjlargEUIR0hzhCJbL5XUbg9LVlu7c1Cqtq+1MmCVWwUstu2sQlpvtVY+WmppswevyjbAYqvHsdTU5tj/unVCwGqF7TtVrpPOVrQ61tWS9RwqrAI33Ihc4qb2gdg0e4hsn89wQ0TUQimVCiihgEaFFhvQXEmIGgKPFbYQVr3NYgtL1wckYQtojue297XaQp59nVVUvhYCtnbbc9s6q21b+zqrqHwtbEGusv36z3FeZ7E611bzPnXX5ti+ltosVgEBQFR5DyGcX9uPS9X3uX4frVresyMZboiIyCsoFAqoFIBKaQ96DHytFS88QURERF6F4YaIiIi8CsMNEREReRWGGyIiIvIqDDdERETkVRhuiIiIyKsw3BAREZFXYbghIiIir8JwQ0RERF6F4YaIiIi8CsMNEREReRWGGyIiIvIqDDdERETkVRhuiIiIyKuo5S7A04QQAICCggKZKyEiIqL6sv/dtv8dr0urCzeFhYUAgOjoaJkrISIiooYqLCxEQEBAndsoRH0ikBexWq24fPky/P39oVAoXPreBQUFiI6ORnp6OoxGo0vf29vwWNUfj1X98Vg1DI9X/fFY1Z+7jpUQAoWFhWjbti2Uyrpn1bS6nhulUol27dq59TOMRiN/+euJx6r+eKzqj8eqYXi86o/Hqv7ccaxu1GNjxwnFRERE5FUYboiIiMirMNy4kE6nw6JFi6DT6eQupdnjsao/Hqv647FqGB6v+uOxqr/mcKxa3YRiIiIi8m7suSEiIiKvwnBDREREXoXhhoiIiLwKww0RERF5FYYbF1mxYgViYmKg1+sRHx+PvXv3yl2Sxy1evBgKhcJp6dGjh2N9WVkZ5syZgzZt2sDPzw/33nsvMjMznd4jLS0Nd911FwwGA8LCwvDUU0+hoqLC01/F5b777jvcc889aNu2LRQKBT777DOn9UIILFy4EJGRkfDx8UFiYiJOnz7ttE1ubi4mT54Mo9GIwMBAzJgxA0VFRU7bHDlyBMOGDYNer0d0dDReffVVd381l7vRsZo2bVq137PRo0c7bdNajtWSJUtw8803w9/fH2FhYRg3bhxSU1OdtnHVv7tdu3bhpptugk6nQ5cuXbB27Vp3fz2Xqs+xGjFiRLXfrYcffthpm9ZwrN566y307dvXcRG+hIQEfPXVV471LeJ3SlCTrVu3Tmi1WrF69Wpx7NgxMXPmTBEYGCgyMzPlLs2jFi1aJHr16iWuXLniWLKzsx3rH374YREdHS2Sk5PFL7/8Im655RYxePBgx/qKigrRu3dvkZiYKA4ePCi2bt0qQkJCxIIFC+T4Oi61detW8eyzz4pNmzYJAGLz5s1O61955RUREBAgPvvsM3H48GHx+9//XnTs2FGUlpY6thk9erSIi4sTP/30k/j+++9Fly5dxKRJkxzr8/PzRXh4uJg8ebI4evSo+Pjjj4WPj494++23PfU1XeJGx2rq1Kli9OjRTr9nubm5Ttu0lmM1atQosWbNGnH06FFx6NAhceedd4r27duLoqIixzau+Hf322+/CYPBIObPny+OHz8u3njjDaFSqcS2bds8+n2boj7H6tZbbxUzZ850+t3Kz893rG8tx+qLL74QW7ZsEadOnRKpqanir3/9q9BoNOLo0aNCiJbxO8Vw4wKDBg0Sc+bMcby2WCyibdu2YsmSJTJW5XmLFi0ScXFxNa7Ly8sTGo1GbNiwwdF24sQJAUCkpKQIIaQ/akqlUmRkZDi2eeutt4TRaBQmk8mttXvS9X+wrVariIiIEEuXLnW05eXlCZ1OJz7++GMhhBDHjx8XAMS+ffsc23z11VdCoVCIS5cuCSGE+M9//iOCgoKcjtXTTz8tunfv7uZv5D61hZuxY8fWuk9rPVZCCJGVlSUAiN27dwshXPfv7v/+7/9Er169nD4rKSlJjBo1yt1fyW2uP1ZCSOHm8ccfr3Wf1nqshBAiKChIvPvuuy3md4rDUk1kNpuxf/9+JCYmOtqUSiUSExORkpIiY2XyOH36NNq2bYtOnTph8uTJSEtLAwDs378f5eXlTsepR48eaN++veM4paSkoE+fPggPD3dsM2rUKBQUFODYsWOe/SIedO7cOWRkZDgdm4CAAMTHxzsdm8DAQAwcONCxTWJiIpRKJX7++WfHNsOHD4dWq3VsM2rUKKSmpuLatWse+jaesWvXLoSFhaF79+545JFHcPXqVce61nys8vPzAQDBwcEAXPfvLiUlxek97Nu05P/GXX+s7D788EOEhISgd+/eWLBgAUpKShzrWuOxslgsWLduHYqLi5GQkNBifqda3Y0zXS0nJwcWi8XphwgA4eHhOHnypExVySM+Ph5r165F9+7dceXKFbzwwgsYNmwYjh49ioyMDGi1WgQGBjrtEx4ejoyMDABARkZGjcfRvs5b2b9bTd+96rEJCwtzWq9WqxEcHOy0TceOHau9h31dUFCQW+r3tNGjR2PChAno2LEjzp49i7/+9a8YM2YMUlJSoFKpWu2xslqtmDdvHoYMGYLevXsDgMv+3dW2TUFBAUpLS+Hj4+OOr+Q2NR0rAPjDH/6ADh06oG3btjhy5AiefvpppKamYtOmTQBa17H69ddfkZCQgLKyMvj5+WHz5s2IjY3FoUOHWsTvFMMNucyYMWMcz/v27Yv4+Hh06NABn3zySYv5B03N3wMPPOB43qdPH/Tt2xedO3fGrl27MHLkSBkrk9ecOXNw9OhR/PDDD3KX0uzVdqxmzZrleN6nTx9ERkZi5MiROHv2LDp37uzpMmXVvXt3HDp0CPn5+di4cSOmTp2K3bt3y11WvXFYqolCQkKgUqmqzRTPzMxERESETFU1D4GBgejWrRvOnDmDiIgImM1m5OXlOW1T9ThFRETUeBzt67yV/bvV9TsUERGBrKwsp/UVFRXIzc1t9cevU6dOCAkJwZkzZwC0zmP16KOP4ssvv8S3336Ldu3aOdpd9e+utm2MRmOL+x+X2o5VTeLj4wHA6XertRwrrVaLLl26YMCAAViyZAni4uLwr3/9q8X8TjHcNJFWq8WAAQOQnJzsaLNarUhOTkZCQoKMlcmvqKgIZ8+eRWRkJAYMGACNRuN0nFJTU5GWluY4TgkJCfj111+d/jDt2LEDRqMRsbGxHq/fUzp27IiIiAinY1NQUICff/7Z6djk5eVh//79jm2++eYbWK1Wx3+AExIS8N1336G8vNyxzY4dO9C9e/cWOcxSXxcvXsTVq1cRGRkJoHUdKyEEHn30UWzevBnffPNNtaE2V/27S0hIcHoP+zYt6b9xNzpWNTl06BAAOP1utYZjVROr1QqTydRyfqdcMi25lVu3bp3Q6XRi7dq14vjx42LWrFkiMDDQaaZ4a/DEE0+IXbt2iXPnzokff/xRJCYmipCQEJGVlSWEkE4fbN++vfjmm2/EL7/8IhISEkRCQoJjf/vpg3fccYc4dOiQ2LZtmwgNDfWKU8ELCwvFwYMHxcGDBwUAsWzZMnHw4EFx4cIFIYR0KnhgYKD4/PPPxZEjR8TYsWNrPBW8f//+4ueffxY//PCD6Nq1q9PpzXl5eSI8PFw8+OCD4ujRo2LdunXCYDC0uNOb6zpWhYWF4sknnxQpKSni3LlzYufOneKmm24SXbt2FWVlZY73aC3H6pFHHhEBAQFi165dTqcvl5SUOLZxxb87+2m7Tz31lDhx4oRYsWJFizu9+UbH6syZM+LFF18Uv/zyizh37pz4/PPPRadOncTw4cMd79FajtUzzzwjdu/eLc6dOyeOHDkinnnmGaFQKMT27duFEC3jd4rhxkXeeOMN0b59e6HVasWgQYPETz/9JHdJHpeUlCQiIyOFVqsVUVFRIikpSZw5c8axvrS0VMyePVsEBQUJg8Egxo8fL65cueL0HufPnxdjxowRPj4+IiQkRDzxxBOivLzc01/F5b799lsBoNoydepUIYR0Ovjzzz8vwsPDhU6nEyNHjhSpqalO73H16lUxadIk4efnJ4xGo5g+fbooLCx02ubw4cNi6NChQqfTiaioKPHKK6946iu6TF3HqqSkRNxxxx0iNDRUaDQa0aFDBzFz5sxq/yPRWo5VTccJgFizZo1jG1f9u/v2229Fv379hFarFZ06dXL6jJbgRscqLS1NDB8+XAQHBwudTie6dOkinnrqKafr3AjROo7Vn/70J9GhQweh1WpFaGioGDlypCPYCNEyfqcUQgjhmj4gIiIiIvlxzg0RERF5FYYbIiIi8ioMN0RERORVGG6IiIjIqzDcEBERkVdhuCEiIiKvwnBDREREXoXhhohaPYVCgc8++0zuMojIRRhuiEhW06ZNg0KhqLaMHj1a7tKIqIVSy10AEdHo0aOxZs0apzadTidTNUTU0rHnhohkp9PpEBER4bTY786tUCjw1ltvYcyYMfDx8UGnTp2wceNGp/1//fVX/O53v4OPjw/atGmDWbNmoaioyGmb1atXo1evXtDpdIiMjMSjjz7qtD4nJwfjx4+HwWBA165d8cUXX7j3SxOR2zDcEFGz9/zzz+Pee+/F4cOHMXnyZDzwwAM4ceIEAKC4uBijRo1CUFAQ9u3bhw0bNmDnzp1O4eWtt97CnDlzMGvWLPz666/44osv0KVLF6fPeOGFF3D//ffjyJEjuPPOOzF58mTk5uZ69HsSkYu47BacRESNMHXqVKFSqYSvr6/T8vLLLwshpLs5P/zww077xMfHi0ceeUQIIcQ777wjgoKCRFFRkWP9li1bhFKpdNwtvG3btuLZZ5+ttQYA4rnnnnO8LioqEgDEV1995bLvSUSewzk3RCS72267DW+99ZZTW3BwsON5QkKC07qEhAQcOnQIAHDixAnExcXB19fXsX7IkCGwWq1ITU2FQqHA5cuXMXLkyDpr6Nu3r+O5r68vjEYjsrKyGvuViEhGDDdEJDtfX99qw0Su4uPjU6/tNBqN02uFQgGr1eqOkojIzTjnhoiavZ9++qna6549ewIAevbsicOHD6O4uNix/scff4RSqUT37t3h7++PmJgYJCcne7RmIpIPe26ISHYmkwkZGRlObWq1GiEhIQCADRs2YODAgRg6dCg+/PBD7N27F++99x4AYPLkyVi0aBGmTp2KxYsXIzs7G3PnzsWDDz6I8PBwAMDixYvx8MMPIywsDGPGjEFhYSF+/PFHzJ0717NflIg8guGGiGS3bds2REZGOrV1794dJ0+eBCCdybRu3TrMnj0bkZGR+PjjjxEbGwsAMBgM+Prrr/H444/j5ptvhsFgwL333otly5Y53mvq1KkoKyvDP//5Tzz55JMICQnBxIkTPfcFicijFEIIIXcRRES1USgU2Lx5M8aNGyd3KUTUQnDODREREXkVhhsiIiLyKpxzQ0TNGkfOiaih2HNDREREXoXhhoiIiLwKww0RERF5FYYbIiIi8ioMN0RERORVGG6IiIjIqzDcEBERkVdhuCEiIiKvwnBDREREXuX/A3sIF9JXM2fnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# Standardize the features\n",
    "X = standardize_data(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(Layer(X_train.shape[1], 128))  # 64 inputs (8x8 images)\n",
    "network.add_layer(ReLU())\n",
    "network.add_layer(Layer(128, 2))  # 1 classes\n",
    "network.add_layer(Sigmoid())\n",
    "\n",
    "# Train the network\n",
    "network.train(X_train, y_train, epochs=3000, learning_rate=0.01, batch_size=16)\n",
    "\n",
    "network.plot_loss()\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "y_pred = network.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "* L1 and L2 regularizers\n",
    "\n",
    "* validation loss\n",
    "\n",
    "* optimization of hyperparameters (random search and grid search function?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
